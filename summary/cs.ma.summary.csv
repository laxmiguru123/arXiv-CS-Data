summary
"We present a method for solving service allocation problems in which a set of
services must be allocated to a set of agents so as to maximize a global
utility. The method is completely distributed so it can scale to any number of
services without degradation. We first formalize the service allocation problem
and then present a simple hill-climbing, a global hill-climbing, and a
bidding-protocol algorithm for solving it. We analyze the expected performance
of these algorithms as a function of various problem parameters such as the
branching factor and the number of agents. Finally, we use the sensor
allocation problem, an instance of a service allocation problem, to show the
bidding protocol at work. The simulations also show that phase transition on
the expected quality of the solution exists as the amount of communication
between agents increases."
"Objective-C is still the language of choice if users want to run their
simulation efficiently under the Swarm environment since the Swarm environment
itself was written in Objective-C. The language is a fast, object-oriented and
easy to learn. However, the language is less well known than, less expressive
than, and lacks support for many important features of C++ (eg. OpenMP for high
performance computing application). In this paper, we present a methodology and
software tools that we have developed for auto generating an Objective-C object
template (and all the necessary interfacing functions) from a given C++ model,
utilising the Classdesc's object description technology, so that the C++ model
can both be run and accessed under the Objective-C and C++ environments. We
also present a methodology for modifying an existing Swarm application to make
part of the model (eg. the heatbug's step method) run under the C++
environment."
"\EcoLab{} is an agent based modeling system for C++ programmers, strongly
influenced by the design of Swarm. This paper is just a brief outline of
\EcoLab's features, more details can be found in other published articles,
documentation and source code from the \EcoLab{} website."
"Agent Academy (AA) aims to develop a multi-agent society that can train new
agents for specific or general tasks, while constantly retraining existing
agents in a recursive mode. The system is based on collecting information both
from the environment and the behaviors of the acting agents and their related
successes/failures to generate a body of data, stored in the Agent Use
Repository, which is mined by the Data Miner module, in order to generate
useful knowledge about the application domain. Knowledge extracted by the Data
Miner is used by the Agent Training Module as to train new agents or to enhance
the behavior of agents already running. In this paper the Agent Academy
framework is introduced, and its overall architecture and functionality are
presented. Training issues as well as agent ontologies are discussed. Finally,
a scenario, which aims to provide environmental alerts to both individuals and
public authorities, is described an AA-based use case."
"Solutions to the coalition formation problem commonly assume agent
rationality and, correspondingly, utility maximization. This in turn may
prevent agents from making compromises. As shown in recent studies, compromise
may facilitate coalition formation and increase agent utilities. In this study
we leverage on those new results. We devise a novel coalition formation
mechanism that enhances compromise. Our mechanism can utilize information on
task dependencies to reduce formation complexity. Further, it works well with
both cardinal and ordinal task values. Via experiments we show that the use of
the suggested compromise-based coalition formation mechanism provides
significant savings in the computation and communication complexity of
coalition formation. Our results also show that when information on task
dependencies is used, the complexity of coalition formation is further reduced.
We demonstrate successful use of the mechanism for collaborative information
filtering, where agents combine linguistic rules to analyze documents'
contents."
"This paper reviews recent attempts at modelling inequality of wealth as an
emergent phenomenon of interacting-agent processes. We point out that recent
models of wealth condensation which draw their inspiration from molecular
dynamics have, in fact, reinvented a process introduced quite some time ago by
Angle (1986) in the sociological literature. We emphasize some problematic
aspects of simple wealth exchange models and contrast them with a monetary
model based on economic principles of market mediated exchange. The paper also
reports new results on the influence of market power on the wealth distribution
in statistical equilibrium. As it turns out, inequality increases but market
power alone is not sufficient for changing the exponential tails of simple
exchange models into Pareto tails."
"By harvesting friendship networks from e-mail contacts or instant message
""buddy lists"" Peer-to-Peer (P2P) applications can improve performance in low
trust environments such as the Internet. However, natural social networks are
not always suitable, reliable or available. We propose an algorithm (SLACER)
that allows peer nodes to create and manage their own friendship networks.
  We evaluate performance using a canonical test application, requiring
cooperation between peers for socially optimal outcomes. The Artificial Social
Networks (ASN) produced are connected, cooperative and robust - possessing many
of the disable properties of human friendship networks such as trust between
friends (directly linked peers) and short paths linking everyone via a chain of
friends.
  In addition to new application possibilities, SLACER could supply ASN to P2P
applications that currently depend on human social networks thus transforming
them into fully autonomous, self-managing systems."
"The recent commercial launch of twin-deck Very Large Transport Aircraft
(VLTA) such as the Airbus A380 has raised questions concerning the speed at
which they may be evacuated. The abnormal height of emergency exits on the
upper deck has led to speculation that emotional factors such as fear may lead
to door delay, and thus play a significant role in increasing overall
evacuation time. Full-scale evacuation tests are financially expensive and
potentially hazardous, and systematic studies of the evacuation of VLTA are
rare. Here we present a computationally cheap agent-based framework for the
general simulation of aircraft evacuation, and apply it to the particular case
of the Airbus A380. In particular, we investigate the effect of door delay, and
conclude that even a moderate average delay can lead to evacuation times that
exceed the maximum for safety certification. The model suggests practical ways
to minimise evacuation time, as well as providing a general framework for the
simulation of evacuation."
"Oftentimes, the need to build multidiscipline knowledge bases, oriented to
policy scenarios, entails the involvement of stakeholders in manifold domains,
with a juxtaposition of different languages whose semantics can hardly allow
inter-domain transfers. A useful support for planning is the building up of
durable IT based interactive platforms, where it is possible to modify initial
positions toward a semantic convergence. The present paper shows an area-based
application of these tools, for the integrated distance-management of different
forms of knowledge expressed by selected stakeholders about environmental
planning issues, in order to build alternative development scenarios.
  Keywords: Environmental planning, Scenario building, Multi-source knowledge,
IT-based"
"Systems of systems differ from traditional systems in that they are open at
the top, open at the bottom, and continually (but slowly) evolving. ""Open at
the top"" means that there is no pre-defined top level application. New
applications may be created at any time. ""Open at the bottom"" means that the
system primitives are defined functionally rather than concretely. This allows
the implementation of these primitives to be modified as technology changes.
""Continually (but slowly) evolving"" means that the system's functionality is
stable enough to be useful but is understood to be subject to modification.
Systems with these properties tend to be environments within which other
systems operate--and hence are systems of systems. It is also important to
understand the larger environment within which a system of systems exists."
"One may define a complex system as a system in which phenomena emerge as a
consequence of multiscale interaction among the system's components and their
environments. The field of Complex Systems is the study of such
systems--usually naturally occurring, either bio-logical or social. Systems
Engineering may be understood to include the conceptualising and building of
systems that consist of a large number of concurrently operating and
interacting components--usually including both human and non-human elements. It
has become increasingly apparent that the kinds of systems that systems
engineers build have many of the same multiscale characteristics as those of
naturally occurring complex systems. In other words, systems engineering is the
engineering of complex systems. This paper and the associated panel will
explore some of the connections between the fields of complex systems and
systems engineering."
"In this paper, we study the construction and transformation of
two-dimensional persistent graphs. Persistence is a generalization to directed
graphs of the undirected notion of rigidity. In the context of moving
autonomous agent formations, persistence characterizes the efficacy of a
directed structure of unilateral distances constraints seeking to preserve a
formation shape. Analogously to the powerful results about Henneberg sequences
in minimal rigidity theory, we propose different types of directed graph
operations allowing one to sequentially build any minimally persistent graph
(i.e. persistent graph with a minimal number of edges for a given number of
vertices), each intermediate graph being also minimally persistent. We also
consider the more generic problem of obtaining one minimally persistent graph
from another, which corresponds to the on-line reorganization of an autonomous
agent formation. We prove that we can obtain any minimally persistent formation
from any other one by a sequence of elementary local operations such that
minimal persistence is preserved throughout the reorganization process."
"In 2005, Railsback et al. proposed a very simple model ({\em Stupid
  Model}) that could be implemented within a couple of hours, and later
extended to demonstrate the use of common ABM platform functionality. They
provided implementations of the model in several agent based modelling
platforms, and compared the platforms for ease of implementation of this simple
model, and performance. In this paper, I implement Railsback et al's Stupid
Model in the EcoLab simulation platform, a C++ based modelling platform,
demonstrating that it is a feasible platform for these sorts of models, and
compare the performance of the implementation with Repast, Mason and Swarm
versions."
"This text provides with an introduction to the modern approach of
artificiality and simulation in social sciences. It presents the relationship
between complexity and artificiality, before introducing the field of
artificial societies which greatly benefited from the computer power fast
increase, gifting social sciences with formalization and experimentation tools
previously owned by ""hard"" sciences alone. It shows that as ""a new way of doing
social sciences"", artificial societies should undoubtedly contribute to a
renewed approach in the study of sociality and should play a significant part
in the elaboration of original theories of social phenomena."
"An edge-colored directed graph is \emph{observable} if an agent that moves
along its edges is able to determine his position in the graph after a
sufficiently long observation of the edge colors. When the agent is able to
determine his position only from time to time, the graph is said to be
\emph{partly observable}. Observability in graphs is desirable in situations
where autonomous agents are moving on a network and one wants to localize them
(or the agent wants to localize himself) with limited information. In this
paper, we completely characterize observable and partly observable graphs and
show how these concepts relate to observable discrete event systems and to
local automata. Based on these characterizations, we provide polynomial time
algorithms to decide observability, to decide partial observability, and to
compute the minimal number of observations necessary for finding the position
of an agent. In particular we prove that in the worst case this minimal number
of observations increases quadratically with the number of nodes in the graph.
  From this it follows that it may be necessary for an agent to pass through
the same node several times before he is finally able to determine his position
in the graph. We then consider the more difficult question of assigning colors
to a graph so as to make it observable and we prove that two different versions
of this problem are NP-complete."
"A population of committees of agents that learn by using neural networks is
implemented to simulate the stock market. Each committee of agents, which is
regarded as a player in a game, is optimised by continually adapting the
architecture of the agents using genetic algorithms. The committees of agents
buy and sell stocks by following this procedure: (1) obtain the current price
of stocks; (2) predict the future price of stocks; (3) and for a given price
trade until all the players are mutually satisfied. The trading of stocks is
conducted by following these rules: (1) if a player expects an increase in
price then it tries to buy the stock; (2) else if it expects a drop in the
price, it sells the stock; (3)and the order in which a player participates in
the game is random. The proposed procedure is implemented to simulate trading
of three stocks, namely, the Dow Jones, the Nasdaq and the S&P 500. A linear
relationship between the number of players and agents versus the computational
time to run the complete simulation is observed. It is also found that no
player has a monopolistic advantage."
"We develop a dynamic multi-agent model of an interbank payment system where
banks choose their level of available funds on the basis of private payoff
maximisation. The model consists of the repetition of a simultaneous move stage
game with incomplete information, incomplete monitoring, and stochastic
payoffs. Adaptation takes place with bayesian updating, with banks maximizing
immediate payoffs. We carry out numerical simulations to solve the model and
investigate two special scenarios: an operational incident and exogenous
throughput guidelines for payment submission. We find that the demand for
intraday credit is an S-shaped function of the cost ratio between intraday
credit costs and the costs associated with delaying payments. We also find that
the demand for liquidity is increased both under operational incidents and in
the presence of effective throughput guidelines."
"This paper presents a model of autonomy called autonomy with regard to an
attribute applicable to cognitive and not cognitive artificial agents. Three
criteria (global / partial, social / nonsocial, absolute / relative) are
defined and used to describe the main characteristics of this type of autonomy.
A software agent autonomous with regard to the mobility illustrates a possible
implementation of this model."
"We investigate convergence properties of a proposed distributed model
predictive control (DMPC) scheme, where agents negotiate to compute an optimal
consensus point using an incremental subgradient method based on primal
decomposition as described in Johansson et al. [2006, 2007]. The objective of
the distributed control strategy is to agree upon and achieve an optimal common
output value for a group of agents in the presence of constraints on the agent
dynamics using local predictive controllers. Stability analysis using a
receding horizon implementation of the distributed optimal consensus scheme is
performed. Conditions are given under which convergence can be obtained even if
the negotiations do not reach full consensus."
"We study a model of opinion dynamics introduced by Krause: each agent has an
opinion represented by a real number, and updates its opinion by averaging all
agent opinions that differ from its own by less than 1. We give a new proof of
convergence into clusters of agents, with all agents in the same cluster
holding the same opinion. We then introduce a particular notion of equilibrium
stability and provide lower bounds on the inter-cluster distances at a stable
equilibrium. To better understand the behavior of the system when the number of
agents is large, we also introduce and study a variant involving a continuum of
agents, obtaining partial convergence results and lower bounds on inter-cluster
distances, under some mild assumptions."
"In this paper we propose an XML-based multi-agent recommender system for
supporting online recruitment services. Our system is characterized by the
following features: {\em (i)} it handles user profiles for personalizing the
job search over the Internet; {\em (ii)} it is based on the Intelligent Agent
Technology; {\em (iii)} it uses XML for guaranteeing a light, versatile and
standard mechanism for information representation, storing and exchange. The
paper discusses the basic features of the proposed system, presents the results
of an experimental study we have carried out for evaluating its performance,
and makes a comparison between the proposed system and other e-recruitment
systems already presented in the past."
"Coordination between organizations on strategic, tactical and operation
levels leads to more effective and efficient supply chains. Supply chain
management is increasing day by day in modern enterprises. The environment is
becoming competitive and many enterprises will find it difficult to survive if
they do not make their sourcing, production and distribution more efficient.
Multi-agent supply chain management has recognized as an effective methodology
for supply chain management. Multi-agent systems (MAS) offer new methods
compared to conventional, centrally organized architectures in the scope of
supply chain management (SCM). Since necessary data are not available within
the whole supply chain, an integrated approach for production planning and
control taking into account all the partners involved is not feasible. In this
study we show how MAS architecture interacts in the integrated SCM architecture
with the help of various intelligent agents to highlight the above problem."
"The simulation of vehicular traffic as well as pedestrian dynamics meanwhile
both have a decades long history. The success of this conference series, PED
and others show that the interest in these topics is still strongly increasing.
This contribution deals with a combination of both systems: pedestrians
crossing a street. In a VISSIM simulation for varying demand jam sizes of
vehicles as well as pedestrians and the travel times of the pedestrians are
measured and compared. The study is considered as a study of VISSIM's con ict
area functionality as such, as there is no empirical data available to use for
calibration issues. Above a vehicle demand threshold the results show a
non-monotonic dependence of pedestrians' travel time on pedestrian demand."
"Recently the dynamic distance potential field (DDPF) was introduced as a
computationally efficient method to make agents in a simulation of pedestrians
move rather on the quickest path than the shortest. It can be considered to be
an estimated-remaining-journey-time-based one-shot dynamic assignment method
for pedestrian route choice on the operational level of dynamics. In this
contribution the method is shortly introduced and the effect of the method on
RiMEA's test case 11 is investigated."
"We are exploring the enhancement of models of agent behaviour with more
""human-like"" decision making strategies than are presently available. Our
motivation is to developed with a view to as the decision analysis and support
for electric taxi company under the mission of energy saving and reduction of
CO2, in particular car-pool and car-sharing management policies. In order to
achieve the object of decision analysis for user, we provide a human-agents
interactive spatial behaviour to support user making decision real time. We
adopt passenger average waiting time and electric taxi average idle time as the
performance measures and decision support fro electric taxi company. Finally,
according to the analysis result, we demonstrate that our multi-agent
simulation and GUI can help users or companies quickly make a quality and
accurate decision to reduce the decision-making cost and time."
"Information management and retrieval of all the citizen occurs in almost all
the public service functions. Electronic Government system is an emerging trend
in India through which efforts are made to strive maximum safety and security.
Various solutions for this have been proposed like Shibboleth, Public Key
Infrastructure, Smart Cards and Light Weight Directory Access Protocols. Still,
none of these guarantee 100 percent security. Efforts are being made to provide
common national identity solution to various diverse Government identity cards.
In this paper, we discuss issues related to these solutions."
"We use the notion of a promise to define local trust between agents
possessing autonomous decision-making. An agent is trustworthy if it is
expected that it will keep a promise. This definition satisfies most
commonplace meanings of trust. Reputation is then an estimation of this
expectation value that is passed on from agent to agent.
  Our definition distinguishes types of trust, for different behaviours, and
decouples the concept of agent reliability from the behaviour on which the
judgement is based. We show, however, that trust is fundamentally heuristic, as
it provides insufficient information for agents to make a rational judgement. A
global trustworthiness, or community trust can be defined by a proportional,
self-consistent voting process, as a weighted eigenvector-centrality function
of the promise theoretical graph."
"We describe the usage of the Multi-agent system in the data preprocessing
stage of an on-going project, called e-Wedding. The aim of this project is to
utilize MAS and various approaches, like Web services, Ontology, and Data
mining techniques, in e-Business that want to improve responsiveness and
efficiency of systems so as to extract customer behavior model on Wedding
Businesses. However, in this paper, we propose and implement the
multi-agent-system, based on JADE, to only cope data preprocessing stage
specified on handle with missing value techniques. JADE is quite easy to learn
and use. Moreover, it supports many agent approaches such as agent
communication, protocol, behavior and ontology. This framework has been
experimented and evaluated in the realization of a simple, but realistic. The
results, though still preliminary, are quite."
"This paper presents a reconfigurable parallel data flow architecture. This
architecture uses the concepts of multi-agent paradigm in reconfigurable
hardware systems. The utilization of this new paradigm has the potential to
greatly increase the flexibility, efficiency, expandability of data flow
systems and to provide an attractive alternative to the current set of disjoint
approaches that are currently applied to this problem domain. The ability of
methodology to implement data flow type processing with different models is
presented in this paper."
"A facial recognition system is a computer application for automatically
identifying or verifying a person from a digital image or a video frame from a
video source. One of the way is to do this is by comparing selected facial
features from the image and a facial database.It is typically used in security
systems and can be compared to other biometrics such as fingerprint or eye iris
recognition systems. In this paper we focus on 3-D facial recognition system
and biometric facial recognision system. We do critics on facial recognision
system giving effectiveness and weaknesses. This paper also introduces scope of
recognision system in India."
"Multi-agent systems where the agents are developed by parties with competing
interests, and where there is no access to an agent's internal state, are often
classified as `open'. The member agents of such systems may inadvertently fail
to, or even deliberately choose not to, conform to the system specification.
Consequently, it is necessary to specify the normative relations that may exist
between the agents, such as permission, obligation, and institutional power.
The specification of open agent systems of this sort is largely seen as a
design-time activity. Moreover, there is no support for run-time specification
modification. Due to environmental, social, or other conditions, however, it is
often required to revise the specification during the system execution. To
address this requirement, we present an infrastructure for `dynamic'
specifications, that is, specifications that may be modified at run-time by the
agents. The infrastructure consists of well-defined procedures for proposing a
modification of the `rules of the game', as well as decision-making over and
enactment of proposed modifications. We evaluate proposals for rule
modification by modelling a dynamic specification as a metric space, and by
considering the effects of accepting a proposal on system utility. Furthermore,
we constrain the enactment of proposals that do not meet the evaluation
criteria. We employ the action language C+ to formalise dynamic specifications,
and the `Causal Calculator' implementation of C+ to execute the specifications.
We illustrate our infrastructure by presenting a dynamic specification of a
resource-sharing protocol."
"This paper studies the strategic manipulation of set-valued social choice
functions according to Kelly's preference extension, which prescribes that one
set of alternatives is preferred to another if and only if all elements of the
former are preferred to all elements of the latter. It is shown that
set-monotonicity---a new variant of Maskin-monotonicity---implies
Kelly-strategyproofness in comprehensive subdomains of the linear domain.
Interestingly, there are a handful of appealing Condorcet extensions---such as
the top cycle, the minimal covering set, and the bipartisan set---that satisfy
set-monotonicity even in the unrestricted linear domain, thereby answering
questions raised independently by Barber\`a (1977) and Kelly (1977)."
"The embedding of self-organizing inter-agent processes in distributed
software applications enables the decentralized coordination system elements,
solely based on concerted, localized interactions. The separation and
encapsulation of the activities that are conceptually related to the
coordination, is a crucial concern for systematic development practices in
order to prepare the reuse and systematic integration of coordination processes
in software systems. Here, we discuss a programming model that is based on the
externalization of processes prescriptions and their embedding in Multi-Agent
Systems (MAS). One fundamental design concern for a corresponding execution
middleware is the minimal-invasive augmentation of the activities that affect
coordination. This design challenge is approached by the activation of agent
modules. Modules are converted to software elements that reason about and
modify their host agent. We discuss and formalize this extension within the
context of a generic coordination architecture and exemplify the proposed
programming model with the decentralized management of (web) service
infrastructures."
"In this paper we study the problem of tracking an object moving randomly
through a network of wireless sensors. Our objective is to devise strategies
for scheduling the sensors to optimize the tradeoff between tracking
performance and energy consumption. We cast the scheduling problem as a
Partially Observable Markov Decision Process (POMDP), where the control actions
correspond to the set of sensors to activate at each time step. Using a
bottom-up approach, we consider different sensing, motion and cost models with
increasing levels of difficulty. At the first level, the sensing regions of the
different sensors do not overlap and the target is only observed within the
sensing range of an active sensor. Then, we consider sensors with overlapping
sensing range such that the tracking error, and hence the actions of the
different sensors, are tightly coupled. Finally, we consider scenarios wherein
the target locations and sensors' observations assume values on continuous
spaces. Exact solutions are generally intractable even for the simplest models
due to the dimensionality of the information and action spaces. Hence, we
devise approximate solution techniques, and in some cases derive lower bounds
on the optimal tradeoff curves. The generated scheduling policies, albeit
suboptimal, often provide close-to-optimal energy-tracking tradeoffs."
"We provide a brief description of the Jason-DTU system, including the
methodology, the tools and the team strategy that we plan to use in the agent
contest."
"Since many of the currently available multi-agent frameworks are generally
mostly intended for research, it can be difficult to built multi-agent systems
using physical robots. In this report I describe a way to combine the
multi-agent framework Jason, an extended version of the agent-oriented
programming language AgentSpeak, with Lego robots to address this problem. By
extending parts of the Jason reasoning cycle I show how Lego robots are able to
complete tasks such as following lines on a floor and communicating to be able
to avoid obstacles with minimal amount of coding. The final implementation is a
functional extension that is able to built multi-agent systems using Lego
agents, however there are some issues that have not been addressed. If the
agents are highly dependent on percepts from their sensors, they are required
to move quite slowly, because there currently is a high delay in the reasoning
cycle, when it is combined with a robot. Overall the system is quite robust and
can be used to make simple Lego robots perform tasks of an advanced agent in a
multi-agent environment."
"Whereas classical multi-agent systems have the agent in center, there have
recently been a development towards focusing more on the organization of the
system. This allows the designer to focus on what the system goals are, without
considering how the goals should be fulfilled. This paper investigates whether
taking this approach has any clear advantages to the classical way of
implementing multi-agent systems. The investigation is done by implementing
each type of system in the same environment in order to realize what advantages
and disadvantages each approach has."
"This study addresses the matter of reflexive control of the emotional states
by means of Reflexive Game Theory (RGT). It is shown how to build a bridge
between RGT and emotions. For this purpose the Pleasure-Arousal-Dominance (PAD)
model is adopted. The major advantages of RGT are its ability to predict human
behavior and unfold the entire spectra of reflexion in the human mind. On the
other hand, PAD provides ultimate approach to model emotions. It is illustrated
that emotions are reflexive processes and, consequently, RGT fused with PAD
model is natural solution to model emotional interactions between people. The
fusion of RGT and PAD, called Emotional Reflexive Games (ERG), inherits the key
features of both components. Using ERG, we show how reflexive control can be
successfully applied to model human emotional states. Up to date, EGR is a
unique methodology capable of modeling human reflexive processes and emotional
aspects simultaneously."
"This paper proposes a Context Aware Agent based Military Sensor Network
(CAMSN) to form an improved infrastructure for multi-sensor image fusion. It
considers contexts driven by a node and sink. The contexts such as general and
critical object detection are node driven where as sensing time (such as day or
night) is sink driven. The agencies used in the scheme are categorized as node
and sink agency. Each agency employs a set of static and mobile agents to
perform dedicated tasks. Node agency performs context sensing and context
interpretation based on the sensed image and sensing time. Node agency
comprises of node manager agent, context agent and node blackboard (NBB).
Context agent gathers the context from the target and updates the NBB, Node
manager agent interprets the context and passes the context information to sink
node by using flooding mechanism. Sink agency mainly comprises of sink manager
agent, fusing agent, and sink black board. A context at the sensor node
triggers the fusion process at the sink. Based on the context, sink manager
agent triggers the fusing agent. Fusing agent roams around the network, visits
active sensor node, fuses the relevant images and sends the fused image to
sink. The fusing agent uses wavelet transform for fusion. The scheme is
simulated for testing its operation effectiveness in terms of fusion time, mean
square error, throughput, dropping rate, bandwidth requirement, node battery
usage and agent overhead."
"We study the problem of locating a particularly dangerous node, the so-called
black hole in a synchronous anonymous ring network with mobile agents. A black
hole is a harmful stationary process residing in a node of the network and
destroying destroys all mobile agents visiting that node without leaving any
trace. We consider the more challenging scenario when the agents are identical
and initially scattered within the network. Moreover, we solve the problem with
agents that have constant-sized memory and carry a constant number of identical
tokens, which can be placed at nodes of the network. In contrast, the only
known solutions for the case of scattered agents searching for a black hole,
use stronger models where the agents have non-constant memory, can write
messages in whiteboards located at nodes or are allowed to mark both the edges
and nodes of the network with tokens. This paper solves the problem for ring
networks containing a single black hole. We are interested in the minimum
resources (number of agents and tokens) necessary for locating all links
incident to the black hole. We present deterministic algorithms for ring
topologies and provide matching lower and upper bounds for the number of agents
and the number of tokens required for deterministic solutions to the black hole
search problem, in oriented or unoriented rings, using movable or unmovable
tokens."
"The simulation of evacuation of pedestrians from skyscraper is a situation
where the symmetry analysis method and equations of fluid dynamics finds to be
very useful. When applied, they strongly reduce the number of free parameters
used in simulations and in such a way speed up the calculations and make them
easier to manage by the programmer and what is even more important, they can
give a fresh insight into a problem of evacuation and help with incorporation
of ""Ambient Intelligent Devices"" into future real buildings. We have analyzed
various, simplified, cases of evacuation from skyscraper by employing improved
""Social Force Model"". For each of them we obtained the average force acting on
the pedestrian as a function of the evacuation time. The results clearly show
that both methods mentioned above, can be successfully implemented in the
simulation process and return with satisfactory conclusions."
"Nowadays, a globalization of national markets requires developing flexible
and demand-driven production systems. Agent-based technology, being
distributed, flexible and autonomous is expected to provide a short-time
reaction to disturbances and sudden changes of environment and allows
satisfying the mentioned requirements. The distributed constraint satisfaction
approach underlying the suggested method is described by a modified Petri
network providing both the conceptual notions and main details of
implementation."
"The success of online auctions has given buyers access to greater product
diversity with potentially lower prices. It has provided sellers with access to
large numbers of potential buyers and reduced transaction costs by enabling
auctions to take place without regard to time or place. However it is difficult
to spend more time period with system and closely monitor the auction until
auction participant wins the bid or closing of the auction. Determining which
items to bid on or what may be the recommended bid and when to bid it are
difficult questions to answer for online auction participants. The multi agent
auction advisor system JADE and TRACE, which is connected with decision support
system, gives the recommended bid to buyers for online auctions. The auction
advisor system relies on intelligent agents both for the retrieval of relevant
auction data and for the processing of that data to enable meaningful
recommendations, statistical reports and market prediction report to be made to
auction participants."
"This study presents a georeferenced agent-based model to analyze the climate
change impacts on the ski industry in Andorra and the effect of snowmaking as
future adaptation strategy. The present study is the first attempt to analyze
the ski industry in the Pyrenees region and will contribute to a better
understanding of the vulnerability of Andorran ski resorts and the suitability
of snowmaking as potential adaptation strategy to climate change. The resulting
model can be used as a planning support tool to help local stakeholders
understand the vulnerability and potential impacts of climate change. This
model can be used in the decision-making process of designing and developing
appropriate sustainable adaptation strategies to future climate variability."
"We examine properties of a model of resource allocation in which several
agents exchange resources in order to optimise their individual holdings. The
schemes discussed relate to well-known negotiation protocols proposed in
earlier work and we consider a number of alternative notions of rationality
covering both quantitative measures, e.g. cooperative and individual
rationality and more qualitative forms, e.g. Pigou-Dalton transfers. While it
is known that imposing particular rationality and structural restrictions may
result in some reallocations of the resource set becoming unrealisable, in this
paper we address the issue of the number of restricted rational deals that may
be required to implement a particular reallocation when it is possible to do
so. We construct examples showing that this number may be exponential (in the
number of resources m), even when all of the agent utility functions are
monotonic. We further show that k agents may achieve in a single deal a
reallocation requiring exponentially many rational deals if at most k-1 agents
can participate, this same reallocation being unrealisable by any sequences of
rational deals in which at most k-2 agents are involved."
"Many current large-scale multiagent team implementations can be characterized
as following the belief-desire-intention (BDI) paradigm, with explicit
representation of team plans. Despite their promise, current BDI team
approaches lack tools for quantitative performance analysis under uncertainty.
Distributed partially observable Markov decision problems (POMDPs) are well
suited for such analysis, but the complexity of finding optimal policies in
such models is highly intractable. The key contribution of this article is a
hybrid BDI-POMDP approach, where BDI team plans are exploited to improve POMDP
tractability and POMDP analysis improves BDI team plan performance. Concretely,
we focus on role allocation, a fundamental problem in BDI teams: which agents
to allocate to the different roles in the team. The article provides three key
contributions. First, we describe a role allocation technique that takes into
account future uncertainties in the domain; prior work in multiagent role
allocation has failed to address such uncertainties. To that end, we introduce
RMTDP (Role-based Markov Team Decision Problem), a new distributed POMDP model
for analysis of role allocations. Our technique gains in tractability by
significantly curtailing RMTDP policy search; in particular, BDI team plans
provide incomplete RMTDP policies, and the RMTDP policy search fills the gaps
in such incomplete policies by searching for the best role allocation. Our
second key contribution is a novel decomposition technique to further improve
RMTDP policy search efficiency. Even though limited to searching role
allocations, there are still combinatorially many role allocations, and
evaluating each in RMTDP to identify the best is extremely difficult. Our
decomposition technique exploits the structure in the BDI team plans to
significantly prune the search space of role allocations. Our third key
contribution is a significantly faster policy evaluation algorithm suited for
our BDI-POMDP hybrid approach. Finally, we also present experimental results
from two domains: mission rehearsal simulation and RoboCupRescue disaster
rescue simulation."
"Effective coordination of agents actions in partially-observable domains is a
major challenge of multi-agent systems research. To address this, many
researchers have developed techniques that allow the agents to make decisions
based on estimates of the states and actions of other agents that are typically
learnt using some form of machine learning algorithm. Nevertheless, many of
these approaches fail to provide an actual means by which the necessary
information is made available so that the estimates can be learnt. To this end,
we argue that cooperative communication of state information between agents is
one such mechanism. However, in a dynamically changing environment, the
accuracy and timeliness of this communicated information determine the fidelity
of the learned estimates and the usefulness of the actions taken based on
these. Given this, we propose a novel information-sharing protocol,
post-task-completion sharing, for the distribution of state information. We
then show, through a formal analysis, the improvement in the quality of
estimates produced using our strategy over the widely used protocol of sharing
information between nearest neighbours. Moreover, communication heuristics
designed around our information-sharing principle are subjected to empirical
evaluation along with other benchmark strategies (including Littmans Q-routing
and Stones TPOT-RL) in a simulated call-routing application. These studies,
conducted across a range of environmental settings, show that, compared to the
different benchmarks used, our strategy generates an improvement of up to 60%
in the call connection rate; of more than 1000% in the ability to connect
long-distance calls; and incurs as low as 0.25 of the message overhead."
"A multiagent system may be thought of as an artificial society of autonomous
software agents and we can apply concepts borrowed from welfare economics and
social choice theory to assess the social welfare of such an agent society. In
this paper, we study an abstract negotiation framework where agents can agree
on multilateral deals to exchange bundles of indivisible resources. We then
analyse how these deals affect social welfare for different instances of the
basic framework and different interpretations of the concept of social welfare
itself. In particular, we show how certain classes of deals are both sufficient
and necessary to guarantee that a socially optimal allocation of resources will
be reached eventually."
"We provide a brief description of the Python-DTU system, including the
overall design, the tools and the algorithms that we plan to use in the agent
contest."
"In this paper, multi-agent systems minimizing a sum of objective functions,
where each component is only known to a particular node, is considered for
continuous-time dynamics with time-varying interconnection topologies. Assuming
that each node can observe a convex solution set of its optimization component,
and the intersection of all such sets is nonempty, the considered optimization
problem is converted to an intersection computation problem. By a simple
distributed control rule, the considered multi-agent system with
continuous-time dynamics achieves not only a consensus, but also an optimal
agreement within the optimal solution set of the overall optimization
objective. Directed and bidirectional communications are studied, respectively,
and connectivity conditions are given to ensure a global optimal consensus. In
this way, the corresponding intersection computation problem is solved by the
proposed decentralized continuous-time algorithm. We establish several
important properties of the distance functions with respect to the global
optimal solution set and a class of invariant sets with the help of convex and
non-smooth analysis."
"In this paper, we investigate distributed multi-agent tracking of a convex
set specified by multiple moving leaders with unmeasurable velocities. Various
jointly-connected interaction topologies of the follower agents with
uncertainties are considered in the study of set tracking. Based on the
connectivity of the time-varying multi-agent system, necessary and sufficient
conditions are obtained for set input-to-state stability and set integral
input-to-state stability for a nonlinear neighbor-based coordination rule with
switching directed topologies. Conditions for asymptotic set tracking are also
proposed with respect to the polytope spanned by the leaders."
"This paper investigates the role persistent arcs play for a social network to
reach a global belief agreement under discrete-time or continuous-time
evolution. Each (directed) arc in the underlying communication graph is assumed
to be associated with a time-dependent weight function which describes the
strength of the information flow from one node to another. An arc is said to be
persistent if its weight function has infinite $\mathscr{L}_1$ or $\ell_1$ norm
for continuous-time or discrete-time belief evolutions, respectively. The graph
that consists of all persistent arcs is called the persistent graph of the
underlying network. Three necessary and sufficient conditions on agreement or
$\epsilon$-agreement are established, by which we prove that the persistent
graph fully determines the convergence to a common opinion in social networks.
It is shown how the convergence rates explicitly depend on the diameter of the
persistent graph. The results adds to the understanding of the fundamentals
behind global agreements, as it is only persistent arcs that contribute to the
convergence."
"We consider the problem of information fusion from multiple sensors of
different types with the objective of improving the confidence of inference
tasks, such as object classification, performed from the data collected by the
sensors. We propose a novel technique based on distributed belief aggregation
using a multi-agent prediction market to solve this information fusion problem.
To monitor the improvement in the confidence of the object classification as
well as to dis-incentivize agents from misreporting information, we have
introduced a market maker that rewards the agents instantaneously as well as at
the end of the inference task, based on the quality of the submitted reports.
We have implemented the market maker's reward calculation in the form of a
scoring rule and have shown analytically that it incentivizes truthful
revelation or accurate reporting by each agent. We have experimentally verified
our technique for multi-sensor information fusion for an automated landmine
detection scenario. Our experimental results show that, for identical data
distributions and settings, using our information aggregation technique
increases the accuracy of object classification favorably as compared to two
other commonly used techniques for information fusion for landmine detection."
"In this paper we study the strengths and limitations of collaborative teams
of simple agents. In particular, we discuss the efficient use of ""ant robots""
for covering a connected region on the $Z^{2}$ grid, whose area is unknown in
advance and which expands stochastically. Specifically, we discuss the problem
where an initial connected region of $S_0$ boundary tiles expand outward with
probability $p$ at every time step. On this grid region a group of $k$ limited
and simple agents operate, in order to clean the unmapped and dynamically
expanding region. A preliminary version of this problem was discussed in
[1],[2] involving a deterministic expansion of a region in the grid.In this
work we extend the model and examine cases where the spread of the region is
done stochastically, where each tile has some probability $p$ to expand, at
every time step. For this extended model we obtain an analytic probabilistic
lower bounds for the minimal number of agents and minimal time required to
enable a collaborative coverage of the expanding region, regardless of the
algorithm used and the robots' hardware and software specifications. In
addition, we present an impossibility result, for a variety of regions that
would be impossible to completely clean, regardless of the algorithm used.
Finally, we validate the analytic bounds using extensive empirical computer
simulation results."
"Since the time when concept of e-maintenance was introduced, most of the
works insisted on the relevance of the underlying Information and Communication
Technologies infrastructure. Through a review of current e-maintenance
conceptual approaches and realizations, this paper aims to reconsider the
predominance of ICT within e-maintenance projects and literature. The review
brings to light the importance of intelligence as a fundamental dimension of
e-maintenance that is to be led in a holistic predefined manner rather than
isolated efforts within ICT driven approaches. As a contribution towards an
intelligence based e-maintenance conceptual framework, a proposal is outlined
in this paper to model e-maintenance system as an intelligent system. The
proposed frame is based on CogAff architecture for intelligent agents. Within
the proposed frame, more importance was reserved to the environment that the
system is to be continuously aware of: Plant Environment, Internal and External
Enterprise Environment and Human Environment. In addition to the abilities
required for internal coherent behavior of the system, requirements for
maintenance activities support are also mapped within the same frame according
to corresponding levels of management. A case study was detailed in this paper
sustaining the applicability of the proposal in relation to the classification
of existing e-maintenance platforms. However, more work is needed to enhance
exhaustiveness of the frame to serve as a comparison tool of existing
e-maintenance systems. At the conceptual level, our future work is to use the
proposed frame in an e-maintenance project."
"We present a novel, game theoretic representation of a multi-agent prediction
market using a partially observable stochastic game with information (POSGI).
We then describe a correlated equilibrium (CE)-based solution strategy for this
game which enables each agent to dynamically calculate the prices at which it
should trade a security in the prediction market. We have extended our results
to risk averse traders and shown that a Pareto optimal correlated equilibrium
strategy can be used to incentively truthful revelations from risk averse
agents. Simulation results comparing our CE strategy with five other strategies
commonly used in similar markets, with both risk neutral and risk averse
agents, show that the CE strategy improves price predictions and provides
higher utilities to the agents as compared to other existing strategies."
"This paper deals with the specification and the implementation of multi-level
agent-based models, using a formal model, IRM4MLS (an Influence Reaction Model
for Multi-Level Simulation), based on the Influence Reaction principle.
Proposed examples illustrate forms of top-down control in (multi-level)
multi-agent based-simulations."
"This work deals with coupling Clinical Decision Support System (CDSS) with
Computerized Prescriber Order Entry (CPOE) and their dynamic plugging in the
medical Workflow Management System (WfMS). First, in this paper we argue some
existing CDSS representative of the state of the art in order to emphasize
their inability to deal with coupling with CPOE and medical WfMS. The
multi-agent technology is at the basis of our proposition since (i) it provides
natural abstractions to deal with distribution, heterogeneity and autonomy
which are inherent to the previous systems (CDSS, CPOE and medical WfMS), and
(ii) it introduces powerful concepts such as organizations, goals and roles
useful to describe in details the coordination of the different components
involved in these systems. In this paper, we also propose a Multi-Agent System
(MAS) to support the coupling CDSS with CPOE. Finally, we show how we integrate
the proposed MAS in the medical workflow management system which is also based
on collaborating agents"
"This volume contains the proceedings of the 3rd International Workshop on
Formal Aspects of Virtual Organisations (FAVO 2011). The workshop was held in
Sao Paulo, Brazil on October 18th, 2011 as a satellite event to the 12th IFIP
Working Conference on Virtual Enterprises (PRO-VE'11). The FAVO workshop aims
to provide a forum for researchers interested in the application of formal
techniques in the design and analysis of Virtual Organisations."
"This paper showcases an improved architecture for a complete negotiation
system that permits multi party multi issue negotiation. The concepts of
multithreading and concurrency has been utilized to perform parallel execution.
The negotiation history has been implemented that stores all the records of the
messages exchanged for every successful and rejected negotiation process and
implements the concepts of artificial intelligence in determination of proper
weights for a valid negotiation mechanism. The issues are arranged in a
hierarchical pattern so as to simplify the representation and priorities are
assigned to each issue, which amounts to its relative importance. There is
refinement of utilities by consideration of the non-functional attributes. So
as to avoid overloading of the system, a maximum number of parties are allowed
to participate in the entire mechanism and if more parties arrive, they're put
into a waiting queue in accordance to certain criteria such as the first come
first serve or the relative priorities. This helps in fault tolerance. It also
supports the formation of alliances among the various parties while carrying
out a negotiation."
"We consider a smart grid with an independent system operator (ISO), and
distributed aggregators who have energy storage and purchase energy from the
ISO to serve its customers. All the entities in the system are foresighted:
each aggregator seeks to minimize its own long-term payments for energy
purchase and operational costs of energy storage by deciding how much energy to
buy from the ISO, and the ISO seeks to minimize the long-term total cost of the
system (e.g. energy generation costs and the aggregators' costs) by dispatching
the energy production among the generators. The decision making of the entities
is complicated for two reasons. First, the information is decentralized: the
ISO does not know the aggregators' states (i.e. their energy consumption
requests from customers and the amount of energy in their storage), and each
aggregator does not know the other aggregators' states or the ISO's state (i.e.
the energy generation costs and the status of the transmission lines). Second,
the coupling among the aggregators is unknown to them. Specifically, each
aggregator's energy purchase affects the price, and hence the payments of the
other aggregators. However, none of them knows how its decision influences the
price because the price is determined by the ISO based on its state. We propose
a design framework in which the ISO provides each aggregator with a conjectured
future price, and each aggregator distributively minimizes its own long-term
cost based on its conjectured price as well as its local information. The
proposed framework can achieve the social optimum despite being decentralized
and involving complex coupling among the various entities."
"Promises, impositions, proposals, predictions, and suggestions are
categorized as voluntary co-operational methods. The class of voluntary
co-operational methods is included in the class of so-called directionals.
Directionals are mechanisms supporting the mutual coordination of autonomous
agents.
  Notations are provided capable of expressing residual fragments of
directionals. An extensive example, involving promises about the suitability of
programs for tasks imposed on the promisee is presented. The example
illustrates the dynamics of promises and more specifically the corresponding
mechanism of trust updating and credibility updating. Trust levels and
credibility levels then determine the way certain promises and impositions are
handled.
  The ubiquity of promises and impositions is further demonstrated with two
extensive examples involving human behaviour: an artificial example about an
agent planning a purchase, and a realistic example describing technology
mediated interaction concerning the solution of pay station failure related
problems arising for an agent intending to leave the parking area."
"Leading agent-based trust models address two important needs. First, they
show how an agent may estimate the trustworthiness of another agent based on
prior interactions. Second, they show how agents may share their knowledge in
order to cooperatively assess the trustworthiness of others. However, in
real-life settings, information relevant to trust is usually obtained
piecemeal, not all at once. Unfortunately, the problem of maintaining trust has
drawn little attention. Existing approaches handle trust updates in a
heuristic, not a principled, manner. This paper builds on a formal model that
considers probability and certainty as two dimensions of trust. It proposes a
mechanism using which an agent can update the amount of trust it places in
other agents on an ongoing basis. This paper shows via simulation that the
proposed approach (a) provides accurate estimates of the trustworthiness of
agents that change behavior frequently; and (b) captures the dynamic behavior
of the agents. This paper includes an evaluation based on a real dataset drawn
from Amazon Marketplace, a leading e-commerce site."
"This paper focuses on some of the key intelligent techniques for conflict
resolution in Multi-Agent Decision Support Systems."
"We analyse the computational complexity of three problems in judgment
aggregation: (1) computing a collective judgment from a profile of individual
judgments (the winner determination problem); (2) deciding whether a given
agent can influence the outcome of a judgment aggregation procedure in her
favour by reporting insincere judgments (the strategic manipulation problem);
and (3) deciding whether a given judgment aggregation scenario is guaranteed to
result in a logically consistent outcome, independently from what the judgments
supplied by the individuals are (the problem of the safety of the agenda). We
provide results both for specific aggregation procedures (the quota rules, the
premise-based procedure, and a distance-based procedure) and for classes of
aggregation procedures characterised in terms of fundamental axioms."
"A flow of moving agents can be observed at different scales. Thus, in traffic
modeling, three levels are generally considered: the micro, meso and macro
levels, representing respectively the interactions between vehicles, groups of
vehicles sharing common properties (such as a common destination or a common
localization) and flows of vehicles. Each approach is useful in a given
context: micro and meso models allow to simulate road networks with complex
topologies such as urban area, while macro models allow to develop control
strategies to prevent congestion in highways. However, to simulate large-scale
road networks, it can be interesting to integrate different representations,
e.g., micro and macro, in a single model. Existing models share the same
limitation: connections between levels are fixed a priori and cannot be changed
at runtime. Therefore, to be able to observe some emerging phenomena such as
congestion formation or to find the exact location of a jam in a large macro
section, a dynamic hybrid modeling approach is needed. In 2013 we started the
development of a multi-level agent-based simulator called JAM-FREE within the
ISART project. It allows to simulate large road networks efficiently using a
dynamic level of detail. This simulator relies on a multi-level agent-based
modeling framework called SIMILAR."
"Discrete pedestrian simulation models are viable alternatives to particle
based approaches based on a continuous spatial representation. The effects of
discretisation, however, also imply some difficulties in modelling certain
phenomena that can be observed in reality. This paper focuses on the
possibility to manage heterogeneity in the walking speed of the simulated
population of pedestrians by modifying an existing multi-agent model extending
the floor field approach. Whereas some discrete models allow pedestrians (or
cars, when applied to traffic modelling) to move more than a single cell per
time step, the present work proposes a maximum speed of one cell per step, but
we model lower speeds by having pedestrians yielding their movement in some
turns. Different classes of pedestrians are associated to different desired
walking speeds and we define a stochastic mechanism ensuring that they maintain
an average speed close to this threshold. In the paper we formally describe the
model and we show the results of its application in benchmark scenarios.
Finally, we also show how this approach can also support the definition of
slopes and stairs as elements reducing the walking speed of pedestrians
climbing them in a simulated scenario."
"A new approach of coordination of decisions in a multi site system is
proposed. It is based this approach on a multi-agent concept and on the
principle of distributed network of enterprises. For this purpose, each
enterprise is defined as autonomous and performs simultaneously at the local
and global levels. The basic component of our approach is a so-called Virtual
Enterprise Node (VEN), where the enterprise network is represented as a set of
tiers (like in a product breakdown structure). Within the network, each partner
constitutes a VEN, which is in contact with several customers and suppliers.
Exchanges between the VENs ensure the autonomy of decision, and guarantiee the
consistency of information and material flows. Only two complementary VEN
agents are necessary: one for external interactions, the Negotiator Agent (NA)
and one for the planning of internal decisions, the Planner Agent (PA). If
supply problems occur in the network, two other agents are defined: the Tier
Negotiator Agent (TNA) working at the tier level only and the Supply Chain
Mediator Agent (SCMA) working at the level of the enterprise network. These two
agents are only active when the perturbation occurs. Otherwise, the VENs
process the flow of information alone. With this new approach, managing
enterprise network becomes much more transparent and looks like managing a
simple enterprise in the network. The use of a Multi-Agent System (MAS) allows
physical distribution of the decisional system, and procures a heterarchical
organization structure with a decentralized control that guaranties the
autonomy of each entity and the flexibility of the network."
"The purpose of this paper is to propose a new approach for the supply chain
management. This approach is based on the virtual enterprise paradigm and the
used of multi-agent concept. Each entity (like enterprise) is autonomous and
must perform local and global goals in relation with its environment. The base
component of our approach is a Virtual Enterprise Node (VEN). The supply chain
is viewed as a set of tiers (corresponding to the levels of production), in
which each partner of the supply chain (VEN) is in relation with several
customers and suppliers. Each VEN belongs to one tier. The main customer gives
global objectives (quantity, cost and delay) to the supply chain. The Mediator
Agent (MA) is in charge to manage the supply chain in order to respect those
objectives as global level. Those objectives are taking over to Negotiator
Agent at the tier level (NAT). These two agents are only active if a
perturbation occurs; otherwise information flows are only exchange between
VENs. This architecture allows supply chains management which is completely
transparent seen from simple enterprise of the supply chain. The used of
Multi-Agent System (MAS) allows physical distribution of the decisional system.
Moreover, the hierarchical organizational structure with a decentralized
control guaranties, in the same time, the autonomy of each entity and the whole
flexibility."
"This paper presents some basic elements regarding the domain of the
collaborative systems, a domain of maximum actuality and also the multiagent
systems, developed as a result of a sound study on the one-agent systems."
"In this paper, we investigate the possibility to deterministically solve the
gathering problem (GP) with weak robots (anonymous, autonomous, disoriented,
deaf and dumb, and oblivious). We introduce strong multiplicity detection as
the ability for the robots to detect the exact number of robots located at a
given position. We show that with strong multiplicity detection, there exists a
deterministic self-stabilizing algorithm solving GP for n robots if, and only
if, n is odd."
"In this report we define characteristic control design elements and show how
conventional single-agent MPC implements these. We survey recent literature on
multi-agent MPC and discuss how this literature deals with decomposition,
problem assignment, and cooperation."
"This paper asks a new question: how can we control the collective behavior of
self-organized multi-agent systems? We try to answer the question by proposing
a new notion called 'Soft Control', which keeps the local rule of the existing
agents in the system. We show the feasibility of soft control by a case study.
Consider the simple but typical distributed multi-agent model proposed by
Vicsek et al. for flocking of birds: each agent moves with the same speed but
with different headings which are updated using a local rule based on the
average of its own heading and the headings of its neighbors. Most studies of
this model are about the self-organized collective behavior, such as
synchronization of headings. We want to intervene in the collective behavior
(headings) of the group by soft control. A specified method is to add a special
agent, called a 'Shill', which can be controlled by us but is treated as an
ordinary agent by other agents. We construct a control law for the shill so
that it can synchronize the whole group to an objective heading. This control
law is proved to be effective analytically and numerically. Note that soft
control is different from the approach of distributed control. It is a natural
way to intervene in the distributed systems. It may bring out many interesting
issues and challenges on the control of complex systems."
"Fatal crush conditions occur in crowds with tragic frequency. Event
organisers and architects are often criticised for failing to consider the
causes and implications of crush, but the reality is that the prediction and
mitigation of such conditions offers a significant technical challenge. Full
treatment of physical force within crowd simulations is precise but
computationally expensive; the more common method of human interpretation of
results is computationally ""cheap"" but subjective and time-consuming. In this
paper we propose an alternative method for the analysis of crowd behaviour,
which uses information theory to measure crowd disorder. We show how this
technique may be easily incorporated into an existing simulation framework, and
validate it against an historical event. Our results show that this method
offers an effective and efficient route towards automatic detection of crush."
"In this paper we study the strengths and limitations of collaborative teams
of simple agents. In particular, we discuss the efficient use of ""ant robots""
for covering a connected region on the Z^{2} grid, whose area is unknown in
advance, and which expands at a given rate, where $n$ is the initial size of
the connected region.
  We show that regardless of the algorithm used, and the robots' hardware and
software specifications, the minimal number of robots required in order for
such coverage to be possible is \Omega({\sqrt{n}}).
  In addition, we show that when the region expands at a sufficiently slow
rate, a team of \Theta(\sqrt{n}) robots could cover it in at most O(n^{2} \ln
n) time.
  This completion time can even be achieved by myopic robots, with no ability
to directly communicate with each other, and where each robot is equipped with
a memory of size O(1) bits w.r.t the size of the region (therefore, the robots
cannot maintain maps of the terrain, nor plan complete paths).
  Regarding the coverage of non-expanding regions in the grid, we improve the
current best known result of O(n^{2}) by demonstrating an algorithm that
guarantees such a coverage with completion time of O(\frac{1}{k} n^{1.5} + n)
in the worst case, and faster for shapes of perimeter length which is shorter
than O(n)."
"The paper studies the visibility maintenance problem (VMP) for a
leader-follower pair of Dubins-like vehicles with input constraints, and
proposes an original solution based on the notion of controlled invariance. The
nonlinear model describing the relative dynamics of the vehicles is interpreted
as linear uncertain system, with the leader robot acting as an external
disturbance. The VMP is then reformulated as a linear constrained regulation
problem with additive disturbances (DLCRP). Positive D-invariance conditions
for linear uncertain systems with parametric disturbance matrix are introduced
and used to solve the VMP when box bounds on the state, control input and
disturbance are considered. The proposed design procedure is shown to be easily
adaptable to more general working scenarios. Extensive simulation results are
provided to illustrate the theory and show the effectiveness of our approach"
"The evacuation of football stadium scenarios are discussed as model realizing
ordered states, described as movements of individuals according to fields of
displacements, calculated correspondingly to given scenario. The symmetry of
the evacuation space is taken into account in calculation of displacements
field - the displacements related to every point of this space are presented in
the coordinate frame in the best way adapted to given symmetry space group,
which the set of basic vectors of irreducible representation of given group is.
The speeds of individuals at every point in the presented model have the same
quantity. As the results the times of evacuation and average forces acting on
individuals during the evacuation are given. Both parameters are compared with
the same parameters got without symmetry considerations. They are calculated in
the simulation procedure. The new program (using modified Helbing model) has
been elaborated and presented in this work for realization the simulation tasks
the."
"An efficient Learning resource centre can be achieved with the help of a
network of collaborating, coordinating and communicating software agents.
Agent-oriented techniques represent an exciting new means of analysing,
designing and building complex software systems. The designing of the
interacting agents is done with the help of Gaia, extended for the multiagent
systems. Gaia is a methodology for agent-oriented analysis and design proposed
by M. Wooldridge [9]."
"We introduce a logic specifically designed to support reasoning about social
choice functions. The logic includes operators to capture strategic ability,
and operators to capture agent preferences. We establish a correspondence
between formulae in the logic and properties of social choice functions, and
show that the logic is expressively complete with respect to social choice
functions, i.e., that every social choice function can be characterised as a
formula of the logic. We prove that the logic is decidable, and give a complete
axiomatization. To demonstrate the value of the logic, we show in particular
how it can be applied to the problem of determining whether a social choice
function is strategy-proof."
"Understanding how spatial configurations of economic activity emerge is
important when formulating spatial planning and economic policy. Not only
micro-simulation and agent-based model such as UrbanSim, ILUMAS and SIMFIRMS,
but also Simon's model of hierarchical concentration have widely applied, for
this purpose. These models, however, have limitations with respect to
simulating structural changes in spatial economic systems and the impact of
proximity. The present paper proposes a model of firm development that is based
on behavioural rules such as growth, closure, spin-off and relocation. An
important aspect of the model is that locational preferences of firms are based
on agglomeration advantages, accessibility of markets and congestion, allowing
for a proper description of concentration and deconcentration tendencies. By
comparing the outcomes of the proposed model with real world data, we will
calibrate the parameters and assess how well the model predicts existing
spatial configurations and decide. The model is implemented as an agent-based
simulation model describing firm development in the Netherlands in 21
industrial sectors from 1950 to 2004."
"During last decade, multi-level agent-based modeling has received significant
and dramatically increasing interest. In this article we present a
comprehensive and structured review of literature on the subject. We present
the main theoretical contributions and application domains of this concept,
with an emphasis on social, flow, biological and biomedical models."
"This article introduces a formal model to specify, model and validate
hierarchical complex systems described at different levels of analysis. It
relies on concepts that have been developed in the multi-agent-based simulation
(MABS) literature: level, influence and reaction. One application of such model
is the specification of hierarchical complex systems, in which decisional
capacities are dynamically adapted at each level with respect to the
emergences/constraints paradigm. In the conclusion, we discuss the main
perspective of this work: the definition of a generic meta-model for holonic
multi-agent systems (HMAS)."
"We study the emergent flocking behavior in a group of Cucker-Smale flocking
agents under rooted leadership with alternating leaders. It is well known that
the network topology regulates the emergent behaviors of flocks. All existing
results on the Cucker-Smale model with leader-follower topologies assume a
fixed leader during temporal evolution process. The rooted leadership is the
most general topology taking a leadership. Motivated by collective behaviors
observed in the flocks of birds, swarming fishes and potential engineering
applications, we consider the rooted leadership with alternating leaders; that
is, at each time slice there is a leader but it can be switched among the
agents from time to time. We will provide several sufficient conditions leading
to the asymptotic flocking among the Cucker-Smale agents under rooted
leadership with alternating leaders."
"We present a new Dynamic Programming (DP) formulation of the Coalition
Structure Generation (CSG) problem based on imposing a hierarchical
organizational structure over the agents. We show the efficiency of this
formulation by deriving DyPE, a new optimal DP algorithm which significantly
outperforms current DP approaches in speed and memory usage. In the classic
case, in which all coalitions are feasible, DyPE has half the memory
requirements of other DP approaches. On graph-restricted CSG, in which
feasibility is restricted by a (synergy) graph, DyPE has either the same or
lower computational complexity depending on the underlying graph structure of
the problem. Our empirical evaluation shows that DyPE outperforms the
state-of-the-art DP approaches by several orders of magnitude in a large range
of graph structures (e.g. for certain scalefree graphs DyPE reduces the memory
requirements by $10^6$ and solves problems that previously needed hours in
minutes)."
"In this paper, a meta-model called IRM4MLS, that aims to be a generic ground
to specify and execute multi-level agent-based models is presented. It relies
on the influence/reaction principle and more specifically on IRM4S. Simulation
models for IRM4MLS are defined. The capabilities and possible extensions of the
meta-model are discussed."
"The employment of micro-simulation (agent-based) tools in the phase of design
of public and private spaces and facilities and for the definition of transport
schemes that impact on pedestrian flows, thanks to their achieved accuracy and
predictive capacity, has become a consolidated practice. These instruments
provide support to the organization of spaces, services and facilities and to
the definition of management procedures for normal and emergency situations.
The employment of these tools is effective for various but not for all the
contexts, nevertheless new features and functions are under constant
development and new products are often launched on the market. Therefore, there
is a higher necessity of a standard criteria both for the evaluation of the
kinds of function that these software provide, at use of practitioners and
end-users, and for the definition of software requirements as a reference for
the developers that aim at being competitive on this market.
  On the basis of our experience as pedestrian modellers and as researchers in
the crowd modelling area, we designed a comprehensive and detailed ready-to-use
checklist for the quantitative evaluation of Pedestrian Simulation Software
functionalities that aims at capturing all the aspects that we claim that are
useful to undertake a professional study. These functions in our opinion are
necessary to provide accurate results in the planning of new facilities or
schemes that involve pedestrian activities. With this work we propose a set of
criteria of evaluation for these products also to encourage a debate for the
definition of objective standards for pedestrian simulation software
certification."
"Multi-Agent Reinforcement Learning (MARL) is a widely used technique for
optimization in decentralised control problems. However, most applications of
MARL are in static environments, and are not suitable when agent behaviour and
environment conditions are dynamic and uncertain. Addressing uncertainty in
such environments remains a challenging problem for MARL-based systems. The
dynamic nature of the environment causes previous knowledge of how agents
interact to become outdated. Advanced knowledge of potential changes through
prediction significantly supports agents converging to near-optimal control
solutions. In this paper we propose P-MARL, a decentralised MARL algorithm
enhanced by a prediction mechanism that provides accurate information regarding
up-coming changes in the environment. This prediction is achieved by employing
an Artificial Neural Network combined with a Self-Organising Map that detects
and matches changes in the environment. The proposed algorithm is validated in
a realistic smart-grid scenario, and provides a 92% Pareto efficient solution
to an electric vehicle charging problem."
"Crisis response is a critical area of research, with encouraging progress in
the past view yeas. The aim of the research is to contribute to building future
crisis environment where software agents, robots, responders, crisis managers,
and crisis organizations interact to provide advice, protection and aid. This
paper discusses the crisis response domain requirements, and provides analysis
of five crisis response systems namely: DrillSim [2], DEFACTO [15], ALADDIN
[1], RoboCup Rescue [18], and FireGrid [3]. Analysis of systems includes
systems architecture and methodology. In addition, we identified features and
limitations of systems based on crisis response domain requirements."
"The design of multi-agent based simulations (MABS) is up to now mainly done
in laboratories and based on designers' understanding of the activities to be
simulated. Domain experts have little chance to directly validate agent
behaviors. To fill this gap, we are investigating participatory methods of
design, which allow users to participate in the design the pickup and delivery
problem (PDP) in the taxi planning problem. In this paper, we present a
participatory process for designing new socio-technical architectures to afford
the taxi dispatch for this transportation system. The proposed dispatch
architecture attempts to increase passenger satisfaction more globally, by
concurrently dispatching multiple taxis to the same number of passengers in the
same geographical region, and vis-avis human driver and dispatcher
satisfaction."
"A common assumption in modern microeconomic theory is that choice should be
rationalizable via a binary preference relation, which \citeauthor{Sen71a}
showed to be equivalent to two consistency conditions, namely $\alpha$
(contraction) and $\gamma$ (expansion). Within the context of \emph{social}
choice, however, rationalizability and similar notions of consistency have
proved to be highly problematic, as witnessed by a range of impossibility
results, among which Arrow's is the most prominent. Since choice functions
select \emph{sets} of alternatives rather than single alternatives, we propose
to rationalize choice functions by preference relations over sets
(set-rationalizability). We also introduce two consistency conditions,
$\hat\alpha$ and $\hat\gamma$, which are defined in analogy to $\alpha$ and
$\gamma$, and find that a choice function is set-rationalizable if and only if
it satisfies $\hat\alpha$. Moreover, a choice function satisfies $\hat\alpha$
and $\hat\gamma$ if and only if it is \emph{self-stable}, a new concept based
on earlier work by \citeauthor{Dutt88a}. The class of self-stable social choice
functions contains a number of appealing Condorcet extensions such as the
minimal covering set and the essential set."
"This paper gives an overview of a proposed strategy for the ""Cows and
Herders"" scenario given in the Multi-Agent Programming Contest 2009. The
strategy is to be implemented using the Jason platform, based on the
agent-oriented programming language Agent-Speak. The paper describes the
agents, their goals and the strategies they should follow. The basis for the
paper and for participating in the contest is a new course given in spring 2009
and our main objective is to show that we are able to implement complex
multi-agent systems with the knowledge gained in an introductory course on
multi-agent systems."
"In this paper we present an analysis of the complexities of large group
collaboration and its application to develop detailed requirements for
collaboration schema for Autonomous Systems (AS). These requirements flow from
our development of a framework for collaboration that provides a basis for
designing, supporting and managing complex collaborative systems that can be
applied and tested in various real world settings. We present the concepts of
""collaborative flow"" and ""working as one"" as descriptive expressions of what
good collaborative teamwork can be in such scenarios. The paper considers the
application of the framework within different scenarios and discuses the
utility of the framework in modelling and supporting collaboration in complex
organisational structures."
"The Internet has changed the way business is conducted in many ways. For
example, in the field of procurement, the possibility to directly interact with
a trading partner has given rise to new mechanisms in the supply chain
management. One such interactive dynamic procurement, which lets both buyer and
seller software agents bid by potential buyer agents instead of static
procurement by vendors. Dynamic procurement decision could provide the buying
and selling channel to buyer, to avoid occurring condition that seller could
not deliver on the contract promise. Using NYOP(Name Your Own Price) to be the
core of dynamic procurement negotiation algorithm sets up multi-agent dynamic
supply chain system, to present the DSINs(Dynamic Supply Chain Information
Networks) by JADE, and to present the dynamic supply chain logistic simulation
by eM-Plant. Finally, evaluating supply chain performance with supply chain
performance metrics (such as bullwhip, fill rate), to be the reference of
enterprise making deciding in the future."
"The aim our work is to create virtual humans as intelligent entities, which
includes approximate the maximum as possible the virtual agent animation to the
natural human behavior. In order to accomplish this task, our agent must be
capable to interact with the environment, interacting with objects and other
agents. The virtual agent needs to act as real person, so he should be capable
to extract semantic information from the geometric model of the world where he
is inserted, based on his own perception, and he realizes his own decision. The
movement of the individuals is representing by the combination of two
approaches of movement which are, the social force model and the based-rule
model. These movements are influenced by a set of socio-psychological rules to
give a more realistic result."
"To a large degree information and services for chemical e-Science have become
accessible - anytime, anywhere - but not necessarily useful. The Rule Responder
eScience middleware is about providing information consumers with rule-based
agents to transform existing information into relevant information of practical
consequences, hence providing control to the end-users to express in a
declarative rule-based way how to turn existing information into personally
relevant information and how to react or make automated decisions on top of it."
"We investigate an abstract conceptualisation of DigitalEcosystems from a
computer science perspective. We then provide a conceptual framework for the
cross pollination of ideas, concepts and understanding between different
classes of ecosystems through the universally applicable principles of Complex
Adaptive Systems (CAS) modelling. A framework to assist the cross-disciplinary
collaboration of research into Digital Ecosystems, including Digital
BusinessEcosystems (DBEs) and Digital Knowledge Ecosystems (DKEs). So, we have
defined the key steps towards a theoretical framework for Digital Ecosystems,
that is compatible with the diverse theoretical views prevalent. Therefore, a
theoretical edifice that can unify the diverse efforts within Digital
Ecosystems research."
"Despite the extensive use of the agent technology in the Supply Chain
Management field, its integration with Advanced Planning and Scheduling (APS)
tools still represents a promising field with several open research questions.
Specifically, the literature falls short in providing an integrated framework
to analyze, specify, design and implement simulation experiments covering the
whole simulation cycle. Thus, this paper proposes an agent-based strategy to
convert the 'analysis' models into 'specification' and 'design' models
combining two existing methodologies proposed in the literature. The first one
is a recent and unique approach dedicated to the 'analysis' of agent-based APS
systems. The second one is a well-established methodological framework to
'specify' and 'design' agent-based supply chain systems. The proposed
conversion strategy is original and is the first one allowing simulation
analysts to integrate the whole simulation development process in the domain of
distributed APS."
"The way of analyzing, designing and building of real-time projects has been
changed due to the rapid growth of internet, mobile technologies and
intelligent applications. Most of these applications are intelligent, tiny and
distributed components called as agent. Agent works like it takes the input
from numerous real-time sources and gives back the real-time response. In this
paper how these agents can be implemented in vehicle traffic management
especially in large cities and identifying various challenges when there is a
rapid growth of population and vehicles. In this paper our proposal gives a
solution for using autonomous or agent based technology. These autonomous or
intelligent agents have the capability to observe, act and learn from their
past experience. This system uses the knowledge flow of precedent signal or
data to identify the incoming flow of forthcoming signal. Our architecture
involves the video analysis and exploration using some Intelligence learning
algorithm to estimate and identify the flow of traffic."
"Development of agents as well as their wide usage requires good underlying
infrastructure. Literature indicates scarcity of agent development tools in
initial years of research which limited the exploitation of this beneficial
technology. However, today a wide variety of tools are available, for
developing robust infrastructure. This technical note provides a deep overview
of such tools and contrasts features provided by them."
"Autonomic computing is a computing system that can manage itself by
self-configuration, self-healing, self-optimizing and self-protection.
Researchers have been emphasizing the strong role that multi agent systems can
play progressively towards the design and implementation of complex autonomic
systems. The important of autonomic computing is to create computing systems
capable of managing themselves to a far greater extent than they do today. With
the nature of autonomy, reactivity, sociality and pro-activity, software agents
are promising to make autonomic computing system a reality. This paper mixed
multi-agent system with autonomic feature that completely hides its complexity
from users/services. Mentioned Java Application Development Framework as
platform example of this environment, could applied to web services as front
end to users. With multi agent support it also provides adaptability,
intelligence, collaboration, goal oriented interactions, flexibility, mobility
and persistence in software systems"
"We propose MITRA, a meta-model for the information flow in (computational)
trust and reputation architectures. On an abstract level, MITRA describes the
information flow as it is inherent in prominent trust and reputation models
from the literature. We use MITRA to provide a structured comparison of these
models. This makes it possible to get a clear overview of the complex research
area. Furthermore, by doing so, we identify interesting new approaches for
trust and reputation modeling that so far have not been investigated."
"In this era of ""Services"" everywhere, with the explosive growth of E-Commerce
and B2B transactions, there is a pressing need for the development of
intelligent negotiation systems which consists of feasible architecture, a
reliable framework and flexible multi agent based protocols developed in
specialized negotiation languages with complete semantics and support for
message passing between the buyers and sellers. This is possible using web
services on the internet. The key issue is negotiation and its automation. In
this paper we review the classical negotiation methods and some of the existing
architectures and frameworks. We are proposing here a new combinatory framework
and architecture, NAAS. The key feature in this framework is a component for
prediction or probabilistic behavior pattern recognition of a buyer, along with
the other classical approaches of negotiation frameworks and architectures.
Negotiation is practically very complex activity to automate without human
intervention so in the future we also intend to develop a new protocol which
will facilitate automation of all the types of negotiation strategies like
bargaining, bidding, auctions, under our NAAS framework."
"Thanks to improvements in wireless communication technologies and increasing
computing power in hand-held devices, mobile ad hoc networks are becoming an
ever-more present reality. Coordination languages are expected to become
important means in supporting this type of interaction. To this extent we argue
the interest of the Bach coordination language as a middleware that can handle
and react to context changes as well as cope with unpredictable physical
interruptions that occur in opportunistic network connections. More concretely,
our proposal is based on blackboard rules that model declaratively the actions
to be taken once the blackboard content reaches a predefined state, but also
that manage the engagement and disengagement of hosts and transient sharing of
blackboards. The idea of reactiveness has already been introduced in previous
work, but as will be appreciated by the reader, this article presents a new
perspective, more focused on a declarative setting."
"There are many well-studied swarming algorithms which are often suited to
very specific purposes. As mobile sensor networks become increasingly complex,
and are comprised of more and more agents, it makes sense to consider swarming
algorithms for movement control. We introduce a natural way to measure the
reliability of various swarming algorithms so a balance can be struck between
algorithmic complexity and sampling accuracy."
"We provide a brief description of the Python-DTU system, including the
overall design, the tools and the algorithms that we plan to use in the agent
contest."
"Consensus strategies find a variety of applications in distributed
coordination and decision making in multi-agent systems. In particular, average
consensus plays a key role in a number of applications and is closely
associated with two classes of digraphs, weight-balanced (for continuous-time
systems) and bistochastic (for discrete-time systems). A weighted digraph is
called balanced if, for each node, the sum of the weights of the edges outgoing
from that node is equal to the sum of the weights of the edges incoming to that
node. In addition, a weight-balanced digraph is bistochastic if all weights are
nonnegative and, for each node, the sum of weights of edges incoming to that
node and the sum of the weights of edges out-going from that node is unity;
this implies that the corresponding weight matrix is column and row stochastic
(i.e., doubly stochastic). We propose two distributed algorithms: one solves
the weight-balance problem and the other solves the bistochastic matrix
formation problem for a distributed system whose components (nodes) can
exchange information via interconnection links (edges) that form an arbitrary,
possibly directed, strongly connected communication topology (digraph). Both
distributed algorithms achieve their goals asymptotically and operate
iteratively by having each node adapt the (nonnegative) weights on its outgoing
edges based on the weights of its incoming links (i.e., based on purely local
information). We also provide examples to illustrate the operation,
performance, and potential advantages of the proposed algorithms."
"In this article, we propose to represent a multi-level phenomenon as a set of
interacting models. This perspective makes the levels of representation and
their relationships explicit. To deal with coherence, causality and
coordination issues between models, we rely on AA4MM, a metamodel dedicated to
such a representation. We illustrate our proposal and we show the interest of
our approach on a flocking phenomenon."
"Multi-agent systems are currently applied to solve complex problems. The
security of networks is an eloquent example of a complex and difficult problem.
A new model-concept Hybrid Sensitive Robot Metaheuristic for Intrusion
Detection is introduced in the current paper. The proposed technique could be
used with machine learning based intrusion detection techniques. The new model
uses the reaction of virtual sensitive robots to different stigmergic variables
in order to keep the tracks of the intruders when securing a sensor network."
"This paper addresses the issue of integrating agents with a variety of
external resources and services, as found in enterprise computing environments.
We propose an approach for interfacing agents and existing message routing and
mediation engines based on the endpoint concept from the enterprise integration
patterns of Hohpe and Woolf. A design for agent endpoints is presented, and an
architecture for connecting the Jason agent platform to the Apache Camel
enterprise integration framework using this type of endpoint is described. The
approach is illustrated by means of a business process use case, and a number
of Camel routes are presented. These demonstrate the benefits of interfacing
agents to external services via a specialised message routing tool that
supports enterprise integration patterns."
"Emergency evacuation plans and evacuation drills are mandatory in public
buildings in many countries. Their importance is considerable when it comes to
guarantee safety and protection during a crisis. However, sometimes
discrepancies arise between the goals of the plan and its outcomes, because
people find it hard to take them very seriously, or due to the financial and
time resources required. Serious games are a possible solution to tackle this
problem. They have been successfully applied in different areas such as health
care and education, since they can simulate an environment/task quite
accurately, making them a practical alternative to real-life simulations. This
paper presents a serious game developed using Unity3D to recreate a virtual
fire evacuation training tool. The prototype application was deployed which
allowed the validation by user testing. A sample of 30 individuals tested the
evacuating scenario, having to leave the building during a fire in the shortest
time possible. Results have shown that users effectively end up learning some
evacuation procedures from the activity, even if only to look for emergency
signs indicating the best evacuation paths. It was also evidenced that users
with higher video game experience had a significantly better performance."
"In recent years crowd modeling has become increasingly important both in the
computer games industry and in emergency simulation. This paper discusses some
aspects of what has been accomplished in this field, from social sciences to
the computer implementation of modeling and simulation. Problem overview is
described including some of the most common techniques used. Multi-Agent
Systems is stated as the preferred approach for emergency evacuation
simulations. A framework is proposed based on the work of Fangqin and Aizhu
with extensions to include some BDI aspects. Future work includes expansion of
the model's features and implementation of a prototype for validation of the
propose methodology."
"The problem of evacuating crowded closed spaces, such as discotheques, public
exhibition pavilions or concert houses, has become increasingly important and
gained attention both from practitioners and from public authorities. A
simulation implementation using NetLogo, an agent-based simulation framework
that permits the quickly creation of prototypes, is presented. Our aim is to
prove that this model developed using NetLogo, albeit simple can be expanded
and adapted for fire safety experts test various scenarios and validate the
outcome of their design. Some preliminary experiments are carried out, whose
results are presented, validated and discussed so as to illustrate their
efficiency. Finally, we draw some conclusions and point out ways in which this
work can be further extended."
"Representing knowledge with the use of ontology description languages offers
several advantages arising from knowledge reusability, possibilities of
carrying out reasoning processes and the use of existing concepts of knowledge
integration. In this work we are going to present an environment for the
integration of knowledge expressed in such a way. Guaranteeing knowledge
integration is an important element during the development of the Semantic Web.
Thanks to this, it is possible to obtain access to services which offer
knowledge contained in various distributed databases associated with
semantically described web portals. We will present the advantages of the
multi-agent approach while solving this problem. Then, we will describe an
example of its application in systems supporting company management knowledge
in the process of constructing supply-chains."
"Agent mediated e-commerce involves buying and selling on Internet through
software agents. The success of an agent mediated e-commerce system lies in the
underlying reputation management system which is used to improve the quality of
services in e-market environment. A reputation system encourages the honest
behaviour of seller agents and discourages the malicious behaviour of dishonest
seller agents in the e-market where actual traders never meet each other. This
paper evaluates various reputation systems for assigning reputation rating to
software agents acting on behalf of buyers and sellers in e-market. These
models are analysed on the basis of a number of features viz. reputation
computation and their defence mechanisms against different attacks. To address
the problems of traditional reputation systems which are relatively static in
nature, this paper identifies characteristics of a dynamic reputation framework
which ensures judicious use of information sharing for inter-agent cooperation
and also associates the reputation of an agent with the value of a transaction
so that the market approaches an equilibrium state and dishonest agents are
weeded out of the market."
"The design of punishment policies applied to specific domains linking agents
actions to material penalties is an open research issue. The proposed framework
applies principles of contract law to set penalties: expectation damages,
opportunity cost, reliance damages, and party design remedies. In order to
decide which remedy provides maximum welfare within an electronic market, a
simulation environment called DEMCA (Designing Electronic Markets for
Contractual Agents) was developed. Knowledge representation and the reasoning
capabilities of the agents are based on an extended version of temporal
defeasible logic."
"In this paper we assess the impact of path reservation as an additional
feature in our distributed real-time vehicle guidance protocol BeeJamA. Through
our microscopic simulations we show that na\""{\i}ve reservation of links
without any further measurements is only an improvement in case of complete
market penetration, otherwise it even reduces the performance of our approach
based on real-time link loads. Moreover, we modified the reservation process to
incorporate current travel times and show that this improves the results in our
simulations when at least 40% market penetration is possible."
"Social choice theory is a theoretical framework for analysis of combining
individual preferences, interests, or welfare to reach a collective decision or
social welfare in some sense. We introduce a new criterion for social choice
protocols called social disappointment. Social disappointment happens when the
outcome of a voting system occurs for those alternatives which are at the end
of at least half of individual preference profiles. Here we introduce some
protocols that prevent social disappointment and prove an impossibility theorem
based on this key concept."
"During the last years several ant-based techniques were involved to solve
hard and complex optimization problems. The current paper is a short study
about the influence of artificial ant species in solving optimization problems.
There are studied the artificial Pharaoh Ants, Lasius Niger and also artificial
ants with no special specificity used commonly in Ant Colony Optimization."
"This paper investigates agreement protocols over cooperative and
cooperative--antagonistic multi-agent networks with coupled continuous-time
nonlinear dynamics. To guarantee convergence for such systems, it is common in
the literature to assume that the vector field of each agent is pointing inside
the convex hull formed by the states of the agent and its neighbors, given that
the relative states between each agent and its neighbors are available. This
convexity condition is relaxed in this paper, as we show that it is enough that
the vector field belongs to a strict tangent cone based on a local supporting
hyperrectangle. The new condition has the natural physical interpretation of
requiring shared reference directions in addition to the available local
relative states. Such shared reference directions can be further interpreted as
if each agent holds a magnetic compass indicating the orientations of a global
frame. It is proven that the cooperative multi-agent system achieves
exponential state agreement if and only if the time-varying interaction graph
is uniformly jointly quasi-strongly connected. Cooperative--antagonistic
multi-agent systems are also considered. For these systems, the relation has a
negative sign for arcs corresponding to antagonistic interactions. State
agreement may not be achieved, but instead it is shown that all the agents'
states asymptotically converge, and their limits agree componentwise in
absolute values if and in general only if the time-varying interaction graph is
uniformly jointly strongly connected."
"In this paper, we address the problems faced by a group of agents that
possess situational awareness, but lack a security mechanism, by the
introduction of a adaptive risk management system. The Belief-Desire-Intention
(BDI) architecture lacks a framework that would facilitate an adaptive risk
management system that uses the situational awareness of the agents. We extend
the BDI architecture with the concept of adaptive alertness. Agents can modify
their level of alertness by monitoring the risks faced by them and by their
peers. Alert-BDI enables the agents to detect and assess the risks faced by
them in an efficient manner, thereby increasing operational efficiency and
resistance against attacks."
"Pedestrian behavior has much more complicated characteristics in a dense
crowd and thus attracts the widespread interest of scientists and engineers.
However, even successful modeling approaches such as pedestrian models based on
particle systems are still not fully considered the perceptive mechanism
underlying collective pedestrian behavior. This paper extends a behavioral
heuristics-based pedestrian model to an adaptive agent-based model, which
explicitly considers the crowding effect of neighboring individuals and
perception anisotropy on the representation of a pedestrians visual
information. The adaptive agents with crowding perception are constructed to
investigate complex, selforganized collective dynamics of pedestrian motion.
The proposed model simulates selforganized pedestrian flows in good
quantitative agreement with empirical data. The selforganized phenomena include
lane formation in bidirectional flow and fundamental diagrams of unidirectional
flow. Simulation results show that the emergence of lane formation in
bidirectional flow can be well reproduced. To investigate this further,
increasing view distance has a significant effect on reducing the number of
lanes, increasing lane width, and stabilizing the self-organized lanes. The
paper also discusses phase transitions of fundamental diagrams of pedestrian
crowds with unidirectional flow. It is found that the heterogeneity of how
pedestrians perceive crowding in the population has a remarkable impact on the
flow quality, which results in the buildup of congestion and rapidly decreases
the efficiency of pedestrian flows. It also indicates that the concept of
heterogeneity may be used to explain the instability of phase transitions."
"The computational cost of large-scale multi-agent based simulations (MABS)
can be extremely important, especially if simulations have to be monitored for
validation purposes. In this paper, two methods, based on self-observation and
statistical survey theory, are introduced in order to optimize the computation
of observations in MABS. An empirical comparison of the computational cost of
these methods is performed on a toy problem."
"This article proposes a methodology to model and simulate complex systems,
based on IRM4MLS, a generic agent-based meta-model able to deal with
multi-level systems. This methodology permits the engineering of dynamic
multi-level agent-based models, to represent complex systems over several
scales and domains of interest. Its goal is to simulate a phenomenon using
dynamically the lightest representation to save computer resources without loss
of information. This methodology is based on two mechanisms: (1) the activation
or deactivation of agents representing different domain parts of the same
phenomenon and (2) the aggregation or disaggregation of agents representing the
same phenomenon at different scales."
"The present approach highlights the synergies between application integration
and interaction protocols. Since both fields have advanced in different
directions, a number of important technical problems can be addressed by their
proper synthesis. In our previous work, we proposed a methodological approach
based on Interaction Protocols for Enterprise Applica tion Integration (EAI).
This approach permits to specify MAS (Multi-Agent System) interaction
protocols, verify their behavior and use them to integrate multiple business
applications. The result of the proposed approach is a validated interaction
protocol. Based on this protocol, we define in this paper, an agent- based
architecture for the EAI. It includes all the concepts nec- essary to support
communication and coordination mechanisms such as inter-agent and agent-Web
services communication."
"With the proliferation of web technologies it becomes more and more important
to make the traditional negotiation pricing mechanism automated and
intelligent. The behaviour of software agents which negotiate on behalf of
humans is determined by their tactics in the form of decision functions.
Prediction of partners behaviour in negotiation has been an active research
direction in recent years as it will improve the utility gain for the adaptive
negotiation agent and also achieve the agreement much quicker or look after
much higher benefits. In this paper we review the various negotiation methods
and the existing architecture. Although negotiation is practically very complex
activity to automate without human intervention we have proposed architecture
for predicting the opponents behaviour which will take into consideration
various factors which affect the process of negotiation. The basic concept is
that the information about negotiators, their individual actions and dynamics
can be used by software agents equipped with adaptive capabilities to learn
from past negotiations and assist in selecting appropriate negotiation tactics."
"Cloud computing allows subscription based access to computing. It also allows
storage services over Internet. Automated Negotiation is becoming an emerging,
and important area in the field of Multi Agent Systems in ECommerce. Multi
Agent based negotiation system is necessary to increase the efficiency of
E-negotiation process. Cloud computing provides security and privacy to the
user data and low maintenance costs. We propose a Negotiation system using
cloud. In this system, all product information and multiple agent details are
stored on cloud. Both parties select their agents through cloud for
negotiation. Agent acts as a negotiator. Agents have users details and their
requirements for a particular product. Using users requirement, agents
negotiate on some issues such as price, volume, duration, quality and so on.
After completing negotiation process, agents give feedback to the user about
whether negotiation is successful or not. This negotiation system is dynamic in
nature and increases the agents with the increase in participating user."
"This paper introduces the basic structure of multi-agent based protection
system for distribution system with DGs. The entire system consists of
intelligent agents and communication system. Intelligent agents can be divided
into three layers, the bottom layer, the middle layer and the upper layer. The
design of the agent in different layer is analyzed in detail. Communication
system is the bridge of multi-agent system (MAS). The transmission mode,
selective communication and other principles are discussed to improve the
transmission efficiency. Finally, some evaluations are proposed, which provides
the design of MAS with reference."
"This paper investigates the problem of protesting crowd simulation. It
considers CROCADILE, an agent based distillation system, for this purpose. A
model of protesting crowd was determined and then a CROCADILE model of
protesting crowd was engineered and demonstrated. We validated the model by
using two scenarios where protesters are varied with different personalities.
The results indicated that CROCADILE served well as the platform for protesting
crowd modeling simulation"
"Coordination in multi-agent system is very essential, in order to perform
complex tasks and lead MAS towards its goal. Also, the member agents of
multi-agent system should be autonomous as well as collaborative to accomplish
the complex task for which multi-agent system is designed specifically.
Contract-Net Protocol (CNP) is one of the coordination mechanisms which is used
by multi-agent systems which prefer coordination through interaction protocols.
In order to overcome the limitations of conventional CNP, this paper proposes a
modification in conventional CNP called updated-CNP. Updated-CNP is an effort
towards updating of a CNP in terms of its limitations of modifiability and
communication overhead. The limitation of the modification of tasks, if the
task requirements change at any instance, corresponding to tasks which are
allocated to contractor agents by manager agents is possible in our updated-CNP
version, which was not possible in the case of conventional-CNP, as it has to
be restarted in the case of task modification. This in turn will be reducing
the communication overhead of CNP, which is time taken by various agents using
CNP to pass messages to each other. For the illustration of the updated CNP, we
have used a sound predator-prey case study."
"This article describes the development of an agent-based model (AMEL,
Agent-based Model for Earthquake evacuation in Lebanon) that aims at simulating
the movement of pedestrians shortly after an earthquake. The GAMA platform was
chosen to implement the model. AMEL is applied to a real case study, a district
of the city of Beirut, Lebanon, which potentially could be stricken by a M7
earthquake. The objective of the model is to reproduce real life mobility
behaviours that have been gathered through a survey in Beirut and to test
different future scenarios, which may help the local authorities to target
information campaigns."
"Previous papers have described a computational approach to System of Systems
(SoS) development using an Agent-Based Model (ABM). This paper describes the
Fuzzy Decision Analysis used in the negotiation between the SoS agent and a
System agent in the ABM of an Acknowledged SoS development. An Acknowledged SoS
has by definition a limited influence on the development of the individual
Systems. The individual Systems have their own priorities, pressures, and
agenda which may or may not align with the goals of the SoS. The SoS has some
funding and deadlines which can be used to negotiate with the individual System
in order to illicit the required capability from that System. The Fuzzy
Decision Analysis determines how the SoS agent will adjust the funding and
deadlines for each of the Systems in order to achieve the desired SoS
architecture quality. The Fuzzy Decision Analysis has inputs of performance,
funding, and deadlines as well as weights for each capability. The performance,
funding, and deadlines are crisp values which are fuzzified. The fuzzified
values are then used with a Fuzzy Inference Engine to get the fuzzy outputs of
funding adjustment and deadline adjustment which must then be defuzzified
before being passed to the System agent. The first contribution of this paper
is the fuzzy decision analysis that represents the negotiation between the SoS
agent and the System agent. A second contribution of this paper is the method
of implementing the fuzzy decision analysis which provides a generalized fuzzy
decision analysis."
"In decision support systems, it is essential to get a candidate solution
fast, even if it means resorting to an approximation. This constraint
introduces a scalability requirement with regard to the kind of heuristics
which can be used in such systems. As execution time is bounded, these
algorithms need to give better results and scale up with additional computing
resources instead of additional time. In this paper, we show how multi-agent
systems can fulfil these requirements. We recall as an example the concept of
Evolutionary Multi-Agent Systems, which combine evolutionary and agent
computing paradigms. We describe several possible implementations and present
experimental results demonstrating how additional resources improve the
efficiency of such systems."
"Large-scale models are generally associated with big modelling units in
space, like counties or super grids (several to dozens km2). Few applied urban
models can pursue large-scale extent with fine-level units simultaneously due
to data availability and computation load. The framework of automatic
identification and characterization parcels developed by Long and Liu (2013)
makes such an ideal model possible by establishing existing urban parcels using
road networks and points of interest for a super large area (like a country or
a continent). In this study, a mega-vector-parcels cellular automata model
(MVP-CA) is developed for simulating urban expansion in the parcel level for
all 654 Chinese cities. Existing urban parcels in 2012, for initiating MVP-CA,
are generated using multi-levelled road networks and ubiquitous points of
interest, followed by simulating parcel-based urban expansion of all cities
during 2012-2017. Reflecting national spatial development strategies discussed
extensively by academics and decision makers, the baseline scenario and other
two simulated urban expansion scenarios have been tested and compared
horizontally. As the first fine-scale urban expansion model from the national
scope, its academic contributions, practical applications, and potential biases
are discussed in this paper as well."
"Multiagent negotiation mechanisms advise original solutions to several
problems for which usual problem solving methods are inappropriate. Mainly
negotiation models are based on agents' interactions through messages. Agents
interact in order to reach an agreement for solving a specific problem. In this
work, we study a new variant of negotiations, which has not yet been addressed
in existing works. This negotiation form is denoted extensible negotiation. In
contrast with current negotiation models, this form of negotiation allows the
agents to dynamically extend the set of items under negotiation. This facility
gives more acceptable solutions for the agents in their negotiation. The
advantage of enlarging the negotiation space is to certainly offer more
facilities for the agents for reaching new agreements which would not have been
obtained using usual negotiation methods. This paper presents the protocol and
the strategies used by the agents to deal with such negotiations."
"Agents in an open system communicate using interaction protocols. Suppose
that we have a system of agents and that we want to add a new protocol that all
(or some) agents should be able to understand. Clearly, modifying the source
code for each agent implementation is not practical. A solution to this problem
of upgrading an open system is to have a mechanism that allows agents to
receive a description of an interaction protocol and use it. In this paper we
propose a representation for protocols based on extending Petri nets. However,
this is not enough: in an open system the source of a protocol may not be
trusted and a protocol that is received may contain steps that are erroneous or
that make confidential information public. We therefore also describe an
analysis method that infers whether a protocol is safe. Finally, we give an
execution model for extended Petri nets."
"This paper describes a metric for measuring the success of a complex system
composed of agents performing autonomous behaviours. Because of the difficulty
in evaluating such systems, this metric will help to give an initial indication
as to how suitable the agents would be for solving the problem. The system is
modelled as a script, or behavioural ontology, with a number of variables to
represent each of the behaviour attributes. The set of equations can be used
both for modeling and as part of the simulation evaluation. Behaviours can be
nested, allowing for compound behaviours of arbitrary complexity to be built.
There is also the capability for including rules or decision making into the
script. The paper also gives some test examples to show how the metric might be
used."
"This paper presents a novel compositional approach to distributed
coordination module (CM) synthesis for multiple discrete-event agents in the
formal languages and automata framework. The approach is supported by two
original ideas. The first is a new formalism called the Distributed Constraint
Specification Network (DCSN) that can comprehensibly describe the networking
constraint relationships among distributed agents. The second is multiagent
conflict resolution planning, which entails generating and using AND/OR graphs
to compactly represent conflict resolution (synthesis-process) plans for a
DCSN. Together with the framework of local CM design developed in the authors'
earlier work, the systematic approach supports separately designing local and
deconflicting CM's for individual agents in accordance to a selected conflict
resolution plan. Composing the agent models and the CM's designed furnishes an
overall nonblocking coordination solution that meets the set of inter-agent
constraints specified in a given DCSN."
"In a container terminal, many operations occur within the storage area:
containers import, containers export and containers shifting. All these
operations require the respect of many rules and even laws in order to
guarantee the port safety and to prevent risks, especially when hazardous
material is concerned. In this paper, we propose a hybrid architecture, using a
Cellular Automaton and a Multi-Agent System to handle the dangerous container
storage problem. It is an optimization problem since the aim is to improve the
container terminal configuration, that is, the way hazardous containers are
dispatched through the terminal to improve its security. In our model, we
consider containers as agents, in order to use a Multi-Agent System for the
decision aid software, and a Cellular Automaton for modelling the terminal
itself. To validate our approach many tests have been performed and the results
show the relevance of our model."
"The diffusion of electric vehicles (EVs) is considered an effective policy
strategy to meet greenhouse gas reduction targets. For large-scale adoption,
however, demand-side oriented policy measures are required, based on consumers
transport needs, values and social norms. We introduce an empirically grounded,
spatially explicit, agent-based model, InnoMind Innovation diffusion driven by
changing Minds), to simulate the effects of policy interventions and social
influence on consumers transport mode preferences. The agents in this model
represent individual consumers. They are calibrated based on empirically
derived attributes and characteristics of survey respondents. We model agent
decision-making with artificial neural networks that account for the role of
emotions in information processing. We present simulations of 4 scenarios for
the diffusion of EVs in the city of Berlin, Germany (3 policy scenarios and 1
base case). The results illustrate the varying effectiveness of measures in
different market segments and the need for appropriate policies tailored to the
heterogeneous needs of different travelers. Moreover, the simulations suggest
that introducing an exclusive zone for EVs in the city would accelerate the
early-phase diffusion of EVs more effectively than financial incentives only."
"We are interested in designing artificial universes for artifi- cial agents.
We view artificial agents as networks of high- level processes on top of of a
low-level detailed-description system. We require that the high-level processes
have some intrinsic explanatory power and we introduce an extension of
informational closure namely interaction closure to capture this. Then we
derive a method to design artificial universes in the form of finite Markov
chains which exhibit high-level pro- cesses that satisfy the property of
interaction closure. We also investigate control or information transfer which
we see as an building block for networks representing artificial agents."
"In this report, we propose a technique using negotiation based on multi-agent
system (MAS) in the context of cognitive radio network (CRN). The agents are
particularly suited to provide responsive solutions to complex problems such as
the negotiation of the spectrum in CRN. We have implemented our proposed
solution with JADE (Java Agent Development Framework) and we have also evaluate
the proposed solution to show its interest."
"Social scientists have used agent-based models to understand how individuals
interact and behave in various political, ecological and economic scenarios.
Agent-based models are ideal for understanding such models involving
interacting individuals producing emergent phenomenon. Sugarscape is one of the
most famous examples of a social agent-based model which has been used to show
how societies grow in the real world.
  This paper builds on the Sugarscape model, using the Flexible Large scale
Agent-based modelling Environment (FLAME) to simulate three different scenarios
of the experiment, which are based on the Sugar and Citizen locations. FLAME is
an agent-based modelling framework which has previously been used to model
biological and economic models. The paper includes details on how the model was
written and the various parameters set for the simulation. The results of the
model simulated are processed for three scenarios and analysed to see what
affect the initial starting states of the agents had on the overall result
obtained through the model and the variance in simulation time of processing
the model on multicore architectures.
  The experiments highlight that there are limitations of the FLAME framework
and writing simulation models in general which are highly dependent on initial
starting states of a model, also raising further potential work which can be
built into the Sugarscape model to study other interesting phenomenon in social
and economic laws."
"The Agent Conversation Reasoning Engine (ACRE) is intended to aid agent
developers to improve the management and reliability of agent communication. To
evaluate its effectiveness, a problem scenario was created that could be used
to compare code written with and without the use of ACRE by groups of test
subjects.
  This paper describes the requirements that the evaluation scenario was
intended to meet and how these motivated the design of the problem. Two
experiments were conducted with two separate sets of students and their
solutions were analysed using a combination of simple objective metrics and
subjective analysis. The analysis suggested that ACRE by default prevents some
common problems arising that would limit the reliability and extensibility of
conversation-handling code.
  As ACRE has to date been integrated only with the Agent Factory multi agent
framework, it was necessary to verify that the problems identified are not
unique to that platform. Thus a comparison was made with best practice
communication code written for the Jason platform, in order to demonstrate the
wider applicability of a system such as ACRE."
"Intelligent Agents act in open and thus risky environments, hence making the
appropriate decision about who to trust in order to interact with, could be a
challenging process. As intelligent agents are gradually enriched with Semantic
Web technology, acting on behalf of their users with limited or no human
intervention, their ability to perform assigned tasks is scrutinized. Hence,
trust and reputation models, based on interaction trust or witness reputation,
have been proposed, yet they often presuppose the use of a centralized
authority. Although such mechanisms are more popular, they are usually faced
with skepticism, since users may question the trustworthiness and the
robustness of a central authority. Distributed models, on the other hand, are
more complex but they provide personalized estimations based on each agent's
interests and preferences. To this end, this article proposes DISARM, a novel
distributed reputation model. DISARM deals MASs as social networks, enabling
agents to establish and maintain relationships, limiting the disadvantages of
the common distributed approaches. Additionally, it is based on defeasible
logic, modeling the way intelligent agents, like humans, draw reasonable
conclusions from incomplete and possibly conflicting (thus inconclusive)
information. Finally, we provide an evaluation that illustrates the usability
of the proposed model."
"Two fundamental algorithm-design paradigms are Tree Search and Dynamic
Programming. The techniques used therein have been shown to complement one
another when solving the complete set partitioning problem, also known as the
coalition structure generation problem [5]. Inspired by this observation, we
develop in this paper an algorithm to solve the coalition structure generation
problem on graphs, where the goal is to identifying an optimal partition of a
graph into connected subgraphs. More specifically, we develop a new depth-first
search algorithm, and combine it with an existing dynamic programming algorithm
due to Vinyals et al. [9]. The resulting hybrid algorithm is empirically shown
to significantly outperform both its constituent parts when the
subset-evaluation function happens to have certain intuitive properties."
"Understanding the nature of strategic voting is the holy grail of social
choice theory, where game-theory, social science and recently computational
approaches are all applied in order to model the incentives and behavior of
voters.
  In a recent paper, Meir et al.[EC'14] made another step in this direction, by
suggesting a behavioral game-theoretic model for voters under uncertainty. For
a specific variation of best-response heuristics, they proved initial existence
and convergence results in the Plurality voting system.
  In this paper, we extend the model in multiple directions, considering voters
with different uncertainty levels, simultaneous strategic decisions, and a more
permissive notion of best-response. We prove that a voting equilibrium exists
even in the most general case. Further, any society voting in an iterative
setting is guaranteed to converge.
  We also analyze an alternative behavior where voters try to minimize their
worst-case regret. We show that the two behaviors coincide in the simple
setting of Meir et al., but not in the general case."
"This paper develops a dynamic agent-based model for rural-urban migration,
based on the previous relevant works. The model conforms to the typical dynamic
linear multi-agent systems model concerned extensively in systems science, in
which the communication network is formulated as a digraph. Simulations reveal
that consensus of certain variable could be harmful to the overall stability
and should be avoided."
"Relationships between objects constitute our notion of space. When these
relationships change we interpret this as the passage of time. Observer
interpretations are essential to the way we understand these relationships.
Hence observer semantics are an integral part of what we mean by spacetime.
  Semantics make up the essential difference in how one describes and uses the
concept of space in physics, chemistry, biology and technology. In these notes,
I have tried to assemble what seems to be a set of natural, and pragmatic,
considerations about discrete, finite spacetimes, to unify descriptions of
these areas.
  It reviews familiar notions of spacetime, and brings them together into a
less familiar framework of promise theory (autonomous agents), in order to
illuminate the goal of encoding the semantics of observers into a description
of spacetime itself. Autonomous agents provide an exacting atomic and local
model for finite spacetime, which quickly reveals the issues of incomplete
information and non-locality. From this we should be able to reconstruct all
other notions of spacetime.
  The aim of this exercise is to apply related tools and ideas to an initial
unification of real and artificial spaces, e.g. databases and information webs
with natural spacetime. By reconstructing these spaces from autonomous agents,
we may better understand naming and coordinatization of semantic spaces, from
crowds and swarms to datacentres and libraries, as well as the fundamental
arena of natural science."
"It has been widely recognized that the performance of a multi-agent system is
highly affected by its organization. A large scale system may have billions of
possible ways of organization, which makes it impractical to find an optimal
choice of organization using exhaustive search methods. In this paper, we
propose a genetic algorithm aided optimization scheme for designing
hierarchical structures of multi-agent systems. We introduce a novel algorithm,
called the hierarchical genetic algorithm, in which hierarchical crossover with
a repair strategy and mutation of small perturbation are used. The phenotypic
hierarchical structure space is translated to the genome-like array
representation space, which makes the algorithm genetic-operator-literate. A
case study with 10 scenarios of a hierarchical information retrieval model is
provided. Our experiments have shown that competitive baseline structures which
lead to the optimal organization in terms of utility can be found by the
proposed algorithm during the evolutionary search. Compared with the
traditional genetic operators, the newly introduced operators produced better
organizations of higher utility more consistently in a variety of test cases.
The proposed algorithm extends of the search processes of the state-of-the-art
multi-agent organization design methodologies, and is more computationally
efficient in a large search space."
"To perform cooperative tasks in a decentralized manner, multi-robot systems
are often required to communicate with each other. Therefore, maintaining the
communication graph connectivity is a fundamental issue when roaming a
territory with obstacles. However, when dealing with real-robot systems,
several sources of data corruption can appear in the agent interaction. In this
paper, the effects of failure and noise in the communication between agents are
analyzed upon a connectivity maintenance control strategy. The results show
that the connectivity strategy is resilient to the negative effects of such
disturbances under realistic settings that consider a bandwidth limit for the
control effort. This opens the perspective of applying the connectivity
maintenance strategy in adaptive schemes that consider, for instance,
autonomous adaptation to constraints other than connectivity itself, e.g.
communication efficiency and energy harvesting."
"We examine the behavior of multi-agent networks where information-sharing is
subject to a positive communications cost over the edges linking the agents. We
consider a general mean-square-error formulation where all agents are
interested in estimating the same target vector. We first show that, in the
absence of any incentives to cooperate, the optimal strategy for the agents is
to behave in a selfish manner with each agent seeking the optimal solution
independently of the other agents. Pareto inefficiency arises as a result of
the fact that agents are not using historical data to predict the behavior of
their neighbors and to know whether they will reciprocate and participate in
sharing information. Motivated by this observation, we develop a reputation
protocol to summarize the opponent's past actions into a reputation score,
which can then be used to form a belief about the opponent's subsequent
actions. The reputation protocol entices agents to cooperate and turns their
optimal strategy into an action-choosing strategy that enhances the overall
social benefit of the network. In particular, we show that when the
communications cost becomes large, the expected social benefit of the proposed
protocol outperforms the social benefit that is obtained by cooperative agents
that always share data. We perform a detailed mean-square-error analysis of the
evolution of the network over three domains: far field, near-field, and
middle-field, and show that the network behavior is stable for sufficiently
small step-sizes. The various theoretical results are illustrated by numerical
simulations."
"Solving a delegation graph for transitive votes is already a non-trivial task
for many programmers. When extending the current main paradigm, where each
voter can only appoint a single transitive delegation, to a system where each
vote can be separated over multiple delegations, solving the delegation graph
becomes even harder. This article presents a solution of an example graph, and
a non-formal proof of why this algorithm works."
"In this paper, we consider distributed decision-making over stochastic
communication links in multi-agent systems. We show how to extend the current
literature on potential games with binary log-linear learning (which mainly
focuses on ideal communication links) to consider the impact of stochastic
communication channels. More specifically, we derive conditions on the
probability of link connectivity to achieve a target probability for the set of
potential maximizers (in the stationary distribution). Furthermore, our toy
example demonstrates a transition phenomenon for achieving any target
probability for the set of potential maximizers."
"This paper explains in layperson's terms how an agent-based model was used to
investigate the widely held belief that creativity is an important component of
effective leadership. Creative leadership was found to increase the mean
fitness of cultural outputs across an artificial society, but the more creative
the followers were, the greater the extent to which the beneficial effect of
creative leadership was washed out. Early in a run when the fitness of ideas
was low, a form of leadership that entails the highest possible degree of
creativity was best for the mean fitness of outputs across the society. As the
mean fitness of outputs increased a transition inevitably occurs after which
point a less creative style of leadership proved most effective. Implications
of these findings are discussed."
"In the Shift Bribery problem, we are given an election (based on preference
orders), a preferred candidate $p$, and a budget. The goal is to ensure that
$p$ wins by shifting $p$ higher in some voters' preference orders. However,
each such shift request comes at a price (depending on the voter and on the
extent of the shift) and we must not exceed the given budget. We study the
parameterized computational complexity of Shift Bribery with respect to a
number of parameters (pertaining to the nature of the solution sought and the
size of the election) and several classes of price functions. When we
parameterize Shift Bribery by the number of affected voters, then for each of
our voting rules (Borda, Maximin, Copeland) the problem is W[2]-hard. If,
instead, we parameterize by the number of positions by which $p$ is shifted in
total,then the problem is fixed-parameter tractable for Borda and Maximin,and
is W[1]-hard for Copeland. If we parameterize by the budget, then the results
depend on the price function class. We also show that Shift Bribery tends to be
tractable when parameterized by the number of voters, but that the results for
the number of candidates are more enigmatic."
"This paper explains in layperson's terms how an agent-based model was used to
investigate the hypothesis that culture evolves more effectively when
novelty-generating creative processes are tempered by imitation processes that
preserve proven successful ideas. Using EVOC, an agent-based model of cultural
evolution we found that (1) the optimal ratio of inventing to imitating ranged
from 1:1 to 2:1 depending on the fitness function, (2) there was a trade-off
between the proportion of creators to conformers and how creative the creators
were, and (3) when agents in increased or decreased their creativity depending
on the success of their latest creative efforts, they segregated into creators
and conformers, and the mean fitness of ideas across the society was higher. It
is tentatively suggested that through the unconscious use of social cues,
members of a society self-organizes to achieve a balanced mix of creators and
conformers."
"Electronic commerce (a.k.a. E-commerce) systems such as eBay and Taobao of
Alibaba are becoming increasingly popular. Having an effective reputation
system is critical to this type of internet service because it can assist
buyers to evaluate the trustworthiness of sellers, and it can also improve the
revenue for reputable sellers and E-commerce operators. We formulate a
stochastic model to analyze an eBay-like reputation system and propose four
measures to quantify its effectiveness: (1) new seller ramp up time, (2) new
seller drop out probability, (3) long term profit gains for sellers, and (4)
average per seller transaction gains for the E-commerce operator. Through our
analysis, we identify key factors which influence these four measures. We
propose a new insurance mechanism which consists of an insurance protocol and a
transaction mechanism to improve the above four measures. We show that our
insurance mechanism can reduce the ramp up time by around 87.2%, and guarantee
new sellers ramp up before the deadline $T_w$ with a high probability (close to
1.0). It also increases the long term profit gains and average per seller
transaction gains by at least 95.3%."
"Activity-based models, as a specific instance of agent-based models, deal
with agents that structure their activity in terms of (daily) activity
schedules. An activity schedule consists of a sequence of activity instances,
each with its assigned start time, duration and location, together with
transport modes used for travel between subsequent activity locations. A
critical step in the development of simulation models is validation. Despite
the growing importance of activity-based models in modelling transport and
mobility, there has been so far no work focusing specifically on statistical
validation of such models. In this paper, we propose a six-step Validation
Framework for Activity-based Models (VALFRAM) that allows exploiting historical
real-world data to assess the validity of activity-based models. The framework
compares temporal and spatial properties and the structure of activity
schedules against real-world travel diaries and origin-destination matrices. We
confirm the usefulness of the framework on three real-world activity-based
transport models."
"Crowd management is a complex, challenging and crucial task. Lack of
appropriate management of crowd has, in past, led to many unfortunate stampedes
with significant loss of life. To increase the crowd management efficiency, we
deploy automated real time detection of stampede prone areas. Then, we use
robotic agents to aid the crowd management police in controlling the crowd in
these stampede prone areas. While doing so, we aim for minimum interference by
robotic agents in our environment. Thereby not disturbing the ambiance and
aesthetics of the place. We evaluate the effectiveness of our model in dealing
with difficult scenarios like emergency evacuation and presence of localized
congestion. Lastly, we simulate a multi agent system based on our model and use
it to illustrate the utility of robotic agents for detecting and reducing
congestion."
"As agent systems grow larger and more complex, there is an increasing need to
formally verify them. Furthermore, it is often suggested that complex systems
can be regulated using organizational models, imposing constraints on the
agents in the systems. Agents that can understand the organizational model and
constraints in a system is said to be organization-aware. This paper is
concerned with verification of organization-aware agents. We show how agents
using AORTA, a framework for making agents organization-aware, can be formally
verified using an extended version of the Agent Java PathFinder (AJPF), a model
checking system designed specifically for agent programming languages. We
integrate AORTA with the Agent Infrastructure Layer (AIL), which is an
intermediate layer on top of which APLs can be implemented, and use our
extension of AJPF to verify a system of agents aiming to write a paper together
by using an organization for coordination."
"This paper presents a simulation model based on the general framework of
Multi-Agent System (MAS) that can be used to investigate construction project
bidding process. Specifically, it can be used to investigate different
strategies in project bidding management from the general contractors'
perspective. The effectiveness of the studied management strategies is
evaluated by the quality, time and cost of bidding activities. As an
implementation of MAS theory, this work is expected to test the suitability of
MAS in studying construction management related problems."
"This paper explores the emergence of norms in agents' societies when agents
play multiple -even incompatible- roles in their social contexts
simultaneously, and have limited interaction ranges. Specifically, this article
proposes two reinforcement learning methods for agents to compute agreements on
strategies for using common resources to perform joint tasks. The computation
of norms by considering agents' playing multiple roles in their social contexts
has not been studied before. To make the problem even more realistic for open
societies, we do not assume that agents share knowledge on their common
resources. So, they have to compute semantic agreements towards performing
their joint actions. %The paper reports on an empirical study of whether and
how efficiently societies of agents converge to norms, exploring the proposed
social learning processes w.r.t. different society sizes, and the ways agents
are connected. The results reported are very encouraging, regarding the speed
of the learning process as well as the convergence rate, even in quite complex
settings."
"Agent-based models (ABMs) are ubiquitous in research and industry. Currently,
simulating ABMs involves at least some imperative (step-by-step) computer
instructions. An alternative approach is declarative programming, in which a
set of requirements is described at a high level of abstraction. Here we
describe a fully declarative approach to the automated construction of
simulations for ABMs. In this framework, logic for ABM simulations is
encapsulated into predefined components. The user specifies a set of
requirements describing the desired functionality. Additionally, each component
has a set of consistency requirements. The framework iteratively seeks a
simulation design that satisfies both user and system requirements. This
approach allows the user to omit most details from the simulation
specification, simplifying simulation design."
"Reputation is generally defined as the opinion of a group on an aspect of a
thing. This paper presents a reputation model that follows a probabilistic
modelling of opinions based on three main concepts: (1) the value of an opinion
decays with time, (2) the reputation of the opinion source impacts the
reliability of the opinion, and (3) the certainty of the opinion impacts its
weight with respect to other opinions. Furthermore, the model is flexible with
its opinion sources: it may use explicit opinions or implicit opinions that can
be extracted from agent behavior in domains where explicit opinions are sparse.
We illustrate the latter with an approach to extract opinions from behavioral
information in the sports domain, focusing on football in particular. One of
the uses of a reputation model is predicting behavior. We take up the challenge
of predicting the behavior of football teams in football matches, which we
argue is a very interesting yet difficult approach for evaluating the model."
"Schelling's model of segregation, first described in 1969, has become one of
the best known models of self-organising behaviour. While Schelling's explicit
concern was to understand the mechanisms underlying racial segregation in large
cities from a game theoretic perspective, the model should be seen as one of a
family, arising in fields as diverse as statistical mechanics, neural networks
and the social sciences, and which are concerned with interacting populations
situated on network structures. Despite extensive study, however, the
(unperturbed) Schelling model has largely resisted rigorous analysis, prior
results in the literature generally pertaining to variants of the model in
which noise is introduced into the dynamics of the system, the resulting model
then being amenable to standard techniques from statistical mechanics or
stochastic evolutionary game theory. A series of recent papers (one by Brandt,
Immorlica, Kamath, and Kleinberg, and two by the authors), has seen the first
rigorous analysis of the one dimensional version of the unperturbed model. Here
we provide the first rigorous analysis of the two and three dimensional
unperturbed models, establishing most of the phase diagram, and answering a
challenge from a recent paper by Brandt, Immorlica, Kamath, and Kleinberg."
"In this study the concept of reflexia is applied to modeling behavior of
autonomous units. The relationship between reflexia, on the one hand, and
mirror neuron system and perception of emotions, on the other hand, is
introduced. The main method of using reflexia in a group of autonomous units is
Reflexive Game Theory (RGT). To embody RGT in a group of autonomous agents a
communication system is employed. This communication system uses frequency
domain multiplexing by means of Izhikevich's resonate-and-fire neural models.
The result of socialization of autonomous units by means of RGT and
communication system is illustrated in several examples."
"In a previous study, we considered an information-theoretic model of code
evolution. In it, agents obtain information about their (common) environment by
the perception of messages of other agents, which is determined by an
interaction probability (the structure of the population). For an agent to
understand another agent's messages, the former must either know the identity
of the latter, or the code producing the messages must be universally
interpretable. A universal code, however, introduces a vulnerability: a
parasitic entity can take advantage of it. Here, we investigate this problem.
In our specific setting, we consider a parasite to be an agent that tries to
inflict as much damage as possible in the mutual understanding of the
population (i.e. the parasite acts as a disinformation agent). We show that,
after introducing a parasite in the population, the former adopts a code such
that it captures the information about the environment that is missing in the
population. Such agent would be of great value, but only if the rest of the
population could understand its messages. However, it is of little use here,
since the parasite utilises the most common messages in the population to
express different concepts. Now we let the population respond by updating their
codes such that, in this arms race, they again maximise their mutual
understanding. As a result, there is a code drift in the population where the
utilisation of the messages of the parasite is avoided. A consequence of this
is that the information that the parasite possesses but the agents lack becomes
understandable and readily available."
"Using Promise Theory as a calculus, I review how to define agency in a
scalable way, for the purpose of understanding semantic spacetimes. By
following simple scaling rules, replacing individual agents with `super-agents'
(sub-spaces), it is shown how agency can be scaled both dynamically and
semantically.
  The notion of occupancy and tenancy, or how space is used and filled in
different ways, is also defined, showing how spacetime can be shared between
independent parties, both by remote association and local encapsulation. I
describe how to build up dynamic and semantic continuity, by joining discrete
individual atoms and molecules of space into quasi-continuous lattices."
"We consider the problem of the evolution of a code within a structured
population of agents. The agents try to maximise their information about their
environment by acquiring information from the outputs of other agents in the
population. A naive use of information-theoretic methods would assume that
every agent knows how to ""interpret"" the information offered by other agents.
However, this assumes that one ""knows"" which other agents one observes, and
thus which code they use. In our model, however, we wish to preclude that: it
is not clear which other agents an agent is observing, and the resulting usable
information is therefore influenced by the universality of the code used and by
which agents an agent is ""listening"" to. We further investigate whether an
agent who does not directly perceive the environment can distinguish states by
observing other agents' outputs. For this purpose, we consider a population of
different types of agents ""talking"" about different concepts, and try to
extract new ones by considering their outputs only."
"Sugarscape is a well known and influential Agent Based Social Simulation
(ABSS). Various parts of Sugarscape are supplied as examples in almost all
Agent Based Model (ABM) toolkits. It has been used for demonstrating the
applicability of different approaches to ABM. However a lack of agreement on
the precise definition of the rules within Sugarscape has curtailed its
usefulness. We provide a formal specification of Sugarscape using the Z
specification language. This demonstrates the ability of formal specification
to capture the definition of an ABM in a precise manner. It shows that formal
specifications could be used as an approach to tackle the replication problem
in the field of ABM. It also provides the first clear interpretation of
Sugarscape identifying areas where information is missing and/or ambiguous.
This enables researchers to make proper comparisons between different
implementations of this model."
"Hybrid traffic modeling and simulation provide an important way to represent
and evaluate large-scale traffic networks at different levels of details. The
first level, called ""microscopic"" allows the description of individual vehicles
and their interactions as well as the study of driver's individual behavior.
The second, based on the analogy with fluidic dynamic, is the ""macroscopic"" one
and provides an efficient way to represent traffic flow behavior in large
traffic infrastructures, using three aggregated variables: traffic density,
mean speed and traffic volume. An intermediate level called ""mesoscopic""
considers a group of vehicles sharing common properties such as a same origin
and destination. The work conducted in this paper presents a first step
allowing simulation of wide area traffic network on the basis of dynamic hybrid
modeling, where the representation associated to a network section can change
at runtime. The proposed approach is implemented in a simulation platform,
called Jam-free."
"Cooperative ITS is enabling vehicles to communicate with the infrastructure
to provide improvements in traffic control. A promising approach consists in
anticipating the road profile and the upcoming dynamic events like traffic
lights. This topic has been addressed in the French public project Co-Drive
through functions developed by Valeo named Green Light Optimal Speed Advisor
(GLOSA). The system advises the optimal speed to pass the next traffic light
without stopping. This paper presents results of its performance in different
scenarios through simulations and real driving measurements. A scaling is done
in an urban area, with different penetration rates in vehicle and
infrastructure equipment for vehicular communication. Our simulation results
indicate that GLOSA can reduce CO2 emissions, waiting time and travel time,
both in experimental conditions and in real traffic conditions."
"In complex, open, and heterogeneous environments, agents must be able to
reorganize towards the most appropriate organizations to adapt unpredictable
environment changes within Multi-Agent Systems (MAS). Types of reorganization
can be seen from two different levels. The individual agents level
(micro-level) in which an agent changes its behaviors and interactions with
other agents to adapt its local environment. And the organizational level
(macro-level) in which the whole system changes it structure by adding or
removing agents. This chapter is dedicated to overview different aspects of
what is called MAS Organization including its motivations, paradigms, models,
and techniques adopted for statically or dynamically organizing agents in MAS."
"Within Multi Agent Systems, communication by means of Agent Communication
Languages (ACLs) has a key role to play in the co-operation, co-ordination and
knowledge-sharing between agents. Despite this, complex reasoning about agent
messaging, and specifically about conversations between agents, tends not to
have widespread support amongst general-purpose agent programming languages.
  ACRE (Agent Communication Reasoning Engine) aims to complement the existing
logical reasoning capabilities of agent programming languages with the
capability of reasoning about complex interaction protocols in order to
facilitate conversations between agents. This paper outlines the aims of the
ACRE project and gives details of the functioning of a prototype implementation
within the Agent Factory multi agent framework."
"Norms are known to be a major factor determining humans behavior. It's also
shown that norms can be quite effective tool for building agent-based
societies. Various normative architectures have been proposed for designing
normative multi-agent systems (NorMAS). Due to human nature of the concept
norms, many of these architectures are built based on theories in social
sciences. Tipping point theory, as is briefly discussed in this paper, seems to
have a great potential to be used for designing normative architectures. This
theory deals with the factors that affect social epidemics that arise in human
societies. In this paper, we try to apply the main concepts of this theory to
agent-based normative architectures. We show several ways to implement these
concepts, and study their effects in an agent-based normative scenario."
"Our subject is oriented towards investigation of potential ways of societal
organization, that allow for collective intelligent organization and management
of resources. The main objective of such organizations is the exploration of
the social energy from the existing societies. We conjecture that an
organizational model that fulfills the mentioned requirements is the Fractal
Social Organization (FSO). Our goal is to prove and verify the effectiveness of
this model by performing various simulations using the NetLogo environment, a
tool that allows agent-based rapid prototyping. We begin by simulating trivial
real life activities that demonstrate the main properties of the core unit of
the FSO, namely the SoC. Further, more complex scenarios involving various
nested SoCs are simulated. Two main simulation models are presented, allowing
us to obtain preliminary results using the FSO concepts as a potential
solution. In the first simulation model we demonstrate that by the use of FSO
properties the individuals may benefit by receiving more qualitative healthcare
services, while in the second simulation model we show how it might be possible
to improve the fall detection systems by the use of FSO mechanism."
"This paper analyzes two modeling approaches for occupant behaviour in
buildings. It compares a purely statistical approach with a multi-agent social
simulation based approach. The study concerns the door openings in an office."
"Dense human flow has been a concern for the safety of public events for a
long time. Macroscopic pedestrian models, which are mainly based on fluid
dynamics, are often used to simulate huge crowds due to their low computational
costs (Columbo & Rosini 2005). Similar approaches are used in the field of
traffic simulations (Lighthill & Whitham 1955). A combined macroscopic
simulation of vehicles and pedestrians is extremely helpful for
all-encompassing traffic control. Therefore, we developed a hybrid model that
contains networks for vehicular traffic and human flow. This comprehensive
model supports concurrent multi-modal simulations of traffic and pedestrians."
"The increased complexity and dynamism of present and future Multi-Agent
Systems (MAS) enforce the need for considering both of their static
(design-time) and the dynamic (run-time) aspects. A type of balance between the
two aspects can definitely give better results related to system stability and
adaptivity. MAS organization is the research area that is concerned with these
issues and it is currently a very active and interesting research area.
Designing a MAS with an initial organization and giving it the ability to
dynamically reorganize to adapt the dynamic changes of its unpredictable and
uncertain environment, is the feasible way to survive and to run effectively.
Normally, MAS organization is tackled by what is called, MAS organizational
models, which are concerned with the description (formally or informally) of
the structural and dynamical aspects of agent organizations. This paper
proposes a two-dimension space, called MOS-2, for positioning and assessing MAS
organizational models based on two dimensions: their adopted engineering
viewpoint (agent-centered or organization-centered) as the vertical dimension
and the agents awareness/unawareness of the existence of the organizational
level as the horizontal dimension. The MOS-2 space is applied for positioning a
number of familiar organizational models. Its future trends and possible
improvements are highlighted. They include the following, (1) adding Time as a
dimension, (2) increasing the considered dimensions, (3) providing a
quantitative approach for positioning MAS organizational models."
"This contribution introduces an element of ""aggressiveness"" into the
Floor-Field based model with adaptive time-span. The aggressiveness is
understood as an ability to win conflicts and push through the crowd. From
experiments it is observed that this ability is not directly correlated with
the desired velocity in the free flow regime. The influence of the
aggressiveness is studied by means of the dependence of the travel time on the
occupancy of a room. A simulation study shows that the conflict solution based
on the aggressiveness parameter can mimic the observations from the experiment."
"Many companies now use crowdsourcing to leverage external (as well as
internal) crowds to perform specialized work, and so methods of improving
efficiency are critical. Tasks in crowdsourcing systems with specialized work
have multiple steps and each step requires multiple skills. Steps may have
different flexibilities in terms of obtaining service from one or multiple
agents, due to varying levels of dependency among parts of steps. Steps of a
task may have precedence constraints among them. Moreover, there are variations
in loads of different types of tasks requiring different skill-sets and
availabilities of different types of agents with different skill-sets.
Considering these constraints together necessitates the design of novel schemes
to allocate steps to agents. In addition, large crowdsourcing systems require
allocation schemes that are simple, fast, decentralized and offer customers
(task requesters) the freedom to choose agents. In this work we study the
performance limits of such crowdsourcing systems and propose efficient
allocation schemes that provably meet the performance limits under these
additional requirements. We demonstrate our algorithms on data from a
crowdsourcing platform run by a non-profit company and show significant
improvements over current practice."
"Agent technology, a new paradigm in software engineering, has received
attention from research and industry since 1990s. However, it is still not used
widely to date because it requires expertise on both programming and agent
technology; gaps among requirements, agent design, and agent deployment also
pose more difficulties. Goal Net methodology attempts to solve these issues
with a goal-oriented approach that resembles human behaviours, and an agent
designer that supports agent development using this philosophy. However, there
are limitations on existing Goal Net Designer, the design and modelling
component of the agent designer. Those limitations, including limited access,
difficult deployment, inflexibility in user operations, design workflows
against typical Goal Net methodology workflows, and lack of data protection,
have inhibited widespread adoption of Goal Net methodology.
  Motivated by this, this book focuses on improvements on Goal Net Designer. In
this project, Goal Net Designer is completely re-implemented using new
technology with optimised software architecture and design. It allows access
from all major desktop operating systems, as well as in web environment via all
modern browsers. Enhancements such as refined workflows, model validation tool,
access control, team collaboration tool, and link to compiler make Goal Net
Designer a fully functional and powerful Integrated Development Environment.
User friendliness and usability are greatly enhanced by simplifying user's
actions to accomplish their tasks. User behaviour logging and quantitative
feedback channel are also included to allow Goal Net Designer to continuously
evolve with the power of big data analytics in future. To evaluate the new Goal
Net Designer, a teachable agent has been developed with the help of Goal Net
Designer and the development process is illustrated in a case study."
"Increased stress, fuel consumption, air pollution, accidents and delays are
some of the consequences of traffic congestion usually incurring in tremendous
economic impacts, which society aims to remedy in order to leverage a
sustainable development. Recently, unconventional means for modeling and
controlling such complex traffic systems relying on multi-agent systems have
arisen. This paper contributes to the understanding of such complex and highly
dynamic systems by proposing an open-source tool-chain to implement
multi-agent-based solutions in traffic and transportation. The proposed
approach relies on two very popular tools in both domains, with focus on
traffic light control. This tool-chain consists in combining JADE (Java Agent
DEvelopment Framework), for the implementation of multi-agent systems, with
SUMO (Simulation of Urban MObility), for the microscopic simulation of traffic
interactions. TraSMAPI (Traffic Simulation Manager Application Programming
Interface) is used to combine JADE and SUMO allowing communication between
them. A demonstration of the concept is presented to illustrate the main
features of this tool-chain, using Q-Learning as the reinforcement learning
method for each traffic light agent in a simulated network. Results demonstrate
the feasibility of the proposed framework as a practical means to experiment
with different agent-based designs of intelligent transportation solutions."
"We present a new algorithm to simulate dynamic group behaviors for
interactive multi-agent crowd simulation. Our approach is general and makes no
assumption about the environment, shape, or size of the groups. We use the
least effort principle to perform coherent group navigation and present
efficient inter-group and intra-group maintenance techniques. We extend the
reciprocal collision avoidance scheme to perform agent-group and group-group
collision avoidance that can generate collision-free as well as coherent and
trajectories. The additional overhead of dynamic group simulation is relatively
small. We highlight its interactive performance on complex scenarios with
hundreds of agents and compare the trajectory behaviors with real-world videos."
"Robots playing games that humans are adept in is a challenge. We studied
robotic agents playing Chain Catch game as a Multi-Agent System (MAS). Our game
starts with a traditional Catch game similar to Pursuit evasion, and further
extends it to form a growing chain of predator agents to chase remaining preys.
Hence Chain Catch is a combination of two challenges - pursuit domain and
robotic chain formation. These are games that require team of robotic agents to
cooperate among themselves and to compete with other group of agents through
quick decision making. In this paper, we present a Chain Catch simulator that
allows us to incorporate game rules, design strategies and simulate the game
play. We developed cost model driven strategies for each of Escapee, Catcher
and Chain. Our results show that Sliding slope strategy is the best strategy
for Escapees whereas Tagging method is the best method for chain s movement in
Chain Catch. We also use production quality robots to implement the game play
in a physical environment and analyze game strategies on real robots. Our real
robots implementation in different scenarios shows that game strategies work as
expected and a complete chain formation takes place successfully in each game."
"This paper considers the problem of routing and rebalancing a shared fleet of
autonomous (i.e., self-driving) vehicles providing on-demand mobility within a
capacitated transportation network, where congestion might disrupt throughput.
We model the problem within a network flow framework and show that under
relatively mild assumptions the rebalancing vehicles, if properly coordinated,
do not lead to an increase in congestion (in stark contrast to common belief).
From an algorithmic standpoint, such theoretical insight suggests that the
problem of routing customers and rebalancing vehicles can be decoupled, which
leads to a computationally-efficient routing and rebalancing algorithm for the
autonomous vehicles. Numerical experiments and case studies corroborate our
theoretical insights and show that the proposed algorithm outperforms
state-of-the-art point-to-point methods by avoiding excess congestion on the
road. Collectively, this paper provides a rigorous approach to the problem of
congestion-aware, system-wide coordination of autonomously driving vehicles,
and to the characterization of the sustainability of such robotic systems."
"Agent based distributed manufacturing control and scheduling systems are
subsets of new manufacturing systems. Multi agent systems (MAS) not only drive
design and engineering control solutions but also influence flexibility,
agility, and re-configurability, which makes MASs a better centralized systems
than its traditional counterparts. However, implementation of all MASs in the
real factories are timely, also extremely costly. A simulation environment that
would allow independent development and testing of the services and business
processes of the related manufacturing hardware is needed. This paper presents
the design and implementation of a userfriendly simulation platform for multi
agent based manufacturing control systems by considering the shop floor level.
The proposed simulation platform can simulate the software level of the factory
by considering the hardware level of the mentioned factory. An example of the
simulation platform is presented for a flexible manufacturing system, which is
located in EMU CIM lab."
"Optimal operation of a country's air transport infrastructure plays a major
role in the economic development of nations. Due to the increasing use of air
transportation in today's world, flights' boarding times have become a concern
for both airlines and airports, thus the importance of knowing beforehand how
changes in flights demand parameters and physical airport layout will affect
passengers flow and boarding times. This paper presents a pedestrian modeling
study in which a national airport passenger flow was analyzed. The study was
conducted at Vanguardia National Airport in Villavicencio, Meta, Colombia.
Different effects of structural changes are shown and provide judging elements
for decision makers regarding passenger traffic in airport design."
"The influence of agents heterogeneity on the microscopic characteristics of
pedestrian flow is studied via an evacuation simulation tool based on the
Floor-Field model. The heterogeneity is introduced in agents velocity,
aggressiveness, and sensitivity to occupation. The simulation results are
compared to data gathered during an original experiment. The comparison shows
that the heterogeneity in aggressiveness and sensitivity occupation enables to
reproduce some microscopic aspects. The heterogeneity in velocity seems to be
redundant."
"This paper presents a computational approach to modelling group creativity.
It presents an analysis of two studies of group creativity selected from
different research cultures and identifies a common theme (""idea build-up"")
that is then used in the formalisation of an agent-based model used to support
reasoning about the complex dynamics of building on the ideas of others."
"The paper deals with a step-wise analytic hierarchy process (AHP) applied by
a group of decision makers wherein nobody has a dominant position and it is
unlikely to come to terms with respect to either the weights of different
objectives or expected utilities of different alternatives. One of the AHP
outcomes, that is the consistency index is computed for each decision maker,
for all other decision makers but that one, and for the whole group. Doing so,
the group is able to assess to which extent each decision maker alters the
group consistency index and a better consistency index could be achieved if the
assessment procedure is being resumed by the most influential decision maker in
terms of consistency. The main contribution of the new approach is the
algorithm presented in as a flow chart where the condition to stop the process
might be either a threshold value for the consistency index, or a given number
of iterations for the group or decision maker, depending on the degree to which
the targeted goal has been decomposed into conflictual objectives."
"In this paper, we develop a variational method to track and make predictions
about a real-world system from continuous imperfect observations about this
system, using an agent-based model that describes the system dynamics. By
combining the power of big data with the power of model-thinking in the
stochastic process framework, we can make many valuable predictions. We show
how to track the spread of an epidemic at the individual level and how to make
short-term predictions about traffic congestion. This method points to a new
way to bring together modelers and data miners by turning the real world into a
living lab."
"Reaching some form of consensus is often necessary for autonomous agents that
want to coordinate their actions or otherwise engage in joint activities. One
way to reach a consensus is by aggregating individual information, such as
decisions, beliefs, preferences and constraints. Judgment aggregation is a
social choice method, which generalises voting, that studies the aggregation of
individual judgments regarding the truth-value of logically related
propositions. As such, judgment aggregation is applicable for consensus
reaching problems in multi agent systems. As other social choice theory,
judgment aggregation research is abundant with impossibility results. However,
the aim of this tutorial is to give an introduction to the methods of judgment
aggregation, not the impossibility results. In particular, the tutorial will
introduce the basic frameworks that model judgment aggregation problems and
give an overview of the judgment aggregation functions so far developed as well
as their social theoretic and computational complexity properties. The focus of
the tutorial are consensus reaching problems in multi agent systems that can be
modelled as judgment aggregation problems. The desirable properties of a
judgment aggregation method applied to these problems are not necessarily the
same as properties desirable in legal or political contexts, which is
considered to be the native domain of judgment aggregation. After this tutorial
the participants are expected to be able to read and understand judgment
aggregation literature and have a grasp on the state-of-the-art and open
questions in judgment aggregation research of interest to multi agent systems."
"This paper addresses the issues concerning the rescheduling of a static
timetable in case of a disaster encountered in a large and complex railway
network system. The proposed approach tries to modify the schedule so as to
minimise the overall delay of trains. This is achieved by representing the
rescheduling problem in the form of a Petri-Net and the highly uncertain
disaster recovery times in such a model is handled as Markov Decision Processes
(MDP ). For solving the rescheduling problem, a istributed Constraint
Optimisation (DCOP ) based strategy involving the use of autonomous agents is
used to generate the desired schedule. The proposed approach is evaluated on
the actual schedule of the Eastern Railways, India by constructing vari- ous
disaster scenarios using the Java Agent DEvelopment Framework (JADE). When
compared to the existing approaches, the proposed framework substantially
reduces the delay of trains after rescheduling."
"This paper studies how the communication network affects the power
utilization and fairness in a simplified power system model, composed by three
coupled layers: physical, communication and regulatory. Using an agent-based
approach, we build a scenario where individuals may cooperate (by removing a
load) or not (by keeping their loads or adding one more). The agent decision
reflects its desire of maximizing the delivered power based on its internal
state, its global state perception, a randomized selfishness related to its
willingness to follow demand-side control requests, and the state information
received from its neighbors in the communication network. Our focus is to
understand how the network topology and errors in the communication layer
affect the agents' behavior, reflected in the power utilization and fairness
for different demand-side policies. Our results show that for optimal power
utilization and fairness a global knowledge about the system is needed. We show
that close to optimal results can be archived with either a demand control
signal or a global pricing for energy."
"A team of identical and oblivious ant-like agents - a(ge)nts - leaving
pheromone traces, are programmed to jointly patrol an area modeled as a graph.
They perform this task using simple local interactions, while also achieving
the important byproduct of partitioning the graph into roughly equal-sized
disjoint sub-graphs. Each a(ge)nt begins to operate at an arbitrary initial
location, and throughout its work does not acquire any information on either
the shape or size of the graph, or the number or whereabouts of other a(ge)nts.
Graph partitioning occurs spontaneously, as each of the a(ge)nts patrols and
expands its own pheromone-marked sub-graph, or region. This graph partitioning
algorithm is inspired by molecules hitting the borders of air filled elastic
balloons: an a(ge)nt that hits a border edge from the interior of its region
more frequently than an external a(ge)nt hits the same edge from an adjacent
vertex in the neighboring region, may conquer that adjacent vertex, expanding
its region at the expense of the neighbor. Since the rule of patrolling a
region ensures that each vertex is visited with a frequency inversely
proportional to the size of the region, in terms of vertex count, a smaller
region will effectively exert higher ""pressure"" at its borders, and conquer
adjacent vertices from a larger region, thereby increasing the smaller region
and shrinking the larger. The algorithm, therefore, tends to equalize the sizes
of the regions patrolled, resembling a set of perfectly elastic physical
balloons, confined to a closed volume and filled with an equal amount of air.
The pheromone based local interactions of agents eventually cause the system to
evolve into a partition that is close to balanced rather quickly, and if the
graph and the number of a(ge)nts remain unchanged, it is guaranteed that the
system settles into a stable and balanced partition."
"The simulation of the dynamical behavior of pedestrians and crowds in spatial
structures is a consolidated research and application context that still
presents challenges for researchers in different fields and disciplines.
Despite currently available commercial systems for this kind of simulation are
growingly employed by designers and planners for the evaluation of alternative
solutions, this class of systems is generally not integrated with existing
monitoring and control infrastructures, usually employed by crowd managers and
field operators for security reasons. This paper introduces the essentials and
the related computational frame- work of an Integrated Crowd Management Support
System based on a Collective Artificial Intelligence approach encompassing (i)
interfaces from and to monitored and controlled environments (respectively,
sen- sors and actuators), (ii) a set of software tools supporting the analysis
of pedestrians and crowd phenomena taking place in the environment to feed a
(iii) faster than real-time simulation of the plausible evolution of the
current situation in order to support forms of inference provid- ing decision
support to crowd managers, potentially directly controlling elements of the
environment (e.g. blocking turnstiles, escalators), com- municating orders to
operators on the field or trying to influence the pedestrians by means of
dynamic signage or audible messages."
"This paper introduces a demand-side distributed and secured energy commitment
framework and operations for a Power Producer and Supplier (PPS) in deregulated
environment. Due to the diversity of geographical location as well as
customers' energy profile coupled with high number of customers, managing
energy transactions and resulting energy exchanges are challenging for a PPS.
The envisioned PPS maintains several aggregators (e.g. Microgrids), named as
Sub Service Provider (SSP) that manage customers/subscribers under their
domains. The SSPs act as agents that perform local energy matching (inside
their domains) and distributed energy matching within SSPs to determine the
energy commitment. The goal of the distributed energy matching is to reduce the
involvement of External Energy Supplier (e.g. Utility) while providing a
platform to demand side players to be a part of energy transaction. A
distributed assignment problem is designed that requires minimum and aggregated
information exchange (hence, secured) and solved by Linear Programming (LP)
that provides the distributed matching decision. The communicative burden among
SSPs due to the exchange of energy information is reduced by applying an
adaptive coalition formation method. The simulations are conducted by
implementing a synchronous distributed matching algorithm while showing the
effectiveness of the proposed framework."
"Microscopic Pedestrian Simulation Model is computer simulation model of
pedestrian movement where every pedestrian in the model is treated as
individual. Most of pedestrian researches have been done on macroscopic level,
which does not consider the interaction between pedestrians and does not well
suited for prediction of pedestrian flow performance in pedestrian areas or
building with some objects that reduce the effective width of it. In the other
hand, microscopic level has more general usage and considers detail of the
design. Tough the analytical model for microscopic pedestrian model is existed
exist, the numerical solution of the model is very difficult and simulation is
favorable. The model has practical application of Evacuation from building,
Design of pedestrian area, and Experimental & Optimization Design Tool. In
general, Microscopic Pedestrian Simulation Model consist of two terms, that
make the pedestrian moving toward the destination and make repulsive effect
toward other pedestrian or obstacles."
"Finding feasible, collision-free paths for multiagent systems can be
challenging, particularly in non-communicating scenarios where each agent's
intent (e.g. goal) is unobservable to the others. In particular, finding time
efficient paths often requires anticipating interaction with neighboring
agents, the process of which can be computationally prohibitive. This work
presents a decentralized multiagent collision avoidance algorithm based on a
novel application of deep reinforcement learning, which effectively offloads
the online computation (for predicting interaction patterns) to an offline
learning procedure. Specifically, the proposed approach develops a value
network that encodes the estimated time to the goal given an agent's joint
configuration (positions and velocities) with its neighbors. Use of the value
network not only admits efficient (i.e., real-time implementable) queries for
finding a collision-free velocity vector, but also considers the uncertainty in
the other agents' motion. Simulation results show more than 26 percent
improvement in paths quality (i.e., time to reach the goal) when compared with
optimal reciprocal collision avoidance (ORCA), a state-of-the-art collision
avoidance strategy."
"Autonomous Mobility On Demand (MOD) systems can utilize fleet management
strategies in order to provide a high customer quality of service (QoS).
Previous works on autonomous MOD systems have developed methods for rebalancing
single capacity vehicles, where QoS is maintained through large fleet sizing.
This work focuses on MOD systems utilizing a small number of vehicles, such as
those found on a campus, where additional vehicles cannot be introduced as
demand for rides increases. A predictive positioning method is presented for
improving customer QoS by identifying key locations to position the fleet in
order to minimize expected customer wait time. Ridesharing is introduced as a
means for improving customer QoS as arrival rates increase. However, with
ridesharing perceived QoS is dependent on an often unknown customer preference.
To address this challenge, a customer ratings model, which learns customer
preference from a 5-star rating, is developed and incorporated directly into a
ridesharing algorithm. The predictive positioning and ridesharing methods are
applied to simulation of a real-world campus MOD system.A combined predictive
positioning and ridesharing approach is shown to reduce customer service times
by up to 29% and the customer ratings model is shown to provide the best
overall MOD fleet management performance over a range of customer preferences."
"We consider distributed multitask learning problems over a network of agents
where each agent is interested in estimating its own parameter vector, also
called task, and where the tasks at neighboring agents are related according to
a set of linear equality constraints. Each agent possesses its own convex cost
function of its parameter vector and a set of linear equality constraints
involving its own parameter vector and the parameter vectors of its neighboring
agents. We propose an adaptive stochastic algorithm based on the projection
gradient method and diffusion strategies in order to allow the network to
optimize the individual costs subject to all constraints. Although the
derivation is carried out for linear equality constraints, the technique can be
applied to other forms of convex constraints. We conduct a detailed
mean-square-error analysis of the proposed algorithm and derive closed-form
expressions to predict its learning behavior. We provide simulations to
illustrate the theoretical findings. Finally, the algorithm is employed for
solving two problems in a distributed manner: a minimum-cost flow problem over
a network and a space-time varying field reconstruction problem."
"The modelling and simulation of the interaction among vehicles and
pedestrians during cross-walking is an open challenge for both research and
practical computational solutions supporting urban/traffic decision makers and
managers. The social cost of pedestrians' risky behaviour pushes the
development of a new generation of computational models integrating analytical
knowledge, data and experience about the complex dynamics occurring in
pedestrian/vehicle interactions, which are not completely understood despite
recent efforts. This paper presents the results of a significant data gathering
campaign realised at an unsignalized zebra crossing. The selected area of the
city of Milan (Italy) is characterised by a significant presence of elderly
inhabitants and pedestrian-vehicle risky interactions, testified by a high
number of accidents involving pedestrians in the past years. The results
concern the analysis of: (i) vehicular and pedestrian traffic volumes; (ii)
level of service; (iii) pedestrian-vehicle interactions, considering the impact
of ageing on crossing behaviour. Results showed that the phenomenon is
characterised by three main phases: approaching, appraising (evaluation of the
distance and speed of oncoming vehicles) and crossing. The final objective of
the research is to support the development of a microscopic agent-based tool
for simulating pedestrian behaviour at unsignalized crosswalks, focusing on the
specific needs of the elderly pedestrians."
"Computer-based simulation of pedestrian dynamics reached meaningful results
in the last decade, thanks to empirical evidences and acquired knowledge
fitting fundamental diagram constraints and space utilization. Moreover,
computational models for pedestrian wayfinding often neglect extensive
empirical evidences supporting the calibration and validation phase of
simulations. The paper presents the results of a set of controlled experiments
(with human volunteers) designed and performed to understand pedestrian's route
choice. The setting offers alternative paths to final destinations, at
different crowding conditions. Results show that the length of paths and level
of congestion influence decisions (negative feedback), as well as imitative
behaviour of ""emergent leaders"" choosing a new path (positive feedback). A
novel here illustrated model for the simulation of pedestrian route choice
captures such evidences, encompassing both the tendency to avoid congestion and
to follow emerging leaders. The found conflicting tendencies are modelled with
the introduction of a utility function allowing a consistent calibration over
the achieved results. A demonstration of the simulated dynamics on a larger
scenario will be also illustrated in the paper."
"Nowadays the composition and formation of effective teams is highly important
for both companies to assure their competitiveness and for a wide range of
emerging applications exploiting multiagent collaboration (e.g. crowdsourcing,
human-agent collaborations). The aim of this article is to provide an
integrative perspective on team composition, team formation and their
relationship with team performance. Thus, we review the contributions in both
the computer science literature and the organisational psychology literature
dealing with these topics. Our purpose is twofold. First, we aim at identifying
the strengths and weaknesses of the contributions made by these two diverse
bodies of research. Second, we pursue to identify cross-fertilisation
opportunities that help both disciplines benefit from one another. Given the
volume of existing literature, our review is not intended to be exhaustive.
Instead, we have preferred to focus on the most significant contributions in
both fields together with recent contributions that break new ground to spur
innovative research."
"Dynamic rescheduling decision-making problem is an important issue in modern
manufacturing system with the feature of combinational computation complexity.
This paper introduces a multi-agent based approach using the detailed process,
provided by Prometheus methodology, which used for the design of a simultaneous
dynamic rescheduling decision making for flexible flow line manufacturing
system that working under dynamic customer demand. The application has been
completely modeled with the Prometheus Design Tool (PDT), which offers full
support to Prometheus Methodology. The proposed dynamic scheduling decision
making system is developed for Automated UPVC door and Windows Company and can
be support both static and dynamic scheduling."
"A game theoretic distributed decision making approach is presented for the
problem of control effort allocation in a robotic team based on a novel variant
of fictitious play. The proposed learning process allows the robots to
accomplish their objectives by coordinating their actions in order to
efficiently complete their tasks. In particular, each robot of the team
predicts the other robots' planned actions while making decisions to maximise
their own expected reward that depends on the reward for joint successful
completion of the task. Action selection is interpreted as an $n$-player
cooperative game. The approach presented can be seen as part of the
\emph{Belief Desire Intention} (BDI) framework, also can address the problem of
cooperative, legal, safe, considerate and emphatic decisions by robots if their
individual and group rewards are suitably defined. After theoretical analysis
the performance of the proposed algorithm is tested on four simulation
scenarios. The first one is a coordination game between two material handling
robots, the second one is a warehouse patrolling task by a team of robots, the
third one presents a coordination mechanism between two robots that carry a
heavy object on a corridor and the fourth one is an example of coordination on
a sensors network."
"Published during a severe economic crisis, this study presents the first
spatial microsimulation model for the analysis of income inequalities and
poverty in Greece. First, we present a brief overview of the method and discuss
its potential for the analysis of multidimensional poverty and income
inequality in Greece. We then present the SimAthens model, based on a
combination of small-area demographic and socioeconomic information available
from the Greek census of population with data from the European Union
Statistics on Income and Living Conditions (EU-SILC). The model is based on an
iterative proportional fitting (IPF) algorithm, and is used to reweigh EU-SILC
records to fit in small-area descriptions for Athens based on 2001 and 2011
censuses. This is achieved by using demographic and socioeconomic
characteristics as constraint variables. Finally, synthesis of the labor market
and occupations are chosen as the main variables for externally validating our
results, in order to verify the integrity of the model. Results of this
external validation process are found to be extremely satisfactory, indicating
a high goodness of fit between simulated and real values. Finally, the study
presents a number of model outputs, illustrating changes in social and economic
geography, during a severe economic crisis, offering a great opportunity for
discussing further potential of this model in policy analysis."
"Provably safe and scalable multi-vehicle path planning is an important and
urgent problem due to the expected increase of automation in civilian airspace
in the near future. Although this problem has been studied in the past, there
has not been a method that guarantees both goal satisfaction and safety for
vehicles with general nonlinear dynamics while taking into account disturbances
and potential adversarial agents, to the best of our knowledge. Hamilton-Jacobi
(HJ) reachability is the ideal tool for guaranteeing goal satisfaction and
safety under such scenarios, and has been successfully applied to many
small-scale problems. However, a direct application of HJ reachability in most
cases becomes intractable when there are more than two vehicles due to the
exponentially scaling computational complexity with respect to system
dimension. In this paper, we take advantage of the guarantees HJ reachability
provides, and eliminate the computation burden by assigning a strict priority
ordering to the vehicles under consideration. Under this sequential path
planning (SPP) scheme, vehicles reserve ""space-time"" portions in the airspace,
and the space-time portions guarantee dynamic feasibility, collision avoidance,
and optimality of the paths given the priority ordering. With a computation
complexity that scales quadratically when accounting for both disturbances and
an intruder, and linearly when accounting for only disturbances, SPP can
tractably solve the multi-vehicle path planning problem for vehicles with
general nonlinear dynamics in a practical setting. We demonstrate our theory in
representative simulations."
"Distributed estimation and processing in networks modeled by graphs have
received a great deal of interest recently, due to the benefits of
decentralised processing in terms of performance and robustness to
communications link failure between nodes of the network. Diffusion-based
algorithms have been demonstrated to be among the most effective for
distributed signal processing problems, through the combination of local node
estimate updates and sharing of information with neighbour nodes through
diffusion. In this work, we develop a serial-inspired approach based on
message-passing strategies that provides a significant improvement in
performance over prior art. The concept of serial processing in the graph has
been successfully applied in sum-product based algorithms and here provides
inspiration for an algorithm which makes use of the most up-to-date information
in the graph in combination with the diffusion approach to offer improved
performance."
"We review disruptive innovations introduced in the RoboCup 2D Soccer
Simulation League over the twenty years since its inception, and trace the
progress of our champion team (Gliders). We conjecture that the League has been
developing as an ecosystem shaped by diverse approaches taken by participating
teams, increasing in its overall complexity. A common feature is that different
champion teams succeeded in finding a way to decompose the enormous
search-space of possible single- and multi-agent behaviours, by automating the
exploration of the problem space with various techniques which accelerated the
software development efforts. These methods included interactive debugging,
machine learning, automated planning, and opponent modelling. The winning
approach developed by Gliders is centred on human-based evolutionary
computation which optimised several components such as an action-dependent
evaluation function, dynamic tactics with Voronoi diagrams, information
dynamics, and bio-inspired collective behaviour."
"Advancement in intelligent transportation systems with complex operations
requires autonomous planning and management to avoid collisions in day-to-day
traffic. As failure and/or inadequacy in traffic safety system are
life-critical, such collisions must be detected and resolved in an efficient
way to manage continuously rising traffic. In this paper, we address different
types of collision scenarios along with their early detection and resolution
techniques in a complex railway system. In order to handle collisions
dynamically in distributed manner, a novel agent based solution approach is
proposed using the idea of max-sum algorithm, where each agent (train agent,
station agent, and junction agent) communicates and cooperates with others to
generate a good feasible solution that keeps the system in a safe state, i.e.,
collision free. We implement the proposed mechanism in Java Agent DEvelopment
Framework (JADE). The results are evaluated with exhaustive experiments and
compared with different existing collision handling methods to show the
efficiency of our proposed approach."
"Multi-agent systems (MAS) is able to characterize the behavior of individual
agent and the interaction between agents. Thus, it motivates us to leverage the
distributed constraint optimization problem (DCOP), a framework of modeling
MAS, to solve the user association problem in heterogeneous networks (HetNets).
Two issues we have to consider when we take DCOP into the application of HetNet
including: (i) How to set up an effective model by DCOP taking account of the
negtive impact of the increment of users on the modeling process (ii) Which
kind of algorithms is more suitable to balance the time consumption and the
quality of soltuion. Aiming to overcome these issues, we firstly come up with
an ECAV-$\eta$ (Each Connection As Variable) model in which a parameter $\eta$
with an adequate assignment ($\eta=3$ in this paper) is able to control the
scale of the model. After that, a Markov chain (MC) based algorithm is proposed
on the basis of log-sum-exp function. Experimental results show that the
solution obtained by DCOP framework is better than the one obtained by the
Max-SINR algorithm. Comparing with the Lagrange dual decomposition based method
(LDD), the solution performance has been improved since there is no need to
transform original problem into a satisfied one. In addition, it is also
apparent that the DCOP based method has better robustness than LDD when the
number of users increases but the available resource at base stations are
limited."
"Voter control problems model situations in which an external agent tries
toaffect the result of an election by adding or deleting the fewest number of
voters. The goal of the agent is to make a specific candidate either win
(\emph{constructive} control) or lose (\emph{destructive} control) the
election. We study the constructive and destructive voter control problems
whenadding and deleting voters have a \emph{combinatorial flavor}: If we add
(resp.\ delete) a voter~$v$, we also add (resp.\ delete) a bundle~$\kappa(v) $
of voters that are associated with~$v$. While the bundle~$\kappa(v)$ may have
more than one voter, a voter may also be associated with more than one voter.
We analyze the computational complexity of the four voter control problems for
the Plurality rule. We obtain that, in general, making a candidate lose is
computationally easier than making her win. In particular, if the bundling
relation is symmetric (i.e.\ $\forall w\colon w \in \kappa(v) \Leftrightarrow v
\in \kappa(w) $), and if each voter has at most two voters associated with him,
then destructive control is polynomial-time solvable while the constructive
variant remains $\NP$-hard. Even if the bundles are disjoint (i.e.\ $\forall
w\colon w \in \kappa(v) \Leftrightarrow \kappa(v) = \kappa(w) $), the
constructive problem variants remain intractable. Finally, the minimization
variant of constructive control by adding voters does not admit an efficient
approximation algorithm, unless P=NP."
"Affect Control Theory (ACT) is a powerful and general sociological model of
human affective interaction. ACT provides an empirically derived mathematical
model of culturally shared sentiments as heuristic guides for human decision
making. BayesACT, a variant on classical ACT, combines affective reasoning with
cognitive (denotative or logical) reasoning as is traditionally found in AI.
Bayes\-ACT allows for the creation of agents that are both emotionally guided
and goal-directed. In this work, we simulate BayesACT agents in the Iterated
Networked Prisoner's Dilemma (INPD), and we show four out of five known
properties of human play in INPD are replicated by these socio-affective
agents. In particular, we show how the observed human behaviours of network
structure invariance, anti-correlation of cooperation and reward, and player
type stratification are all clearly emergent properties of the networked
BayesACT agents. We further show that decision hyteresis (Moody Conditional
Cooperation) is replicated by BayesACT agents in over $2/3$ of the cases we
have considered. In contrast, previously used imitation-based agents are only
able to replicate one of the five properties. We discuss the implications of
these findings in the development of human-agent societies."
"In many problems, agents cooperate locally so that a leader or fusion center
can infer the state of every agent from probing the state of only a small
number of agents. Versions of this problem arise when a fusion center
reconstructs an extended physical field by accessing the state of just a few of
the sensors measuring the field, or a leader monitors the formation of a team
of robots. Given a link cost, the paper presents a polynomial time algorithm to
design a minimum cost coordinated network dynamics followed by the agents,
under an observability constraint. The problem is placed in the context of
structural observability and solved even when up to k agents in the coordinated
network dynamics fail."
"Multi-agents systems communication is a technology, which provides a way for
multiple interacting intelligent agents to communicate with each other and with
environment. Multiple-agent systems are used to solve problems that are
difficult for solving by individual agent. Multiple-agent communication
technologies can be used for management and organization of computing fog and
act as a global, distributed operating system. In present publication we
suggest technology, which combines decentralized P2P BOINC general-purpose
computing tasks distribution, multiple-agents communication protocol and
smart-contract based rewards, powered by Ethereum blockchain. Such system can
be used as distributed P2P computing power market, protected from any central
authority. Such decentralized market can further be updated to system, which
learns the most efficient way for software-hardware combinations usage and
optimization. Once system learns to optimize software-hardware efficiency it
can be updated to general-purpose distributed intelligence, which acts as
combination of single-purpose AI."
"One of the key challenges for multi-agent learning is scalability. In this
paper, we introduce a technique for speeding up multi-agent learning by
exploiting concurrent and incremental experience sharing. This solution
adaptively identifies opportunities to transfer experiences between agents and
allows for the rapid acquisition of appropriate policies in large-scale,
stochastic, homogeneous multi-agent systems. We introduce an online,
distributed, supervisor-directed transfer technique for constructing high-level
characterizations of an agent's dynamic learning environment---called
contexts---which are used to identify groups of agents operating under
approximately similar dynamics within a short temporal window. A set of
supervisory agents computes contextual information for groups of subordinate
agents, thereby identifying candidates for experience sharing. Our method uses
a tiered architecture to propagate, with low communication overhead, state,
action, and reward data amongst the members of each dynamically-identified
information-sharing group. We applied this method to a large-scale distributed
task allocation problem with hundreds of information-sharing agents operating
in an unknown, non-stationary environment. We demonstrate that our approach
results in significant performance gains, that it is robust to noise-corrupted
or suboptimal context features, and that communication costs scale linearly
with the supervisor-to-subordinate ratio."
"The problem of achieving common understanding between agents that use
different vocabularies has been mainly addressed by designing techniques that
explicitly negotiate mappings between their vocabularies, requiring agents to
share a meta-language. In this paper we consider the case of agents that use
different vocabularies and have no meta-language in common, but share the
knowledge of how to perform a task, given by the specification of an
interaction protocol. For this situation, we present a framework that lets
agents learn a vocabulary alignment from the experience of interacting. Unlike
previous work in this direction, we use open protocols that constrain possible
actions instead of defining procedures, making our approach more general. We
present two techniques that can be used either to learn an alignment from
scratch or to repair an existent one, and we evaluate experimentally their
performance."
"The integration of multiple viewpoints became an increasingly popular
approach to deal with agent-based simulations. Despite their disparities,
recent approaches successfully manage to run such multi-level simulations. Yet,
are they doing it appropriately?
  This paper tries to answer that question, with an analysis based on a generic
model of the temporal dynamics of multi-level simulations. This generic model
is then used to build an orthogonal approach to multi-level simulation called
SIMILAR. In this approach, most time-related issues are explicitly modeled,
owing to an implementation-oriented approach based on the influence/reaction
principle."
"Norms have been extensively proposed as coordination mechanisms for both
agent and human societies. Nevertheless, choosing the norms to regulate a
society is by no means straightforward. The reasons are twofold. First, the
norms to choose from may not be independent (i.e, they can be related to each
other). Second, different preference criteria may be applied when choosing the
norms to enact. This paper advances the state of the art by modeling a series
of decision-making problems that regulation authorities confront when choosing
the policies to establish. In order to do so, we first identify three different
norm relationships -namely, generalisation, exclusivity, and substitutability-
and we then consider norm representation power, cost, and associated moral
values as alternative preference criteria. Thereafter, we show that the
decision-making problems faced by policy makers can be encoded as linear
programs, and hence solved with the aid of state-of-the-art solvers."
"The paper proposes a hierarchical, agent-based, DES supported, distributed
architecture for networked organization control. Taking into account enterprise
integration engineering frameworks and business process management techniques,
the paper intends to apply control engineering approaches for solving some
problems of coordinating networked organizations, such as performance
evaluation and optimization of workflows."
"Residential microgrids (MGs) may host a large number of Distributed Energy
Resources (DERs). The strategy that maximizes the revenue for each individual
DER is the one in which the DER operates at capacity, injecting all available
power into the grid. However, when the DER penetration is high and the
consumption low, this strategy may lead to power surplus that causes voltage
increase over recommended limits. In order to create incentives for the DER to
operate below capacity, we propose a proportional-fairness control strategy in
which (i) a subset of DERs decrease their own power output, sacrificing the
individual revenue, and (ii) the DERs in the subset are dynamically selected
based on the record of their control history. The trustworthy implementation of
the scheme is carried out through a custom-designed blockchain mechanism that
maintains a distributed database trusted by all DERs. In particular, the
blockchain is used to stipulate and store a smart contract that enforces
proportional fairness. The simulation results verify the potential of the
proposed framework."
"Society has become more dependent on automated intelligent systems, at the
same time, these systems have become more and more complicated. Society's
expectation regarding the capabilities and intelligence of such systems has
also grown. We have become a more complicated society with more complicated
problems. As the expectation of intelligent systems rises, we discover many
more applications for artificial intelligence. Additionally, as the difficulty
level and computational requirements of such problems rise, there is a need to
distribute the problem solving. Although the field of multiagent systems (MAS)
and distributed artificial intelligence (DAI) is relatively young, the
importance and applicability of this technology for solving today's problems
continue to grow. In multiagent systems, the main goal is to provide fruitful
cooperation among agents in order to enrich the support given to all user
activities. This paper deals with the development of a multiagent system aimed
at solving the reservation problems encountered in rural tourism. Due to their
benefits over the last few years, online travel agencies have become a very
useful instrument in planning vacations. A MAS concept (which is based on the
Internet exploitation) can improve this activity and provide clients with a
new, rapid and efficient way of making accommodation arrangements."
"The efficient use of available resources is a key factor in achieving success
on both personal and organizational levels. One of the crucial resources in
knowledge economy is time. The ability to force others to adapt to our schedule
even if it harms their efficiency can be seen as an outcome of social
stratification. The principal objective of this paper is to use time allocation
to model and study the global efficiency of social stratification, and to
reveal whether hierarchy is an emergent property. A multi-agent model with an
evolving social network is used to verify our hypotheses. The network's
evolution is driven by the intensity of inter-agent communications, and the
communications as such depend on the preferences and time resources of the
communicating agents. The entire system is to be perceived as a metaphor of a
social network of people regularly filling out agenda for their meetings for a
period of time. The overall efficiency of the network of those scheduling
agents is measured by the average utilization of the agent's preferences to
speak on specific subjects. The simulation results shed light on the effects of
different scheduling methods, resource availabilities, and network evolution
mechanisms on communication system efficiency. The non-stratified systems show
better long-term efficiency. Moreover, in the long term hierarchy disappears in
overwhelming majority of cases. Some exceptions are observed for cases where
privileges are granted on the basis of node degree weighted by relationship
intensities but only in the short term."
"We consider a team of heterogeneous robots which are deployed within a common
workspace to gather different types of data. The robots have different roles
due to different capabilities: some gather data from the workspace (source
robots) and others receive data from source robots and upload them to a data
center (relay robots). The data-gathering tasks are specified locally to each
source robot as high-level Linear Temporal Logic (LTL) formulas, that capture
the different types of data that need to be gathered at different regions of
interest. All robots have a limited buffer to store the data. Thus the data
gathered by source robots should be transferred to relay robots before their
buffers overflow, respecting at the same time limited communication range for
all robots. The main contribution of this work is a distributed motion
coordination and intermittent communication scheme that guarantees the
satisfaction of all local tasks, while obeying the above constraints. The robot
motion and inter-robot communication are closely coupled and coordinated during
run time by scheduling intermittent meeting events to facilitate the local plan
execution. We present both numerical simulations and experimental studies to
demonstrate the advantages of the proposed method over existing approaches that
predominantly require all-time network connectivity."
"We summarise the results of RoboCup 2D Soccer Simulation League in 2016
(Leipzig), including the main competition and the evaluation round. The
evaluation round held in Leipzig confirmed the strength of RoboCup-2015
champion (WrightEagle, i.e. WE2015) in the League, with only eventual finalists
of 2016 competition capable of defeating WE2015. An extended, post-Leipzig,
round-robin tournament which included the top 8 teams of 2016, as well as
WE2015, with over 1000 games played for each pair, placed WE2015 third behind
the champion team (Gliders2016) and the runner-up (HELIOS2016). This
establishes WE2015 as a stable benchmark for the 2D Simulation League. We then
contrast two ranking methods and suggest two options for future evaluation
challenges. The first one, ""The Champions Simulation League"", is proposed to
include 6 previous champions, directly competing against each other in a
round-robin tournament, with the view to systematically trace the advancements
in the League. The second proposal, ""The Global Challenge"", is aimed to
increase the realism of the environmental conditions during the simulated
games, by simulating specific features of different participating countries."
"The World Wide Web is fast becoming a source of information for a large part
of the world's population. Because of its sheer size and complexity users often
resort to recommendations from others to decide which sites to visit. We
present a dynamical theory of recommendations which predicts site visits by
users of the World Wide Web. We show that it leads to a universal power law for
the number of users that visit given sites over periods of time, with an
exponent related to the rate at which users discover new sites on their own. An
extensive empirical study of user behavior in the Web that we conducted
confirms the existence of this law of influence while yielding bounds on the
rate of novelty encountered by users."
"We address the issues of semantics and conversations for agent communication
languages and the Knowledge Query Manipulation Language (KQML) in particular.
Based on ideas from speech act theory, we present a semantic description for
KQML that associates ``cognitive'' states of the agent with the use of the
language's primitives (performatives). We have used this approach to describe
the semantics for the whole set of reserved KQML performatives. Building on the
semantics, we devise the conversation policies, i.e., a formal description of
how KQML performatives may be combined into KQML exchanges (conversations),
using a Definite Clause Grammar. Our research offers methods for a speech act
theory-based semantic description of a language of communication acts and for
the specification of the protocols associated with these acts. Languages of
communication acts address the issue of communication among software
applications at a level of abstraction that is useful to the emerging software
agents paradigm."
"With the increasing use of mobile workstations for a wide variety of tasks
and associated information needs, and with many variations of available
networks, access to data becomes a prime consideration. This paper discusses
issues of workstation mobility and proposes a solution wherein the data
structures are accessed in an encapsulated form - through the Portable File
System (PFS) wrapper. The paper discusses an implementation of the Portable
File System, highlighting the architecture and commenting upon performance of
an experimental system. Although investigations have been focused upon mobile
access of WWW documents, this technique could be applied to any mobile data
access situation."
"We present our approach to the problem of how an agent, within an economic
Multi-Agent System, can determine when it should behave strategically (i.e.
learn and use models of other agents), and when it should act as a simple
price-taker. We provide a framework for the incremental implementation of
modeling capabilities in agents, and a description of the forms of knowledge
required. The agents were implemented and different populations simulated in
order to learn more about their behavior and the merits of using and learning
agent models. Our results show, among other lessons, how savvy buyers can avoid
being ``cheated'' by sellers, how price volatility can be used to
quantitatively predict the benefits of deeper models, and how specific types of
agent populations influence system behavior."
"Coalition formation is a key topic in multiagent systems. One would prefer a
coalition structure that maximizes the sum of the values of the coalitions, but
often the number of coalition structures is too large to allow exhaustive
search for the optimal one. But then, can the coalition structure found via a
partial search be guaranteed to be within a bound from optimum? We show that
none of the previous coalition structure generation algorithms can establish
any bound because they search fewer nodes than a threshold that we show
necessary for establishing a bound. We present an algorithm that establishes a
tight bound within this minimal amount of search, and show that any other
algorithm would have to search strictly more. The fraction of nodes needed to
be searched approaches zero as the number of agents grows. If additional time
remains, our anytime algorithm searches further, and establishes a
progressively lower tight bound. Surprisingly, just searching one more node
drops the bound in half. As desired, our algorithm lowers the bound rapidly
early on, and exhibits diminishing returns to computation. It also drastically
outperforms its obvious contenders. Finally, we show how to distribute the
desired search across self-interested manipulative agents."
"We present a new approach to the simulation and analysis of immune system
behavior. The simulations that can be done with our software package called
SIMMUNE are based on immunological data that describe the behavior of immune
system agents (cells, molecules) on a microscopial (i.e. agent-agent
interaction) scale by defining cellular stimulus-response mechanisms. Since the
behavior of the agents in SIMMUNE can be very flexibly configured, its
application is not limited to immune system simulations. We outline the
principles of SIMMUNE's multiscale analysis of emergent structure within the
simulated immune system that allow the identification of immunological contexts
using minimal a priori assumptions about the higher level organization of the
immune system."
"This paper presents some fundamental collective choice theory for information
system designers, particularly those working in the field of computer-supported
cooperative work. This paper is focused on a presentation of Arrow's
Possibility and Impossibility theorems which form the fundamental boundary on
the efficacy of collective choice: voting and selection procedures. It restates
the conditions that Arrow placed on collective choice functions in more
rigorous second-order logic, which could be used as a set of test conditions
for implementations, and a useful probabilistic result for analyzing votes on
issue pairs. It also describes some simple collective choice functions. There
is also some discussion of how enterprises should approach putting their
resources under collective control: giving an outline of a superstructure of
performative agents to carry out this function and what distributing processing
technology would be needed."
"We describe a framework and equations used to model and predict the behavior
of multi-agent systems (MASs) with learning agents. A difference equation is
used for calculating the progression of an agent's error in its decision
function, thereby telling us how the agent is expected to fare in the MAS. The
equation relies on parameters which capture the agent's learning abilities,
such as its change rate, learning rate and retention rate, as well as relevant
aspects of the MAS such as the impact that agents have on each other. We
validate the framework with experimental results using reinforcement learning
agents in a market system, as well as with other experimental results gathered
from the AI literature. Finally, we use PAC-theory to show how to calculate
bounds on the values of the learning parameters."
"With the increase in agent-based applications, there are now agent systems
that support \emph{concurrent} client accesses. The ability to process large
volumes of simultaneous requests is critical in many such applications. In such
a setting, the traditional approach of serving these requests one at a time via
queues (e.g. \textsf{FIFO} queues, priority queues) is insufficient.
Alternative models are essential to improve the performance of such
\emph{heavily loaded} agents. In this paper, we propose a set of
\emph{cost-based algorithms} to \emph{optimize} and \emph{merge} multiple
requests submitted to an agent. In order to merge a set of requests, one first
needs to identify commonalities among such requests. First, we provide an
\emph{application independent framework} within which an agent developer may
specify relationships (called \emph{invariants}) between requests. Second, we
provide two algorithms (and various accompanying heuristics) which allow an
agent to automatically rewrite requests so as to avoid redundant work---these
algorithms take invariants associated with the agent into account. Our
algorithms are independent of any specific agent framework. For an
implementation, we implemented both these algorithms on top of the \impact
agent development platform, and on top of a (non-\impact) geographic database
agent. Based on these implementations, we conducted experiments and show that
our algorithms are considerably more efficient than methods that use the $A^*$
algorithm."
"The search for information on the web is faced with several problems, which
arise on the one hand from the vast number of available sources, and on the
other hand from their heterogeneity. A promising approach is the use of
multi-agent systems of information agents, which cooperatively solve advanced
information-retrieval problems. This requires capabilities to address complex
tasks, such as search and assessment of sources, query planning, information
merging and fusion, dealing with incomplete information, and handling of
inconsistency. In this paper, our interest is in the role which some methods
from the field of declarative logic programming can play in the realization of
reasoning capabilities for information agents. In particular, we are interested
in how they can be used and further developed for the specific needs of this
application domain. We review some existing systems and current projects, which
address information-integration problems. We then focus on declarative
knowledge-representation methods, and review and evaluate approaches from logic
programming and nonmonotonic reasoning for information agents. We discuss
advantages and drawbacks, and point out possible extensions and open issues."
"This paper reviews the origins of interface agents, discusses challenges that
exist within the interface agent field and presents a survey of current
attempts to find solutions to these challenges. A history of agent systems from
their birth in the 1960's to the current day is described, along with the
issues they try to address. A taxonomy of interface agent systems is presented,
and today's agent systems categorized accordingly. Lastly, an analysis of the
machine learning and user modelling techniques used by today's agents is
presented."
"In this paper we introduce a qualitative decision and game theory based on
belief (B) and desire (D) rules. We show that a group of agents acts as if it
is maximizing achieved joint goals."
"Recent advances in Multiagent Systems (MAS) and Epistemic Logic within
Distributed Systems Theory, have used various combinatorial structures that
model both the geometry of the systems and the Kripke model structure of models
for the logic. Examining one of the simpler versions of these models,
interpreted systems, and the related Kripke semantics of the logic $S5_n$ (an
epistemic logic with $n$-agents), the similarities with the geometric /
homotopy theoretic structure of groupoid atlases is striking. These latter
objects arise in problems within algebraic K-theory, an area of algebra linked
to the study of decomposition and normal form theorems in linear algebra. They
have a natural well structured notion of path and constructions of path
objects, etc., that yield a rich homotopy theory."
"This paper proposes to model the intracellular signalling networks using a
fusion of behaviour-based systems and the blackboard architecture. In virtue of
this fusion, the model developed by us, which has been named Cellulat, allows
to take account two essential aspects of the intracellular signalling networks:
(1) the cognitive capabilities of certain types of networks' components and (2)
the high level of spatial organization of these networks. A simple example of
modelling of Ca2+ signalling pathways using Cellulat is presented here. An
intracellular signalling virtual laboratory is being developed from Cellulat."
"A cell can be seen as an adaptive autonomous agent or as a society of
adaptive autonomous agents, where each can exhibit a particular behaviour
depending on its cognitive capabilities. We present an intracellular signalling
model obtained by integrating several computational techniques into an
agent-based paradigm. Cellulat, the model, takes into account two essential
aspects of the intracellular signalling networks: cognitive capacities and a
spatial organization. Exemplifying the functionality of the system by modelling
the EGFR signalling pathway, we discuss the methodology as well as the purposes
of an intracellular signalling virtual laboratory, presently under development."
"We introduce the topic of learning in multiagent systems. We first provide a
quick introduction to the field of game theory, focusing on the equilibrium
concepts of iterated dominance, and Nash equilibrium. We show some of the most
relevant findings in the theory of learning in games, including theorems on
fictitious play, replicator dynamics, and evolutionary stable strategies. The
CLRI theory and n-level learning agents are introduced as attempts to apply
some of these findings to the problem of engineering multiagent systems with
learning agents. Finally, we summarize some of the remaining challenges in the
field of learning in multiagent systems."
"Recently, Jadbabaie, Lin, and Morse (IEEE TAC, 48(6)2003:988-1001) offered a
mathematical analysis of the discrete time model of groups of mobile autonomous
agents raised by Vicsek et al. in 1995. In their paper, Jadbabaie et al. showed
that all agents shall move in the same heading, provided that these agents are
periodically linked together. This paper sharpens this result by showing that
coordination will be reached under a very weak condition that requires all
agents are finally linked together. This condition is also strictly weaker than
the one Jadbabaie et al. desired."
"Fairly rapid environmental changes call for continuous surveillance and
on-line decision making. There are two main areas where IT technologies can be
valuable. In this paper we present a multi-agent system for monitoring and
assessing air-quality attributes, which uses data coming from a meteorological
station. A community of software agents is assigned to monitor and validate
measurements coming from several sensors, to assess air-quality, and, finally,
to fire alarms to appropriate recipients, when needed. Data mining techniques
have been used for adding data-driven, customized intelligence into agents. The
architecture of the developed system, its domain ontology, and typical agent
interactions are presented. Finally, the deployment of a real-world test case
is demonstrated."
"Combining two or more items and selling them as one good, a practice called
bundling, can be a very effective strategy for reducing the costs of producing,
marketing, and selling goods. In this paper, we consider a form of multi-issue
negotiation where a shop negotiates both the contents and the price of bundles
of goods with his customers. We present some key insights about, as well as a
technique for, locating mutually beneficial alternatives to the bundle
currently under negotiation. The essence of our approach lies in combining
historical sales data, condensed into aggregate knowledge, with current data
about the ongoing negotiation process, to exploit these insights. In
particular, when negotiating a given bundle of goods with a customer, the shop
analyzes the sequence of the customer's offers to determine the progress in the
negotiation process. In addition, it uses aggregate knowledge concerning
customers' valuations of goods in general. We show how the shop can use these
two sources of data to locate promising alternatives to the current bundle.
When the current negotiation's progress slows down, the shop may suggest the
most promising of those alternatives and, depending on the customer's response,
continue negotiating about the alternative bundle, or propose another
alternative. Extensive computer simulation experiments show that our approach
increases the speed with which deals are reached, as well as the number and
quality of the deals reached, as compared to a benchmark. In addition, we show
that the performance of our system is robust to a variety of changes in the
negotiation strategies employed by the customers."
"in this paper we describe a method which allows agents to dynamically select
protocols and roles when they need to execute collaborative tasks"
"We define and construct a new data structure, the tables, this structure
generalizes the (finite) $k$-sets sets of Eilenberg \cite{Ei}, it is versatile
(one can vary the letters, the words and the coefficients). We derive from this
structure a new semiring (with several semiring structures) which can be
applied to the needs of automatic processing multi-agents behaviour problems.
The purpose of this account/paper is to present also the basic elements of this
new structures from a combinatorial point of view. These structures present a
bunch of properties. They will be endowed with several laws namely : Sum,
Hadamard product, Cauchy product, Fuzzy operations (min, max, complemented
product) Two groups of applications are presented. The first group is linked to
the process of ""forgetting"" information in the tables. The second, linked to
multi-agent systems, is announced by showing a methodology to manage emergent
organization from individual behaviour models."
"This paper presents a methodology for optimal target detection in a multi
sensor surveillance system. The system consists of mobile sensors that guard a
rectangular surveillance zone crisscrossed by moving targets. Targets percolate
the surveillance zone in a poisson fashion with uniform velocities. Under these
statistics this paper computes a motion strategy for a sensor that maximizes
target detections for the next T time steps. A coordination mechanism between
sensors ensures that overlapping areas between sensors is reduced. This
coordination mechanism is interleaved with the motion strategy computation to
reduce detections of the same target by more than one sensor. To avoid an
exhaustive search in the joint space of all sensors the coordination mechanism
constraints the search by assigning priorities to the sensors. A comparison of
this methodology with other multi target tracking schemes verifies its efficacy
in maximizing detections. A tabulation of these comparisons is reported in
results section of the paper"
"Simulations of artificial stock markets were considered as early as 1964 and
multi-agent ones were introduced as early as 1989. Starting the early 90's,
collaborations of economists and physicists produced increasingly realistic
simulation platforms. Currently, the market stylized facts are easily
reproduced and one has now to address the realistic details of the Market
Microstructure and of the Traders Behaviour. This calls for new methods and
tools capable of bridging smoothly between simulations and experiments in
economics.
  We propose here the following Avatar-Based Method (ABM). The subjects
implement and maintain their Avatars (programs encoding their personal decision
making procedures) on NatLab, a market simulation platform. Once these
procedures are fed in a computer edible format, they can be operationally used
as such without the need for belabouring, interpreting or conceptualising them.
Thus ABM short-circuits the usual behavioural economics experiments that search
for the psychological mechanisms underlying the subjects behaviour. Finally,
ABM maintains a level of objectivity close to the classical behaviourism while
extending its scope to subjects' decision making mechanisms.
  We report on experiments where Avatars designed and maintained by humans from
different backgrounds (including real traders) compete in a continuous
double-auction market. We hope this unbiased way of capturing the adaptive
evolution of real subjects behaviour may lead to a new kind of behavioural
economics experiments with a high degree of reliability, analysability and
reproducibility."
"In this paper, we deal with some specific domains of applications to game
theory. This is one of the major class of models in the new approaches of
modelling in the economic domain. For that, we use genetic automata which allow
to buid adaptive strategies for the players. We explain how the automata-based
formalism proposed - matrix representation of automata with multiplicities -
allows to define a semi-distance between the strategy behaviors. With that
tools, we are able to generate an automatic processus to compute emergent
systems of entities whose behaviors are represented by these genetic automata."
"In order to overcome difficult dynamic optimization and environment extrema
tracking problems, We propose a Self-Regulated Swarm (SRS) algorithm which
hybridizes the advantageous characteristics of Swarm Intelligence as the
emergence of a societal environmental memory or cognitive map via collective
pheromone laying in the landscape (properly balancing the
exploration/exploitation nature of our dynamic search strategy), with a simple
Evolutionary mechanism that trough a direct reproduction procedure linked to
local environmental features is able to self-regulate the above exploratory
swarm population, speeding it up globally. In order to test his adaptive
response and robustness, we have recurred to different dynamic multimodal
complex functions as well as to Dynamic Optimization Control problems,
measuring reaction speeds and performance. Final comparisons were made with
standard Genetic Algorithms (GAs), Bacterial Foraging strategies (BFOA), as
well as with recent Co-Evolutionary approaches. SRS's were able to demonstrate
quick adaptive responses, while outperforming the results obtained by the other
approaches. Additionally, some successful behaviors were found. One of the most
interesting illustrate that the present SRS collective swarm of bio-inspired
ant-like agents is able to track about 65% of moving peaks traveling up to ten
times faster than the velocity of a single individual composing that precise
swarm tracking system."
"Artificial life models, swarm intelligent and evolutionary computation
algorithms are usually built on fixed size populations. Some studies indicate
however that varying the population size can increase the adaptability of these
systems and their capability to react to changing environments. In this paper
we present an extended model of an artificial ant colony system designed to
evolve on digital image habitats. We will show that the present swarm can adapt
the size of the population according to the type of image on which it is
evolving and reacting faster to changing images, thus converging more rapidly
to the new desired regions, regulating the number of his image foraging agents.
Finally, we will show evidences that the model can be associated with the
Mathematical Morphology Watershed algorithm to improve the segmentation of
digital grey-scale images. KEYWORDS: Swarm Intelligence, Perception and Image
Processing, Pattern Recognition, Mathematical Morphology, Social Cognitive
Maps, Social Foraging, Self-Organization, Distributed Search."
"Physical processes are computations only when we use them to externalize
thought. Computation is the performance of one or more fixed processes within a
contingent environment. We reformulate the Church-Turing thesis so that it
applies to programs rather than to computability. When suitably formulated
agent-based computing in an open, multi-scalar environment represents the
current consensus view of how we interact with the world. But we don't know how
to formulate multi-scalar environments."
"We investigate knowledge exchange among commercial organisations, the
rationale behind it and its effects on the market. Knowledge exchange is known
to be beneficial for industry, but in order to explain it, authors have used
high level concepts like network effects, reputation and trust. We attempt to
formalise a plausible and elegant explanation of how and why companies adopt
information exchange and why it benefits the market as a whole when this
happens. This explanation is based on a multi-agent model that simulates a
market of software providers. Even though the model does not include any
high-level concepts, information exchange naturally emerges during simulations
as a successful profitable behaviour. The conclusions reached by this
agent-based analysis are twofold: (1) A straightforward set of assumptions is
enough to give rise to exchange in a software market. (2) Knowledge exchange is
shown to increase the efficiency of the market."
"The biologically-inspired swarm paradigm is being used to design
self-organizing systems of locally interacting artificial agents. A major
difficulty in designing swarms with desired characteristics is understanding
the causal relation between individual agent and collective behaviors.
Mathematical analysis of swarm dynamics can address this difficulty to gain
insight into system design. This paper proposes a framework for mathematical
modeling of swarms of microscopic robots that may one day be useful in medical
applications. While such devices do not yet exist, the modeling approach can be
helpful in identifying various design trade-offs for the robots and be a useful
guide for their eventual fabrication. Specifically, we examine microscopic
robots that reside in a fluid, for example, a bloodstream, and are able to
detect and respond to different chemicals. We present the general mathematical
model of a scenario in which robots locate a chemical source. We solve the
scenario in one-dimension and show how results can be used to evaluate certain
design decisions."
"It has been argued that a central objective of nanotechnology is to make
products inexpensively, and that self-replication is an effective approach to
very low-cost manufacturing. The research presented here is intended to be a
step towards this vision. We describe a computational simulation of nanoscale
machines floating in a virtual liquid. The machines can bond together to form
strands (chains) that self-replicate and self-assemble into user-specified
meshes. There are four types of machines and the sequence of machine types in a
strand determines the shape of the mesh they will build. A strand may be in an
unfolded state, in which the bonds are straight, or in a folded state, in which
the bond angles depend on the types of machines. By choosing the sequence of
machine types in a strand, the user can specify a variety of polygonal shapes.
A simulation typically begins with an initial unfolded seed strand in a soup of
unbonded machines. The seed strand replicates by bonding with free machines in
the soup. The child strands fold into the encoded polygonal shape, and then the
polygons drift together and bond to form a mesh. We demonstrate that a variety
of polygonal meshes can be manufactured in the simulation, by simply changing
the sequence of machine types in the seed."
"In this paper we propose a Multi-Objective Ant Colony Optimization (MOACO)
algorithm called CHAC, which has been designed to solve the problem of finding
the path on a map (corresponding to a simulated battlefield) that minimizes
resources while maximizing safety. CHAC has been tested with two different
state transition rules: an aggregative function that combines the heuristic and
pheromone information of both objectives and a second one that is based on the
dominance concept of multiobjective optimization problems. These rules have
been evaluated in several different situations (maps with different degree of
difficulty), and we have found that they yield better results than a greedy
algorithm (taken as baseline) in addition to a military behaviour that is also
better in the tactical sense. The aggregative function, in general, yields
better results than the one based on dominance."
"Community structure identification has been one of the most popular research
areas in recent years due to its applicability to the wide scale of
disciplines. To detect communities in varied topics, there have been many
algorithms proposed so far. However, most of them still have some drawbacks to
be addressed. In this paper, we present an agent-based based community
detection algorithm. The algorithm that is a stochastic one makes use of agents
by forcing them to perform biased moves in a smart way. Using the information
collected by the traverses of these agents in the network, the network
structure is revealed. Also, the network modularity is used for determining the
number of communities. Our algorithm removes the need for prior knowledge about
the network such as number of the communities or any threshold values.
Furthermore, the definite community structure is provided as a result instead
of giving some structures requiring further processes. Besides, the
computational and time costs are optimized because of using thread like working
agents. The algorithm is tested on three network data of different types and
sizes named Zachary karate club, college football and political books. For all
three networks, the real network structures are identified in almost every run."
"This paper develops and compares two simple asynchronous distributed
searchlight scheduling algorithms for multiple robotic agents in nonconvex
polygonal environments. A searchlight is a ray emitted by an agent which cannot
penetrate the boundary of the environment. A point is detected by a searchlight
if and only if the point is on the ray at some instant. Targets are points
which can move continuously with unbounded speed. The objective of the proposed
algorithms is for the agents to coordinate the slewing (rotation about a point)
of their searchlights in a distributed manner, i.e., using only local sensing
and limited communication, such that any target will necessarily be detected in
finite time. The first algorithm we develop, called the DOWSS (Distributed One
Way Sweep Strategy), is a distributed version of a known algorithm described
originally in 1990 by Sugihara et al \cite{KS-IS-MY:90}, but it can be very
slow in clearing the entire environment because only one searchlight may slew
at a time. In an effort to reduce the time to clear the environment, we develop
a second algorithm, called the PTSS (Parallel Tree Sweep Strategy), in which
searchlights sweep in parallel if guards are placed according to an environment
partition belonging to a class we call PTSS partitions. Finally, we discuss how
DOWSS and PTSS could be combined with with deployment, or extended to
environments with holes."
"Game theory has many limitations implicit in its application. By utilizing
multiagent modeling, it is possible to solve a number of problems that are
unsolvable using traditional game theory. In this paper reinforcement learning
is applied to neural networks to create intelligent agents"
"This paper presents a proposal for a flexible agent mobility architecture
based on IEEE-FIPA standards and intended to be one of them. This proposal is a
first step towards interoperable mobility mechanisms, which are needed for
future agent migration between different kinds of platforms. Our proposal is
presented as a flexible and robust architecture that has been successfully
implemented in the JADE and AgentScape platforms. It is based on an open set of
protocols, allowing new protocols and future improvements to be accommodated in
the architecture. With this proposal we demonstrate that a standard
architecture for agent mobility capable of supporting several agent platforms
can be defined and implemented."
"This paper treats the problem of the merging of formations, where the
underlying model of a formation is graphical. We first analyze the rigidity and
persistence of meta-formations, which are formations obtained by connecting
several rigid or persistent formations. Persistence is a generalization to
directed graphs of the undirected notion of rigidity. In the context of moving
autonomous agent formations, persistence characterizes the efficacy of a
directed structure of unilateral distance constraints seeking to preserve a
formation shape. We derive then, for agents evolving in a two- or
three-dimensional space, the conditions under which a set of persistent
formations can be merged into a persistent meta-formation, and give the minimal
number of interconnections needed for such a merging. We also give conditions
for a meta-formation obtained by merging several persistent formations to be
persistent."
"New methods are being employed to meet the Navy's changing
software-development environment."
"We proposed in previous papers an extension and an implementation of the
STROBE model, which regards the Agents as Scheme interpreters. These Agents are
able to interpret messages in a dedicated environment including an interpreter
that learns from the current conversation therefore representing evolving
meta-level Agent's knowledge. When the Agent's interpreter is a
nondeterministic one, the dialogues may consist of subsequent refinements of
specifications in the form of constraint sets. The paper presents a worked out
example of dynamic service generation - such as necessary on Grids - by
exploiting STROBE Agents equipped with a nondeterministic interpreter. It shows
how enabling dynamic specification of a problem. Then it illustrates how these
principles could be effective for other applications. Details of the
implementation are not provided here, but are available."
"In this paper we present a method of discrete modeling and analysis of
multi-level dynamics of complex large-scale hierarchical dynamic systems
subject to external dynamic control mechanism. In a model each state describes
parallel dynamics and simultaneous trends of changes in system parameters. The
essence of the approach is in analysis of system state dynamics while it is in
the control loop."
"We discuss for the concept of promises within a framework that can be applied
to either humans or technology. We compare promises to the more established
notion of obligations and find promises to be both simpler and more effective
at reducing uncertainty in behavioural outcomes."
"Classification of some objects in classes of concepts is an essential and
even breathtaking task in many applications. A solution is discussed here based
on Multi-Agent systems. A kernel of some expert agents in several classes is to
consult a central agent decide among the classification problem of a certain
object. This kernel is moderated with the center agent, trying to manage the
querying agents for any decision problem by means of a data-header like feature
set. Agents have cooperation among concepts related to the classes of this
classification decision-making; and may affect on each others' results on a
certain query object in a multi-agent learning approach. This leads to an
online feature learning via the consulting trend. The performance is discussed
to be much better in comparison to some other prior trends while system's
message passing overload is decreased to less agents and the expertism helps
the performance and operability of system win the comparison."
"We investigate ways for the exchange of information (explicit communication)
among deaf and dumb mobile robots scattered in the plane. We introduce the use
of movement-signals (analogously to flight signals and bees waggle) as a mean
to transfer messages, enabling the use of distributed algorithms among the
robots. We propose one-to-one deterministic movement protocols that implement
explicit communication. We first present protocols for synchronous robots. We
begin with a very simple coding protocol for two robots. Based on on this
protocol, we provide one-to-one communication for any system of n \geq 2 robots
equipped with observable IDs that agree on a common direction (sense of
direction). We then propose two solutions enabling one-to-one communication
among anonymous robots. Since the robots are devoid of observable IDs, both
protocols build recognition mechanisms using the (weak) capabilities offered to
the robots. The first protocol assumes that the robots agree on a common
direction and a common handedness (chirality), while the second protocol
assumes chirality only. Next, we show how the movements of robots can provide
implicit acknowledgments in asynchronous systems. We use this result to design
asynchronous one-to-one communication with two robots only. Finally, we combine
this solution with the schemes developed in synchronous settings to fit the
general case of asynchronous one-to-one communication among any number of
robots. Our protocols enable the use of distributing algorithms based on
message exchanges among swarms of Stigmergic robots. Furthermore, they provides
robots equipped with means of communication to overcome faults of their
communication device."
"We view Digital Ecosystems to be the digital counterparts of biological
ecosystems, which are considered to be robust, self-organising and scalable
architectures that can automatically solve complex, dynamic problems. So, this
work is concerned with the creation, investigation, and optimisation of Digital
Ecosystems, exploiting the self-organising properties of biological ecosystems.
First, we created the Digital Ecosystem, a novel optimisation technique
inspired by biological ecosystems, where the optimisation works at two levels:
a first optimisation, migration of agents which are distributed in a
decentralised peer-to-peer network, operating continuously in time; this
process feeds a second optimisation based on evolutionary computing that
operates locally on single peers and is aimed at finding solutions to satisfy
locally relevant constraints. We then investigated its self-organising aspects,
starting with an extension to the definition of Physical Complexity to include
evolving agent populations. Next, we established stability of evolving agent
populations over time, by extending the Chli-DeWilde definition of agent
stability to include evolutionary dynamics. Further, we evaluated the diversity
of the software agents within evolving agent populations. To conclude, we
considered alternative augmentations to optimise and accelerate our Digital
Ecosystem, by studying the accelerating effect of a clustering catalyst on the
evolutionary dynamics. We also studied the optimising effect of targeted
migration on the ecological dynamics, through the indirect and emergent
optimisation of the agent migration patterns. Overall, we have advanced the
understanding of creating Digital Ecosystems, the self-organisation that occurs
within them, and the optimisation of their Ecosystem-Oriented Architecture."
"Submodular functions are an important class of functions in combinatorial
optimization which satisfy the natural properties of decreasing marginal costs.
The study of these functions has led to strong structural properties with
applications in many areas. Recently, there has been significant interest in
extending the theory of algorithms for optimizing combinatorial problems (such
as network design problem of spanning tree) over submodular functions.
Unfortunately, the lower bounds under the general class of submodular functions
are known to be very high for many of the classical problems.
  In this paper, we introduce and study an important subclass of submodular
functions, which we call discounted price functions. These functions are
succinctly representable and generalize linear cost functions. In this paper we
study the following fundamental combinatorial optimization problems: Edge
Cover, Spanning Tree, Perfect Matching and Shortest Path, and obtain tight
upper and lower bounds for these problems.
  The main technical contribution of this paper is designing novel adaptive
greedy algorithms for the above problems. These algorithms greedily build the
solution whist rectifying mistakes made in the previous steps."
"The F.A.S.T. model for microscopic simulation of pedestrians was formulated
with the idea of parallelizability and small computation times in general in
mind, but so far it was never demonstrated, if it can in fact be implemented
efficiently for execution on a multi-core or multi-CPU system. In this
contribution results are given on computation times for the F.A.S.T. model on
an eight-core PC."
"Background: Many different simulation frameworks, in different topics, need
to treat realistic datasets to initialize and calibrate the system. A precise
reproduction of initial states is extremely important to obtain reliable
forecast from the model. Methodology/Principal Findings: This paper proposes an
algorithm to create an artificial population where individuals are described by
their age, and are gathered in households respecting a variety of statistical
constraints (distribution of household types, sizes, age of household head,
difference of age between partners and among parents and children). Such a
population is often the initial state of microsimulation or (agent)
individual-based models. To get a realistic distribution of households is often
very important, because this distribution has an impact on the demographic
evolution. Usual techniques from microsimulation approach cross different
sources of aggregated data for generating individuals. In our case the number
of combinations of different households (types, sizes, age of participants)
makes it computationally difficult to use directly such methods. Hence we
developed a specific algorithm to make the problem more easily tractable.
Conclusions/Significance: We generate the populations of two pilot
municipalities in Auvergne region (France), to illustrate the approach. The
generated populations show a good agreement with the available statistical
datasets (not used for the generation) and are obtained in a reasonable
computational time."
"In the naming game, individuals or agents exchange pairwise local information
in order to communicate about objects in their common environment. The goal of
the game is to reach a consensus about naming these objects. Originally used to
investigate language formation and self-organizing vocabularies, we extend the
classical naming game with a globally shared memory accessible by all agents.
This shared memory can be interpreted as an external source of knowledge like a
book or an Internet site. The extended naming game models an environment
similar to one that can be found in the context of social bookmarking and
collaborative tagging sites where users tag sites using appropriate labels, but
also mimics an important aspect in the field of human-based image labeling.
Although the extended naming game is non-deterministic in its word selection,
we show that consensus towards a common vocabulary is reached. More
importantly, we show the qualitative and quantitative influence of the external
source of information, i.e. the shared memory, on the consensus dynamics
between the agents."
"Current approaches to the engineering of space software such as satellite
control systems are based around the development of feedback controllers using
packages such as MatLab's Simulink toolbox. These provide powerful tools for
engineering real time systems that adapt to changes in the environment but are
limited when the controller itself needs to be adapted.
  We are investigating ways in which ideas from temporal logics and agent
programming can be integrated with the use of such control systems to provide a
more powerful layer of autonomous decision making. This paper will discuss our
initial approaches to the engineering of such systems."
"Agents offer a new and exciting way of understanding the world of work. In
this paper we describe the development of agent-based simulation models,
designed to help to understand the relationship between people management
practices and retail performance. We report on the current development of our
simulation models which includes new features concerning the evolution of
customers over time. To test the features we have conducted a series of
experiments dealing with customer pool sizes, standard and noise reduction
modes, and the spread of customers' word of mouth. To validate and evaluate our
model, we introduce new performance measure specific to retail operations. We
show that by varying different parameters in our model we can simulate a range
of customer experiences leading to significant differences in performance
measures. Ultimately, we are interested in better understanding the impact of
changes in staff behavior due to changes in store management practices. Our
multi-disciplinary research team draws upon expertise from work psychologists
and computer scientists. Despite the fact we are working within a relatively
novel and complex domain, it is clear that intelligent agents offer potential
for fostering sustainable organizational capabilities in the future."
"This paper describes the design of a web based multi agent design for a
collision avoidance auto navigation biomimetic submarine for submarine
hydroelectricity. The paper describes the nature of the map - topology
interface for river bodies and the design of interactive agents for the control
of the robotic submarine. The agents are migratory on the web and are designed
in XML/html interface with both interactive capabilities and visibility on a
map. The paper describes mathematically the user interface and the map
definition languages used for the multi agent description"
"The goal is to develop a novel approach for cardiac disease prediction and
diagnosis using intelligent agents. Initially the symptoms are preprocessed
using filter and wrapper based agents. The filter removes the missing or
irrelevant symptoms. Wrapper is used to extract the data in the data set
according to the threshold limits. Dependency of each symptom is identified
using dependency checker agent. The classification is based on the prior and
posterior probability of the symptoms with the evidence value. Finally the
symptoms are classified in to five classes namely absence, starting, mild,
moderate and serious. Using the cooperative approach the cardiac problem is
solved and verified."
"Farming and herding were introduced to Europe from the Near East and
Anatolia; there are, however, considerable arguments about the mechanisms of
this transition. Were it people who moved and outplaced the indigenous hunter-
gatherer groups or admixed with them? Or was it just material and information
that moved-the Neolithic Package-consisting of domesticated plants and animals
and the knowledge of its use? The latter process is commonly referred to as
cultural diffusion and the former as demic diffusion. Despite continuous and
partly combined efforts by archaeologists, anthropologists, linguists,
paleontologists and geneticists a final resolution of the debate has not yet
been reached. In the present contribution we interpret results from the Global
Land Use and technological Evolution Simulator (GLUES), a mathematical model
for regional sociocultural development embedded in the western Eurasian
geoenvironmental context during the Holocene. We demonstrate that the model is
able to realistically hindcast the expansion speed and the inhomogeneous
space-time evolution of the transition to agropastoralism in Europe. GLUES, in
contrast to models that do not resolve endogenous sociocultural dynamics, also
describes and explains how and why the Neolithic advanced in stages. In the
model analysis, we uncouple the mechanisms of migration and information
exchange. We find that (1) an indigenous form of agropastoralism could well
have arisen in certain Mediterranean landscapes, but not in Northern and
Central Europe, where it depended on imported technology and material, (2) both
demic diffusion by migration or cultural diffusion by trade may explain the
western European transition equally well, (3) [...]"
"Multi-Agent Systems (MAS) promise to offer solutions to problems where
established, older paradigms fall short. In order to validate such claims that
are repeatedly made in software agent publications, empirical in-depth studies
of advantages and weaknesses of multi-agent solutions versus conventional ones
in practical applications are needed. Climate control in large buildings is one
application area where multi-agent systems, and market-oriented programming in
particular, have been reported to be very successful, although central control
solutions are still the standard practice. We have therefore constructed and
implemented a variety of market designs for this problem, as well as different
standard control engineering solutions. This article gives a detailed analysis
and comparison, so as to learn about differences between standard versus agent
approaches, and yielding new insights about benefits and limitations of
computational markets. An important outcome is that ""local information plus
market communication produces global control""."
"Agents in dynamic multi-agent environments must monitor their peers to
execute individual and group plans. A key open question is how much monitoring
of other agents' states is required to be effective: The Monitoring Selectivity
Problem. We investigate this question in the context of detecting failures in
teams of cooperating agents, via Socially-Attentive Monitoring, which focuses
on monitoring for failures in the social relationships between the agents. We
empirically and analytically explore a family of socially-attentive teamwork
monitoring algorithms in two dynamic, complex, multi-agent domains, under
varying conditions of task distribution and uncertainty. We show that a
centralized scheme using a complex algorithm trades correctness for
completeness and requires monitoring all teammates. In contrast, a simple
distributed teamwork monitoring algorithm results in correct and complete
detection of teamwork failures, despite relying on limited, uncertain
knowledge, and monitoring only key agents in a team. In addition, we report on
the design of a socially-attentive monitoring system and demonstrate its
generality in monitoring several coordination relationships, diagnosing
detected failures, and both on-line and off-line applications."
"There is an increasing need for automated support for humans monitoring the
activity of distributed teams of cooperating agents, both human and machine. We
characterize the domain-independent challenges posed by this problem, and
describe how properties of domains influence the challenges and their
solutions. We will concentrate on dynamic, data-rich domains where humans are
ultimately responsible for team behavior. Thus, the automated aid should
interactively support effective and timely decision making by the human. We
present a domain-independent categorization of the types of alerts a plan-based
monitoring system might issue to a user, where each type generally requires
different monitoring techniques. We describe a monitoring framework for
integrating many domain-specific and task-specific monitoring techniques and
then using the concept of value of an alert to avoid operator overload. We use
this framework to describe an execution monitoring approach we have used to
implement Execution Assistants (EAs) in two different dynamic, data-rich,
real-world domains to assist a human in monitoring team behavior. One domain
(Army small unit operations) has hundreds of mobile, geographically distributed
agents, a combination of humans, robots, and vehicles. The other domain (teams
of unmanned ground and air vehicles) has a handful of cooperating robots. Both
domains involve unpredictable adversaries in the vicinity. Our approach
customizes monitoring behavior for each specific task, plan, and situation, as
well as for user preferences. Our EAs alert the human controller when reported
events threaten plan execution or physically threaten team members. Alerts were
generated in a timely manner without inundating the user with too many alerts
(less than 10 percent of alerts are unwanted, as judged by domain experts)."
"A traffic flow is one of the main transportation issues in nowadays
industrialized agglomerations. Configuration of traffic lights is among the key
aspects in traffic flow management. This paper proposes an evolutionary
optimization tool that utilizes multiagent simulator in order to obtain
accurate model. Even though more detailed studies are still necessary, a
preliminary research gives an expectation for promising results."
"Gadgets helping the disabled, especially blind that are in least
accessibility of information, use acoustic methods that can cause stress to ear
and infringe user's privacy. Even if some project uses embedded Radio Frequency
Identification (RFID) into the sidewalk for blind's free walking, the tag
memory design is not specified for buildings and road conditions. This paper
suggested allocation scheme of RFID tag referring to EPCglobal SGLN, tactile
method for conveying information, and use of lithium battery as power source
with solar cells as an alternative. Results have shown independent mobility,
accidents prevention, stress relief and satisfied factors in terms of cost and
human usability."
"The issues in air traffic control have so far been addressed with the intent
to improve resource utilization and achieve an optimized solution with respect
to fuel comsumption of aircrafts, efficient usage of the available airspace
with minimal congestion related losses under various dynamic constraints. So
the focus has almost always been more on smarter management of traffic to
increase profits while human safety, though achieved in the process, we
believe, has remained less seriously attended. This has become all the more
important given that we have overburdened and overstressed air traffic
controllers managing hundreds of airports and thousands of aircrafts per day.
  We propose a multiagent system based distributed approach to handle air
traffic ensuring complete human (passenger) safety without removing any humans
(ground controllers) from the loop thereby also retaining the earlier
advantages in the new solution. The detailed design of the agent system, which
will be easily interfacable with the existing environment, is described. Based
on our initial findings from simulations, we strongly believe the system to be
capable of handling the nuances involved, to be extendable and customizable at
any later point in time."
"This paper studies bilateral multi-issue negotiation between self-interested
autonomous agents. Now, there are a number of different procedures that can be
used for this process; the three main ones being the package deal procedure in
which all the issues are bundled and discussed together, the simultaneous
procedure in which the issues are discussed simultaneously but independently of
each other, and the sequential procedure in which the issues are discussed one
after another. Since each of them yields a different outcome, a key problem is
to decide which one to use in which circumstances. Specifically, we consider
this question for a model in which the agents have time constraints (in the
form of both deadlines and discount factors) and information uncertainty (in
that the agents do not know the opponents utility function). For this model, we
consider issues that are both independent and those that are interdependent and
determine equilibria for each case for each procedure. In so doing, we show
that the package deal is in fact the optimal procedure for each party. We then
go on to show that, although the package deal may be computationally more
complex than the other two procedures, it generates Pareto optimal outcomes
(unlike the other two), it has similar earliest and latest possible times of
agreement to the simultaneous procedure (which is better than the sequential
procedure), and that it (like the other two procedures) generates a unique
outcome only under certain conditions (which we define)."
"Allocating scarce resources among agents to maximize global utility is, in
general, computationally challenging. We focus on problems where resources
enable agents to execute actions in stochastic environments, modeled as Markov
decision processes (MDPs), such that the value of a resource bundle is defined
as the expected value of the optimal MDP policy realizable given these
resources. We present an algorithm that simultaneously solves the
resource-allocation and the policy-optimization problems. This allows us to
avoid explicitly representing utilities over exponentially many resource
bundles, leading to drastic (often exponential) reductions in computational
complexity. We then use this algorithm in the context of self-interested agents
to design a combinatorial auction for allocating resources. We empirically
demonstrate the effectiveness of our approach by showing that it can, in
minutes, optimally solve problems for which a straightforward combinatorial
resource-allocation technique would require the agents to enumerate up to 2^100
resource bundles and the auctioneer to solve an NP-complete problem with an
input of that size."
"This paper introduces application of Reflexive Game Theory to the matter of
multistage decision making processes. The idea behind is that each decision
making session has certain parameters like ""when the session is taking place"",
""who are the group members to make decision"", ""how group members influence on
each other"", etc. This study illustrates the consecutive or sequential decision
making process, which consist of two stages. During the stage 1 decisions about
the parameters of the ultimate decision making are made. Then stage 2 is
implementation of Ultimate decision making itself. Since during stage 1 there
can be multiple decision sessions. In such a case it takes more than two
sessions to make ultimate (final) decision. Therefore the overall process of
ultimate decision making becomes multistage decision making process consisting
of consecutive decision making sessions."
"This paper considers the controllability problem for multi-agent systems. In
particular, the structural controllability of multi-agent systems under
switching topologies is investigated. The structural controllability of
multi-agent systems is a generalization of the traditional controllability
concept for dynamical systems, and purely based on the communication topologies
among agents. The main contributions of the paper are graph-theoretic
characterizations of the structural controllability for multi-agent systems. It
turns out that the multi-agent system with switching topology is structurally
controllable if and only if the union graph G of the underlying communication
topologies is connected (single leader) or leader-follower connected
(multi-leader). Finally, the paper concludes with several illustrative examples
and discussions of the results and future work."
"Agent technology is a software paradigm that permits to implement large and
complex distributed applications. In order to assist analyzing, conception and
development or implementation phases of multi-agent systems, we've tried to
present a practical application of a generic and scalable method of a MAS with
a component-oriented architecture and agent-based approach that allows MDA to
generate source code from a given model. We've designed on AUML the class
diagrams as a class meta-model of different agents of a MAS. Then we generated
the source code of the models developed using an open source tool called
AndroMDA. This agent-based and evolutive approach enhances the modularity and
genericity developments and promotes their reusability in future developments.
This property distinguishes our design methodology of existing methodologies in
that it is constrained by any particular agent-based model while providing a
library of generic models"
"The concept of dynamic coalitions (also virtual organizations) describes the
temporary interconnection of autonomous agents, who share information or
resources in order to achieve a common goal. Through modern technologies these
coalitions may form across company, organization and system borders. Therefor
questions of access control and security are of vital significance for the
architectures supporting these coalitions.
  In this paper, we present our first steps to reach a formal framework for
modeling and verifying the design of privacy-sensitive dynamic coalition
infrastructures and their processes. In order to do so we extend existing
dynamic coalition modeling approaches with an access-control-concept, which
manages access to information through policies. Furthermore we regard the
processes underlying these coalitions and present first works in formalizing
these processes. As a result of the present paper we illustrate the usefulness
of the Abstract State Machine (ASM) method for this task. We demonstrate a
formal treatment of privacy-sensitive dynamic coalitions by two example ASMs
which model certain access control situations. A logical consideration of these
ASMs can lead to a better understanding and a verification of the ASMs
according to the aspired specification."
"One of the strength of Virtual Organisations is their ability to dynamically
and rapidly adapt in response to changing environmental conditions. Dynamic
adaptability has been studied in other system areas as well and system
management through policies has crystallized itself as a very prominent
solution in system and network administration. However, these areas are often
concerned with very low-level technical aspects. Previous work on the APPEL
policy language has been aimed at dynamically adapting system behaviour to
satisfy end-user demands and - as part of STPOWLA - APPEL was used to adapt
workflow instances at runtime. In this paper we explore how the ideas of APPEL
and STPOWLA can be extended from workflows to the wider scope of Virtual
Organisations. We will use a Travel Booking VO as example."
"We consider solving multi-objective optimization problems in a distributed
manner by a network of cooperating and learning agents. The problem is
equivalent to optimizing a global cost that is the sum of individual
components. The optimizers of the individual components do not necessarily
coincide and the network therefore needs to seek Pareto optimal solutions. We
develop a distributed solution that relies on a general class of adaptive
diffusion strategies. We show how the diffusion process can be represented as
the cascade composition of three operators: two combination operators and a
gradient descent operator. Using the Banach fixed-point theorem, we establish
the existence of a unique fixed point for the composite cascade. We then study
how close each agent converges towards this fixed point, and also examine how
close the Pareto solution is to the fixed point. We perform a detailed
mean-square error analysis and establish that all agents are able to converge
to the same Pareto optimal solution within a sufficiently small
mean-square-error (MSE) bound even for constant step-sizes. We illustrate one
application of the theory to collaborative decision making in finance by a
network of agents."
"In this paper, we propose to develop service model architecture by merging
multi-agentsystems and semantic web technology. The proposed architecture works
in two stages namely, Query Identification and Solution Development. A person
referred to as customer will submit the problem details or requirements which
will be referred to as a query. Anyone who can provide a service will need to
register with the registrar module of the architecture. Services can be
anything ranging from expert consultancy in the field of agriculture to
academic research, from selling products to manufacturing goods, from medical
help to legal issues or even providing logistics. Query submitted by customer
is first parsed and then iteratively understood with the help of domain experts
and the customer to get a precise set of properties. Query thus identified will
be solved again with the help of intelligent agent systems which will search
the semantic web for all those who can find or provide a solution. A workable
solution workflow is created and then depending on the requirements, using the
techniques of negotiation or auctioning, solution is implemented to complete
the service for customer. This part is termed as solution development. In this
service oriented architecture, we first try to analyze the complex set of user
requirements then try to provide best possible solution in an optimized way by
combining better information searches through semantic web and better workflow
provisioning using multi agent systems."
"We revisit the formalism of modular interpreted systems (MIS) which
encourages modular and open modeling of synchronous multi-agent systems. The
original formulation of MIS did not live entirely up to its promise. In this
paper, we propose how to improve modularity and openness of MIS by changing the
structure of interference functions. These relatively small changes allow for
surprisingly high flexibility when modeling actual multi-agent systems. We
demonstrate this on two well-known examples, namely the trains, tunnel and
controller, and the dining cryptographers.
  Perhaps more importantly, we propose how the notions of multi-agency and
openness, crucial for multi-agent systems, can be precisely defined based on
their MIS representations."
"Commercially available business process management systems (BPMS) still
suffer to support organizations to enact their business processes in an
effective and efficient way. Current BPMS, in general, are based on BPMN 2.0
and/or BPEL. It is well known, that these approaches have some restrictions
according modeling and immediate transfer of the model into executable code.
Recently, a method for modeling and execution of business processes, named
subject-oriented business process management (S-BPM), gained attention. This
methodology facilitates modeling of any business process using only five
symbols and allows direct execution based on such models. Further on, this
methodology has a strong theoretical and formal basis realizing distributed
systems; any process is defined as a network of independent and distributed
agents - i.e. instances of subjects - which coordinate work through the
exchange of messages. In this work, we present a framework and a prototype
based on off-the-shelf technologies as a possible realization of the S-BPM
methodology. We can prove and demonstrate the principal architecture concept;
these results should also stimulate a discussion about actual BPMS and its
underlying concepts."
"Holland's (1975) genetic algorithm is a minimal computer model of natural
selection that made it possible to investigate the effect of manipulating
specific parameters on the evolutionary process. If culture is, like biology, a
form of evolution, it should be possible to similarly abstract the underlying
skeleton of the process and develop a minimal model of it. Meme and Variations,
or MAV, is a computational model, inspired by the genetic algorithm, of how
ideas evolve in a society of interacting individuals (Gabora 1995). The name is
a pun on the classical music form 'theme and variations', because it is based
on the premise that novel ideas are variations of old ones; they result from
tweaking or combining existing ideas in new ways (Holland et al. 1981). MAV
explores the impact of biological phenomena such as over-dominance and
epistasis as well as cognitive and social phenomena such as the ability to
learn generalizations or imitate others on the fitness and diversity of
cultural transmissible actions."
"Problem: This paper addresses the design of an intelligent software system
for the IC (incident commander) of a team in order to coordinate actions of
agents (field units or robots) in the domain of emergency/crisis response
operations. Objective: This paper proposes GICoordinator. It is a GIS-based
assistant software agent that assists and collaborates with the human planner
in strategic planning and macro tasks assignment for centralized multi-agent
coordination. Method: Our approach to design GICoordinator was to: analyze the
problem, design a complete data model, design an architecture of GICoordinator,
specify required capabilities of human and system in coordination problem
solving, specify development tools, and deploy. Result: The result was an
architecture/design of GICoordinator that contains system requirements.
Findings: GICoordinator efficiently integrates geoinformatics with artifice
intelligent techniques in order to provide a spatial intelligent coordinator
system for an IC to efficiently coordinate and control agents by making
macro/strategic decisions. Results define a framework for future works to
develop this system."
"Crowd simulation is rapidly becoming a standard tool for evacuation planning
and evaluation. However, the many crowd models in the literature are
structurally different, and few have been rigorously calibrated against
real-world egress data, especially in emergency situations. In this paper we
describe a procedure to quantitatively compare different crowd models or
between models and real-world data. We simulated three models: (1) the lattice
gas model, (2) the social force model, and (3) the RVO2 model, and obtained the
distributions of six observables: (1) evacuation time, (2) zoned evacuation
time, (3) passage density, (4) total distance traveled, (5) inconvenience, and
(6) flow rate. We then used the DISTATIS procedure to compute the compromise
matrix of statistical distances between the three models. Projecting the three
models onto the first two principal components of the compromise matrix, we
find the lattice gas and RVO2 models are similar in terms of the evacuation
time, passage density, and flow rates, whereas the social force and RVO2 models
are similar in terms of the total distance traveled. Most importantly, we find
that the zoned evacuation times of the three models to be very different from
each other. Thus we propose to use this variable, if it can be measured, as the
key test between different models, and also between models and the real world.
Finally, we compared the model flow rates against the flow rate of an emergency
evacuation during the May 2008 Sichuan earthquake, and found the social force
model agrees best with this real data."
"Coalition formation is a fundamental type of interaction that involves the
creation of coherent groupings of distinct, autonomous, agents in order to
efficiently achieve their individual or collective goals. Forming effective
coalitions is a major research challenge in the field of multi-agent systems.
Central to this endeavour is the problem of determining which of the many
possible coalitions to form in order to achieve some goal. This usually
requires calculating a value for every possible coalition, known as the
coalition value, which indicates how beneficial that coalition would be if it
was formed. Once these values are calculated, the agents usually need to find a
combination of coalitions, in which every agent belongs to exactly one
coalition, and by which the overall outcome of the system is maximized.
However, this coalition structure generation problem is extremely challenging
due to the number of possible solutions that need to be examined, which grows
exponentially with the number of agents involved. To date, therefore, many
algorithms have been proposed to solve this problem using different techniques
ranging from dynamic programming, to integer programming, to stochastic search
all of which suffer from major limitations relating to execution time, solution
quality, and memory requirements.
  With this in mind, we develop an anytime algorithm to solve the coalition
structure generation problem. Specifically, the algorithm uses a novel
representation of the search space, which partitions the space of possible
solutions into sub-spaces such that it is possible to compute upper and lower
bounds on the values of the best coalition structures in them. These bounds are
then used to identify the sub-spaces that have no potential of containing the
optimal solution so that they can be pruned. The algorithm, then, searches
through the remaining sub-spaces very efficiently using a branch-and-bound
technique to avoid examining all the solutions within the searched subspace(s).
In this setting, we prove that our algorithm enumerates all coalition
structures efficiently by avoiding redundant and invalid solutions
automatically. Moreover, in order to effectively test our algorithm we develop
a new type of input distribution which allows us to generate more reliable
benchmarks compared to the input distributions previously used in the field.
Given this new distribution, we show that for 27 agents our algorithm is able
to find solutions that are optimal in 0.175% of the time required by the
fastest available algorithm in the literature. The algorithm is anytime, and if
interrupted before it would have normally terminated, it can still provide a
solution that is guaranteed to be within a bound from the optimal one.
Moreover, the guarantees we provide on the quality of the solution are
significantly better than those provided by the previous state of the art
algorithms designed for this purpose. For example, for the worst case
distribution given 25 agents, our algorithm is able to find a 90% efficient
solution in around 10% of time it takes to find the optimal solution."
"Because an agents resources dictate what actions it can possibly take, it
should plan which resources it holds over time carefully, considering its
inherent limitations (such as power or payload restrictions), the competing
needs of other agents for the same resources, and the stochastic nature of the
environment. Such agents can, in general, achieve more of their objectives if
they can use --- and even create --- opportunities to change which resources
they hold at various times. Driven by resource constraints, the agents could
break their overall missions into an optimal series of phases, optimally
reconfiguring their resources at each phase, and optimally using their assigned
resources in each phase, given their knowledge of the stochastic environment.
In this paper, we formally define and analyze this constrained, sequential
optimization problem in both the single-agent and multi-agent contexts. We
present a family of mixed integer linear programming (MILP) formulations of
this problem that can optimally create phases (when phases are not predefined)
accounting for costs and limitations in phase creation. Because our
formulations multaneously also find the optimal allocations of resources at
each phase and the optimal policies for using the allocated resources at each
phase, they exploit structure across these coupled problems. This allows them
to find solutions significantly faster(orders of magnitude faster in larger
problems) than alternative solution techniques, as we demonstrate empirically."
"The problem of adversarial multi-robot patrol has gained interest in recent
years, mainly due to its immediate relevance to various security applications.
In this problem, robots are required to repeatedly visit a target area in a way
that maximizes their chances of detecting an adversary trying to penetrate
through the patrol path. When facing a strong adversary that knows the patrol
strategy of the robots, if the robots use a deterministic patrol algorithm,
then in many cases it is easy for the adversary to penetrate undetected (in
fact, in some of those cases the adversary can guarantee penetration).
Therefore this paper presents a non-deterministic patrol framework for the
robots. Assuming that the strong adversary will take advantage of its knowledge
and try to penetrate through the patrols weakest spot, hence an optimal
algorithm is one that maximizes the chances of detection in that point. We
therefore present a polynomial-time algorithm for determining an optimal patrol
under the Markovian strategy assumption for the robots, such that the
probability of detecting the adversary in the patrols weakest spot is
maximized. We build upon this framework and describe an optimal patrol strategy
for several robotic models based on their movement abilities (directed or
undirected) and sensing abilities (perfect or imperfect), and in different
environment models - either patrol around a perimeter (closed polygon) or an
open fence (open polyline)."
"Recent research has shown that surprisingly rich models of human activity can
be learned from GPS (positional) data. However, most effort to date has
concentrated on modeling single individuals or statistical properties of groups
of people. Moreover, prior work focused solely on modeling actual successful
executions (and not failed or attempted executions) of the activities of
interest. We, in contrast, take on the task of understanding human
interactions, attempted interactions, and intentions from noisy sensor data in
a fully relational multi-agent setting. We use a real-world game of capture the
flag to illustrate our approach in a well-defined domain that involves many
distinct cooperative and competitive joint activities. We model the domain
using Markov logic, a statistical-relational language, and learn a theory that
jointly denoises the data and infers occurrences of high-level activities, such
as a player capturing an enemy. Our unified model combines constraints imposed
by the geometry of the game area, the motion model of the players, and by the
rules and dynamics of the game in a probabilistically and logically sound
fashion. We show that while it may be impossible to directly detect a
multi-agent activity due to sensor noise or malfunction, the occurrence of the
activity can still be inferred by considering both its impact on the future
behaviors of the people involved as well as the events that could have preceded
it. Further, we show that given a model of successfully performed multi-agent
activities, along with a set of examples of failed attempts at the same
activities, our system automatically learns an augmented model that is capable
of recognizing success and failure, as well as goals of peoples actions with
high accuracy. We compare our approach with other alternatives and show that
our unified model, which takes into account not only relationships among
individual players, but also relationships among activities over the entire
length of a game, although more computationally costly, is significantly more
accurate. Finally, we demonstrate that explicitly modeling unsuccessful
attempts boosts performance on other important recognition tasks."
"In this paper we propose and analyze a distributed algorithm for achieving
globally optimal decisions, either estimation or detection, through a
self-synchronization mechanism among linearly coupled integrators initialized
with local measurements. We model the interaction among the nodes as a directed
graph with weights (possibly) dependent on the radio channels and we pose
special attention to the effect of the propagation delay occurring in the
exchange of data among sensors, as a function of the network geometry. We
derive necessary and sufficient conditions for the proposed system to reach a
consensus on globally optimal decision statistics. One of the major results
proved in this work is that a consensus is reached with exponential convergence
speed for any bounded delay condition if and only if the directed graph is
quasi-strongly connected. We provide a closed form expression for the global
consensus, showing that the effect of delays is, in general, the introduction
of a bias in the final decision. Finally, we exploit our closed form expression
to devise a double-step consensus mechanism able to provide an unbiased
estimate with minimum extra complexity, without the need to know or estimate
the channel parameters."
"In any spatially discrete model of pedestrian motion which uses a regular
lattice as basis, there is the question of how the symmetry between the
different directions of motion can be restored as far as possible but with
limited computational effort. This question is equivalent to the question ''How
important is the orientation of the axis of discretization for the result of
the simulation?'' An optimization in terms of symmetry can be combined with the
implementation of higher and heterogeniously distributed walking speeds by
representing different walking speeds via different amounts of cells an agent
may move during one round. Therefore all different possible neighborhoods for
speeds up to v = 10 (cells per round) will be examined for the amount of
deviation from radial symmetry. Simple criteria will be stated which will allow
find an optimal neighborhood for each speed. It will be shown that following
these criteria even the best mixture of steps in Moore and von Neumann
neighborhoods is unable to reproduce the optimal neighborhood for a speed as
low as 4."
"A discrete model of pedestrian motion is presented that is implemented in the
Floor field- and Agentbased Simulation Tool (F.A.S.T.) which has already been
applicated to a variety of real life scenarios."
"The F.A.S.T. (Floor field and Agent based Simulation Tool) model is a
microscopic model of pedestrian dynamics, which is discrete in space and time.
It was developed in a number of more or less consecutive steps from a simple CA
model. This contribution is a summary of a study on an extension of the
F.A.S.T-model for counterflow situations. The extensions will be explained and
it will be shown that the extended F.A.S.T.-model is capable of handling
various counterflow situations and to reproduce the well known lane formation
effect."
"Distributed system as e.g. artificial immune systems, complex adaptive
systems, or multi-agent systems are widely used in Computer Science, e.g. for
network security, optimisations, or simulations. In these systems, small
entities move through the network and perform certain tasks. At some time, the
entities move to another place and require therefore information where to move
is most profitable. Common used systems do not provide any information or use a
centralised approach where a center delegates the entities. This article
discusses whether small information about the neighbours enhances the
performance of the overall system or not. Therefore, two information-protocols
are introduced and analysed. In addition, the protocols are implemented and
tested using the artificial immune system SANA that protects a network against
intrusions."
"The human immune system protects the human body against various pathogens
like e.g. biological viruses and bacteria. Artificial immune systems reuse the
architecture, organization, and workflows of the human immune system for
various problems in computer science. In the network security, the artificial
immune system is used to secure a network and its nodes against intrusions like
viruses, worms, and trojans. However, these approaches are far away from
production where they are academic proof-of-concept implementations or use only
a small part to protect against a certain intrusion. This article discusses the
required steps to bring artificial immune systems into production in the
network security domain. It furthermore figures out the challenges and provides
the description and results of the prototype of an artificial immune system,
which is SANA called."
"Current network protection systems use a collection of intelligent components
- e.g. classifiers or rule-based firewall systems to detect intrusions and
anomalies and to secure a network against viruses, worms, or trojans. However,
these network systems rely on individuality and support an architecture with
less collaborative work of the protection components. They give less
administration support for maintenance, but offer a large number of individual
single points of failures - an ideal situation for network attacks to succeed.
In this work, we discuss the required features, the performance, and the
problems of a distributed protection system called {\it SANA}. It consists of a
cooperative architecture, it is motivated by the human immune system, where the
components correspond to artificial immune cells that are connected for their
collaborative work. SANA promises a better protection against intruders than
common known protection systems through an adaptive self-management while
keeping the resources efficiently by an intelligent reduction of redundancies.
We introduce a library of several novel and common used protection components
and evaluate the performance of SANA by a proof-of-concept implementation."
"In this contribution first results of experiments on pedestrian flow through
bottlenecks are presented and then compared to simulation results obtained with
the Social Force Model in the Vissim simulation framework. Concerning the
experiments it is argued that the basic dependence between flow and bottleneck
width is not a step function but that it is linear and modified by the effect
of a psychological phenomenon. The simulation results as well show a linear
dependence and the parameters can be calibrated such that the absolute values
for flow and time fit to range of experimental results."
"In a setting where heterogeneous agents interact to accomplish a given set of
goals, cooperation is of utmost importance, especially when agents cannot
achieve their individual goals by exclusive use of their own efforts. Even when
we consider friendly environments and benevolent agents, cooperation involves
several issues: with whom to cooperate, reciprocation, how to address credit
assignment and complex division of gains, etc. We propose a model where
heterogeneous agents cooperate by forming groups and formation of larger groups
is promoted. Benefit of agents is proportional to the performance and the size
of the group. There is a time pressure to form a group. We investigate how
preferring similar or complement agents in group formation affects an agent's
success. Preferring complement in group formation is found to be better, yet
there is no need to push the strategy to the extreme since the effect of
complementing partners is saturated."
"Experimental verification has been the method of choice for verifying the
stability of a multi-agent reinforcement learning (MARL) algorithm as the
number of agents grows and theoretical analysis becomes prohibitively complex.
For cooperative agents, where the ultimate goal is to optimize some global
metric, the stability is usually verified by observing the evolution of the
global performance metric over time. If the global metric improves and
eventually stabilizes, it is considered a reasonable verification of the
system's stability.
  The main contribution of this note is establishing the need for better
experimental frameworks and measures to assess the stability of large-scale
adaptive cooperative systems. We show an experimental case study where the
stability of the global performance metric can be rather deceiving, hiding an
underlying instability in the system that later leads to a significant drop in
performance. We then propose an alternative metric that relies on agents' local
policies and show, experimentally, that our proposed metric is more effective
(than the traditional global performance metric) in exposing the instability of
MARL algorithms."
"This contribution investigates situations in pedestrian dynamics, where
trying to walk the shortest path leads to largely different results than trying
to walk the quickest path. A heuristic one-shot method to model the influence
of the will to walk the quickest path is introduced."
"Pandemics can cause immense disruption and damage to communities and
societies. Thus far, modeling of pandemics has focused on either large-scale
difference equation models like the SIR and the SEIR models, or detailed
micro-level simulations, which are harder to apply at a global scale. This
paper introduces a hybrid model for pandemics considering both global and local
spread of infections. We hypothesize that the spread of an infectious disease
between regions is significantly influenced by global traffic patterns and the
spread within a region is influenced by local conditions. Thus we model the
spread of pandemics considering the connections between regions for the global
spread of infection and population density based on the SEIR model for the
local spread of infection. We validate our hybrid model by carrying out a
simulation study for the spread of SARS pandemic of 2002-2003 using available
data on population, population density, and traffic networks between different
regions. While it is well-known that international relationships and global
traffic patterns significantly influence the spread of pandemics, our results
show that integrating these factors into relatively simple models can greatly
improve the results of modeling disease spread."
"Formal modelling of Multi-Agent Systems (MAS) is a challenging task due to
high complexity, interaction, parallelism and continuous change of roles and
organisation between agents. In this paper we record our research experience on
formal modelling of MAS. We review our research throughout the last decade, by
describing the problems we have encountered and the decisions we have made
towards resolving them and providing solutions. Much of this work involved
membrane computing and classes of P Systems, such as Tissue and Population P
Systems, targeted to the modelling of MAS whose dynamic structure is a
prominent characteristic. More particularly, social insects (such as colonies
of ants, bees, etc.), biology inspired swarms and systems with emergent
behaviour are indicative examples for which we developed formal MAS models.
Here, we aim to review our work and disseminate our findings to fellow
researchers who might face similar challenges and, furthermore, to discuss
important issues for advancing research on the application of membrane
computing in MAS modelling."
"The Naming Games (NG) are agent-based models for agreement dynamics, peer
pressure and herding in social networks, and protocol selection in autonomous
ad-hoc sensor networks. By introducing a small noise term to the NG, the
resulting Markov Chain model called Noisy Naming Games (NNG) are ergodic, in
which all partial consensus states are recurrent. By using Gibbs-Markov
equivalence we show how to get the NNG's stationary distribution in terms of
the local specification of a related Markov Random Field (MRF). By ordering the
partially-synchronized states according to their Gibbs energy, taken here to be
a good measure of social tension, this method offers an enhanced method for
community-detection in social interaction data. We show how the lowest Gibbs
energy multi-name states separate and display the hidden community structures
within a social network."
"Adaptive networks are well-suited to perform decentralized information
processing and optimization tasks and to model various types of self-organized
and complex behavior encountered in nature. Adaptive networks consist of a
collection of agents with processing and learning abilities. The agents are
linked together through a connection topology, and they cooperate with each
other through local interactions to solve distributed optimization, estimation,
and inference problems in real-time. The continuous diffusion of information
across the network enables agents to adapt their performance in relation to
streaming data and network conditions; it also results in improved adaptation
and learning performance relative to non-cooperative agents. This article
provides an overview of diffusion strategies for adaptation and learning over
networks. The article is divided into several sections: 1. Motivation; 2.
Mean-Square-Error Estimation; 3. Distributed Optimization via Diffusion
Strategies; 4. Adaptive Diffusion Strategies; 5. Performance of
Steepest-Descent Diffusion Strategies; 6. Performance of Adaptive Diffusion
Strategies; 7. Comparing the Performance of Cooperative Strategies; 8.
Selecting the Combination Weights; 9. Diffusion with Noisy Information
Exchanges; 10. Extensions and Further Considerations; Appendix A: Properties of
Kronecker Products; Appendix B: Graph Laplacian and Network Connectivity;
Appendix C: Stochastic Matrices; Appendix D: Block Maximum Norm; Appendix E:
Comparison with Consensus Strategies; References."
"The exploration problem in the discrete universe, using identical oblivious
asynchronous robots without direct communication, has been well investigated.
These robots have sensors that allow them to see their environment and move
accordingly. However, the previous work on this problem assume that robots have
an unlimited visibility, that is, they can see the position of all the other
robots. In this paper, we consider deterministic exploration in an anonymous,
unoriented ring using asynchronous, oblivious, and myopic robots. By myopic, we
mean that the robots have only a limited visibility. We study the computational
limits imposed by such robots and we show that under some conditions the
exploration problem can still be solved. We study the cases where the robots
visibility is limited to 1, 2, and 3 neighboring nodes, respectively."
"EVOC is a computer model of the EVOlution of Culture. It consists of neural
network based agents that invent ideas for actions, and imitate neighbors'
actions. EVOC replicates using a different fitness function the results
obtained with an earlier model (MAV), including (1) an increase in mean fitness
of actions, and (2) an increase and then decrease in the diversity of actions.
Diversity of actions is positively correlated with number of needs, population
size and density, and with the erosion of borders between populations. Slowly
eroding borders maximize diversity, fostering specialization followed by
sharing of fit actions. Square (as opposed to toroidal) worlds also exhibit
higher diversity. Introducing a leader that broadcasts its actions throughout
the population increases the fitness of actions but reduces diversity; these
effects diminish the more leaders there are. Low density populations have less
fit ideas but broadcasting diminishes this effect."
"Human culture is uniquely cumulative and open-ended. Using a computational
model of cultural evolution in which neural network based agents evolve ideas
for actions through invention and imitation, we tested the hypothesis that this
is due to the capacity for recursive recall. We compared runs in which agents
were limited to single-step actions to runs in which they used recursive recall
to chain simple actions into complex ones. Chaining resulted in higher cultural
diversity, open-ended generation of novelty, and no ceiling on the mean fitness
of actions. Both chaining and no-chaining runs exhibited convergence on optimal
actions, but without chaining this set was static while with chaining it was
ever-changing. Chaining increased the ability to capitalize on the capacity for
learning. These findings show that the recursive recall hypothesis provides a
computationally plausible explanation of why humans alone have evolved the
cultural means to transform this planet."
"In a society, a proportion of the individuals can benefit from creativity
without being creative themselves by copying the creators. This paper uses an
agent-based model of cultural evolution to investigate how society is affected
by different levels of individual creativity. We performed a time series
analysis of the mean fitness of ideas across the artificial society varying
both the percentage of creators, C, and how creative they are, p using two
discounting methods. Both analyses revealed a valley in the adaptive landscape,
indicating a tradeoff between C and p. The results suggest that excess
creativity at the individual level can be detrimental at the level of the
society because creators invest in unproven ideas at the expense of propagating
proven ideas."
"The speed and transformative power of human cultural evolution is evident
from the change it has wrought on our planet. This chapter proposes a human
computation program aimed at (1) distinguishing algorithmic from
non-algorithmic components of cultural evolution, (2) computationally modeling
the algorithmic components, and amassing human solutions to the non-algorithmic
(generally, creative) components, and (3) combining them to develop
human-machine hybrids with previously unforeseen computational power that can
be used to solve real problems. Drawing on recent insights into the origins of
evolutionary processes from biology and complexity theory, human minds are
modeled as self-organizing, interacting, autopoietic networks that evolve
through a Lamarckian (non-Darwinian) process of communal exchange. Existing
computational models as well as directions for future research are discussed."
"In this paper, we investigate the interactions among oligarchs, political
parties, and voters using an agent-based modeling approach. We introduce the
OLIGO model, which is based on the spatial model of democracy, where voters
have positions in a policy space and vote for the party that appears closest to
them, and parties move in policy space to seek more votes. We extend the
existing literature on agent-based models of political economy in the following
manner: (1) by introducing a new class of agents- oligarchs - that represent
leaders of firms in a common industry who lobby for beneficial subsidies
through campaign donations; and (2) by investigating the effects of ideological
preferences of the oligarchs on legislative action. We test hypotheses from the
literature in political economics on the behavior of oligarchs and political
parties as they interact, under conditions of imperfect information and bounded
rationality. Our key results indicate that (1) oligarchs tend to donate less to
political campaigns when the parties are more resistant to changing their
policies, or when voters are more informed; and (2) if Oligarchs donate to
parties based on a combination of ideological and profit motivations, Oligarchs
will tend to donate at a lower equilibrium level, due to the influence of lost
profits. We validate these outcomes via comparisons to real world polling data
on changes in party support over time."
"Manipulation is a problem of fundamental importance in the context of voting
in which the voters exercise their votes strategically instead of voting
honestly to prevent selection of an alternative that is less preferred. The
Gibbard-Satterthwaite theorem shows that there is no strategy-proof voting rule
that simultaneously satisfies certain combinations of desirable properties.
Researchers have attempted to get around the impossibility results in several
ways such as domain restriction and computational hardness of manipulation.
However these approaches have been shown to have limitations. Since prevention
of manipulation seems to be elusive, an interesting research direction
therefore is detection of manipulation. Motivated by this, we initiate the
study of detection of possible manipulators in an election.
  We formulate two pertinent computational problems - Coalitional Possible
Manipulators (CPM) and Coalitional Possible Manipulators given Winner (CPMW),
where a suspect group of voters is provided as input to compute whether they
can be a potential coalition of possible manipulators. In the absence of any
suspect group, we formulate two more computational problems namely Coalitional
Possible Manipulators Search (CPMS), and Coalitional Possible Manipulators
Search given Winner (CPMSW). We provide polynomial time algorithms for these
problems, for several popular voting rules. For a few other voting rules, we
show that these problems are in NP-complete. We observe that detecting
manipulation maybe easy even when manipulation is hard, as seen for example, in
the case of the Borda voting rule."
"In a party-based election system, the voters are grouped into parties and all
voters of a party are assumed to vote according to the party preferences over
the candidates. Hence, once the party preferences are declared the outcome of
the election can be determined. However, in the actual election, the members of
some ""instable"" parties often leave their own party to join other parties. We
introduce two parameters to measure the credibility of the prediction based on
party preferences: Min is the minimum number of voters leaving the instable
parties such that the prediction is no longer true, while Max is the maximum
number of voters leaving the instable parties such that the prediction remains
valid. Concerning the complexity of computing Min and Max, we consider both
positional scoring rules (Plurality, Veto, r-Approval and Borda) and
Condorcet-consistent rules (Copeland and Maximin). We show that for all
considered scoring rules, Min is polynomial-time computable, while it is
NP-hard to compute Min for Copeland and Maximin. With the only exception of
Borda, Max can be computed in polynomial time for other scoring rules. We have
NP-hardness results for the computation of Max under Borda, Maximin and
Copeland."
"We consider the problem of estimating local sensor parameters, where the
local parameters and sensor observations are related through linear stochastic
models. Sensors exchange messages and cooperate with each other to estimate
their own local parameters iteratively. We study the Gaussian Sum-Product
Algorithm over a Wireless Network (gSPAWN) procedure, which is based on belief
propagation, but uses fixed size broadcast messages at each sensor instead.
Compared with the popular diffusion strategies for performing network parameter
estimation, whose communication cost at each sensor increases with increasing
network density, the gSPAWN algorithm allows sensors to broadcast a message
whose size does not depend on the network size or density, making it more
suitable for applications in wireless sensor networks. We show that the gSPAWN
algorithm converges in mean and has mean-square stability under some technical
sufficient conditions, and we describe an application of the gSPAWN algorithm
to a network localization problem in non-line-of-sight environments. Numerical
results suggest that gSPAWN converges much faster in general than the diffusion
method, and has lower communication costs, with comparable root mean square
errors."
"Planning for ad hoc teamwork is challenging because it involves agents
collaborating without any prior coordination or communication. The focus is on
principled methods for a single agent to cooperate with others. This motivates
investigating the ad hoc teamwork problem in the context of individual decision
making frameworks. However, individual decision making in multiagent settings
faces the task of having to reason about other agents' actions, which in turn
involves reasoning about others. An established approximation that
operationalizes this approach is to bound the infinite nesting from below by
introducing level 0 models. We show that a consequence of the finitely-nested
modeling is that we may not obtain optimal team solutions in cooperative
settings. We address this limitation by including models at level 0 whose
solutions involve learning. We demonstrate that the learning integrated into
planning in the context of interactive dynamic influence diagrams facilitates
optimal team behavior, and is applicable to ad hoc teamwork."
"Replacing traditional fossil fuel vehicles with innovative zero-emission
vehicles for the transport in ci ties is one of the major tactics to achieve
the UK government 2020 target of cutting emission. We are developing an
agent-based simulation model to study the possible impact of different
governmental interventions on the diffusion of such vehicles. Options that
could be studied with our what-if analysis to include things like car parking
charges, price of electrical car, energy awareness and word of mouth. In this
paper we present a first case study related to the introduction of a new car
park charging scheme at the University of Nottingham. We have developed an
agent based model to simulate theimpact of different car parking rates and
other incentives on the uptake of electrical cars. The goal of this case study
is to demonstrate the usefulness of agent-based modelling and simulation for
such investigations."
"There is great potential to be explored regarding the use of agent-based
modelling and simulation as an alternative paradigm to investigate early-stage
cancer interactions with the immune system. It does not suffer from some
limitations of ordinary differential equation models, such as the lack of
stochasticity, representation of individual behaviours rather than aggregates
and individual memory. In this paper we investigate the potential contribution
of agent-based modelling and simulation when contrasted with stochastic
versions of ODE models using early-stage cancer examples. We seek answers to
the following questions: (1) Does this new stochastic formulation produce
similar results to the agent-based version? (2) Can these methods be used
interchangeably? (3) Do agent-based models outcomes reveal any benefit when
compared to the Gillespie results? To answer these research questions we
investigate three well-established mathematical models describing interactions
between tumour cells and immune elements. These case studies were
re-conceptualised under an agent-based perspective and also converted to the
Gillespie algorithm formulation. Our interest in this work, therefore, is to
establish a methodological discussion regarding the usability of different
simulation approaches, rather than provide further biological insights into the
investigated case studies. Our results show that it is possible to obtain
equivalent models that implement the same mechanisms; however, the incapacity
of the Gillespie algorithm to retain individual memory of past events affects
the similarity of some results. Furthermore, the emergent behaviour of ABMS
produces extra patters of behaviour in the system, which was not obtained by
the Gillespie algorithm."
"Agent programming is mostly a symbolic discipline and, as such, draws little
benefits from probabilistic areas as machine learning and graphical models.
However, the greatest objective of agent research is the achievement of
autonomy in dynamical and complex environments --- a goal that implies
embracing uncertainty and therefore the entailed representations, algorithms
and techniques. This paper proposes an innovative and conflict free two layer
approach to agent programming that uses already established methods and tools
from both symbolic and probabilistic artificial intelligence. Moreover, this
framework is illustrated by means of a widely used agent programming example,
GoldMiners."
"This paper studies fundamental limitations of performance for distributed
decision-making in robotic networks. The class of decision-making problems we
consider encompasses a number of prototypical problems such as average-based
consensus as well as distributed optimization, leader election, majority
voting, MAX, MIN, and logical formulas. We first propose a formal model for
distributed computation on robotic networks that is based on the concept of I/O
automata and is inspired by the Computer Science literature on distributed
computing clusters. Then, we present a number of bounds on time, message, and
byte complexity, which we use to discuss the relative performance of a number
of approaches for distributed decision-making. From a methodological
standpoint, our work sheds light on the relation between the tools developed by
the Computer Science and Controls communities on the topic of distributed
algorithms."
"""Cognizing"" (e.g., thinking, understanding, and knowing) is a mental state.
Systems without mental states, such as cognitive technology, can sometimes
contribute to human cognition, but that does not make them cognizers. Cognizers
can offload some of their cognitive functions onto cognitive technology,
thereby extending their performance capacity beyond the limits of their own
brain power. Language itself is a form of cognitive technology that allows
cognizers to offload some of their cognitive functions onto the brains of other
cognizers. Language also extends cognizers' individual and joint performance
powers, distributing the load through interactive and collaborative cognition.
Reading, writing, print, telecommunications and computing further extend
cognizers' capacities. And now the web, with its network of cognizers, digital
databases and software agents, all accessible anytime, anywhere, has become our
'Cognitive Commons,' in which distributed cognizers and cognitive technology
can interoperate globally with a speed, scope and degree of interactivity
inconceivable through local individual cognition alone. And as with language,
the cognitive tool par excellence, such technological changes are not merely
instrumental and quantitative: they can have profound effects on how we think
and encode information, on how we communicate with one another, on our mental
states, and on our very nature."
"Simulating the evolution of the Human Immunodeficiency Virus (HIV) epidemic
requires a detailed description of the population network, especially for small
populations in which individuals can be represented in detail and accuracy. In
this paper, we introduce the concept of a Complex Agent Network(CAN) to model
the HIV epidemics by combining agent-based modelling and complex networks, in
which agents represent individuals that have sexual interactions. The
applicability of CANs is demonstrated by constructing and executing a detailed
HIV epidemic model for men who have sex with men (MSM) in Amsterdam, including
a distinction between steady and casual relationships. We focus on MSM contacts
because they play an important role in HIV epidemics and have been tracked in
Amsterdam for a long time. Our experiments show good correspondence between the
historical data of the Amsterdam cohort and the simulation results."
"The effects of policy sharing between agents in a multi-agent dynamical
system has not been studied extensively. I simulate a system of agents
optimizing the same task using reinforcement learning, to study the effects of
different population densities and policy sharing. I demonstrate that sharing
policies decreases the time to reach asymptotic behavior, and results in
improved asymptotic behavior."
"We discuss certain types of cyclic and nearly cyclic interactions among N
""point""-agents in the plane, leading to formations of interesting limiting
geometric configurations. Cyclic pursuit and local averaging interactions have
been analyzed in the context of multi-agent gathering. In this paper, we
consider some nearly cyclic interactions that break symmetry leading to factor
circulants rather than circulant interaction matrices."
"Display advertising has traditionally been sold via guaranteed contracts -- a
guaranteed contract is a deal between a publisher and an advertiser to allocate
a certain number of impressions over a certain period, for a pre-specified
price per impression. However, as spot markets for display ads, such as the
RightMedia Exchange, have grown in prominence, the selection of advertisements
to show on a given page is increasingly being chosen based on price, using an
auction. As the number of participants in the exchange grows, the price of an
impressions becomes a signal of its value. This correlation between price and
value means that a seller implementing the contract through bidding should
offer the contract buyer a range of prices, and not just the cheapest
impressions necessary to fulfill its demand.
  Implementing a contract using a range of prices, is akin to creating a mutual
fund of advertising impressions, and requires {\em randomized bidding}. We
characterize what allocations can be implemented with randomized bidding,
namely those where the desired share obtained at each price is a non-increasing
function of price. In addition, we provide a full characterization of when a
set of campaigns are compatible and how to implement them with randomized
bidding strategies."
"It is well-known that the eigenvalue spectrum of the Laplacian matrix of a
network contains valuable information about the network structure and the
behavior of many dynamical processes run on it. In this paper, we propose a
fully decentralized algorithm that iteratively modifies the structure of a
network of agents in order to control the moments of the Laplacian eigenvalue
spectrum. Although the individual agents have knowledge of their local network
structure only (i.e., myopic information), they are collectively able to
aggregate this local information and decide on what links are most beneficial
to be added or removed at each time step. Our approach relies on gossip
algorithms to distributively compute the spectral moments of the Laplacian
matrix, as well as ensure network connectivity in the presence of link
deletions. We illustrate our approach in nontrivial computer simulations and
show that a good final approximation of the spectral moments of the target
Laplacian matrix is achieved for many cases of interest."
"Pandemic influenza has great potential to cause large and rapid increases in
deaths and serious illness. The objective of this paper is to develop an
agent-based model to simulate the spread of pandemic influenza (novel H1N1) in
Egypt. The proposed multi-agent model is based on the modeling of individuals'
interactions in a space time context. The proposed model involves different
types of parameters such as: social agent attributes, distribution of Egypt
population, and patterns of agents' interactions. Analysis of modeling results
leads to understanding the characteristics of the modeled pandemic,
transmission patterns, and the conditions under which an outbreak might occur.
In addition, the proposed model is used to measure the effectiveness of
different control strategies to intervene the pandemic spread."
"We study the asymptotic properties of distributed consensus algorithms over
switching directed random networks. More specifically, we focus on consensus
algorithms over independent and identically distributed, directed random
graphs, where each agent can communicate with any other agent with some
exogenously specified probability. While different aspects of consensus
algorithms over random switching networks have been widely studied, a complete
characterization of the distribution of the asymptotic value for general
\textit{asymmetric} random consensus algorithms remains an open problem. In
this paper, we derive closed-form expressions for the mean and an upper bound
for the variance of the asymptotic consensus value, when the underlying network
evolves according to an i.i.d. \textit{directed} random graph process. We also
provide numerical simulations that illustrate our results."
"Multiagent learning is a necessary yet challenging problem as multiagent
systems become more prevalent and environments become more dynamic. Much of the
groundbreaking work in this area draws on notable results from game theory, in
particular, the concept of Nash equilibria. Learners that directly learn an
equilibrium obviously rely on their existence. Learners that instead seek to
play optimally with respect to the other players also depend upon equilibria
since equilibria are fixed points for learning. From another perspective,
agents with limitations are real and common. These may be undesired physical
limitations as well as self-imposed rational limitations, such as abstraction
and approximation techniques, used to make learning tractable. This article
explores the interactions of these two important concepts: equilibria and
limitations in learning. We introduce the question of whether equilibria
continue to exist when agents have limitations. We look at the general effects
limitations can have on agent behavior, and define a natural extension of
equilibria that accounts for these limitations. Using this formalization, we
make three major contributions: (i) a counterexample for the general existence
of equilibria with limitations, (ii) sufficient conditions on limitations that
preserve their existence, (iii) three general classes of games and limitations
that satisfy these conditions. We then present empirical results from a
specific multiagent learning algorithm applied to a specific instance of
limited agents. These results demonstrate that learning with limitations is
feasible, when the conditions outlined by our theoretical analysis hold."
"We study the problem of allocating multiple users to a set of wireless
channels in a decentralized manner when the channel quali- ties are
time-varying and unknown to the users, and accessing the same channel by
multiple users leads to reduced quality due to interference. In such a setting
the users not only need to learn the inherent channel quality and at the same
time the best allocations of users to channels so as to maximize the social
welfare. Assuming that the users adopt a certain online learning algorithm, we
investigate under what conditions the socially optimal allocation is
achievable. In particular we examine the effect of different levels of
knowledge the users may have and the amount of communications and cooperation.
The general conclusion is that when the cooperation of users decreases and the
uncertainty about channel payoffs increases it becomes harder to achieve the
socially opti- mal allocation."
"A Multi-Agent System is a distributed system where the agents or nodes
perform complex functions that cannot be written down in analytic form.
Multi-Agent Systems are highly connected, and the information they contain is
mostly stored in the connections. When agents update their state, they take
into account the state of the other agents, and they have access to those
states via the connections. There is also external, user-generated input into
the Multi-Agent System. As so much information is stored in the connections,
agents are often memory-less. This memory-less property, together with the
randomness of the external input, has allowed us to model Multi-Agent Systems
using Markov chains. In this paper, we look at Multi-Agent Systems that evolve,
i.e. the number of agents varies according to the fitness of the individual
agents. We extend our Markov chain model, and define stability. This is the
start of a methodology to control Multi-Agent Systems. We then build upon this
to construct an entropy-based definition for the degree of instability (entropy
of the limit probabilities), which we used to perform a stability analysis. We
then investigated the stability of evolving agent populations through
simulation, and show that the results are consistent with the original
definition of stability in non-evolving Multi-Agent Systems, proposed by Chli
and De Wilde. This paper forms the theoretical basis for the construction of
Digital Business Ecosystems, and applications have been reported elsewhere."
"This paper introduces a novel framework for modeling interacting humans in a
multi-stage game. This ""iterated semi network-form game"" framework has the
following desirable characteristics: (1) Bounded rational players, (2)
strategic players (i.e., players account for one another's reward functions
when predicting one another's behavior), and (3) computational tractability
even on real-world systems. We achieve these benefits by combining concepts
from game theory and reinforcement learning. To be precise, we extend the
bounded rational ""level-K reasoning"" model to apply to games over multiple
stages. Our extension allows the decomposition of the overall modeling problem
into a series of smaller ones, each of which can be solved by standard
reinforcement learning algorithms. We call this hybrid approach ""level-K
reinforcement learning"". We investigate these ideas in a cyber battle scenario
over a smart power grid and discuss the relationship between the behavior
predicted by our model and what one might expect of real human defenders and
attackers."
"We consider a scenario in which leaders are required to recruit teams of
followers. Each leader cannot recruit all followers, but interaction is
constrained according to a bipartite network. The objective for each leader is
to reach a state of local stability in which it controls a team whose size is
equal to a given constraint. We focus on distributed strategies, in which
agents have only local information of the network topology and propose a
distributed algorithm in which leaders and followers act according to simple
local rules. The performance of the algorithm is analyzed with respect to the
convergence to a stable solution.
  Our results are as follows. For any network, the proposed algorithm is shown
to converge to an approximate stable solution in polynomial time, namely the
leaders quickly form teams in which the total number of additional followers
required to satisfy all team size constraints is an arbitrarily small fraction
of the entire population. In contrast, for general graphs there can be an
exponential time gap between convergence to an approximate solution and to a
stable solution."
"Supply chain management is a very dynamic operation research problem where
one has to quickly adapt according to the changes perceived in environment in
order to maximize the benefit or minimize the loss. Therefore we require a
system which changes as per the changing requirements. Multi agent system
technology in recent times has emerged as a possible way of efficient solution
implementation for many such complex problems. Our research here focuses on
building a Multi Agent System (MAS), which implements a modified version of
Gravitational Search swarm intelligence Algorithm (GSA) to find out an optimal
strategy in managing the demand supply chain. We target the grains distribution
system among various centers of Food Corporation of India (FCI) as application
domain. We assume centers with larger stocks as objects of greater mass and
vice versa. Applying Newtonian law of gravity as suggested in GSA, larger
objects attract objects of smaller mass towards itself, creating a virtual
grain supply source. As heavier object sheds its mass by supplying some to the
one in demand, it loses its gravitational pull and thus keeps the whole system
of supply chain per-fectly in balance. The multi agent system helps in
continuous updation of the whole system with the help of autonomous agents
which react to the change in environment and act accordingly. This model also
reduces the communication bottleneck to greater extents."
"Characterization of successful formulas in Public Announcement Logic (PAL) is
a well known open problem in Dynamic Epistemic Logic. Recently, Holliday and
ICard have given a complete characterization for the single agent case.
However, the problem for the multi-agent case is open. This paper gives a
partial solution to the problem, characterizing the subclass of the language
consisting of unary operators, and discusses methods to give a complete
solution."
"In this talk I review where we stand regarding the engineering of multi-agent
systems. There is both good news and bad news. The good news is that over the
past decade we've made considerable progress on techniques for engineering
multi-agent systems: we have good, usable methodologies, and mature tools.
Furthermore, we've seen a wide range of demonstrated applications, and have
even begun to quantify the advantages of agent technology. However, industry
involvement in AAMAS appears to be declining (as measured by industry
sponsorship of the conference), and industry affiliated attendants at AAMAS
2012 were few (1-2%). Furthermore, looking at the applications of agents being
reported at recent AAMAS, usage of Agent Oriented Software Engineering (AOSE)
and of Agent Oriented Programming Languages (AOPLs) is quite limited. This
observation is corroborated by the results of a 2008 survey by Frank and
Virginia Dignum. Based on these observations, I make five recommendations: (1)
Re-engage with industry; (2) Stop designing AOPLs and AOSE methodologies ...
and instead ... (3) Move to the ""macro"" level: develop techniques for designing
and implementing interaction, integrate micro (single cognitive agent) and
macro (MAS) design and implementation; (4) Develop techniques for the Assurance
of MAS; and (5) Re-engage with the US."
"Classical approaches for asymptotic convergence to the global average in a
distributed fashion typically assume timely and reliable exchange of
information between neighboring components of a given multi-component system.
These assumptions are not necessarily valid in practical settings due to
varying delays that might affect transmissions at different times, as well as
possible changes in the underlying interconnection topology (e.g., due to
component mobility). In this work, we propose protocols to overcome these
limitations. We first consider a fixed interconnection topology (captured by a
- possibly directed - graph) and propose a discrete-time protocol that can
reach asymptotic average consensus in a distributed fashion, despite the
presence of arbitrary (but bounded) delays in the communication links. The
protocol requires that each component has knowledge of the number of its
outgoing links (i.e., the number of components to which it sends information).
We subsequently extend the protocol to also handle changes in the underlying
interconnection topology and describe a variety of rather loose conditions
under which the modified protocol allows the components to reach asymptotic
average consensus. The proposed algorithms are illustrated via examples."
"This paper describes multi-agent based availability prediction approach for
the reconfigurable networked software system."
"The giant single-celled slime mould Physarum polycephalum exhibits complex
morphological adaptation and amoeboid movement as it forages for food and may
be seen as a minimal example of complex robotic behaviour. Swarm computation
has previously been used to explore how spatiotemporal complexity can emerge
from, and be distributed within, simple component parts and their interactions.
Using a particle based swarm approach we explore the question of how to
generate collective amoeboid movement from simple non-oscillatory component
parts in a model of P. polycephalum. The model collective behaves as a cohesive
and deformable virtual material, approximating the local coupling within the
plasmodium matrix. The collective generates de-novo and complex oscillatory
patterns from simple local interactions. The origin of this motor behaviour is
distributed within the collective rendering is morphologically adaptive,
amenable to external influence, and robust to simulated environmental insult.
We show how to gain external influence over the collective movement by
simulated chemo-attraction (pulling towards nutrient stimuli) and simulated
light irradiation hazards (pushing from stimuli). The amorphous and distributed
properties of the collective are demonstrated by cleaving it into two
independent entities and fusing two separate entities to form a single device,
thus enabling it to traverse narrow, separate or tortuous paths. We conclude by
summarising the contribution of the model to swarm based robotics and
soft-bodied modular robotics and discuss the future potential of such material
approaches to the field."
"This proposal aims at solving one of the long prevailing problems in the
Indian Railways. This simple method of continuous monitoring and assessment of
the condition of the rail tracks can prevent major disasters and save precious
human lives. Our method is capable of alerting the train in case of any
dislocations in the track or change in strength of the soil. Also it can avert
the collisions of the train with other or with the vehicles trying to move
across the unmanned level crossings."
"A market of potato commodity for industry scale usage is engaging several
types of actors. They are farmers, middlemen, and industries. A multi-agent
system has been built to simulate these actors into agent entities, based on
manually given parameters within a simulation scenario file. Each type of
agents has its own fuzzy logic representing actual actors' knowledge, to be
used to interpreting values and take appropriated decision of it while on
simulation. The system will simulate market activities with programmed
behaviors then produce the results as spreadsheet and chart graph files. These
results consist of each agent's yearly finance and commodity data. The system
will also predict each of next value from these outputs."
"We provide experimental evaluation of a number of known and new algorithms
for approximate computation of Monroe's and Chamberlin-Courant's rules. Our
experiments, conducted both on real-life preference-aggregation data and on
synthetic data, show that even very simple and fast algorithms can in many
cases find near-perfect solutions. Our results confirm and complement very
recent theoretical analysis of Skowron et al., who have shown good lower bounds
on the quality of (some of) the algorithms that we study."
"A key problem in verification of multi-agent systems by model checking
concerns the fact that the state-space of the system grows exponentially with
the number of agents present. This makes practical model checking unfeasible
whenever the system contains more than a few agents. In this paper we put
forward a technique to establish a cutoff result, thereby showing that all
systems of arbitrary number of agents can be verified by model checking a
single system containing a number of agents equal to the cutoff of the system.
While this problem is undecidable in general, we here define a class of
parameterised interpreted systems and a parameterised temporal-epistemic logic
for which the result can be shown. We exemplify the theoretical results on a
robotic example and present an implementation of the technique on top of mcmas,
an open-source model checker for multi-agent systems."
"Traffic models based on cellular automata have high computational efficiency
because of their simplicity in describing unrealistic vehicular behavior and
the versatility of cellular automata to be implemented on parallel processing.
On the other hand, the other microscopic traffic models such as car-following
models are computationally more expensive, but they have more realistic driver
behaviors and detailed vehicle characteristics. We propose a new class between
these two categories, defining a traffic model based on continuous cellular
automata where we combine the efficiency of cellular automata models with the
accuracy of the other microscopic models. More precisely, we introduce a
stochastic cellular automata traffic model in which the space is not
coarse-grain but continuous. The continuity also allows us to embed a
multi-agent fuzzy system proposed to handle uncertainties in decision making on
road traffic. Therefore, we simulate different driver behaviors and study the
effect of various compositions of vehicles within the traffic stream from the
macroscopic point of view. The experimental results show that our model is able
to reproduce the typical traffic flow phenomena showing a variety of effects
due to the heterogeneity of traffic."
"Brandt et al. (2013) have recently disproved a conjecture by Schwartz (1990)
by non-constructively showing the existence of a counterexample with about
10^136 alternatives. We provide a concrete counterexample for Schwartz's
conjecture with only 24 alternatives."
"We discuss the possibility of reaching consensus in finite time using only
linear iterations, with the additional restrictions that the update matrices
must be stochastic with positive diagonals and consistent with a given graph
structure. We show that finite-time average consensus can always be achieved
for connected undirected graphs. For directed graphs, we show some necessary
conditions for finite-time consensus, including strong connectivity and the
presence of a simple cycle of even length."
"Models of consensus are used to manage multiple agent systems in order to
choose between different recommendations provided by the system. It is assumed
that there is a central agent that solicits recommendations or plans from other
agents. That agent the n determines the consensus of the other agents, and
chooses the resultant consensus recommendation or plan. Voting schemes such as
this have been used in a variety of domains, including air traffic control.
This paper uses an analytic model to study the use of consensus in multiple
agent systems. The binomial model is used to study the probability that the
consensus judgment is correct or incorrect. That basic model is extended to
account for both different levels of agent competence and unequal prior odds.
The analysis of that model is critical in the investigation of multiple agent
systems, since the model leads us to conclude that in some cases consensus
judgment is not appropriate. In addition, the results allow us to determine how
many agents should be used to develop consensus decisions, which agents should
be used to develop consensus decisions and under which conditions the consensus
model should be used."
"In this paper, we address the problem of distributed interference management
of cognitive femtocells that share the same frequency range with macrocells
(primary user) using distributed multi-agent Q-learning. We formulate and solve
three problems representing three different Q-learning algorithms: namely,
centralized, distributed and partially distributed power control using
Q-learning (CPC-Q, DPC-Q and PDPC-Q). CPCQ, although not of practical interest,
characterizes the global optimum. Each of DPC-Q and PDPC-Q works in two
different learning paradigms: Independent (IL) and Cooperative (CL). The former
is considered the simplest form for applying Qlearning in multi-agent
scenarios, where all the femtocells learn independently. The latter is the
proposed scheme in which femtocells share partial information during the
learning process in order to strike a balance between practical relevance and
performance. In terms of performance, the simulation results showed that the CL
paradigm outperforms the IL paradigm and achieves an aggregate femtocells
capacity that is very close to the optimal one. For the practical relevance
issue, we evaluate the robustness and scalability of DPC-Q, in real time, by
deploying new femtocells in the system during the learning process, where we
showed that DPC-Q in the CL paradigm is scalable to large number of femtocells
and more robust to the network dynamics compared to the IL paradigm"
"The evacuation of complex buildings is a challenge under any circumstances.
Fire drills are a way of training and validating evacuation plans. However,
sometimes these plans are not taken seriously by their participants. It is also
difficult to have the financial and time resources required. In this scenario,
serious games can be used as a tool for training, planning and evaluating
emergency plans. In this paper a prototype of a serious games evacuation
simulator is presented. To make the environment as realistic as possible, 3D
models were made using Blender and loaded onto Unity3D, a popular game engine.
This framework provided us with the appropriate simulation environment. Some
experiences were made and results show that this tool has potential for
practitioners and planners to use it for training building occupants."
"Studies related to crowds of pedestrians, both those of theoretical nature
and application oriented ones, have generally focused on either the analysis or
the synthesis of the phenomena related to the interplay between individual
pedestrians, each characterised by goals, preferences and potentially relevant
relationships with others, and the environment in which they are situated. The
cases in which these activities have been systematically integrated for a
mutual benefit are still very few compared to the corpus of crowd related
literature. This paper presents a case study of an integrated approach to the
definition of an innovative model for pedestrian and crowd simulation (on the
side of synthesis) that was actually motivated and supported by the analyses of
empirical data acquired from both experimental settings and observations in
real world scenarios. In particular, we will introduce a model for the adaptive
behaviour of pedestrians that are also members of groups, that strive to
maintain their cohesion even in difficult (e.g. high density) situations. The
paper will show how the synthesis phase also provided inputs to the analysis of
empirical data, in a virtuous circle."
"Coordination of multi agent systems remains as a problem since there is no
prominent method to completely solve this problem. Metaheuristic agents are
specific implementations of multi-agent systems, which imposes working together
to solve optimisation problems with metaheuristic algorithms. The idea borrowed
from swarm intelligence seems working much better than those implementations
suggested before. This paper reports the performance of swarms of simulated
annealing agents collaborating with particle swarm optimization algorithm. The
proposed approach is implemented for multidimensional knapsack problem and has
resulted much better than some other works published before."
"In this paper we address the problem of coalition formation in hedonic
context. Our modelling tries to be as realistic as possible. In previous
models, once an agent joins a coalition it would not be able to leave the
coalition and join the new one; in this research we made it possible to leave a
coalition but put some restrictions to control the behavior of agents. Leaving
or staying of an agent in a coalition will affect on the trust of the other
agents included in this coalition. Agents will use the trust values in
computing the expected utility of coalitions. Three different risk behaviors
are introduced for agents that want to initiate a coalition. Using these risk
behaviors, some simulations are made and results are analyzed."
"Adaptive networks are suitable for decentralized inference tasks, e.g., to
monitor complex natural phenomena. Recent research works have intensively
studied distributed optimization problems in the case where the nodes have to
estimate a single optimum parameter vector collaboratively. However, there are
many important applications that are multitask-oriented in the sense that there
are multiple optimum parameter vectors to be inferred simultaneously, in a
collaborative manner, over the area covered by the network. In this paper, we
employ diffusion strategies to develop distributed algorithms that address
multitask problems by minimizing an appropriate mean-square error criterion
with $\ell_2$-regularization. The stability and convergence of the algorithm in
the mean and in the mean-square sense is analyzed. Simulations are conducted to
verify the theoretical findings, and to illustrate how the distributed strategy
can be used in several useful applications related to spectral sensing, target
localization, and hyperspectral data unmixing."
"This paper reports on the application of sequence analysis algorithms for
agents in robotic soccer and a suitable representation is proposed to achieve
this mapping. The objective of this research is to generate novel better
in-game strategies with the aim of faster adaptation to the changing
environment. A homogeneous non-communicating multi-agent architecture using the
representation is presented. To achieve real-time learning during a game, a
bucket brigade algorithm is used to reinforce Cellular Automata Based
Classifier. A technique for selecting strategies based on sequence analysis is
adopted."
"In this paper we try to define the difference between hierarchical
organization and self-organization. Organization is defined as a structure with
a function. So we can define the difference between hierarchical organization
and self-organization both on the structure as on the function. In the next two
chapters these two definitions are given. For the structure we will use some
existing definitions in graph theory, for the function we will use existing
theory on (self-)organization. In the third chapter we will look how these two
definitions agree. Finally we give a conclusion."
"This paper investigates multi-agent frequencybased patrolling of
intersecting, circle graphs under conditions where graph nodes have non-uniform
visitation requirements and agents have limited ability to communicate. The
task is modeled as a partially observable Markov decision process, and a
reinforcement learning solution is developed. Each agent generates its own
policy from Markov chains, and policies are exchanged only when agents occupy
the same or adjacent nodes. This constraint on policy exchange models sparse
communication conditions over large, unstructured environments. Empirical
results provide perspectives on convergence properties, agent cooperation, and
generalization of learned patrolling policies to new instances of the task. The
emergent behavior indicates learned coordination strategies between
heterogeneous agents for patrolling large, unstructured regions as well as the
ability to generalize to dynamic variation in node visitation requirements."
"Investigating congestion in train rapid transit systems (RTS) in today's
urban cities is a challenge compounded by limited data availability and
difficulties in model validation. Here, we integrate information from travel
smart card data, a mathematical model of route choice, and a full-scale
agent-based model of the Singapore RTS to provide a more comprehensive
understanding of the congestion dynamics than can be obtained through
analytical modelling alone. Our model is empirically validated, and allows for
close inspection of the dynamics including station crowdedness, average travel
duration, and frequency of missed trains---all highly pertinent factors in
service quality. Using current data, the crowdedness in all 121 stations
appears to be distributed log-normally. In our preliminary scenarios, we
investigate the effect of population growth on service quality. We find that
the current population (2 million) lies below a critical point; and increasing
it beyond a factor of $\sim10\%$ leads to an exponential deterioration in
service quality. We also predict that incentivizing commuters to avoid the most
congested hours can bring modest improvements to the service quality provided
the population remains under the critical point. Finally, our model can be used
to generate simulated data for analytical modelling when such data are not
empirically available, as is often the case."
"This paper highlights the multi-agent learning virtual environment and agents
communication algorithms. The researcher proposed three algorithms required
software agents interaction in virtual learning information system environment.
The first proposed algorithm is agents interaction localization algorithm, the
second one is the dynamic agents distribution algorithm (load distribution
algorithm), and the third model is Agent communication algorithm based on using
agents intermediaries. The main objectives of these algorithms are to reduce
the response time for any agents changes in virtual learning environment (VLE)
by increasing the information exchange intensity between software agents and
reduce the overall network load, and to improve the communication between
mobile agents in distributed information system to support effectiveness.
Finally the paper describe the algorithms of information exchange between
mobile agents in VLE based on the expansion of the address structure and the
use of an agent, intermediary agents, matchmaking agents, brokers and their
entrepreneurial functions"
"The field of Distributed Constraint Optimization Problems (DCOPs) has gained
momentum, thanks to its suitability in capturing complex problems (e.g.,
multi-agent coordination and resource allocation problems) that are naturally
distributed and cannot be realistically addressed in a centralized manner. The
state of the art in solving DCOPs relies on the use of ad-hoc infrastructures
and ad-hoc constraint solving procedures. This paper investigates an
infrastructure for solving DCOPs that is completely built on logic programming
technologies. In particular, the paper explores the use of a general constraint
solver (a constraint logic programming system in this context) to handle the
agent-level constraint solving. The preliminary experiments show that logic
programming provides benefits over a state-of-the-art DCOP system, in terms of
performance and scalability, opening the doors to the use of more advanced
technology (e.g., search strategies and complex constraints) for solving DCOPs."
"We study the problem of allocating a set of indivisible goods to multiple
agents. Recent work [Bouveret and Lang, 2011] focused on allocating goods in a
sequential way, and studied what is the ""best"" sequence of agents to pick
objects based on utilitarian or egalitarian criterion. In this paper, we
propose a parallel elicitation-free protocol for allocating indivisible goods.
In every round of the allocation process, some agents will be selected
(according to some policy) to report their preferred objects among those that
remain, and every reported object will be allocated randomly to an agent
reporting it. Empirical comparison between the parallel protocol (applying a
simple selection policy) and the sequential protocol (applying the optimal
sequence) reveals that our proposed protocol is promising. We also address
strategical issues."
"We present a new strategic logic NCHATL that allows for reasoning about norm
compliance on concurrent game structures that satisfy anonymity. We represent
such game structures compactly, avoiding models that have exponential size in
the number of agents. Then we show that model checking can be done in
polynomial time with respect to this compact representation, even for normative
systems that are not anonymous. That is, as long as the underlying game
structures are anonymous, model checking normative formulas is tractable even
if norms can prescribe different sets of forbidden actions to different agents."
"In this paper we analyse some of the classical paradoxes in Social Choice
Theory (namely, the Condorcet paradox, the discursive dilemma, the Ostrogorski
paradox and the multiple election paradox) using a general framework for the
study of aggregation problems called binary aggregation with integrity
constraints. We provide a definition of paradox that is general enough to
account for the four cases mentioned, and identify a common structure in the
syntactic properties of the rationality assumptions that lie behind such
paradoxes. We generalise this observation by providing a full characterisation
of the set of rationality assumptions on which the majority rule does not
generate a paradox."
"Voter control problems model situations such as an external agent trying to
affect the result of an election by adding voters, for example by convincing
some voters to vote who would otherwise not attend the election. Traditionally,
voters are added one at a time, with the goal of making a distinguished
alternative win by adding a minimum number of voters. In this paper, we
initiate the study of combinatorial variants of control by adding voters: In
our setting, when we choose to add a voter~$v$, we also have to add a whole
bundle $\kappa(v)$ of voters associated with $v$. We study the computational
complexity of this problem for two of the most basic voting rules, namely the
Plurality rule and the Condorcet rule."
"In this paper we propose a two-stage protocol for resource management in a
hierarchically organized cloud. The first stage exploits spatial locality for
the formation of coalitions of supply agents; the second stage, a combinatorial
auction, is based on a modified proxy-based clock algorithm and has two phases,
a clock phase and a proxy phase. The clock phase supports price discovery; in
the second phase a proxy conducts multiple rounds of a combinatorial auction
for the package of services requested by each client. The protocol strikes a
balance between low-cost services for cloud clients and a decent profit for the
service providers. We also report the results of an empirical investigation of
the combinatorial auction stage of the protocol."
"Computational Social Choice is an interdisciplinary research area involving
Economics, Political Science, and Social Science on the one side, and
Mathematics and Computer Science (including Artificial Intelligence and
Multiagent Systems) on the other side. Typical computational problems studied
in this field include the vulnerability of voting procedures against attacks,
or preference aggregation in multi-agent systems. Parameterized Algorithmics is
a subfield of Theoretical Computer Science seeking to exploit meaningful
problem-specific parameters in order to identify tractable special cases of in
general computationally hard problems. In this paper, we propose nine of our
favorite research challenges concerning the parameterized complexity of
problems appearing in this context."
"In the first chapter of this report, we provide an overview on mobile and
wireless networks, with special focus on the IEEE 802.22 norm, which is a norm
dedicated to cognitive radio (CR). Chapter 2 goes into detail about CR and
Chapter 3 is devoted to the presentation of the concept of agents and in
particular the concept of multi-agent systems (MAS). Finally, Chapter 4
provides a state of the art on the use of artificial intelligence techniques,
particularly MAS for radio resource allocation and dynamic spectrum access in
the field of CR."
"We consider approval-based committee voting, i.e. the setting where each
voter approves a subset of candidates, and these votes are then used to select
a fixed-size set of winners (committee). We propose a natural axiom for this
setting, which we call justified representation (JR). This axiom requires that
if a large enough group of voters exhibits agreement by supporting the same
candidate, then at least one voter in this group has an approved candidate in
the winning committee. We show that for every list of ballots it is possible to
select a committee that provides JR. However, it turns out that several
prominent approval-based voting rules may fail to output such a committee. In
particular, while Proportional Approval Voting (PAV) always outputs a committee
that provides JR, Reweighted Approval Voting (RAV), a tractable approximation
to PAV, does not have this property. We then introduce a stronger version of
the JR axiom, which we call extended justified representation (EJR), and show
that PAV satisfies EJR, while other rules we consider do not; indeed, EJR can
be used to characterize PAV within the class of weighted PAV rules. We also
consider several other questions related to JR and EJR, including the
relationship between JR/EJR and core stability, and the complexity of the
associated algorithmic problems."
"The transition between low and high density phases is a typical feature of
systems with social interactions. This contribution focuses on simple
evacuation design of one room with one entrance and one exit; four
passing-through experiments were organized and evaluated by means of automatic
image processing. The phase of the system, determined by travel time and
occupancy, is evaluated with respect to the inflow, a controlled boundary
condition. Critical values of inflow and outflow were described with respect to
the transition from low density to congested state. Moreover, microscopic
analysis of travel time is provided."
"Master's Degree Thesis: Department of Physics, University of Turin
  Supervisor: Prof. Marco Maggiora, Department of Physics, University of Turin;
email: marco.maggiora@unito.it
  Co-Supervisor: Prof. Walter Allasia, Innovation Department, EURIX; email:
allasia@eurix.it
  The thesis describes an agent-based model aimed to simulate those processes
in which a digital object faces the risk of obsolescence, a migration process
has to be performed and the most appropriate file format has to be adopted.
Agents have been designed in order to monitor and control the local system
where they reside and its environment. They are able to become aware of
obsolescent formats based on global parameters such as their diffusion. They
communicate as well with each other to find out the most suitable preservation
action to be performed. Agents request suggestions that are evaluated and
propagated according to a weighting based on the level of trust assigned to
both the agents who identified the problem and proposed the solution. In the
current research, the definition of the trust level has been chosen based on
the cultural and geographical distances, the expertise of the involved agents
and the file format numerosity. The level of trust between two agents is
automatically updated after every interaction by the mean of a feedback
mechanism profiting of an inter agent communication based on stigmergy. Summing
up, the thesis demonstrates how a multi-agent system can either perform an
autonomous preservation action or suggest a list of best candidate solutions to
the user. It benefits the management of several kinds of digital archive,
especially those with limited resources specifically dedicated to digital
preservation, such as small personal collections and many public institutions."
"Social intelligence in natural and artificial systems is usually measured by
the evaluation of associated traits or tasks that are deemed to represent some
facets of social behaviour. The amalgamation of these traits is then used to
configure the intuitive notion of social intelligence. Instead, in this paper
we start from a parametrised definition of social intelligence as the expected
performance in a set of environments with several agents, and we assess and
derive tests from it. This definition makes several dependencies explicit: (1)
the definition depends on the choice (and weight) of environments and agents,
(2) the definition may include both competitive and cooperative behaviours
depending on how agents and rewards are arranged into teams, (3) the definition
mostly depends on the abilities of other agents, and (4) the actual difference
between social intelligence and general intelligence (or other abilities)
depends on these choices. As a result, we address the problem of converting
this definition into a more precise one where some fundamental properties
ensuring social behaviour (such as action and reward dependency and
anticipation on competitive/cooperative behaviours) are met as well as some
other more instrumental properties (such as secernment, boundedness, symmetry,
validity, reliability, efficiency), which are convenient to convert the
definition into a practical test. From the definition and the formalised
properties, we take a look at several representative multi-agent environments,
tests and games to see whether they meet these properties."
"This paper details the implementation of a software framework that aids the
development of distributed and self-configurable software systems. This
framework is an instance of a novel integration strategy called SoSAA (SOcially
Situated Agent Architecture), which combines Component-Based Software
Engineering and Agent-Oriented Software Engineering, drawing its inspiration
from hybrid agent control architectures. The framework defines a complete
construction process by enhancing a simple component-based framework with
reasoning and self-awareness capabilities through a standardized interface.
  The capabilities of the resulting framework are demonstrated through its
application to a non-trivial Multi Agent System (MAS). The system in question
is a pre-existing Information Retrieval (IR) system that has not previously
taken advantage of CBSE principles. In this paper we contrast these two systems
so as to highlight the benefits of using this new hybrid approach. We also
outline how component-based elements may be integrated into the Agent Factory
agent-oriented application framework."
"In this two-part paper, we propose a general algorithmic framework for the
minimization of a nonconvex smooth function subject to nonconvex smooth
constraints. The algorithm solves a sequence of (separable) strongly convex
problems and mantains feasibility at each iteration. Convergence to a
stationary solution of the original nonconvex optimization is established. Our
framework is very general and flexible; it unifies several existing Successive
Convex Approximation (SCA)-based algorithms such as (proximal) gradient or
Newton type methods, block coordinate (parallel) descent schemes, difference of
convex functions methods, and improves on their convergence properties. More
importantly, and differently from current SCA approaches, it naturally leads to
distributed and parallelizable implementations for a large class of nonconvex
problems.
  This Part I is devoted to the description of the framework in its generality.
In Part II we customize our general methods to several multi-agent optimization
problems, mainly in communications and networking; the result is a new class of
(distributed) algorithms that compare favorably to existing ad-hoc
(centralized) schemes (when they exist)."
"Consider the problem of minimizing the expected value of a (possibly
nonconvex) cost function parameterized by a random (vector) variable, when the
expectation cannot be computed accurately (e.g., because the statistics of the
random variables are unknown and/or the computational complexity is
prohibitive). Classical sample stochastic gradient methods for solving this
problem may empirically suffer from slow convergence. In this paper, we propose
for the first time a stochastic parallel Successive Convex Approximation-based
(best-response) algorithmic framework for general nonconvex stochastic
sum-utility optimization problems, which arise naturally in the design of
multi-agent systems. The proposed novel decomposition enables all users to
update their optimization variables in parallel by solving a sequence of
strongly convex subproblems, one for each user. Almost surely convergence to
stationary points is proved. We then customize our algorithmic framework to
solve the stochastic sum rate maximization problem over
Single-Input-Single-Output (SISO) frequency-selective interference channels,
multiple-input-multiple-output (MIMO) interference channels, and MIMO
multiple-access channels. Numerical results show that our algorithms are much
faster than state-of-the-art stochastic gradient schemes while achieving the
same (or better) sum-rates."
"In complex systems, many different parts interact in non-obvious ways.
Traditional research focuses on a few or a single aspect of the problem so as
to analyze it with the tools available. To get a better insight of phenomena
that emerge from complex interactions, we need instruments that can analyze
simultaneously complex interactions between many parts. Here, a simulator
modeling different types of economies, is used to visualize complex
quantitative aspects that affect economic dynamics. The main conclusions are:
1- Relatively simple economic settings produce complex non-linear dynamics and
therefore linear regressions are often unsuitable to capture complex economic
dynamics; 2- Flexible pricing of goods by individual agents according to their
micro-environment increases the health and wealth of the society, but
asymmetries in price sensitivity between buyers and sellers increase price
inflation; 3- Prices for goods conferring risky long term benefits are not
tracked efficiently by simple market forces. 4- Division of labor creates
synergies that improve enormously the health and wealth of the society by
increasing the efficiency of economic activity. 5- Stochastic modeling improves
our understanding of real economies, and didactic games based on them might
help policy makers and non specialists in grasping the complex dynamics
underlying even simple economic settings."
"We consider the problem of planning trajectories for a group of $N$ vehicles,
each aiming to reach its own target set while avoiding danger zones of other
vehicles. The analysis of problems like this is extremely important
practically, especially given the growing interest in utilizing unmanned
aircraft systems for civil purposes. The direct solution of this problem by
solving a single-obstacle Hamilton-Jacobi-Isaacs (HJI) variational inequality
(VI) is numerically intractable due to the exponential scaling of computation
complexity with problem dimensionality. Furthermore, the single-obstacle HJI VI
cannot directly handle situations in which vehicles do not have a common
scheduled arrival time. Instead, we perform sequential path planning by
considering vehicles in order of priority, modeling higher-priority vehicles as
time-varying obstacles for lower-priority vehicles. To do this, we solve a
double-obstacle HJI VI which allows us to obtain the reach-avoid set, defined
as the set of states from which a vehicle can reach its target while staying
within a time-varying state constraint set. From the solution of the
double-obstacle HJI VI, we can also extract the latest start time and the
optimal control for each vehicle. This is a first application of the
double-obstacle HJI VI which can handle systems with time-varying dynamics,
target sets, and state constraint sets, and results in computation complexity
that scales linearly, as opposed to exponentially, with the number of vehicles
in consideration."
"The fusion of the multi-agent paradigm with evolutionary computation yielded
promising results in many optimization problems. Evolutionary multi-agent
system (EMAS) are more similar to biological evolution than classical
evolutionary algorithms. However, technological limitations prevented the use
of fully asynchronous agents in previous EMAS implementations. In this paper we
present a new algorithm for agent-based evolutionary computations. The
individuals are represented as fully autonomous and asynchronous agents. An
efficient implementation of this algorithm was possible through the use of
modern technologies based on functional languages (namely Erlang and Scala),
which natively support lightweight processes and asynchronous communication.
Our experiments show that such an asynchronous approach is both faster and more
efficient in solving common optimization problems."
"Preventing traffic congestion by forecasting near time traffic flows is an
important problem as it leads to effective use of transport resources. Social
network provides information about activities of humans and social events.
Thus, with the help of social network, we can extract which humans will attend
a particular event (in near time) and can estimate flow of traffic based on it.
This opens up a wide area of research which poses need to have a framework for
traffic management that can capture essential parameters of real-life behaviour
and provide a way to iterate upon and evaluate new ideas. In this paper, we
present building blocks of a framework and a system to simulate a city with its
transport system, humans and their social network. We emphasize on relevant
parameters selected and modular design of the framework. Our framework defines
metrics to evaluate congestion avoidance strategies. To show utility of the
framework, we present experimental studies of few strategies on a public
transport system."
"The idea that a group of cooperating agents can solve problems more
efficiently than when those agents work independently is hardly controversial,
despite our obliviousness of the conditions that make cooperation a successful
problem solving strategy. Here we investigate the performance of a group of
agents in locating the global maxima of NK fitness landscapes with varying
degrees of ruggedness. Cooperation is taken into account through imitative
learning and the broadcasting of messages informing on the fitness of each
agent. We find a trade-off between the group size and the frequency of
imitation: for rugged landscapes, too much imitation or too large a group yield
a performance poorer than that of independent agents. By decreasing the
diversity of the group, imitative learning may lead to duplication of work and
hence to a decrease of its effective size. However, when the parameters are set
to optimal values the cooperative group substantially outperforms the
independent agents."
"Several logics for expressing coalitional ability under resource bounds have
been proposed and studied in the literature. Previous work has shown that if
only consumption of resources is considered or the total amount of resources
produced or consumed on any path in the system is bounded, then the
model-checking problem for several standard logics, such as Resource-Bounded
Coalition Logic (RB-CL) and Resource-Bounded Alternating-Time Temporal Logic
(RB-ATL) is decidable. However, for coalition logics with unbounded resource
production and consumption, only some undecidability results are known. In this
paper, we show that the model-checking problem for RB-ATL with unbounded
production and con- sumption of resources is decidable but EXPSPACE-hard. We
also investigate some tractable cases and provide a detailed comparison to a
variant of the resource logic RAL, together with new complexity results."
"In this paper, the recent developments on distributed coordination control,
especially the consensus and formation control, are summarized with the graph
theory playing a central role, in order to present a cohesive overview of the
multi-agent distributed coordination control, together with brief reviews of
some closely related issues including rendezvous/alignment, swarming/flocking
and containment control.In terms of the consensus problem, the recent results
on consensus for the agents with different dynamics from first-order,
second-order to high-order linear and nonlinear dynamics, under different
communication conditions, such as cases with/without switching communication
topology and varying time-delays, are reviewed, in which the algebraic graph
theory is very useful in the protocol designs, stability proofs and converging
analysis. In terms of the formation control problem, after reviewing the
results of the algebraic graph theory employed in the formation control, we
mainly pay attention to the developments of the rigid and persistent graphs.
With the notions of rigidity and persistence, the formation transformation,
splitting and reconstruction can be completed, and consequently the range-based
formation control laws are designed with the least required information in
order to maintain a formation rigid/persistent. Afterwards, the recent results
on rendezvous/alignment, swarming/flocking and containment control, which are
very closely related to consensus and formation control, are briefly
introduced, in order to present an integrated view of the graph theory used in
the coordination control problem. Finally, towards the practical applications,
some directions possibly deserving investigation in coordination control are
raised as well."
"In the context of using norms for controlling multi-agent systems, a vitally
important question that has not yet been addressed in the literature is the
development of mechanisms for monitoring norm compliance under partial action
observability. This paper proposes the reconstruction of unobserved actions to
tackle this problem. In particular, we formalise the problem of reconstructing
unobserved actions, and propose an information model and algorithms for
monitoring norms under partial action observability using two different
processes for reconstructing unobserved actions. Our evaluation shows that
reconstructing unobserved actions increases significantly the number of norm
violations and fulfilments detected."
"Given a connected region in two-dimensional space where events of a certain
kind occur according to a certain time-varying density, we consider the problem
of setting up a network of autonomous mobile agents to detect the occurrence of
those events and possibly record them in as effective a manner as possible. We
assume that agents can communicate with one another wirelessly within a fixed
communication radius, and moreover that initially no agent has any information
regarding the event density. We introduce a new distributed algorithm for agent
control based on the notion of an execution mode, which essentially lets each
agent roam the target region either at random or following its local view of a
density-dependent gradient. Agents can switch back and forth between the two
modes, and the precise manner of such changes depends on the setting of various
parameters that can be adjusted as a function of the application at hand. We
provide simulation results on some synthetic applications especially designed
to highlight the algorithm's behavior relative to the possible execution modes."
"This paper will present an evolution of a fuzzy agent based platform which
performed products configuration. As a first step, we used the notion of
consensus to establish robust results at the end of the configuration process.
We implemented the concept of generalized consensus which implied the
consideration of consensuses from the beginning, in this way robust data are
treated during the entire process and the final result enables the designer to
distinguish the robust components and flexible ones in a set of configurations."
"We present in this paper the behavior of an artificial agent who is a member
of a crowd. The behavior is based on the social comparison theory, as well as
the trajectory mapping towards an agent's goal considering the agent's field of
vision. The crowd of artificial agents were able to exhibit arching, clogging,
and bursty exit rates. We were also able to observe a new phenomenon we called
double arching, which happens towards the end of the simulation, and whose
onset is exhibited by a ""calm"" density graph within the exit passage. The
density graph is usually bursty at this area. Because of these exhibited
phenomena, we can use these agents with high confidence to perform
microsimulation studies for modeling the behavior of humans and objects in very
realistic ways."
"The arching phenomenon is an emergent pattern formed by a $c$-sized crowd of
intelligent, goal-oriented, autonomous, heterogeneous individuals moving
towards a $w$-wide exit along a long $W$-wide corridor, where $W>w$. We
collected empirical data from microsimulations to identify the combination
effects of~$c$ and~$w$ to the time~$T$ of the onset of and the size~$S$ of the
formation of the arch. The arch takes on the form of the perimeter of a half
ellipse halved along the minor axis. We measured the~$S$ with respect to the
lengths of the major~$M$ and minor~$m$ axes of the ellipse, respectively. The
mathematical description of the formation of this phenomenon will be an
important information in the design of walkways to control and easily direct
the flow of large crowds, especially during panic egress conditions."
"Crowdsourcing of jobs to online freelance markets is rapidly gaining
popularity. Most crowdsourcing platforms are uncontrolled and offer freedom to
customers and freelancers to choose each other. This works well for unskilled
jobs (e.g., image classification) with no specific quality requirement since
freelancers are functionally identical. For skilled jobs (e.g., software
development) with specific quality requirements, however, this does not ensure
that the maximum number of job requests is satisfied. In this work we determine
the capacity of freelance markets, in terms of maximum satisfied job requests,
and propose centralized schemes that achieve capacity. To ensure decentralized
operation and freedom of choice for customers and freelancers, we propose
simple schemes compatible with the operation of current crowdsourcing platforms
that approximately achieve capacity. Further, for settings where the number of
job requests exceeds capacity, we propose a scheme that is agnostic of that
information, but is optimal and fair in declining jobs without wait."
"Advances in Agent Oriented Software Engineering have focused on the provision
of frameworks and toolkits to aid in the creation of Multi Agent Systems
(MASs). However, despite the need to address the inherent complexity of such
systems, little progress has been made in the development of tools to allow for
the debugging and understanding of their inner workings.
  This paper introduces a novel performance analysis system, named
AgentSpotter, which facilitates such analysis. AgentSpotter was developed by
mapping conventional profiling concepts to the domain of MASs. We outline its
integration into the Agent Factory multi agent framework."
"The design, implementation and testing of Multi Agent Systems is typically a
very complex task. While a number of specialist agent programming languages and
toolkits have been created to aid in the development of such systems, the
provision of associated development tools still lags behind those available for
other programming paradigms. This includes tools such as debuggers and
profilers to help analyse system behaviour, performance and efficiency.
AgentSpotter is a profiling tool designed specifically to operate on the
concepts of agent-oriented programming. This paper extends previous work on
AgentSpotter by discussing its Call Graph View, which presents system
performance information, with reference to the communication between the agents
in the system. This is aimed at aiding developers in examining the effect that
agent communication has on the processing requirements of the system."
"Reinforcement learning has significant applications for multi-agent systems,
especially in unknown dynamic environments. However, most multi-agent
reinforcement learning (MARL) algorithms suffer from such problems as
exponential computation complexity in the joint state-action space, which makes
it difficult to scale up to realistic multi-agent problems. In this paper, a
novel algorithm named negotiation-based MARL with sparse interactions (NegoSI)
is presented. In contrast to traditional sparse-interaction based MARL
algorithms, NegoSI adopts the equilibrium concept and makes it possible for
agents to select the non-strict Equilibrium Dominating Strategy Profile
(non-strict EDSP) or Meta equilibrium for their joint actions. The presented
NegoSI algorithm consists of four parts: the equilibrium-based framework for
sparse interactions, the negotiation for the equilibrium set, the minimum
variance method for selecting one joint action and the knowledge transfer of
local Q-values. In this integrated algorithm, three techniques, i.e., unshared
value functions, equilibrium solutions and sparse interactions are adopted to
achieve privacy protection, better coordination and lower computational
complexity, respectively. To evaluate the performance of the presented NegoSI
algorithm, two groups of experiments are carried out regarding three criteria:
steps of each episode (SEE), rewards of each episode (REE) and average runtime
(AR). The first group of experiments is conducted using six grid world games
and shows fast convergence and high scalability of the presented algorithm.
Then in the second group of experiments NegoSI is applied to an intelligent
warehouse problem and simulated results demonstrate the effectiveness of the
presented NegoSI algorithm compared with other state-of-the-art MARL
algorithms."
"We consider an agent seeking to obtain an item, potentially available at
different locations in a physical environment. The traveling costs between
locations are known in advance, but there is only probabilistic knowledge
regarding the possible prices of the item at any given location. Given such a
setting, the problem is to find a plan that maximizes the probability of
acquiring the good while minimizing both travel and purchase costs. Sample
applications include agents in search-and-rescue or exploration missions, e.g.,
a rover on Mars seeking to mine a specific mineral. These probabilistic
physical search problems have been previously studied, but we present the first
approximation and heuristic algorithms for solving such problems on general
graphs. We establish an interesting connection between these problems and
classical graph-search problems, which led us to provide the approximation
algorithms and hardness of approximation results for our settings. We further
suggest several heuristics for practical use, and demonstrate their
effectiveness with simulation on real graph structure and synthetic graphs."
"This study simulates the evolution of artificial economies in order to
understand the tax relevance of administrative boundaries in the quality of
life of its citizens. The modeling involves the construction of a computational
algorithm, which includes citizens, bounded into families; firms and
governments; all of them interacting in markets for goods, labor and real
estate. The real estate market allows families to move to dwellings with higher
quality or lower price when the families capitalize property values. The goods
market allows consumers to search on a flexible number of firms choosing by
price and proximity. The labor market entails a matching process between firms
(location) and candidates (qualification). The government may be configured
into one, four or seven distinct sub-national governments. The role of
government is to collect taxes on the value added of firms in its territory and
invest the taxes into higher levels of quality of life for residents. The model
does not have a credit market. The results suggest that the configuration of
administrative boundaries is relevant to the levels of quality of life arising
from the reversal of taxes. The model with seven regions is more dynamic, with
higher GDP values, but more unequal and heterogeneous across regions. The
simulation with only one region is more homogeneously poor. The study seeks to
contribute to a theoretical and methodological framework as well as to
describe, operationalize and test computer models of public finance analysis,
with explicitly spatial and dynamic emphasis. Several alternatives of expansion
of the model for future research are described. Moreover, this study adds to
the existing literature in the realm of simple microeconomic computational
models, specifying structural relationships between local governments and
firms, consumers and dwellings mediated by distance."
"Alternating-time temporal logic (ATL) allows to specify requirements on
abilities that different agents should (or should not) possess in a multi-agent
system. However, model checking ATL specifications in realistic systems is
computationally hard. In particular, if the agents have imperfect information
about the global state of the system, the complexity ranges from Delta2P to
undecidable, depending on the syntactic and semantic details. The problem is
also hard in practice, as evidenced by several recent attempts to tackle it. On
the other hand, model checking of alternating epistemic mu-calculus can have a
distinctly lower computational complexity.
  In this work, we look at the idea of approximating the former problem by the
verification of its ""naive"" translations to the latter. In other words, we look
at what happens when one uses the (incorrect) fixpoint algorithm to verify
formulae of ATL with imperfect information."
"Random dictatorship has been characterized as the only social decision scheme
that satisfies efficiency and strategyproofness when individual preferences are
strict. We show that no extension of random dictatorship to weak preferences
satisfies these properties, even when significantly weakening the required
degree of strategyproofness."
"A group of mobile agents, identical, anonymous, and oblivious (memoryless),
having the capability to sense only the relative direction (bearing) to
neighborhing agents within a finite visibility range, are shown to gather to a
meeting point in finite time by applying a very simple rule of motion. The
agents' rule of motion is : set your velocity vector to be the sum of the two
unit vectors in R^2 pointing to your ""extremal"" neighbours determining the
smallest visibility disc sector in which all your visible neighbors reside,
provided it spans an angle smaller than pi, otherwise, since you are
""surrounded"" by visible neighbors, simply stay put (set your velocity to 0). Of
course, the initial constellation of agents must have a visibility graph that
is connected, and provided this we prove that the agents gather to a common
meeting point in finite time, while the distances between agents that initially
see each other monotically decreases. We will also prove a geometrical result,
a tight lower bound on the sum of cosines of the interior angles of a convex
polygon, that we will use to prove the gathering of our dynamical system."
"Problem solving (e.g., drug design, traffic engineering, software
development) by task forces represents a substantial portion of the economy of
developed countries. Here we use an agent-based model of cooperative problem
solving systems to study the influence of diversity on the performance of a
task force. We assume that agents cooperate by exchanging information on their
partial success and use that information to imitate the more successful agent
in the system -- the model. The agents differ only in their propensities to
copy the model. We find that, for easy tasks, the optimal organization is a
homogeneous system composed of agents with the highest possible copy
propensities. For difficult tasks, we find that diversity can prevent the
system from being trapped in sub-optimal solutions. However, when the system
size is adjusted to maximize performance the homogeneous systems outperform the
heterogeneous systems, i.e., for optimal performance, sameness should be
preferred to diversity."
"Modelling & Simulation (M&S) is broadly used in real scenarios where making
physical modifications could be highly expensive. With the so-called Simulation
Software-as-a-Service (SimSaaS), researchers could take advantage of the huge
amount of resource that cloud computing provides. Even so, studying and
analysing a problem through simulation may need several simulation tools, hence
raising interoperability issues. Having this in mind, IEEE developed a standard
for interoperability among simulators named High Level Architecture (HLA).
Moreover, the multi-agent system approach has become recognised as a convenient
approach for modelling and simulating complex systems. Despite all the recent
works and acceptance of these technologies, there is still a great lack of work
regarding synergies among them. This paper shows by means of a literature
review this lack of work or, in other words, the sparse Cloud SimSaaS. The
literature review and the resulting taxonomy are the main contributions of this
paper, as they provide a research agenda illustrating future research
opportunities and trends."
"Nowadays, universities and companies have a huge need for simulation and
modelling methodologies. In the particular case of traffic and transportation,
making physical modifications to the real traffic networks could be highly
expensive, dependent on political decisions and could be highly disruptive to
the environment. However, while studying a specific domain or problem,
analysing a problem through simulation may not be trivial and may need several
simulation tools, hence raising interoperability issues. To overcome these
problems, we propose an agent-directed transportation simulation platform,
through the cloud, by means of services. We intend to use the IEEE standard HLA
(High Level Architecture) for simulators interoperability and agents for
controlling and coordination. Our motivations are to allow multiresolution
analysis of complex domains, to allow experts to collaborate on the analysis of
a common problem and to allow co-simulation and synergy of different
application domains. This paper will start by presenting some preliminary
background concepts to help better understand the scope of this work. After
that, the results of a literature review is shown. Finally, the general
architecture of a transportation simulation platform is proposed."
"We consider the problem of detecting norm violations in open multi-agent
systems (MAS). We show how, using ideas from scrip systems, we can design
mechanisms where the agents comprising the MAS are incentivised to monitor the
actions of other agents for norm violations. The cost of providing the
incentives is not borne by the MAS and does not come from fines charged for
norm violations (fines may be impossible to levy in a system where agents are
free to leave and rejoin again under a different identity). Instead, monitoring
incentives come from (scrip) fees for accessing the services provided by the
MAS. In some cases, perfect monitoring (and hence enforcement) can be achieved:
no norms will be violated in equilibrium. In other cases, we show that, while
it is impossible to achieve perfect enforcement, we can get arbitrarily close;
we can make the probability of a norm violation in equilibrium arbitrarily
small. We show using simulations that our theoretical results hold for
multi-agent systems with as few as 1000 agents---the system rapidly converges
to the steady-state distribution of scrip tokens necessary to ensure monitoring
and then remains close to the steady state."
"Recently, there has been immense interest in using unmanned aerial vehicles
(UAVs) for civilian operations. As a result, unmanned aerial systems traffic
management is needed to ensure the safety and goal satisfaction of potentially
thousands of UAVs flying simultaneously. Currently, the analysis of large
multi-agent systems cannot tractably provide these guarantees if the agents'
set of maneuvers is unrestricted. In this paper, platoons of UAVs flying on air
highways is proposed to impose an airspace structure that allows for tractable
analysis. For the air highway placement problem, the fast marching method is
used to produce a sequence of air highways that minimizes the cost of flying
from an origin to any destination. The placement of air highways can be updated
in real-time to accommodate sudden airspace changes. Within platoons traveling
on air highways, each vehicle is modeled as a hybrid system. Using
Hamilton-Jacobi reachability, safety and goal satisfaction are guaranteed for
all mode transitions. For a single altitude range, the proposed approach
guarantees safety for one safety breach per vehicle, in the unlikely event of
multiple safety breaches, safety can be guaranteed over multiple altitude
ranges. We demonstrate the platooning concept through simulations of three
representative scenarios."
"Multi-UAV systems are safety-critical, and guarantees must be made to ensure
no unsafe configurations occur. Hamilton-Jacobi (HJ) reachability is ideal for
analyzing such safety-critical systems; however, its direct application is
limited to small-scale systems of no more than two vehicles due to an
exponentially-scaling computational complexity. Previously, the sequential path
planning (SPP) method, which assigns strict priorities to vehicles, was
proposed; SPP allows multi-vehicle path planning to be done with a
linearly-scaling computational complexity. However, the previous formulation
assumed that there are no disturbances, and that every vehicle has perfect
knowledge of higher-priority vehicles' positions. In this paper, we make SPP
more practical by providing three different methods to account for disturbances
in dynamics and imperfect knowledge of higher-priority vehicles' states. Each
method has different assumptions about information sharing. We demonstrate our
proposed methods in simulations."
"This article analyzes two classes of job selection policies that control how
a network of autonomous aerial vehicles delivers goods from depots to
customers. Customer requests (jobs) occur according to a spatio-temporal
stochastic process not known by the system. If job selection uses a policy in
which the first job (FJ) is served first, the system may collapse to
instability by removing just one vehicle. Policies that serve the nearest job
(NJ) first show such threshold behavior only in some settings and can be
implemented in a distributed manner. The timing of job selection has
significant impact on delivery time and stability for NJ while it has no impact
for FJ. Based on these findings we introduce a methodological approach for
decision-making support to set up and operate such a system, taking into
account the trade-off between monetary cost and service quality. In particular,
we compute a lower bound for the infrastructure expenditure required to achieve
a certain expected delivery time. The approach includes three time horizons:
long-term decisions on the number of depots to deploy in the service area,
mid-term decisions on the number of vehicles to use, and short-term decisions
on the policy to operate the vehicles."
"An agent-based negotiation team is a group of interdependent agents that join
together as a single negotiation party due to their shared interests in the
negotiation at hand. The reasons to employ an agent-based negotiation team may
vary: (i) more computation and parallelization capabilities, (ii) unite agents
with different expertise and skills whose joint work makes it possible to
tackle complex negotiation domains, (iii) the necessity to represent different
stakeholders or different preferences in the same party (e.g., organizations,
countries, and married couple). The topic of agent-based negotiation teams has
been recently introduced in multi-agent research. Therefore, it is necessary to
identify good practices, challenges, and related research that may help in
advancing the state-of-the-art in agent-based negotiation teams. For that
reason, in this article we review the tasks to be carried out by agent-based
negotiation teams. Each task is analyzed and related with current advances in
different research areas. The analysis aims to identify special challenges that
may arise due to the particularities of agent-based negotiation teams."
"In this article we study the impact of the negotiation environment on the
performance of several intra-team strategies (team dynamics) for agent-based
negotiation teams that negotiate with an opponent. An agent-based negotiation
team is a group of agents that joins together as a party because they share
common interests in the negotiation at hand. It is experimentally shown how
negotiation environment conditions like the deadline of both parties, the
concession speed of the opponent, similarity among team members, and team size
affect performance metrics like the minimum utility of team members, the
average utility of team members, and the number of negotiation rounds. Our goal
is identifying which intra-team strategies work better in different
environmental conditions in order to provide useful knowledge for team members
to select appropriate intra-team strategies according to environmental
conditions."
"Bike-sharing transportation systems have been well studied from a top-down
viewpoint, either for an optimal conception of the system, or for a better
statistical understanding of their working mechanisms in the aim of the
optimization of the management strategy. Yet bottom-up approaches that could
include behavior of users have not been well studied so far. We propose an
agent-based model for the short time evolution of a bike-sharing system, with a
focus on two strategical parameters that are the role of the quantity of
information users have on the all system and the propensity of user to walk
after having dropped their bike. We implement the model in a general way so it
is applicable to every system as soon as data are available in a certain
format. The model of simulation is parametrized and calibrated on processed
real time-series of bike movements for the system of Paris. After showing the
robustness of the simulations by validating internally and externally the
model, we are able to test different user-based strategies for an increase of
the level of service. In particular, we show that an increase of user
information can have significant impact on the homogeneity of repartition of
bikes in docking stations, and, what is important for a future implementation
of the strategy, that an action on only 30% of regular users is enough to
obtain most of the possible amelioration."
"This thesis presents the theoretical, conceptual and methodological aspects
that support the modeling of dynamical systems (DS) by using several agents.
The modeling approach permits the assessment of properties representing order,
change, equilibrium, adaptability, and autonomy, in DS. The modeling processes
were supported by a conceptual corpus regarding systems dynamics, multi-agent
systems, graph theory, and, particularly, the information theory. Besides to
the specification of the dynamical systems as a computational network of
agents, metrics that allow characterizing and assessing the inherent complexity
of such systems were defined. As a result, properties associated with
emergence, self-organization, complexity, homeostasis and autopoiesis were
defined, formalized and measured. The validation of the underlying DS model was
carried out on discrete systems (boolean networks and cellular automata) and
ecological systems. The central contribution of this thesis was the development
of a methodological approach for DS modeling. This approach includes a larger
set of properties than in traditional studies, what allows us to deepen in
questioning essential issues associated with the DS field. All this was
achieved from a simple base of calculation and interpretation, which does not
require advanced mathematical knowledge, and facilitates their application in
different fields of science."
"We consider iterative voting models and position them within the general
framework of acyclic games and game forms. More specifically, we classify
convergence results based on the underlying assumptions on the agent scheduler
(the order of players) and the action scheduler (which better-reply is played).
  Our main technical result is providing a complete picture of conditions for
acyclicity in several variations of Plurality voting. In particular, we show
that (a) under the traditional lexicographic tie-breaking, the game converges
for any order of players under a weak restriction on voters' actions; and (b)
Plurality with randomized tie-breaking is not guaranteed to converge under
arbitrary agent schedulers, but from any initial state there is \emph{some}
path of better-replies to a Nash equilibrium. We thus show a first separation
between restricted-acyclicity and weak-acyclicity of game forms, thereby
settling an open question from [Kukushkin, IJGT 2011]. In addition, we refute
another conjecture regarding strongly-acyclic voting rules."
"Space and movement through space play an important role in many collective
adaptive systems (CAS). CAS consist of multiple components interacting to
achieve some goal in a system or environment that can change over time. When
these components operate in space, then their behaviour can be affected by
where they are located in that space. Examples include the possibility of
communication between two components located at different points, and rates of
movement of a component that may be affected by location. The CARMA language
and its associated software tools can be used to model such systems. In
particular, a graphical editor for CARMA allows for the specification of
spatial structure and generation of templates that can be used in a CARMA model
with space. We demonstrate the use of this tool to experiment with a model of
pedestrian movement over a network of paths."
"This paper proposes an analytical framework for modelling resource contention
in multi-robot systems, where the travel times and task durations are
uncertain. It uses several approximation methods to quickly and accurately
calculate the probability distributions describing the times at which the tasks
start and finish. Specific contributions include a method for calculating the
probability of a set of independent normally distributed random events
occurring in a given order, an upper bound on that probability, and a method
for calculating the most likely and $n$-th most likely orders of occurrence for
a set of independent normally distributed random events that have equal
standard deviations. The complete framework is shown to be much faster than a
Monte Carlo approach for the same accuracy in two multi-robot task allocation
problems. This is a general framework that is agnostic to the optimisation
method and objective function used, and is applicable to a wide range of
robotics and non-robotics problems."
"A framework for consensus modelling is introduced using Kleene's three valued
logic as a means to express vagueness in agents' beliefs. Explicitly borderline
cases are inherent to propositions involving vague concepts where sentences of
a propositional language may be absolutely true, absolutely false or
borderline. By exploiting these intermediate truth values, we can allow agents
to adopt a more vague interpretation of underlying concepts in order to weaken
their beliefs and reduce the levels of inconsistency, so as to achieve
consensus. We consider a consensus combination operation which results in
agents adopting the borderline truth value as a shared viewpoint if they are in
direct conflict. Simulation experiments are presented which show that applying
this operator to agents chosen at random (subject to a consistency threshold)
from a population, with initially diverse opinions, results in convergence to a
smaller set of more precise shared beliefs. Furthermore, if the choice of
agents for combination is dependent on the payoff of their beliefs, this acting
as a proxy for performance or usefulness, then the system converges to beliefs
which, on average, have higher payoff."
"This text reports in detail how SEAL, a modeling framework for the economy
based on individual agents and firms, works. Thus, it aims to be an usage
manual for those wishing to use SEAL or SEAL's results. As a reference work,
theoretical and research studies are only cited. SEAL is thought as a Lab that
enables the simulation of the economy with spatially bounded
microeconomic-based computational agents. Part of the novelty of SEAL comes
from the possibility of simulating the economy in space and the instantiation
of different public offices, i.e. government institutions, with embedded
markets and actual data. SEAL is designed for Public Policy analysis,
specifically those related to Public Finance, Taxes and Real Estate."
"In this paper we focus on spatial Markov population models, describing the
stochastic evolution of populations of agents, explicitly modelling their
spatial distribution, representing space as a discrete, finite graph. More
specifically, we present a heuristic approach to aggregating spatial locations,
which is designed to preserve the dynamical behaviour of the model whilst
reducing the computational cost of analysis. Our approach combines stochastic
approximation ideas (moment closure, linear noise), with computational
statistics (spectral clustering) to obtain an efficient aggregation, which is
experimentally shown to be reasonably accurate on two case studies: an instance
of epidemic spreading and a London bike sharing scenario."
"The calibration and validation of pedestrian simulations require the
acquisition of empirical evidences of human behaviour. The current work
presents the results of an experiment focused on the potentially combined
effect of counter flow and grouping on pedestrian dynamics. In particular, we
focused on: (i) four different configurations of flow ratio (the rate between
the minor flow and the total flow in bidirectional scenarios); (ii) dyads, as
the most frequently observed and basic social groups of crowds. Results showed
that the increase of flow ratio negatively impacted the speed of pedestrians.
Dyads walked significantly slower than singletons, due to the difficulty in
movement coordination among group members (proxemics) in case of counter flow.
The collected results represent an useful contribution towards the validation
of pedestrian simulations."
"We consider the following problem - a group of mobile agents perform some
task on a terrain modeled as a graph. In a given moment of time an adversary
gets an access to the graph and positions of the agents. Shortly before
adversary's observation the mobile agents have a chance to relocate themselves
in order to hide their initial configuration. We assume that the initial
configuration may possibly reveal to the adversary some information about the
task they performed. Clearly agents have to change their location in possibly
short time using minimal energy. In our paper we introduce a definition of a
\emph{well hiding} algorithm in which the starting and final configurations of
the agents have small mutual information. Then we discuss the influence of
various features of the model on the running time of the optimal well-hiding
algorithm. We show that if the topology of the graph is known to the agents,
then the number of steps proportional to the diameter of the graph is
sufficient and necessary. In the unknown topology scenario we only consider a
single agent case. We first show that the task is impossible in the
deterministic case if the agent has no memory. Then we present a polynomial
randomized algorithm. Finally in the model with memory we show that the number
of steps proportional to the number of edges of the graph is sufficient and
necessary. In some sense we investigate how complex is the problem of ""losing""
information about location (both physical and logical) for different settings."
"Logic-based representations of multi-agent systems have been extensively
studied. In this work, we focus on the action language BC to formalize global
views of MAS domains. Methodologically, we start representing the behaviour of
each agent by an action description from a single agent perspective. Then, it
goes through two stages that guide the modeler in composing the global view by
first designating multi-agent aspects of the domain via potential conflicts and
later resolving these conflicts according to the expected behaviour of the
overall system. Considering that representing single agent descriptions is
relatively simpler than representing multi-agent description directly, the
formalization developed here is valuable from a knowledge representation
perspective."
"We present a new model that describes the process of electing a group of
representatives (e.g., a parliament) for a group of voters. In this model,
called the voting committee model, the elected group of representatives runs a
number of ballots to make final decisions regarding various issues. The
satisfaction of voters comes from the final decisions made by the elected
committee. Our results suggest that depending on a decision system used by the
committee to make these final decisions, different multi-winner election rules
are most suitable for electing the committee. Furthermore, we show that if we
allow not only a committee, but also an election rule used to make final
decisions, to depend on the voters' preferences, we can obtain an even better
representation of the voters."
"Individual robots are not effective at exploring large unmapped areas. An
alternate approach is to use a swarm of simple robots that work together,
rather than a single highly capable robot. The central-place foraging algorithm
(CPFA) is effective for coordinating robot swarm search and collection tasks.
Robots start at a centrally placed location (nest), explore potential targets
in the area without global localization or central control, and return the
targets to the nest. The scalability of the CPFA is limited because large
numbers of robots produce more inter-robot collisions and large search areas
result in substantial travel costs. We address these problems with the
multiple-place foraging algorithm (MPFA), which uses multiple nests distributed
throughout the search area. Robots start from a randomly assigned home nest but
return to the closest nest with found targets. We simulate the foraging
behavior of robot swarms in the robot simulator ARGoS and employ a genetic
algorithm to discover different optimized foraging strategies as swarm sizes
and the number of targets are scaled up. In our experiments, the MPFA always
produces higher foraging rates, fewer collisions, and lower travel and search
time compared to the CPFA for the partially clustered targets distribution. The
main contribution of this paper is that we systematically quantify the
advantages of the MPFA (reduced travel time and collisions), the potential
disadvantages (less communication among robots), and the ability of a genetic
algorithm to tune MPFA parameters to mitigate search inefficiency due to less
communication."
"Consensus formation is investigated for multi-agent systems in which agents'
beliefs are both vague and uncertain. Vagueness is represented by a third truth
state meaning \emph{borderline}. This is combined with a probabilistic model of
uncertainty. A belief combination operator is then proposed which exploits
borderline truth values to enable agents with conflicting beliefs to reach a
compromise. A number of simulation experiments are carried out in which agents
apply this operator in pairwise interactions, under the bounded confidence
restriction that the two agents' beliefs must be sufficiently consistent with
each other before agreement can be reached. As well as studying the consensus
operator in isolation we also investigate scenarios in which agents are
influenced either directly or indirectly by the state of the world. For the
former we conduct simulations which combine consensus formation with belief
updating based on evidence. For the latter we investigate the effect of
assuming that the closer an agent's beliefs are to the truth the more visible
they are in the consensus building process. In all cases applying the consensus
operators results in the population converging to a single shared belief which
is both crisp and certain. Furthermore, simulations which combine consensus
formation with evidential updating converge faster to a shared opinion which is
closer to the actual state of the world than those in which beliefs are only
changed as a result of directly receiving new evidence. Finally, if agent
interactions are guided by belief quality measured as similarity to the true
state of the world, then applying the consensus operator alone results in the
population converging to a high quality shared belief."
"Coalition formation typically involves the coming together of multiple,
heterogeneous, agents to achieve both their individual and collective goals. In
this paper, we focus on a special case of coalition formation known as
Graph-Constrained Coalition Formation (GCCF) whereby a network connecting the
agents constrains the formation of coalitions. We focus on this type of problem
given that in many real-world applications, agents may be connected by a
communication network or only trust certain peers in their social network. We
propose a novel representation of this problem based on the concept of edge
contraction, which allows us to model the search space induced by the GCCF
problem as a rooted tree. Then, we propose an anytime solution algorithm
(CFSS), which is particularly efficient when applied to a general class of
characteristic functions called $m+a$ functions. Moreover, we show how CFSS can
be efficiently parallelised to solve GCCF using a non-redundant partition of
the search space. We benchmark CFSS on both synthetic and realistic scenarios,
using a real-world dataset consisting of the energy consumption of a large
number of households in the UK. Our results show that, in the best case, the
serial version of CFSS is 4 orders of magnitude faster than the state of the
art, while the parallel version is 9.44 times faster than the serial version on
a 12-core machine. Moreover, CFSS is the first approach to provide anytime
approximate solutions with quality guarantees for very large systems of agents
(i.e., with more than 2700 agents)."
"We present a simple, yet realistic, agent-based model of an electricity
market. The proposed model combines the spot and balancing markets with a
resolution of one minute, which enables a more accurate depiction of the
physical properties of the power grid. As a test, we compare the results
obtained from our simulation to data from Nord Pool."
"We describe a hybrid agent-based model and simulation of urban morphogenesis.
It consists of a cellular automata grid coupled to a dynamic network topology.
The inherently heterogeneous properties of urban structure and function are
taken into account in the dynamics of the system. We propose various layout and
performance measures to categorize and explore the generated configurations. An
economic evaluation metric was also designed using the sensitivity of
segregation models to spatial configuration. Our model is applied to a
real-world case, offering a means to optimize the distribution of activities in
a zoning context."
"Organic Computing is an initiative in the field of systems engineering that
proposed to make use of concepts such as self-adaptation and self-organisation
to increase the robustness of technical systems. Based on the observation that
traditional design and operation concepts reach their limits, transferring more
autonomy to the systems themselves should result in a reduction of complexity
for users, administrators, and developers. However, there seems to be a need
for an updated definition of the term ""Organic Computing"", of desired
properties of technical, organic systems, and the objectives of the Organic
Computing initiative. With this article, we will address these points."
"This paper extends and adapts an existing abstract model into an empirical
metropolitan region in Brazil. The model - named SEAL: a Spatial Economic
Agent-based Lab - comprehends a framework to enable public policy ex-ante
analysis. The aim of the model is to use official data and municipalities
spatial boundaries to allow for policy experimentation. The current version
considers three markets: housing, labor and goods. Families' members age,
consume, join the labor market and trade houses. A single consumption tax is
collected by municipalities that invest back into quality of life improvements.
We test whether a single metropolitan government - which is an aggregation of
municipalities - would be in the best interest of its citizens. Preliminary
results for 20 simulation runs indicate that it may be the case. Future
developments include improving performance to enable running of higher
percentage of the population and a number of runs that make the model more
robust."
"In multi-robot systems where a central decision maker is specifying the
movement of each individual robot, a communication failure can severely impair
the performance of the system. This paper develops a motion strategy that
allows robots to safely handle critical communication failures for such
multi-robot architectures. For each robot, the proposed algorithm computes a
time horizon over which collisions with other robots are guaranteed not to
occur. These safe time horizons are included in the commands being transmitted
to the individual robots. In the event of a communication failure, the robots
execute the last received velocity commands for the corresponding safe time
horizons leading to a provably safe open-loop motion strategy. The resulting
algorithm is computationally effective and is agnostic to the task that the
robots are performing. The efficacy of the strategy is verified in simulation
as well as on a team of differential-drive mobile robots."
"Online learning with streaming data in a distributed and collaborative manner
can be useful in a wide range of applications. This topic has been receiving
considerable attention in recent years with emphasis on both single-task and
multitask scenarios. In single-task adaptation, agents cooperate to track an
objective of common interest, while in multitask adaptation agents track
multiple objectives simultaneously. Regularization is one useful technique to
promote and exploit similarity among tasks in the latter scenario. This work
examines an alternative way to model relations among tasks by assuming that
they all share a common latent feature representation. As a result, a new
multitask learning formulation is presented and algorithms are developed for
its solution in a distributed online manner. We present a unified framework to
analyze the mean-square-error performance of the adaptive strategies, and
conduct simulations to illustrate the theoretical findings and potential
applications."
"We propose distributed online open loop planning (DOOLP), a general framework
for online multiagent coordination and decision making under uncertainty. DOOLP
is based on online heuristic search in the space defined by a generative model
of the domain dynamics, which is exploited by agents to simulate and evaluate
the consequences of their potential choices.
  We also propose distributed online Thompson sampling (DOTS) as an effective
instantiation of the DOOLP framework. DOTS models sequences of agent choices by
concatenating a number of multiarmed bandits for each agent and uses Thompson
sampling for dealing with action value uncertainty. The Bayesian approach
underlying Thompson sampling allows to effectively model and estimate
uncertainty about (a) own action values and (b) other agents' behavior. This
approach yields a principled and statistically sound solution to the
exploration-exploitation dilemma when exploring large search spaces with
limited resources.
  We implemented DOTS in a smart factory case study with positive empirical
results. We observed effective, robust and scalable planning and coordination
capabilities even when only searching a fraction of the potential search space."
"In this paper a decentralized control algorithm for systems composed of $N$
dynamically decoupled agents, coupled by feasibility constraints, is presented.
The control problem is divided into $N$ optimal control sub-problems and a
communication scheme is proposed to decouple computations. The derivative of
the solution of each sub-problem is used to approximate the evolution of the
system allowing the algorithm to decentralize and parallelize computations. The
effectiveness of the proposed algorithm is shown through simulations in a
cooperative driving scenario."
"Congestion problems are omnipresent in today's complex networks and represent
a challenge in many research domains. In the context of Multi-agent
Reinforcement Learning (MARL), approaches like difference rewards and resource
abstraction have shown promising results in tackling such problems. Resource
abstraction was shown to be an ideal candidate for solving large-scale resource
allocation problems in a fully decentralized manner. However, its performance
and applicability strongly depends on some, until now, undocumented
assumptions. Two of the main congestion benchmark problems considered in the
literature are: the Beach Problem Domain and the Traffic Lane Domain. In both
settings the highest system utility is achieved when overcrowding one resource
and keeping the rest at optimum capacity. We analyse how abstract grouping can
promote this behaviour and how feasible it is to apply this approach in a
real-world domain (i.e., what assumptions need to be satisfied and what
knowledge is necessary). We introduce a new test problem, the Road Network
Domain (RND), where the resources are no longer independent, but rather part of
a network (e.g., road network), thus choosing one path will also impact the
load on other paths having common road segments. We demonstrate the application
of state-of-the-art MARL methods for this new congestion model and analyse
their performance. RND allows us to highlight an important limitation of
resource abstraction and show that the difference rewards approach manages to
better capture and inform the agents about the dynamics of the environment."
"The model presented in this paper experiments with a comprehensive simulant
agent in order to provide an exploratory platform in which simulation modelers
may try alternative scenarios and participation in policy decision-making. The
framework is built in a computationally distributed online format in which
users can join in and visually explore the results. Modeled activity involves
daily routine errands, such as shopping, visiting the doctor or engaging in the
labor market. Further, agents make everyday decisions based on individual
behavioral attributes and minimal requirements, according to social and
contagion networks. Fully developed firms and governments are also included in
the model allowing for taxes collection, production decisions, bankruptcy and
change in ownership. The contributions to the literature are multifold. They
include (a) a comprehensive model with detailing of the agents and firms'
activities and processes and original use of simultaneously (b) reinforcement
learning for firm pricing and demand allocation; (c) social contagion for
disease spreading and social network for hiring opportunities; and (d) Bayesian
networks for demographic-like generation of agents. All of that within a (e)
visually rich environment and multiple use of databases. Hence, the model
provides a comprehensive framework from where interactions among citizens,
firms and governments can be easily explored allowing for learning and
visualization of policies and scenarios."
"Robust environment perception is essential for decision-making on robots
operating in complex domains. Intelligent task execution requires principled
treatment of uncertainty sources in a robot's observation model. This is
important not only for low-level observations (e.g., accelerometer data), but
also for high-level observations such as semantic object labels. This paper
formalizes the concept of macro-observations in Decentralized Partially
Observable Semi-Markov Decision Processes (Dec-POSMDPs), allowing scalable
semantic-level multi-robot decision making. A hierarchical Bayesian approach is
used to model noise statistics of low-level classifier outputs, while
simultaneously allowing sharing of domain noise characteristics between
classes. Classification accuracy of the proposed macro-observation scheme,
called Hierarchical Bayesian Noise Inference (HBNI), is shown to exceed
existing methods. The macro-observation scheme is then integrated into a
Dec-POSMDP planner, with hardware experiments running onboard a team of dynamic
quadrotors in a challenging domain where noise-agnostic filtering fails. To the
best of our knowledge, this is the first demonstration of a real-time,
convolutional neural net-based classification framework running fully onboard a
team of quadrotors in a multi-robot decision-making domain."
"This paper presents the first ever approach for solving
\emph{continuous-observation} Decentralized Partially Observable Markov
Decision Processes (Dec-POMDPs) and their semi-Markovian counterparts,
Dec-POSMDPs. This contribution is especially important in robotics, where a
vast number of sensors provide continuous observation data. A
continuous-observation policy representation is introduced using Stochastic
Kernel-based Finite State Automata (SK-FSAs). An SK-FSA search algorithm titled
Entropy-based Policy Search using Continuous Kernel Observations (EPSCKO) is
introduced and applied to the first ever continuous-observation
Dec-POMDP/Dec-POSMDP domain, where it significantly outperforms
state-of-the-art discrete approaches. This methodology is equally applicable to
Dec-POMDPs and Dec-POSMDPs, though the empirical analysis presented focuses on
Dec-POSMDPs due to their higher scalability. To improve convergence, an entropy
injection policy search acceleration approach for both continuous and discrete
observation cases is also developed and shown to improve convergence rates
without degrading policy quality."
"In large-scale natural disasters, humans are likely to fail when they attempt
to reach high-risk sites or act in search and rescue operations. Robots,
however, outdo their counterparts in surviving the hazards and handling the
search and rescue missions due to their multiple and diverse sensing and
actuation capabilities. The dynamic formation of optimal coalition of these
heterogeneous robots for cost efficiency is very challenging and research in
the area is gaining more and more attention. In this paper, we propose a novel
heuristic. Since the population of robots in large-scale disaster settings is
very large, we rely on Quantum Multi-Objective Particle Swarm Optimization
(QMOPSO). The problem is modeled as a multi-objective optimization problem.
Simulations with different test cases and metrics, and comparison with other
algorithms such as NSGA-II and SPEA-II are carried out. The experimental
results show that the proposed algorithm outperforms the existing algorithms
not only in terms of convergence but also in terms of diversity and processing
time."
"This paper explores the use of Answer Set Programming (ASP) in solving
Distributed Constraint Optimization Problems (DCOPs). The paper provides the
following novel contributions: (1) It shows how one can formulate DCOPs as
logic programs; (2) It introduces ASP-DPOP, the first DCOP algorithm that is
based on logic programming; (3) It experimentally shows that ASP-DPOP can be up
to two orders of magnitude faster than DPOP (its imperative programming
counterpart) as well as solve some problems that DPOP fails to solve, due to
memory limitations; and (4) It demonstrates the applicability of ASP in a wide
array of multi-agent problems currently modeled as DCOPs. Under consideration
in Theory and Practice of Logic Programming (TPLP)."
"In the context of solving large distributed constraint optimization problems
(DCOP), belief-propagation and approximate inference algorithms are candidates
of choice. However, in general, when the factor graph is very loopy (i.e.
cyclic), these solution methods suffer from bad performance, due to
non-convergence and many exchanged messages. As to improve performances of the
Max-Sum inference algorithm when solving loopy constraint optimization
problems, we propose here to take inspiration from the
belief-propagation-guided dec-imation used to solve sparse random graphs
(k-satisfiability). We propose the novel DeciMaxSum method, which is
parameterized in terms of policies to decide when to trigger decimation, which
variables to decimate, and which values to assign to decimated variables. Based
on an empirical evaluation on a classical BP benchmark (the Ising model), some
of these combinations of policies exhibit better performance than
state-of-the-art competitors."
"Before reaching full autonomy, vehicles will gradually be equipped with more
and more advanced driver assistance systems (ADAS), effectively rendering them
semi-autonomous. However, current ADAS technologies seem unable to handle
complex traffic situations, notably when dealing with vehicles arriving from
the sides, either at intersections or when merging on highways. The high rate
of accidents in these settings prove that they constitute difficult driving
situations. Moreover, intersections and merging lanes are often the source of
important traffic congestion and, sometimes, deadlocks. In this article, we
propose a cooperative framework to safely coordinate semi-autonomous vehicles
in such settings, removing the risk of collision or deadlocks while remaining
compatible with human driving. More specifically, we present a supervised
coordination scheme that overrides control inputs from human drivers when they
would result in an unsafe or blocked situation. To avoid unnecessary
intervention and remain compatible with human driving, overriding only occurs
when collisions or deadlocks are imminent. In this case, safe overriding
controls are chosen while ensuring they deviate minimally from those originally
requested by the drivers. Simulation results based on a realistic physics
simulator show that our approach is scalable to real-world scenarios, and
computations can be performed in real-time on a standard computer for up to a
dozen simultaneous vehicles."
"Hedonic games are meant to model how coalitions of people form and break
apart in the real world. However, it is difficult to run simulations when
everything must be done by hand on paper. We present an online software that
allows fast and visual simulation of several types of hedonic games.
http://lukemiles.org/hedonic-games/"
"Finding asymptotically-optimal paths in multi-robot motion planning problems
could be achieved, in principle, using sampling-based planners in the composite
configuration space of all of the robots in the space. The dimensionality of
this space increases with the number of robots, rendering this approach
impractical. This work focuses on a scalable sampling-based planner for coupled
multi-robot problems that provides asymptotic optimality. It extends the dRRT
approach, which proposed building roadmaps for each robot and searching an
implicit roadmap in the composite configuration space. This work presents a new
method, dRRT* , and develops theory for scalable convergence to optimal paths
in multi-robot problems. Simulated experiments indicate dRRT* converges to
high-quality paths while scaling to higher numbers of robots where the naive
approach fails. Furthermore, dRRT* is applicable to high-dimensional problems,
such as planning for robot manipulators"
"Understanding the evolution of human society, as a complex adaptive system,
is a task that has been looked upon from various angles. In this paper, we
simulate an agent-based model with a high enough population tractably. To do
this, we characterize an entity called \textit{society}, which helps us reduce
the complexity of each step from $\mathcal{O}(n^2)$ to $\mathcal{O}(n)$. We
propose a very realistic setting, where we design a joint alternate
maximization step algorithm to maximize a certain \textit{fitness} function,
which we believe simulates the way societies develop. Our key contributions
include (i) proposing a novel protocol for simulating the evolution of a
society with cheap, non-optimal joint alternate maximization steps (ii)
providing a framework for carrying out experiments that adhere to this
joint-optimization simulation framework (iii) carrying out experiments to show
that it makes sense empirically (iv) providing an alternate justification for
the use of \textit{society} in the simulations."
"We propose a minority route choice game to investigate the effect of the
network structure on traffic network performance under the assumption of
drivers' bounded rationality. We investigate ring-and-hub topologies to capture
the nature of traffic networks in cities, and employ a minority game-based
inductive learning process to model the characteristic behavior under the route
choice scenario. Through numerical experiments, we find that topological
changes in traffic networks induce a phase transition from an uncongested phase
to a congested phase. Understanding this phase transition is helpful in
planning new traffic networks."
"The key challenge in multiagent learning is learning a best response to the
behaviour of other agents, which may be non-stationary: if the other agents
adapt their strategy as well, the learning target moves. Disparate streams of
research have approached non-stationarity from several angles, which make a
variety of implicit assumptions that make it hard to keep an overview of the
state of the art and to validate the innovation and significance of new works.
This survey presents a coherent overview of work that addresses
opponent-induced non-stationarity with tools from game theory, reinforcement
learning and multi-armed bandits. Further, we reflect on the principle
approaches how algorithms model and cope with this non-stationarity, arriving
at a new framework and five categories (in increasing order of sophistication):
ignore, forget, respond to target models, learn models, and theory of mind. A
wide range of state-of-the-art algorithms is classified into a taxonomy, using
these categories and key characteristics of the environment (e.g.,
observability) and adaptation behaviour of the opponents (e.g., smooth,
abrupt). To clarify even further we present illustrative variations of one
domain, contrasting the strengths and limitations of each category. Finally, we
discuss in which environments the different approaches yield most merit, and
point to promising avenues of future research."
"Adaptivity, both of the individual agents and of the interaction structure
among the agents, seems indispensable for scaling up multi-agent systems
(MAS's) in noisy environments. One important consideration in designing
adaptive agents is choosing their action spaces to be as amenable as possible
to machine learning techniques, especially to reinforcement learning (RL)
techniques. One important way to have the interaction structure connecting
agents itself be adaptive is to have the intentions and/or actions of the
agents be in the input spaces of the other agents, much as in Stackelberg
games. We consider both kinds of adaptivity in the design of a MAS to control
network packet routing.
  We demonstrate on the OPNET event-driven network simulator the perhaps
surprising fact that simply changing the action space of the agents to be
better suited to RL can result in very large improvements in their potential
performance: at their best settings, our learning-amenable router agents
achieve throughputs up to three and one half times better than that of the
standard Bellman-Ford routing algorithm, even when the Bellman-Ford protocol
traffic is maintained. We then demonstrate that much of that potential
improvement can be realized by having the agents learn their settings when the
agent interaction structure is itself adaptive."
"Often adaptive, distributed control can be viewed as an iterated game between
independent players. The coupling between the players' mixed strategies,
arising as the system evolves from one instant to the next, is determined by
the system designer. Information theory tells us that the most likely joint
strategy of the players, given a value of the expectation of the overall
control objective function, is the minimizer of a Lagrangian function of the
joint strategy. So the goal of the system designer is to speed evolution of the
joint strategy to that Lagrangian minimizing point, lower the expectated value
of the control objective function, and repeat. Here we elaborate the theory of
algorithms that do this using local descent procedures, and that thereby
achieve efficient, adaptive, distributed control."
"We discuss potential market mechanisms for the GRID. A complete dynamical
model of a GRID market is defined with three types of agents. Providers,
middlemen and users exchange universal GRID computing units (GCUs) at varying
prices. Providers and middlemen have strategies aimed at maximizing profit
while users are 'satisficing' agents, and only change their behavior if the
service they receive is sufficiently poor or overpriced. Preliminary results
from a multi-agent numerical simulation of the market model shows that the
distribution of price changes has a power law tail."
"In this paper, we consider a form of multi-issue negotiation where a shop
negotiates both the contents and the price of bundles of goods with his
customers. We present some key insights about, as well as a procedure for,
locating mutually beneficial alternatives to the bundle currently under
negotiation. The essence of our approach lies in combining aggregate
(anonymous) knowledge of customer preferences with current data about the
ongoing negotiation process. The developed procedure either works with already
obtained aggregate knowledge or, in the absence of such knowledge, learns the
relevant information online. We conduct computer experiments with simulated
customers that have_nonlinear_ preferences. We show how, for various types of
customers, with distinct negotiation heuristics, our procedure (with and
without the necessary aggregate knowledge) increases the speed with which deals
are reached, as well as the number and the Pareto efficiency of the deals
reached compared to a benchmark."
"Emergence (macro-level effects from micro-level causes) is at the heart of
the conflict between reductionism and functionalism. How can there be
autonomous higher level laws of nature (the functionalist claim) if everything
can be reduced to the fundamental forces of physics (the reductionist
position)? We cut through this debate by applying a computer science lens to
the way we view nature. We conclude (a) that what functionalism calls the
special sciences (sciences other than physics) do indeed study autonomous laws
and furthermore that those laws pertain to real higher level entities but (b)
that interactions among such higher-level entities is epiphenomenal in that
they can always be reduced to primitive physical forces. In other words,
epiphenomena, which we will identify with emergent phenomena, do real
higher-level work. The proposed perspective provides a framework for
understanding many thorny issues including the nature of entities, stigmergy,
the evolution of complexity, phase transitions, supervenience, and downward
entailment. We also discuss some practical considerations pertaining to systems
of systems and the limitations of modeling."
"We investigate a prototypical agent-based model, the Naming Game, on random
geometric networks. The Naming Game is a minimal model, employing local
communications that captures the emergence of shared communication schemes
(languages) in a population of autonomous semiotic agents. Implementing the
Naming Games on random geometric graphs, local communications being local
broadcasts, serves as a model for agreement dynamics in large-scale,
autonomously operating wireless sensor networks. Further, it captures essential
features of the scaling properties of the agreement process for
spatially-embedded autonomous agents. We also present results for the case when
a small density of long-range communication links are added on top of the
random geometric graph, resulting in a ""small-world""-like network and yielding
a significantly reduced time to reach global agreement."
"Mobile agents research is clearly aiming towards imposing agent based
development as the next generation of tools for writing software. This paper
comes with its own contribution to this global goal by introducing a novel
unifying framework meant to bring simplicity and interoperability to and among
agent platforms as we know them today. In addition to this, we also introduce a
set of agent behaviors which, although tailored for and from the area of
virtual learning environments, are none the less generic enough to be used for
rapid, simple, useful and reliable agent deployment. The paper also presents an
illustrative case study brought forward to prove the feasibility of our design."
"E-learning is nowadays one of the most interesting of the ""e- "" domains
available through the Internet. The main problem to create a Web-based, virtual
environment is to model the traditional domain and to implement the model using
the most suitable technologies. We analyzed the distance learning domain and
investigated the possibility to implement some e-learning services using mobile
agent technologies. This paper presents a model of the Student Assessment
Service (SAS) and an agent-based framework developed to be used for
implementing specific applications. A specific Student Assessment application
that relies on the framework was developed."
"In recent times, a considerable amount of work has been devoted to the
development and analysis of gossip algorithms in Geometric Random Graphs. In a
recently introduced model termed ""Geographic Gossip,"" each node is aware of its
position but possesses no further information. Traditionally, gossip protocols
have always used convex linear combinations to achieve averaging. We develop a
new protocol for Geographic Gossip, in which counter-intuitively, we use {\it
non-convex affine combinations} as updates in addition to convex combinations
to accelerate the averaging process. The dependence of the number of
transmissions used by our algorithm on the number of sensors $n$ is $n
\exp(O(\log \log n)^2) = n^{1 + o(1)}$. For the previous algorithm, this
dependence was $\tilde{O}(n^{1.5})$. The exponent 1+ o(1) of our algorithm is
asymptotically optimal. Our algorithm involves a hierarchical structure of
$\log \log n$ depth and is not completely decentralized. However, the extent of
control exercised by a sensor on another is restricted to switching the other
on or off."
"We prove that for a set of communicating agents to compute the average of
their initial positions (average consensus problem), the optimal topology of
communication is given by a de Bruijn's graph. Consensus is then reached in a
finitely many steps. A more general family of strategies, constructed by block
Kronecker products, is investigated and compared to Cayley strategies."
"Many complex systems can be modeled as multiagent systems in which the
constituent entities (agents) interact with each other. The global dynamics of
such a system is determined by the nature of the local interactions among the
agents. Since it is difficult to formally analyze complex multiagent systems,
they are often studied through computer simulations. While computer simulations
can be very useful, results obtained through simulations do not formally
validate the observed behavior. Thus, there is a need for a mathematical
framework which one can use to represent multiagent systems and formally
establish their properties. This work contains a brief exposition of some known
mathematical frameworks that can model multiagent systems. The focus is on one
such framework, namely that of finite dynamical systems. Both, deterministic
and stochastic versions of this framework are discussed. The paper contains a
sampling of the mathematical results from the literature to show how finite
dynamical systems can be used to carry out a rigorous study of the properties
of multiagent systems and it is shown how the framework can also serve as a
universal model for computation."
"We investigate the problem of autonomous agents processing pieces of
information that may be corrupted (tainted). Agents have the option of
contacting a central database for a reliable check of the status of the
message, but this procedure is costly and therefore should be used with
parsimony. Agents have to evaluate the risk of being infected, and decide if
and when communicating partners are affordable. Trustability is implemented as
a personal (one-to-one) record of past contacts among agents, and as a
mean-field monitoring of the level of message corruption. Moreover, this
information is slowly forgotten in time, so that at the end everybody is
checked against the database. We explore the behavior of a homogeneous system
in the case of a fixed pool of spreaders of corrupted messages, and in the case
of spontaneous appearance of corrupted messages."
"The paper studies distributed static parameter (vector) estimation in sensor
networks with nonlinear observation models and noisy inter-sensor
communication. It introduces \emph{separably estimable} observation models that
generalize the observability condition in linear centralized estimation to
nonlinear distributed estimation. It studies two distributed estimation
algorithms in separably estimable models, the $\mathcal{NU}$ (with its linear
counterpart $\mathcal{LU}$) and the $\mathcal{NLU}$. Their update rule combines
a \emph{consensus} step (where each sensor updates the state by weight
averaging it with its neighbors' states) and an \emph{innovation} step (where
each sensor processes its local current observation.) This makes the three
algorithms of the \textit{consensus + innovations} type, very different from
traditional consensus. The paper proves consistency (all sensors reach
consensus almost surely and converge to the true parameter value,) efficiency,
and asymptotic unbiasedness. For $\mathcal{LU}$ and $\mathcal{NU}$, it proves
asymptotic normality and provides convergence rate guarantees. The three
algorithms are characterized by appropriately chosen decaying weight sequences.
Algorithms $\mathcal{LU}$ and $\mathcal{NU}$ are analyzed in the framework of
stochastic approximation theory; algorithm $\mathcal{NLU}$ exhibits mixed
time-scale behavior and biased perturbations, and its analysis requires a
different approach that is developed in the paper."
"We prove the following results for task allocation of indivisible resources:
  - The problem of finding a leximin-maximal resource allocation is in P if the
agents have max-utility functions and atomic demands.
  - Deciding whether a resource allocation is Pareto-optimal is coNP-complete
for agents with (1-)additive utility functions.
  - Deciding whether there exists a Pareto-optimal and envy-free resource
allocation is Sigma_2^p-complete for agents with (1-)additive utility
functions."
"EVOC (for EVOlution of Culture) is a computer model of culture that enables
us to investigate how various factors such as barriers to cultural diffusion,
the presence and choice of leaders, or changes in the ratio of innovation to
imitation affect the diversity and effectiveness of ideas. It consists of
neural network based agents that invent ideas for actions, and imitate
neighbors' actions. The model is based on a theory of culture according to
which what evolves through culture is not memes or artifacts, but the internal
models of the world that give rise to them, and they evolve not through a
Darwinian process of competitive exclusion but a Lamarckian process involving
exchange of innovation protocols. EVOC shows an increase in mean fitness of
actions over time, and an increase and then decrease in the diversity of
actions. Diversity of actions is positively correlated with population size and
density, and with barriers between populations. Slowly eroding borders increase
fitness without sacrificing diversity by fostering specialization followed by
sharing of fit actions. Introducing a leader that broadcasts its actions
throughout the population increases the fitness of actions but reduces
diversity of actions. Increasing the number of leaders reduces this effect.
Efforts are underway to simulate the conditions under which an agent
immigrating from one culture to another contributes new ideas while still
fitting in."
"Constructing and studying distributed control systems requires the analysis
of the Laplacian spectra and the forest structure of directed graphs. In this
paper, we present some basic results of this analysis partially obtained by the
present authors. We also discuss the application of these results to
decentralized control and touch upon some problems of spectral graph theory."
"This note corrects a pretty serious mistake and some inaccuracies in
""Consensus and cooperation in networked multi-agent systems"" by R.
Olfati-Saber, J.A. Fax, and R.M. Murray, published in Vol. 95 of the
Proceedings of the IEEE (2007, No. 1, P. 215-233). It also mentions several
stronger results applicable to the class of problems under consideration and
addresses the issue of priority whose interpretation in the above-mentioned
paper is not exact."
"In this paper, we consider the consensus problem of dynamical multiple agents
that communicate via a directed moving neighborhood random network. Each agent
performs random walk on a weighted directed network. Agents interact with each
other through random unidirectional information flow when they coincide in the
underlying network at a given instant. For such a framework, we present
sufficient conditions for almost sure asymptotic consensus. Some existed
consensus schemes are shown to be reduced versions of the current model."
"In this paper, we consider a leader-following consensus problem for networks
of continuous-time integrator agents with a time-varying leader under
measurement noises. We propose a neighbor-based state-estimation protocol for
every agent to track the leader, and time-varying consensus gains are
introduced to attenuate the noises. By combining the tools of stochastic
analysis and algebraic graph theory, we study mean square convergence of this
multi-agent system under directed fixed as well as switching interconnection
topologies. Sufficient conditions are given for mean square consensus in both
cases. Finally, a numerical example is given to illustrate our theoretical
results."
"It is an amazing fact that remarkably complex behaviors could emerge from a
large collection of very rudimentary dynamical agents through very simple local
interactions. However, it still remains elusive on how to design these local
interactions among agents so as to achieve certain desired collective
behaviors. This paper aims to tackle this challenge and proposes a
divide-and-conquer approach to guarantee specified global behaviors through
local coordination and control design for multi-agent systems. The basic idea
is to decompose the requested global specification into subtasks for each
individual agent. It should be noted that the decomposition is not arbitrary.
The global specification should be decomposed in such a way that the fulfilment
of these subtasks by each individual agent will imply the satisfaction of the
global specification as a team. First, it is shown by a counterexample that not
all specifications can be decomposed in this sense. Then, a natural follow-up
question is what the necessary and sufficient condition should be for the
proposed decomposability of a global specification. The main part of the paper
is set to answer this question. The case of two cooperative agents is
investigated first, and a necessary and sufficient condition is presented and
proven. Later on, the result is generalized to the case of arbitrary finite
number of agents, and a hierarchical algorithm is proposed, which is shown to
be a sufficient condition. Finally, a cooperative control scenario for a team
of three robots is developed to illustrate the task decomposition procedure."
"In this paper, we investigate synchronization in a small-world network of
coupled nonlinear oscillators. This network is constructed by introducing
random shortcuts in a nearest-neighbors ring. The local stability of the
synchronous state is closely related with the support of the eigenvalue
distribution of the Laplacian matrix of the network. We introduce, for the
first time, analytical expressions for the first three moments of the
eigenvalue distribution of the Laplacian matrix as a function of the
probability of shortcuts and the connectivity of the underlying
nearest-neighbor coupled ring. We apply these expressions to estimate the
spectral support of the Laplacian matrix in order to predict synchronization in
small-world networks. We verify the efficiency of our predictions with
numerical simulations."
"In this paper, we study the dynamics of a viral spreading process in random
geometric graphs (RGG). The spreading of the viral process we consider in this
paper is closely related with the eigenvalues of the adjacency matrix of the
graph. We deduce new explicit expressions for all the moments of the eigenvalue
distribution of the adjacency matrix as a function of the spatial density of
nodes and the radius of connection. We apply these expressions to study the
behavior of the viral infection in an RGG. Based on our results, we deduce an
analytical condition that can be used to design RGG's in order to tame an
initial viral infection. Numerical simulations are in accordance with our
analytical predictions."
"This paper investigates the effectiveness of creative versus uncreative
leadership using EVOC, an agent-based model of cultural evolution. Each
iteration, each agent in the artificial society invents a new action, or
imitates a neighbor's action. Only the leader's actions can be imitated by all
other agents, referred to as followers. Two measures of creativity were used:
(1) invention-to-imitation ratio, iLeader, which measures how often an agent
invents, and (2) rate of conceptual change, cLeader, which measures how
creative an invention is. High iLeader increased mean fitness of ideas, but
only when creativity of followers was low. High iLeader was associated with
greater diversity of ideas in the early stage of idea generation only. High
cLeader increased mean fitness of ideas in the early stage of idea generation;
in the later stage it decreased idea fitness. Reasons for these findings and
tentative implications for creative leadership in human society are discussed."
"Comparative benefits provided by the basic social strategies including
collectivism and egoism are investigated within the framework of democratic
decision-making. In particular, we study the mechanism of growing ""snowball"" of
cooperation."
"New operating systems for mobile devices allow their users to download
millions of applications created by various individual programmers, some of
which may be malicious or flawed. In order to detect that an application is
malicious, monitoring its operation in a real environment for a significant
period of time is often required. Mobile devices have limited computation and
power resources and thus are limited in their monitoring capabilities. In this
paper we propose an efficient collaborative monitoring scheme that harnesses
the collective resources of many mobile devices, ""vaccinating"" them against
potentially unsafe applications. We suggest a new local information flooding
algorithm called ""TTL Probabilistic Propagation"" (TPP). The algorithm
periodically monitors one or more application and reports its conclusions to a
small number of other mobile devices, who then propagate this information
onwards. The algorithm is analyzed, and is shown to outperform existing state
of the art information propagation algorithms, in terms of convergence time as
well as network overhead. The maximal ""load"" of the algorithm (the fastest
arrival rate of new suspicious applications, that can still guarantee complete
monitoring), is analytically calculated and shown to be significantly superior
compared to any non-collaborative approach. Finally, we show both analytically
and experimentally using real world network data that implementing the proposed
algorithm significantly reduces the number of infected mobile devices. In
addition, we analytically prove that the algorithm is tolerant to several types
of Byzantine attacks where some adversarial agents may generate false
information, or abuse the algorithm in other ways."
"This note corrects a pretty serious mistake and some inaccuracies in
""Consensus and cooperation in networked multi-agent systems"" by R.
Olfati-Saber, J.A. Fax, and R.M. Murray, published in Vol. 95 of the
Proceedings of the IEEE (2007, No. 1, P. 215-233). It also mentions several
stronger results applicable to the class of problems under consideration and
addresses the issue of priority whose interpretation in the above-mentioned
paper is not exact."
"The eigenvalue spectrum of the adjacency matrix of a network is closely
related to the behavior of many dynamical processes run over the network. In
the field of robotics, this spectrum has important implications in many
problems that require some form of distributed coordination within a team of
robots. In this paper, we propose a continuous-time control scheme that
modifies the structure of a position-dependent network of mobile robots so that
it achieves a desired set of adjacency eigenvalues. For this, we employ a novel
abstraction of the eigenvalue spectrum by means of the adjacency matrix
spectral moments. Since the eigenvalue spectrum is uniquely determined by its
spectral moments, this abstraction provides a way to indirectly control the
eigenvalues of the network. Our construction is based on artificial potentials
that capture the distance of the network's spectral moments to their desired
values. Minimization of these potentials is via a gradient descent closed-loop
system that, under certain convexity assumptions, ensures convergence of the
network topology to one with the desired set of moments and, therefore,
eigenvalues. We illustrate our approach in nontrivial computer simulations."
"New advances in large scale distributed systems have amazingly offered
complex functionalities through parallelism of simple and rudimentary
components. The key issue in cooperative control of multi-agent systems is the
synthesis of local control and interaction rules among the agents such that the
entire controlled system achieves a desired global behavior. For this purpose,
three fundamental problems have to be addressed: (1) task decomposition for
top-down design, such that the fulfillment of local tasks guarantees the
satisfaction of the global task, by the team; (2) fault-tolerant top-down
design, such that the global task remains decomposable and achievable, in spite
of some failures, and (3) design of interactions among agents to make an
undecomposable task decomposable and achievable in a top-down framework. The
first two problems have been addressed in our previous works, by identifying
necessary and sufficient conditions for task automaton decomposition, and
fault-tolerant task decomposability. This paper deals with the third problem
and proposes a procedure to redistribute the events among agents in order to
enforce decomposability of an undecomposable task automaton. The
decomposability conditions are used to identify the root causes of
undecomposability which are found to be due to over-communications that have to
be deleted, while respecting the fault-tolerant decomposability conditions; or
because of the lack of communications that require new sharing of events, while
considering new violations of decomposability conditions. This result provides
a sufficient condition to make any undecomposable deterministic task automaton
decomposable in order to facilitate cooperative tasking. Illustrative examples
are presented to show the concept of task automaton decomposabilization."
"In this paper, we formulate and solve a randomized optimal consensus problem
for multi-agent systems with stochastically time-varying interconnection
topology. The considered multi-agent system with a simple randomized iterating
rule achieves an almost sure consensus meanwhile solving the optimization
problem $\min_{z\in \mathds{R}^d}\ \sum_{i=1}^n f_i(z),$ in which the optimal
solution set of objective function $f_i$ can only be observed by agent $i$
itself. At each time step, simply determined by a Bernoulli trial, each agent
independently and randomly chooses either taking an average among its neighbor
set, or projecting onto the optimal solution set of its own optimization
component. Both directed and bidirectional communication graphs are studied.
Connectivity conditions are proposed to guarantee an optimal consensus almost
surely with proper convexity and intersection assumptions. The convergence
analysis is carried out using convex analysis. We compare the randomized
algorithm with the deterministic one via a numerical example. The results
illustrate that a group of autonomous agents can reach an optimal opinion by
each node simply making a randomized trade-off between following its neighbors
or sticking to its own opinion at each time step."
"We show that any discrete opinion pooling procedure with positive weights can
be asymptotically approximated by DeGroot's procedure whose communication
digraph is a Hamiltonian cycle with loops. In this cycle, the weight of each
arc (which is not a loop) is inversely proportional to the influence of the
agent the arc leads to."
"A complex system is made up of many components with many interactions. So the
design of systems such as simulation systems, cooperative systems or assistance
systems includes a very accurate modelling of interactional and communicational
levels. The agent-based approach provides an adapted abstraction level for this
problem. After having studied the organizational context and communicative
capacities of agentbased systems, to simulate the reorganization of a flexible
manufacturing, to regulate an urban transport system, and to simulate an
epidemic detection system, our thoughts on the interactional level were
inspired by human-machine interface models, especially those in ""cognitive
engineering"". To provide a general framework for agent-based complex systems
modelling, we then proposed a scale of four behaviours that agents may adopt in
their complex systems (reactive, routine, cognitive, and collective). To
complete the description of multi-level agent models, which is the focus of
this paper, we illustrate our modelling and discuss our ongoing work on each
level."
"A minor change to the standard epistemic logical language, replacing $K_{i}$
with $K_{\node{i,t}}$ where $t$ is a time instance, gives rise to a generalized
and more expressive form of knowledge and common knowledge operators. We
investigate the communication structures that are necessary for such
generalized epistemic states to arise, and the inter-agent coordination tasks
that require such knowledge. Previous work has established a relation between
linear event ordering and nested knowledge, and between simultaneous event
occurrences and common knowledge. In the new, extended, formalism, epistemic
necessity is decoupled from temporal necessity. Nested knowledge and event
ordering are shown to be related even when the nesting order does not match the
temporal order of occurrence. The generalized form of common knowledge does
{\em not} correspond to simultaneity. Rather, it corresponds to a notion of
tight coordination, of which simultaneity is an instance."
"Fashion plays such a crucial rule in the evolution of culture and society
that it is regarded as a second nature to the human being. Also, its impact on
economy is quite nontrivial. On what is fashionable, interestingly, there are
two viewpoints that are both extremely widespread but almost opposite:
conformists think that what is popular is fashionable, while rebels believe
that being different is the essence. Fashion color is fashionable in the first
sense, and Lady Gaga in the second. We investigate a model where the population
consists of the afore-mentioned two groups of people that are located on social
networks (a spatial cellular automata network and small-world networks). This
model captures two fundamental kinds of social interactions (coordination and
anti-coordination) simultaneously, and also has its own interest to game
theory: it is a hybrid model of pure competition and pure cooperation. This is
true because when a conformist meets a rebel, they play the zero sum matching
pennies game, which is pure competition. When two conformists (rebels) meet,
they play the (anti-) coordination game, which is pure cooperation. Simulation
shows that simple social interactions greatly promote cooperation: in most
cases people can reach an extraordinarily high level of cooperation, through a
selfish, myopic, naive, and local interacting dynamic (the best response
dynamic). We find that degree of synchronization also plays a critical role,
but mostly on the negative side. Four indices, namely cooperation degree,
average satisfaction degree, equilibrium ratio and complete ratio, are defined
and applied to measure people's cooperation levels from various angles. Phase
transition, as well as emergence of many interesting geographic patterns in the
cellular automata network, is also observed."
"An important question when eliciting opinions from experts is how to
aggregate the reported opinions. In this paper, we propose a pooling method to
aggregate expert opinions. Intuitively, it works as if the experts were
continuously updating their opinions in order to accommodate the expertise of
others. Each updated opinion takes the form of a linear opinion pool, where the
weight that an expert assigns to a peer's opinion is inversely related to the
distance between their opinions. In other words, experts are assumed to prefer
opinions that are close to their own opinions. We prove that such an updating
process leads to consensus, \textit{i.e.}, the experts all converge towards the
same opinion. Further, we show that if rational experts are rewarded using the
quadratic scoring rule, then the assumption that they prefer opinions that are
close to their own opinions follows naturally. We empirically demonstrate the
efficacy of the proposed method using real-world data."
"During the execution of large scale construction projects performed by
Virtual Organizations (VO), relatively complex technical models have to be
exchanged between the VO members. For linking the trade and transfer of these
models, a so-called multi-model container format was developed. Considering the
different skills and tasks of the involved partners, it is not necessary for
them to know all the models in every technical detailing. Furthermore, the
model size can lead to a delay in communication. In this paper an approach is
presented for defining model cut-outs according to the current project context.
Dynamic dependencies to the project context as well as static dependencies on
the organizational structure are mapped in a context-sensitive rule. As a
result, an approach for dynamic filtering of multi-models is obtained which
ensures, together with a filtering service, that the involved VO members get a
simplified view of complex multi-models as well as sufficient permissions
depending on their tasks."
"Understanding how spatial configurations of economic activity emerge is
important when formulating spatial planning and economic policy. A simple model
was proposed by Simon, who assumed that firms grow at a rate proportional to
their size, and that new divisions of firms with certain probabilities relocate
to other firms or to new centres of economic activity. Simon's model produces
realistic results in the sense that the sizes of economic centres follow a Zipf
distribution, which is also observed in reality. It lacks realism in the sense
that mechanisms such as cluster formation, congestion (defined as an overly
high density of the same activities) and dependence on the spatial distribution
of external parties (clients, labour markets) are ignored.
  The present paper proposed an extension of the Simon model that includes both
centripetal and centrifugal forces. Centripetal forces are included in the
sense that firm divisions are more likely to settle in locations that offer a
higher accessibility to other firms. Centrifugal forces are represented by an
aversion of a too high density of activities in the potential location. The
model is implemented as an agent-based simulation model in a simplified spatial
setting. By running both the Simon model and the extended model, comparisons
are made with respect to their effects on spatial configurations. To this end a
series of metrics are used, including the rank-size distribution and indices of
the degree of clustering and concentration."
"In a distributed algorithm, multiple processes, or agents, work toward a
common goal. More often than not, the actions of some agents are dependent on
the previous execution (if not also on the outcome) of the actions of other
agents. The resulting interdependencies between the timings of the actions of
the various agents give rise to the study of methods for timely coordination of
these actions.
  In this work, we formulate and mathematically analyze ""Timely-Coordinated
Response"" - a novel multi-agent coordination problem in which the time
difference between each pair of actions may be constrained by upper and/or
lower bounds. This problem generalizes coordination problems previously studied
by Halpern and Moses and by Ben-Zvi and Moses.
  We optimally solve timely-coordinated response in two ways: using a
generalization of the fixed-point approach of Halpern and Moses, and using a
generalization of the ""syncausality"" approach of Ben-Zvi and Moses. We
constructively show the equivalence of the solutions yielded by both
approaches, and by combining them, derive strengthened versions of known
results for some previously-defined special cases of this problem.
  Our analysis is conducted under minimal assumptions: we work in a
continuous-time model with possibly infinitely many agents. The general results
we obtain for this model reduce to stronger ones for discrete-time models with
only finitely many agents. In order to distill the properties of such models
that are significant to this reduction, we define several classes of
naturally-occurring models, which in a sense separate the different results. We
present both a more practical optimal solution, as well as a surprisingly
simple condition for solvability, for timely coordinated response under these
models.
  Finally, we show how our results generalize the results known for
previously-studied special cases of this problem."
"In this paper, we address the problem of simultaneous classification and
estimation of hidden parameters in a sensor network with communications
constraints. In particular, we consider a network of noisy sensors which
measure a common scalar unknown parameter. We assume that a fraction of the
nodes represent faulty sensors, whose measurements are poorly reliable. The
goal for each node is to simultaneously identify its class (faulty or
non-faulty) and estimate the common parameter.
  We propose a novel cooperative iterative algorithm which copes with the
communication constraints imposed by the network and shows remarkable
performance. Our main result is a rigorous proof of the convergence of the
algorithm and a characterization of the limit behavior. We also show that, in
the limit when the number of sensors goes to infinity, the common unknown
parameter is estimated with arbitrary small error, while the classification
error converges to that of the optimal centralized maximum likelihood
estimator. We also show numerical results that validate the theoretical
analysis and support their possible generalization. We compare our strategy
with the Expectation-Maximization algorithm and we discuss trade-offs in terms
of robustness, speed of convergence and implementation simplicity."
"Recently, a theory for stochastic optimal control in non-linear dynamical
systems in continuous space-time has been developed (Kappen, 2005). We apply
this theory to collaborative multi-agent systems. The agents evolve according
to a given non-linear dynamics with additive Wiener noise. Each agent can
control its own dynamics. The goal is to minimize the accumulated joint cost,
which consists of a state dependent term and a term that is quadratic in the
control. We focus on systems of non-interacting agents that have to distribute
themselves optimally over a number of targets, given a set of end-costs for the
different possible agent-target combinations. We show that optimal control is
the combinatorial sum of independent single-agent single-target optimal
controls weighted by a factor proportional to the end-costs of the different
combinations. Thus, multi-agent control is related to a standard graphical
model inference problem. The additional computational cost compared to
single-agent control is exponential in the tree-width of the graph specifying
the combinatorial sum times the number of targets. We illustrate the result by
simulations of systems with up to 42 agents."