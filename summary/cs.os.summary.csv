summary
"Modern control systems applications are often built on top of a real time
operating system (RTOS) which provides the necessary hardware abstraction as
well as scheduling, networking and other services. Several open source RTOS
solutions are publicly available, which is very attractive, both from an
economic (no licensing fees) as well as from a technical (control over the
source code) point of view. This contribution gives an overview of the RTLinux
and RTEMS systems (architecture, development environment, API etc.). Both
systems feature most popular CPUs, several APIs (including Posix), networking,
portability and optional commercial support. Some performance figures are
presented, focusing on interrupt latency and context switching delay."
"When a program is loaded into memory for execution, the relative position of
its basic blocks is crucial, since loading basic blocks that are unlikely to be
executed first places them high in the instruction-memory hierarchy only to be
dislodged as the execution goes on. In this paper we study the use of Bayesian
networks as models of the input history of a program. The main point is the
creation of a probabilistic model that persists as the program is run on
different inputs and at each new input refines its own parameters in order to
reflect the program's input history more accurately. As the model is thus
tuned, it causes basic blocks to be reordered so that, upon arrival of the next
input for execution, loading the basic blocks into memory automatically takes
into account the input history of the program. We report on extensive
experiments, whose results demonstrate the efficacy of the overall approach in
progressively lowering the execution times of a program on identical inputs
placed randomly in a sequence of varied inputs. We provide results on selected
SPEC CINT2000 programs and also evaluate our approach as compared to the gcc
level-3 optimization and to Pettis-Hansen reordering."
"Researchers have long proposed using economic approaches to resource
allocation in computer systems. However, few of these proposals became
operational, let alone commercial. Questions persist about the economic
approach regarding its assumptions, value, applicability, and relevance to
system design. The goal of this paper is to answer these questions. We find
that market-based resource allocation is useful, and more importantly, that
mechanism design and system design should be integrated to produce systems that
are both economically and computationally efficient."
"Virtualization, a technique once used to multiplex the resources of
high-priced mainframe hardware, is seeing a resurgence in applicability with
the increasing computing power of commodity computers. By inserting a layer of
software between the machine and traditional operating systems, this technology
allows access to a shared computing medium in a manner that is secure,
resource-controlled, and efficient. These properties are attractive in the
field of on-demand computing, where the fine-grained subdivision of resources
provided by virtualized systems allows potentially higher utilization of
computing resources.
  It this work, we survey a number of virtual machine systems with the goal of
finding an appropriate candidate to serve as the basis for the On-Demand Secure
Cluster Computing project at the National Center for Supercomputing
Applications. Contenders are reviewed on a number of desirable properties
including portability and security. We conclude with a comparison and
justification of our choice."
"This paper shows that it is possible to dramatically reduce the memory
consumption of classes loaded in an embedded Java virtual machine without
reducing its functionalities. We describe how to pack the constant pool by
deleting entries which are only used during the class loading process. We
present some benchmarks which demonstrate the efficiency of this mechanism. We
finally suggest some additional optimizations which can be applied if some
restrictions to the functionalities of the virtual machine can be tolerated."
"We notice a way to execute a binary file on Windows and ELF-based systems. It
can be used to create software installers and other applications not exceeding
64 kilo bytes."
"Demands for implementing original OSs that can achieve high I/O performance
on PC/AT compatible hardware have recently been increasing, but conventional OS
debugging environments have not been able to simultaneously assure their
stability, be easily customized to new OSs and new I/O devices, and assure
efficient execution of I/O operations. We therefore developed a novel OS
debugging method using a lightweight virtual machine. We evaluated this
debugging method experimentally and confirmed that it can transfer data about
5.4 times as fast as the conventional virtual machine monitor."
"This paper presents the methodology and the modeling constructs we have
developed to capture the real time aspects of RTOS simulation models in a
System Level Design Language (SLDL) like SystemC. We describe these constructs
and show how they are used to build a simulation model of an RTOS kernel
targeting the $\mu$-ITRON OS specification standard."
"In this paper we study the global scheduling of periodic task systems upon
multiprocessor platforms. We first show two very general properties which are
well-known for uniprocessor platforms and which remain for multiprocessor
platforms: (i) under few and not so restrictive assumptions, we show that
feasible schedules of periodic task systems are periodic from some point with a
period equal to the least common multiple of task periods and (ii) for the
specific case of synchronous periodic task systems, we show that feasible
schedules repeat from the origin. We then present our main result: we
characterize, for task-level fixed-priority schedulers and for asynchronous
constrained or arbitrary deadline periodic task models, upper bounds of the
first time instant where the schedule repeats. We show that job-level
fixed-priority schedulers are predictable upon unrelated multiprocessor
platforms. For task-level fixed-priority schedulers, based on the upper bounds
and the predictability property, we provide for asynchronous constrained or
arbitrary deadline periodic task sets, exact feasibility tests. Finally, for
the job-level fixed-priority EDF scheduler, for which such an upper bound
remains unknown, we provide an exact feasibility test as well."
"Energy-efficient real-time task scheduling has been actively explored in the
past decade. Different from the past work, this paper considers schedulability
conditions for stochastic real-time tasks. A schedulability condition is first
presented for frame-based stochastic real-time tasks, and several algorithms
are also examined to check the schedulability of a given strategy. An approach
is then proposed based on the schedulability condition to adapt a
continuous-speed-based method to a discrete-speed system. The approach is able
to stay as close as possible to the continuous-speed-based method, but still
guaranteeing the schedulability. It is shown by simulations that the energy
saving can be more than 20% for some system configurations"
"Energy efficient real-time task scheduling attracted a lot of attention in
the past decade. Most of the time, deterministic execution lengths for tasks
were considered, but this model fits less and less with the reality, especially
with the increasing number of multimedia applications. It's why a lot of
research is starting to consider stochastic models, where execution times are
only known stochastically. However, authors consider that they have a pretty
much precise knowledge about the properties of the system, especially regarding
to the worst case execution time (or worst case execution cycles, WCEC).
  In this work, we try to relax this hypothesis, and assume that the WCEC can
vary. We propose miscellaneous methods to react to such a situation, and give
many simulation results attesting that with a small effort, we can provide very
good results, allowing to keep a low deadline miss rate as well as an energy
consumption similar to clairvoyant algorithms."
"In this ongoing work, we are interested in multiprocessor energy efficient
systems, where task durations are not known in advance, but are know
stochastically. More precisely, we consider global scheduling algorithms for
frame-based multiprocessor stochastic DVFS (Dynamic Voltage and Frequency
Scaling) systems. Moreover, we consider processors with a discrete set of
available frequencies."
"In this paper, we propose a synchronous protocol without periodicity for
scheduling multi-mode real-time systems upon identical multiprocessor
platforms. Our proposal can be considered to be a multiprocessor extension of
the uniprocessor protocol called ""Minimal Single Offset protocol""."
"The main objective of this paper is to develop the two different ways in
which round robin architecture is modified and made suitable to be implemented
in real time and embedded systems. The scheduling algorithm plays a significant
role in the design of real time embedded systems. Simple round robin
architecture is not efficient to be implemented in embedded systems because of
higher context switch rate, larger waiting time and larger response time.
Missing of deadlines will degrade the system performance in soft real time
systems. The main objective of this paper is to develop the scheduling
algorithm which removes the drawbacks in simple round robin architecture. A
comparison with round robin architecture to the proposed architectures has been
made. It is observed that the proposed architectures solves the problems
encountered in round robin architecture in soft real time by decreasing the
number of context switches waiting time and response time thereby increasing
the system throughput."
"The difficulty of developing reliable parallel software is generating
interest in deterministic environments, where a given program and input can
yield only one possible result. Languages or type systems can enforce
determinism in new code, and runtime systems can impose synthetic schedules on
legacy parallel code. To parallelize existing serial code, however, we would
like a programming model that is naturally deterministic without language
restrictions or artificial scheduling. We propose ""deterministic consistency"",
a parallel programming model as easy to understand as the ""parallel assignment""
construct in sequential languages such as Perl and JavaScript, where concurrent
threads always read their inputs before writing shared outputs. DC supports
common data- and task-parallel synchronization abstractions such as fork/join
and barriers, as well as non-hierarchical structures such as producer/consumer
pipelines and futures. A preliminary prototype suggests that software-only
implementations of DC can run applications written for popular parallel
environments such as OpenMP with low (<10%) overhead for some applications."
"Virtual memory of computers is usually implemented by demand paging. For some
page replacement algorithms the number of page faults may increase as the
number of page frames increases. Belady, Nelson and Shedler constructed
reference strings for which page replacement algorithm FIFO produces near twice
more page faults in a larger memory than in a smaller one. They formulated the
conjecture that 2 is a general bound. We prove that this ratio can be
arbitrarily large."
"Memory hierarchy is used to compete the processors speed. Cache memory is the
fast memory which is used to conduit the speed difference of memory and
processor. The access patterns of Level 1 cache (L1) and Level 2 cache (L2) are
different, when CPU not gets the desired data in L1 then it accesses L2. Thus
the replacement algorithm which works efficiently on L1 may not be as efficient
on L2. Similarly various applications such as Matrix Multiplication, Web, Fast
Fourier Transform (FFT) etc will have varying access pattern. Thus same
replacement algorithm for all types of application may not be efficient. This
paper works for getting an efficient pair of replacement algorithm on L1 and L2
for the algorithm Merge Sort. With the memory reference string of Merge Sort,
we have analyzed the behavior of various existing replacement algorithms on L1.
The existing replacement algorithms which are taken into consideration are:
Least Recently Used (LRU), Least Frequently Used (LFU) and First In First Out
(FIFO). After Analyzing the memory reference pattern of Merge Sort, we have
proposed a Partition Based Replacement algorithm (PBR_L1)) on L1 Cache.
Furthermore we have analyzed various pairs of algorithms on L1 and L2
respectively, resulting in finding a suitable pair of replacement algorithms.
Simulation on L1 shows, among the considered existing replacement algorithms
FIFO is performing better than others. While the proposed replacement algorithm
PBR_L1 is working about 1.7% to 44 % better than FIFO for various cache sizes."
"This note concerns a search for publications in which one can find statements
that explain the concept of an operating system, reasons for introducing
operating systems, a formalization of the concept of an operating system or
theory about operating systems based on such a formalization. It reports on the
way in which the search has been carried out and the outcome of the search. The
outcome includes not only what the search was meant for, but also some added
bonuses."
"We dwell on how a definition of a theoretical concept of an operating system,
suitable to be incorporated in a mathematical theory of operating systems,
could look like. This is considered a valuable preparation for the development
of a mathematical theory of operating systems."
"Is it possible for an Information Technology [IT] product to be both mature
and state-of-theart at the same time? In the case of the UNIX system, the
answer is an unqualified ""Yes."" The UNIX system has continued to develop over
the past twenty-five years. In millions of installations running on nearly
every hardware platform made, the UNIX system has earned its reputation for
stability and scalability. Over the years, UNIX system suppliers have steadily
assimilated new technologies so that UNIX systems today provide more
functionality as any other operating system."
"In this paper we consider the scheduling of periodic and parallel rigid
tasks. We provide (and prove correct) an exact schedulability test for Fixed
Task Priority (FTP) Gang scheduler sub-classes: Parallelism Monotonic, Idling,
Limited Gang, and Limited Slack Reclaiming. Additionally, we study the
predictability of our schedulers: we show that Gang FJP schedulers are not
predictable and we identify several sub-classes which are actually predictable.
Moreover, we extend the definition of rigid, moldable and malleable jobs to
recurrent tasks."
"Algorithms based on semi-partitioned scheduling have been proposed as a
viable alternative between the two extreme ones based on global and partitioned
scheduling. In particular, allowing migration to occur only for few tasks which
cannot be assigned to any individual processor, while most tasks are assigned
to specific processors, considerably reduces the runtime overhead compared to
global scheduling on the one hand, and improve both the schedulability and the
system utilization factor compared to partitioned scheduling on the other hand.
In this paper, we address the preemptive scheduling problem of hard real-time
systems composed of sporadic constrained-deadline tasks upon identical
multiprocessor platforms. We propose a new algorithm and a scheduling paradigm
based on the concept of semi-partitioned scheduling with restricted migrations
in which jobs are not allowed to migrate, but two subsequent jobs of a task can
be assigned to different processors by following a periodic strategy."
"It is well known that in a firm real time system with a renewal arrival
process, exponential service times and independent and identically distributed
deadlines till the end of service of a job, the earliest deadline first (EDF)
scheduling policy has smaller loss ratio (expected fraction of jobs, not
completed) than any other service time independent scheduling policy, including
the first come first served (FCFS). Various modifications to the EDF and FCFS
policies have been proposed in the literature, with a view to improving
performance. In this article, we compare the loss ratios of these two policies
along with some of the said modifications, as well as their counterparts with
deterministic deadlines. The results include some formal inequalities and some
counter-examples to establish non-existence of an order. A few relations
involving loss ratios are posed as conjectures, and simulation results in
support of these are reported. These results lead to a complete picture of
dominance and non-dominance relations between pairs of scheduling policies, in
terms of loss ratios."
"An optimal solution to the problem of scheduling real-time tasks on a set of
identical processors is derived. The described approach is based on solving an
equivalent uniprocessor real-time scheduling problem. Although there are other
scheduling algorithms that achieve optimality, they usually impose prohibitive
preemption costs. Unlike these algorithms, it is observed through simulation
that the proposed approach produces no more than three preemptions points per
job."
"In this paper, we propose a new approach to building synchronization
primitives, dubbed ""lwlocks"" (short for light-weight locks). The primitives are
optimized for small memory footprint while maintaining efficient performance in
low contention scenarios. A read-write lwlock occupies 4 bytes, a mutex
occupies 4 bytes (2 if deadlock detection is not required), and a condition
variable occupies 4 bytes. The corresponding primitives of the popular pthread
library occupy 56 bytes, 40 bytes and 48 bytes respectively on the x86-64
platform. The API for lwlocks is similar to that of the pthread library but
covering only the most common use cases. Lwlocks allow explicit control of
queuing and scheduling decisions in contention situations and support
""asynchronous"" or ""deferred blocking"" acquisition of locks. Asynchronous
locking helps in working around the constraints of lock-ordering which
otherwise limits concurrency. The small footprint of lwlocks enables the
construction of data structures with very fine-grained locking, which in turn
is crucial for lowering contention and supporting highly concurrent access to a
data structure. Currently, the Data Domain File System uses lwlocks for its
in-memory inode cache as well as in a generic doubly-linked concurrent list
which forms the building block for more sophisticated structures."
"In this paper, we have proposed a new variant of Round Robin scheduling
algorithm by executing the processes according to the new calculated Fit Factor
f and using the concept of dynamic time quantum. We have compared the
performance of our proposed Fittest Job First Dynamic Round Robin(FJFDRR)
algorithm with the Priority Based Static Round Robin(PBSRR) algorithm.
Experimental results show that our proposed algorithm performs better than
PBSRR in terms of reducing the number of context switches, average waiting time
and average turnaround time."
"CPU being considered a primary computer resource, its scheduling is central
to operating-system design. A thorough performance evaluation of various
scheduling algorithms manifests that Round Robin Algorithm is considered as
optimal in time shared environment because the static time is equally shared
among the processes. We have proposed an efficient technique in the process
scheduling algorithm by using dynamic time quantum in Round Robin. Our approach
is based on the calculation of time quantum twice in single round robin cycle.
Taking into consideration the arrival time, we implement the algorithm.
Experimental analysis shows better performance of this improved algorithm over
the Round Robin algorithm and the Shortest Remaining Burst Round Robin
algorithm. It minimizes the overall number of context switches, average waiting
time and average turn-around time. Consequently the throughput and CPU
utilization is better."
"Our goal is to provide a sufficient schedulability test -ideally polynomial-
for the scheduling of Non-Cyclic Generalized Multiframe Task Model using
Fixed-Task-Priority schedulers. We report two first results: (i) we present and
prove correct the critical instant for the Non-Cyclic Generalized Multiframe
Task Model then (ii) we propose an algorithm which provides a sufficient (but
pseudo-polynomial) schedulability test."
"While the engineering of operating systems is well understood, their formal
structure and properties are not. The latter needs a clear definition of the
purpose of an OS and an identification of the core. In this paper I offer
definitions of the OS, processes and files, and present a few useful
principles. The principles allow us to identify work like closure and
continuation algorithms, in programming languages that is useful for the OS
problem. The definitions and principles should yield a symbolic, albeit
semiquantitative, framework that encompasses practice. Towards that end I
specialise the definitions to describe conventional OSes and identify the core
operations for a single computer OS that can be used to express their
algorithms. The assumptions underlying the algorithms offer the design space
framework. The paging and segmentation algorithms for conventional OSes are
extracted from the framework as a check. Among the insights the emerge is that
an OS is a constructive proof of equivalence between models of computation.
Clear and useful definitions and principles are the first step towards a fully
quantitative structure of an OS."
"This paper outlines the design of `Quest-V', which is implemented as a
collection of separate kernels operating together as a distributed system on a
chip. Quest-V uses virtualization techniques to isolate kernels and prevent
local faults from affecting remote kernels. This leads to a high-confidence
multikernel approach, where failures of system subcomponents do not render the
entire system inoperable. A virtual machine monitor for each kernel keeps track
of shadow page table mappings that control immutable memory access
capabilities. This ensures a level of security and fault tolerance in
situations where a service in one kernel fails, or is corrupted by a malicious
attack. Communication is supported between kernels using shared memory regions
for message passing. Similarly, device driver data structures are shareable
between kernels to avoid the need for complex I/O virtualization, or
communication with a dedicated kernel responsible for I/O. In Quest-V, device
interrupts are delivered directly to a kernel, rather than via a monitor that
determines the destination. Apart from bootstrapping each kernel, handling
faults and managing shadow page tables, the monitors are not needed. This
differs from conventional virtual machine systems in which a central monitor,
or hypervisor, is responsible for scheduling and management of host resources
amongst a set of guest kernels. In this paper we show how Quest-V can implement
novel fault isolation and recovery techniques that are not possible with
conventional systems. We also show how the costs of using virtualization for
isolation of system services does not add undue overheads to the overall system
performance."
"Operating systems are vital system software that, without them, humans would
not be able to manage and use computer systems. In essence, an operating system
is a collection of software programs whose role is to manage computer resources
and provide an interface for client applications to interact with the different
computer hardware. Most of the commercial operating systems available today on
the market have buggy code and they exhibit security flaws and vulnerabilities.
In effect, building a trusted operating system that can mostly resist attacks
and provide a secure computing environment to protect the important assets of a
computer is the goal of every operating system manufacturer. This paper deeply
investigates the various security features of the two most widespread and
successful operating systems, Microsoft Windows and Linux. The different
security features, designs, and components of the two systems are to be covered
elaborately, pin-pointing the key similarities and differences between them. In
due course, a head-to-head comparison is to be drawn for each security aspect,
exposing the advantage of one system over the other."
"Efficient task partitioning plays a crucial role in achieving high
performance at multiprocessor plat forms. This paper addresses the problem of
energy-aware static partitioning of periodic real-time tasks on heterogeneous
multiprocessor platforms. A Particle Swarm Optimization variant based on
Min-min technique for task partitioning is proposed. The proposed approach aims
to minimize the overall energy consumption, meanwhile avoid deadline
violations. An energy-aware cost function is proposed to be considered in the
proposed approach. Extensive simulations and comparisons are conducted in order
to validate the effectiveness of the proposed technique. The achieved results
demonstrate that the proposed partitioning scheme significantly surpasses
previous approaches in terms of both number of iterations and energy savings."
"Today, flash memory are strongly used in the embedded system domain. NAND
flash memories are the building block of main secondary storage systems. Such
memories present many benefits in terms of data density, I/O performance, shock
resistance and power consumption. Nevertheless, flash does not come without
constraints: the write / erase granularity asymmetry and the limited lifetime
bring the need for specific management. This can be done through the operating
system using dedicated Flash File Systems (FFSs). In this document, we present
general concepts about FFSs, and implementations example that are JFFS2, YAFFS2
and UBIFS, the most commonly used flash file systems. Then we give performance
evaluation results for these FFSs."
"Traditional monolithic kernels dominated kernel structures for long time
along with small sized kernels,few hardware companies and limited kernel
functionalities. Monolithic kernel structure was not applicable when the number
of hardware companies increased and kernel services consumed by different users
for many purposes. One of the biggest disadvantages of the monolithic kernels
is the inflexibility due to the need to include all the available modules in
kernel compilation causing high time consuming. Lately, new kernel structure
was introduced through multicore operating systems. Unfortunately, many
multicore operating systems such as barrelfish and FOS are experimental. This
paper aims to simulate the performance of multicore hybrid kernels through
dynamic kernel module customized attachment/ deattachment for multicore
machines. In addition, this paper proposes a new technique for loading dynamic
kernel modules based on the user needs and machine capabilities."
"Developing CPU scheduling algorithms and understanding their impact in
practice can be difficult and time consuming due to the need to modify and test
operating system kernel code and measure the resulting performance on a
consistent workload of real applications. As processor is the important
resource, CPU scheduling becomes very important in accomplishing the operating
system (OS) design goals. The intention should be allowed as many as possible
running processes at all time in order to make best use of CPU. This paper
presents a state diagram that depicts the comparative study of various
scheduling algorithms for a single CPU and shows which algorithm is best for
the particular situation. Using this representation, it becomes much easier to
understand what is going on inside the system and why a different set of
processes is a candidate for the allocation of the CPU at different time. The
objective of the study is to analyze the high efficient CPU scheduler on design
of the high quality scheduling algorithms which suits the scheduling goals. Key
Words:-Scheduler, State Diagrams, CPU-Scheduling, Performance"
"The main objective of this paper is to improve the Round Robin scheduling
algorithm using the dynamic time slice concept. CPU scheduling becomes very
important in accomplishing the operating system (OS) design goals. The
intention should be allowed as many as possible running processes at all time
in order to make best use of CPU. CPU scheduling has strong effect on resource
utilization as well as overall performance of the system. Round Robin algorithm
performs optimally in time-shared systems, but it is not suitable for soft real
time systems, because it gives more number of context switches, larger waiting
time and larger response time. In this paper, a new CPU scheduling algorithm
called An Optimum Multilevel Dynamic Round Robin Scheduling Algorithm is
proposed, which calculates intelligent time slice and changes after every round
of execution. The suggested algorithm was evaluated on some CPU scheduling
objectives and it was observed that this algorithm gave good performance as
compared to the other existing CPU scheduling algorithms."
"CPU scheduling has valiant effect on resource utilization as well as overall
quality of the system. Round Robin algorithm performs optimally in time shared
systems, but it performs more number of context switches, larger waiting time
and larger response time. In order to simulate the behavior of various CPU
scheduling algorithms and to improve Round Robin scheduling algorithm using
dynamic time slice concept, in this paper we produce the implementation of new
CPU scheduling algorithm called An Optimum Multilevel Dynamic Round Robin
Scheduling (OMDRRS), which calculates intelligent time slice and warps after
every round of execution. The results display the robustness of this software,
especially for academic, research and experimental use, as well as proving the
desirability and efficiency of the probabilistic algorithm over the other
existing techniques and it is observed that this OMDRRS projects good
performance as compared to the other existing CPU scheduling algorithms."
"In this paper we study the scheduling of (m,k)-firm synchronous periodic task
systems using the Distance Based Priority (DBP) scheduler. We first show three
phenomena: (i) choosing, for each task, the initial k-sequence 1^k is not
optimal, (ii) we can even start the scheduling from a (fictive) error state (in
regard to the initial k-sequence) and (iii) the period of feasible
DBP-schedules is not necessarily the task hyper-period. We then show that any
feasible DBP-schedule is periodic and we upper-bound the length of that period.
Lastly, based on our periodicity result we provide an exact schedulability
test."
"We investigate the global scheduling of sporadic, implicit deadline,
real-time task systems on multiprocessor platforms. We provide a task model
which integrates job parallelism. We prove that the time-complexity of the
feasibility problem of these systems is linear relatively to the number of
(sporadic) tasks for a fixed number of processors. We propose a scheduling
algorithm theoretically optimal (i.e., preemptions and migrations neglected).
Moreover, we provide an exact feasibility utilization bound. Lastly, we propose
a technique to limit the number of migrations and preemptions."
"For microprocessors used in real-time embedded systems, minimizing power
consumption is difficult due to the timing constraints. Dynamic voltage scaling
(DVS) has been incorporated into modern microprocessors as a promising
technique for exploring the trade-off between energy consumption and system
performance. However, it remains a challenge to realize the potential of DVS in
unpredictable environments where the system workload cannot be accurately
known. Addressing system-level power-aware design for DVS-enabled embedded
controllers, this paper establishes an analytical model for the DVS system that
encompasses multiple real-time control tasks. From this model, a feedback
control based approach to power management is developed to reduce dynamic power
consumption while achieving good application performance. With this approach,
the unpredictability and variability of task execution times can be attacked.
Thanks to the use of feedback control theory, predictable performance of the
DVS system is achieved, which is favorable to real-time applications. Extensive
simulations are conducted to evaluate the performance of the proposed approach."
"Embedded computing systems today increasingly feature resource constraints
and workload variability, which lead to uncertainty in resource availability.
This raises great challenges to software design and programming in multitasking
environments. In this paper, the emerging methodology of feedback scheduling is
introduced to address these challenges. As a closed-loop approach to resource
management, feedback scheduling promises to enhance the flexibility and
resource efficiency of various software programs through dynamically
distributing available resources among concurrent tasks based on feedback
information about the actual usage of the resources. With emphasis on the
behavioral design of feedback schedulers, we describe a general framework of
feedback scheduling in the context of real-time control applications. A simple
yet illustrative feedback scheduling algorithm is given. From a programming
perspective, we describe how to modify the implementation of control tasks to
facilitate the application of feedback scheduling. An event-driven paradigm
that combines time-triggered and event-triggered approaches is proposed for
programming of the feedback scheduler. Simulation results argue that the
proposed event-driven paradigm yields better performance than time-triggered
paradigm in dynamic environments where the workload varies irregularly and
unpredictably."
"In this paper, we address the global and preemptive energy-aware scheduling
problem of sporadic constrained-deadline tasks on DVFS-identical multiprocessor
platforms. We propose an online slack reclamation scheme which profits from the
discrepancy between the worst- and actual-case execution time of the tasks by
slowing down the speed of the processors in order to save energy. Our algorithm
called MORA takes into account the application-specific consumption profile of
the tasks. We demonstrate that MORA does not jeopardize the system
schedulability and we show by performing simulations that it can save up to 32%
of energy (in average) compared to execution without using any energy-aware
algorithm."
"The multiprocessor Fixed-Job Priority (FJP) scheduling of real-time systems
is studied. An important property for the schedulability analysis, the
predictability (regardless to the execution times), is studied for
heterogeneous multiprocessor platforms. Our main contribution is to show that
any FJP schedulers are predictable on unrelated platforms. A convenient
consequence is the fact that any FJP schedulers are predictable on uniform
multiprocessors."
"The operating system's role in a computer system is to manage the various
resources. One of these resources is the Central Processing Unit. It is managed
by a component of the operating system called the CPU scheduler. Schedulers are
optimized for typical workloads expected to run on the platform. However, a
single scheduler may not be appropriate for all workloads. That is, a scheduler
may schedule a workload such that the completion time is minimized, but when
another type of workload is run on the platform, scheduling and therefore
completion time will not be optimal; a different scheduling algorithm, or a
different set of parameters, may work better. Several approaches to solving
this problem have been proposed. The objective of this survey is to summarize
the approaches based on data mining, which are available in the literature. In
addition to solutions that can be directly utilized for solving this problem,
we are interested in data mining research in related areas that have potential
for use in operating system scheduling. We also explain general technical
issues involved in scheduling in modern computers, including parallel
scheduling issues related to multi-core CPUs. We propose a taxonomy that
classifies the scheduling approaches we discuss into different categories."
"Multi-mode real-time systems are those which support applications with
different modes of operation, where each mode is characterized by a specific
set of tasks. At run-time, such systems can, at any time, be requested to
switch from its current operating mode to another mode (called ""new mode"") by
replacing the current set of tasks with that of the new-mode. Thereby, ensuring
that all the timing requirements are met not only requires that a
schedulability test is performed on the tasks of each mode but also that (i) a
protocol for transitioning from one mode to another is specified and (ii) a
schedulability test for each transition is performed. We propose two distinct
protocols that manage the mode transitions upon uniform and identical
multiprocessor platforms at run-time, each specific to distinct task
requirements. For each protocol, we formally establish schedulability analyses
that indicate beforehand whether all the timing requirements will be met during
any mode transition of the system. This is performed assuming both
Fixed-Task-Priority and Fixed-Job-Priority schedulers."
"This paper deals with the study of Earliest Deadline First (EDF) which is an
optimal scheduling algorithm for uniprocessor real time systems use for
scheduling the periodic task in soft real-time multiprocessor systems. In hard
real-time systems, a significant disparity exists EDF-based schemes and RMA
scheduling (which is the only known way of optimally scheduling recurrent
real-time tasks on multiprocessors): on M processors, all known EDF variants
have utilization-based schedulability bounds of approximately M/2, while RMA
algorithms can fully utilize all processors. This is unfortunate because EDF
based algorithms entail lower scheduling and task migration overheads. In work
on hard real-time systems, it has been shown that this disparity in
Schedulability can be lessened by placing caps on per task utilizations. Our
main contribution is a new EDF based scheme that ensures bounded deadline
tardiness. In this scheme, per-task utilizations must be focused,but overall
utilization need not be stricted. Our scheme should enable a wide range of soft
real-time applications to be scheduled with no constraints on total
utilization. Also propose techniques and heuristics that can be used to reduce
tardiness as well as increase the efficiency of task."
"This paper proposes the creation of different interfaces in the mobile
operating system for different age groups. The different age groups identified
are kids, elderly people and all others. The motive behind creating different
interfaces is to make the smartphones of today's world usable to all age
groups."
"Computers are a very important part of our lives and the major reason why
they have been such a success is because of the excellent graphical operating
systems that run on these powerful machines. As the computer hardware is
becoming more and more powerful, it is also vital to keep the software updated
in order to utilize the hardware of the system efficiently and make it faster
and smarter. This paper highlights some core issues that if dealt with in the
operating system level would make use of the full potential of the computer
hardware and provide an excellent user experience."
"Multi- and many-core processors are becoming increasingly popular in embedded
systems. Many of these processors now feature hardware virtualization
capabilities, such as the ARM Cortex A15, and x86 processors with Intel VT-x or
AMD-V support. Hardware virtualization offers opportunities to partition
physical resources, including processor cores, memory and I/O devices amongst
guest virtual machines. Mixed criticality systems and services can then
co-exist on the same platform in separate virtual machines. However,
traditional virtual machine systems are too expensive because of the costs of
trapping into hypervisors to multiplex and manage machine physical resources on
behalf of separate guests. For example, hypervisors are needed to schedule
separate VMs on physical processor cores. In this paper, we discuss the design
of the Quest-V separation kernel, that partitions services of different
criticalities in separate virtual machines, or sandboxes. Each sandbox
encapsulates a subset of machine physical resources that it manages without
requiring intervention of a hypervisor. Moreover, a hypervisor is not needed
for normal operation, except to bootstrap the system and establish
communication channels between sandboxes."
"Quest-V is a system we have been developing from the ground up, with
objectives focusing on safety, predictability and efficiency. It is designed to
work on emerging multicore processors with hardware virtualization support.
Quest-V is implemented as a ""distributed system on a chip"" and comprises
multiple sandbox kernels. Sandbox kernels are isolated from one another in
separate regions of physical memory, having access to a subset of processing
cores and I/O devices. This partitioning prevents system failures in one
sandbox affecting the operation of other sandboxes. Shared memory channels
managed by system monitors enable inter-sandbox communication.
  The distributed nature of Quest-V means each sandbox has a separate physical
clock, with all event timings being managed by per-core local timers. Each
sandbox is responsible for its own scheduling and I/O management, without
requiring intervention of a hypervisor.
  In this paper, we formulate bounds on inter-sandbox communication in the
absence of a global scheduler or global system clock. We also describe how
address space migration between sandboxes can be guaranteed without violating
service constraints. Experimental results on a working system show the
conditions under which Quest-V performs real-time communication and migration."
"Modern processors are increasingly featuring multiple cores, as well as
support for hardware virtualization. While these processors are common in
desktop and server-class computing, they are less prevalent in embedded and
real-time systems. However, smartphones and tablet PCs are starting to feature
multicore processors with hardware virtualization. If the trend continues, it
is possible that future real-time systems will feature more sophisticated
processor architectures. Future automotive or avionics systems, for example,
could replace complex networks of uniprocessors with consolidated services on a
smaller number of multicore processors. Likewise, virtualization could be used
to isolate services and increase the availability of a system even when
failures occur.
  This paper investigates whether advances in modern processor technologies
offer new opportunities to rethink the design of real-time operating systems.
We describe some of the design principles behind Quest-V, which is being used
as an exploratory vehicle for real-time system design on multicore processors
with hardware virtualization capabilities. While not all embedded systems
should assume such features, a case can be made that more robust,
safety-critical systems can be built to use hardware virtualization without
incurring significant overheads."
"We propose here a framework to model real-time components consisting of
concurrent real-time tasks running on a single processor, using parametric
timed automata. Our framework is generic and modular, so as to be easily
adapted to different schedulers and more complex task models. We first perform
a parametric schedulability analysis of the components using the inverse
method. We show that the method unfortunately does not provide satisfactory
results when the task periods are consid- ered as parameters. After identifying
and explaining the problem, we present a solution adapting the model by making
use of the worst-case scenario in schedulability analysis. We show that the
analysis with the inverse method always converges on the modified model when
the system load is strictly less than 100%. Finally, we show how to use our
parametric analysis for the generation of timed interfaces in compositional
system design."
"The main objective of this paper is to present a mechanism of enhanced paging
support for the second generation microkernels in the form of explicit support
of multi-pager environment for the tasks running in the system. Proposed
mechanism is based on the intra-kernel high granularity pagers assignments per
virtual address space, which allow efficient and simple dispatching of page
faults to the appropriate pagers. The paging is one of the major features of
the virtual memory, which is extensively used by advanced operating systems to
provide an illusion of elastic memory. Original and present second generation
microkernels provide only limited, inflexible and unnatural support for paging.
Furthermore, facilities provided by current solutions for multi-pager support
on the runtime level introduce an overhead in terms of mode switches and thread
context switches which can be significantly reduced. Limited paging support
limits the attractiveness of the second generation microkernel based systems
use in real-life applications, in which processes usually have concurrent
servicing of multiple paging servers. The purpose of this paper is to present a
facilities for the efficient and flexible support of multi-pager environments
for the second generation microkernels. A comparison of the proposed solution
to the present architecture L4 + L4Re has been made and overhead of the page
fault handling critical path has been evaluated. Proposed solution is simple
enough and provides a natural and flexible support of multi-pager environments
for second generation microkernels in efficient way. It introduces a third less
overhead in terms of the mode switches and thread context switches in
comparison to the present L4 + L4Re solution implemented in the Fiasco.OC."
"Round Robin (RR) scheduling algorithm is a preemptive scheduling algorithm.
It is designed especially for time sharing Operating System (OS). In RR
scheduling algorithm the CPU switches between the processes when the static
Time Quantum (TQ) expires. RR scheduling algorithm is considered as the most
widely used scheduling algorithm in research because the TQ is equally shared
among the processes. In this paper a newly proposed variant of RR algorithm
called Min-Max Round Robin (MMRR) scheduling algorithm is presented. The idea
of this MMRR is to make the TQ repeatedly adjusted using Min-Max dispersion
measure in accordance with remaining CPU burst time. Our experimental analysis
shows that MMRR performs much better than RR algorithm in terms of average
turnaround time, average waiting time and number of context switches."
"Round Robin (RR) Algorithm is considered as optimal in time shared
environment because the static time is equally shared among the processes. If
the time quantum taken is static then it undergoes degradation of the CPU
performance and leads to so many context switches. In this paper, we have
proposed a new effective dynamic RR algorithm SMDRR (Subcontrary Mean Dynamic
Round Robin) based on dynamic time quantum where we use the subcontrary mean or
harmonic mean to find the time quantum. The idea of this approach is to make
the time quantum repeatedly adjusted according to the burst time of the
currently running processes. Our experimental analysis shows that SMDRR
performs better than RR algorithm in terms of reducing the number of context
switches, average turnaround time and average waiting time."
"In this paper, we address the power-aware scheduling of sporadic
constrained-deadline hard real-time tasks using dynamic voltage scaling upon
multiprocessor platforms. We propose two distinct algorithms. Our first
algorithm is an off-line speed determination mechanism which provides an
identical speed for each processor. That speed guarantees that all deadlines
are met if the jobs are scheduled using EDF. The second algorithm is an on-line
and adaptive speed adjustment mechanism which reduces the energy consumption
while the system is running."
"All real time tasks which are termed as critical tasks by nature have to
complete its execution before its deadline, even in presence of faults. The
most popularly used real time task assignment algorithms are First Fit (FF),
Best Fit (BF), Bin Packing (BP).The common task scheduling algorithms are Rate
Monotonic (RM), Earliest Deadline First (EDF) etc.All the current approaches
deal with either fault tolerance or criticality in real time. In this paper we
have proposed an integrated approach with a new algorithm, called SASA (Sorting
And Sequential Assignment) which maps the real time task assignment with task
schedule and fault tolerance"
"In this paper, we address the scheduling problem of multi-mode real-time
systems upon uniform multiprocessor platforms. We propose two transition
protocols, specified together with their schedulability test, and provide the
reader with two distinct upper bounds for the length of the transient phases
during mode transitions, respectively for the cases where jobs priorities are
known and unknown beforehand."
"In this paper we study the partitioning approach for multiprocessor real-time
scheduling. This approach seems to be the easiest since, once the partitioning
of the task set has been done, the problem reduces to well understood
uniprocessor issues. Meanwhile, there is no optimal and polynomial solution to
partition tasks on processors. In this paper we analyze partitioning algorithms
from several points of view such that for a given task set and specific
constraints (processor number, task set type, etc.) we should be able to
identify the best heuristic and the best schedulability test. We also analyze
the influence of the heuristics on the performance of the uniprocessor tests
and the impact of a specific task order on the schedulability. A study on
performance difference between Fixed Priority schedulers and EDF in the case of
partitioning scheduling is also considered."
"System energy models are important for energy optimization and management in
mobile systems. However, existing system energy models are built in lab with
the help from a second computer. Not only are they labor-intensive; but also
they will not adequately account for the great diversity in the hardware and
usage of mobile systems. Moreover, existing system energy models are intended
for energy estimation for time intervals of one second or longer; they do not
provide the required rate for fine-grain use such as per-application energy
accounting.
  In this work, we study a self-modeling paradigm in which a mobile system
automatically generates its energy model without any external assistance. Our
solution, Se-same, leverages the possibility of self power measurement through
the smart battery interface and employs a suite of novel techniques to achieve
accuracy and rate much higher than that of the smart battery interface.
  We report the implementation and evaluation of Se-same on a laptop and a
smartphone. The experiment results show that Sesame generates system energy
models of 95% accuracy at one estimation per second and 88% accuracy at one
estimation per 10ms, without any external assistance. A five-day field studies
with four laptop and four smartphones users further demonstrate the
effectiveness, efficiency, and noninvasiveness of Sesame."
"Almost all of the current process scheduling algorithms which are used in
modern operating systems (OS) have their roots in the classical scheduling
paradigms which were developed during the 1970's. But modern computers have
different types of software loads and user demands. We think it is important to
run what the user wants at the current moment. A user can be a human, sitting
in front of a desktop machine, or it can be another machine sending a request
to a server through a network connection. We think that OS should become
intelligent to distinguish between different processes and allocate resources,
including CPU, to those processes which need them most. In this work, as a
first step to make the OS aware of the current state of the system, we consider
process dependencies and interprocess communications. We are developing a
model, which considers the need to satisfy interactive users and other possible
remote users or customers, by making scheduling decisions based on process
dependencies and interprocess communications. Our simple proof of concept
implementation and experiments show the effectiveness of this approach in the
real world applications. Our implementation does not require any change in the
software applications nor any special kind of configuration in the system,
Moreover, it does not require any additional information about CPU needs of
applications nor other resource requirements. Our experiments show significant
performance improvement for real world applications. For example, almost
constant average response time for Mysql data base server and constant frame
rate for mplayer under different simulated load values."
"This paper describes a study of comparison of global and one-dimensional
local optimization methods to operating system scheduler tuning. The operating
system scheduler we use is the Linux 2.6.23 Completely Fair Scheduler (CFS)
running in simulator (LinSched). We have ported the Hackbench scheduler
benchmark to this simulator and use this as the workload. The global
optimization approach we use is Particle Swarm Optimization (PSO). We make use
of Response Surface Methodology (RSM) to specify optimal parameters for our PSO
implementation. The one-dimensional local optimization approach we use is the
Golden Section method. In order to use this approach, we convert the scheduler
tuning problem from one involving setting of three parameters to one involving
the manipulation of one parameter. Our results show that the global
optimization approach yields better response but the one- dimensional
optimization approach converges to a solution faster than the global
optimization approach."
"Energy consumption is a critical design issue in real-time systems,
especially in battery- operated systems. Maintaining high performance, while
extending the battery life between charges is an interesting challenge for
system designers. Dynamic Voltage Scaling (DVS) allows a processor to
dynamically change speed and voltage at run time, thereby saving energy by
spreading run cycles into idle time. Knowing when to use full power and when
not, requires the cooperation of the operating system scheduler. Usually,
higher processor voltage and frequency leads to higher system throughput while
energy reduction can be obtained using lower voltage and frequency. Instead of
lowering processor voltage and frequency as much as possible, energy efficient
real-time scheduling adjusts voltage and frequency according to some
optimization criteria, such as low energy consumption or high throughput, while
it meets the timing constraints of the real-time tasks. As the quantity and
functional complexity of battery powered portable devices continues to raise,
energy efficient design of such devices has become increasingly important. Many
real-time scheduling algorithms have been developed recently to reduce energy
consumption in the portable devices that use DVS capable processors. Three
algorithms namely Red Tasks Only (RTO), Blue When Possible (BWP) and Red as
Late as Possible (RLP) are proposed in the literature to schedule the real-time
tasks in Weakly-hard real-time systems. This paper proposes optimal slack
management algorithms to make the above existing weakly hard real-time
scheduling algorithms energy efficient using DVS and DPD techniques."
"In this paper we consider the scheduling problem of hard real-time systems
composed of periodic constrained-deadline tasks upon identical multiprocessor
platforms. We assume that tasks are scheduled by using the global-EDF
scheduler. We establish an exact schedulability test for this scheduler by
exploiting on the one hand its predictability property and by providing on the
other hand a feasibility interval so that if it is possible to find a valid
schedule for all the jobs contained in this interval, then the whole system
will be stamped feasible. In addition, we show by means of a counterexample
that the feasibility interval, and thus the schedulability test, proposed by
Leung [Leung 1989] is incorrect and we show which arguments are actually
incorrect."
"Teaching Unix to new students is a common tasks in many higher schools. This
paper presents an approach to such course where the students progress
autonomously with the help of the teacher. The traditional textbook is
complemented with a wiki, and the main thread of the course is a game, in the
form of a treasure hunt. The course finishes with a lab exam, where students
have to perform practical manipulations similar to the ones performed during
the treasure hunt. The exam is graded fully automatically. This paper discusses
the motivations and advantages of the approach, and gives an overall view of
the tools we developed. The tools are available from the web, and open-source,
hence re-usable outside the Ensimag."
"This paper describes the realization of a new Linux distribution based on
Ubuntu Linux and Xenomai Real-Time framework. This realization is motivated by
the eminent need of real-time systems in modern computer science courses. The
majority of the technical choices are made after qualitative comparison. The
main goal of this distribution is to offer standard Operating Systems (OS) that
include Xenomai infrastructure and the essential tools to begin hard real-time
application development inside a convivial desktop environment. The released
live/installable DVD can be adopted to emulate several classic RTOS Application
Program Interfaces (APIs), directly use and understand real-time Linux in
convivial desktop environment and prototyping real-time embedded applications."
"Scheduling is the central concept used frequently in Operating System. It
helps in choosing the processes for execution. Round Robin (RR) is one of the
most widely used CPU scheduling algorithm. But, its performance degrades with
respect to context switching, which is an overhead and it occurs during each
scheduling. Overall performance of the system depends on choice of an optimal
time quantum, so that context switching can be reduced. In this paper, we have
proposed a new variant of RR scheduling algorithm, known as Dynamic Quantum
with Readjusted Round Robin (DQRRR) algorithm. We have experimentally shown
that performance of DQRRR is better than RR by reducing number of context
switching, average waiting time and average turn around time."
"The main objective of the paper is to improve the Round Robin (RR) algorithm
using dynamic ITS by coalescing it with Shortest Remaining Time Next (SRTN)
algorithm thus reducing the average waiting time, average turnaround time and
the number of context switches. The original time slice has been calculated for
each process based on its burst time.This is mostly suited for soft real time
systems where meeting of deadlines is desirable to increase its performance.
The advantage is that processes that are closer to their remaining completion
time will get more chances to execute and leave the ready queue. This will
reduce the number of processes in the ready queue by knocking out short jobs
relatively faster in a hope to reduce the average waiting time, turn around
time and number of context switches. This paper improves the algorithm [8] and
the experimental analysis shows that the proposed algorithm performs better
than algorithm [6] and [8] when the processes are having an increasing order,
decreasing order and random order of burst time."
"In this paper, a new variant of Round Robin (RR) algorithm is proposed which
is suitable for soft real time systems. RR algorithm performs optimally in
timeshared systems, but it is not suitable for soft real time systems. Because
it gives more number of context switches, larger waiting time and larger
response time. We have proposed a novel algorithm, known as Priority Based
Dynamic Round Robin Algorithm(PBDRR),which calculates intelligent time slice
for individual processes and changes after every round of execution. The
proposed scheduling algorithm is developed by taking dynamic time quantum
concept into account. Our experimental results show that our proposed algorithm
performs better than algorithm in [8] in terms of reducing the number of
context switches, average waiting time and average turnaround time."
"In this paper we study the scheduling of parallel and real-time recurrent
tasks. Firstly, we propose a new parallel task model which allows recurrent
tasks to be composed of several threads, each thread requires a single
processor for execution and can be scheduled simultaneously. Secondly, we
define several kinds of real-time schedulers that can be applied to our
parallel task model. We distinguish between two scheduling classes:
hierarchical schedulers and global thread schedulers. We present and prove
correct an exact schedulability test for each class. Lastly, we also evaluate
the performance of our scheduling paradigm in comparison with Gang scheduling
by means of simulations."
"Computing is currently getting at the same time incredibly in the small with
sensors/actuators embedded in our every- day objects and also greatly in the
large with data and ser- vice clouds accessible anytime, anywhere. This
Internet of Things is physically closed to the user but suffers from weak
run-time execution environments. Cloud Environments provide powerful data
storage and computing power but can not be easily accessed and integrate the
final-user context- awareness. We consider smartphones are set to become the
universal interface between these two worlds. In this position paper, we
propose a middleware approach where smartphones provide service gateways to
bridge the gap between IoT services and Cloud services. Since smartphones are
mobile gateways, they should be able to (re)configure themself according to
their place, things discovered around, and their own resources such battery.
Several issues are discussed: collaborative event-based context management,
adaptive and opportunistic service deployment and invocation, multi-criteria
(user- and performance-oriented) optimization decision algorithm."
"Round Robin, considered as the most widely adopted CPU scheduling algorithm,
undergoes severe problems directly related to quantum size. If time quantum
chosen is too large, the response time of the processes is considered too high.
On the other hand, if this quantum is too small, it increases the overhead of
the CPU. In this paper, we propose a new algorithm, called AN, based on a new
approach called dynamic-time-quantum; the idea of this approach is to make the
operating systems adjusts the time quantum according to the burst time of the
set of waiting processes in the ready queue. Based on the simulations and
experiments, we show that the new proposed algorithm solves the fixed time
quantum problem and increases the performance of Round Robin."
"A wide variety of smartphone applications today rely on third-party
advertising services, which provide libraries that are linked into the hosting
application. This situation is undesirable for both the application author and
the advertiser. Advertising libraries require additional permissions, resulting
in additional permission requests to users. Likewise, a malicious application
could simulate the behavior of the advertising library, forging the user's
interaction and effectively stealing money from the advertiser. This paper
describes AdSplit, where we extended Android to allow an application and its
advertising to run as separate processes, under separate user-ids, eliminating
the need for applications to request permissions on behalf of their advertising
libraries.
  We also leverage mechanisms from Quire to allow the remote server to validate
the authenticity of client-side behavior. In this paper, we quantify the degree
of permission bloat caused by advertising, with a study of thousands of
downloaded apps. AdSplit automatically recompiles apps to extract their ad
services, and we measure minimal runtime overhead. We also observe that most ad
libraries just embed an HTML widget within and describe how AdSplit can be
designed with this in mind to avoid any need for ads to have native code."
"Grid computing is a computation methodology using group of clusters connected
over high-speed networks that involves coordinating and sharing computational
power, data storage and network resources. Integrating a set of clusters of
workstations into one large computing environment can improve the availability
of computing power. The goal of scheduling is to achieve highest possible
system throughput and to match the application need with the available
computing resources. A secure scheduling model is presented, that performs job
grouping activity at runtime. In a Grid environment, security is necessary
because grid is a dynamic environment and participates are independent bodies
with different policies, objectives and requirements. Authentication should be
verified for Grid resource owners as well as resource requesters before they
are allowed to join in scheduling activities. In order to achieve secure
resource and job scheduling including minimum processing time and maximum
resource utilization, A Secure Resource by using RSA algorithm on Networking
and Job Scheduling model with Job Grouping strategy(JGS) in Grid Computing has
been proposed. The result shows significant improvement in the processing time
of jobs and resource utilization as compared to dynamic job grouping (DJG)
based scheduling on smart grids (SG)."
"Operating system is a bridge between system and user. An operating system
(OS) is a software program that manages the hardware and software resources of
a computer. The OS performs basic tasks, such as controlling and allocating
memory, prioritizing the processing of instructions, controlling input and
output devices, facilitating networking, and managing files. It is difficult to
present a complete as well as deep account of operating systems developed till
date. So, this paper tries to overview only a subset of the available operating
systems and its different categories. OS are being developed by a large number
of academic and commercial organizations for the last several decades. This
paper, therefore, concentrates on the different categories of OS with special
emphasis to those that had deep impact on the evolution process. The aim of
this paper is to provide a brief timely commentary on the different categories
important operating systems available today."
"The objective of this paper is to take some aspects of disk scheduling and
scheduling algorithms. The disk scheduling is discussed with a sneak peak in
general and selection of algorithm in particular."
"It is common today to deploy complex software inside a virtual machine (VM).
Snapshots provide rapid deployment, migration between hosts, dependability
(fault tolerance), and security (insulating a guest VM from the host). Yet, for
each virtual machine, the code for snapshots is laboriously developed on a
per-VM basis. This work demonstrates a generic checkpoint-restart mechanism for
virtual machines. The mechanism is based on a plugin on top of an unmodified
user-space checkpoint-restart package, DMTCP. Checkpoint-restart is
demonstrated for three virtual machines: Lguest, user-space QEMU, and KVM/QEMU.
The plugins for Lguest and KVM/QEMU require just 200 lines of code. The Lguest
kernel driver API is augmented by 40 lines of code. DMTCP checkpoints
user-space QEMU without any new code. KVM/QEMU, user-space QEMU, and DMTCP need
no modification. The design benefits from other DMTCP features and plugins.
Experiments demonstrate checkpoint and restart in 0.2 seconds using forked
checkpointing, mmap-based fast-restart, and incremental Btrfs-based snapshots."
"Real time system technology traditionally developed for safety critical
systems, has now been extended to support multimedia systems and virtual
reality. A large number of real-time application, related to multimedia and
adaptive control system, require more flexibility than classical real-time
theory usually permits. This paper proposes an efficient adaptive scheduling
framework in real-time systems based on period adjustment. Under this model
periodic task can change their execution rates based on their importance value
to keep the system underloaded. We propose Period_Adjust algorithm, which
consider the tasks whose periods are bounded as well as the tasks whose periods
are not bounded."
"In this work, we investigate the potential utility of parallelization for
meeting real-time constraints and minimizing energy. We consider malleable Gang
scheduling of implicit-deadline sporadic tasks upon multiprocessors. We first
show the non-necessity of dynamic voltage/frequency regarding optimality of our
scheduling problem. We adapt the canonical schedule for DVFS multiprocessor
platforms and propose a polynomial-time optimal processor/frequency-selection
algorithm. We evaluate the performance of our algorithm via simulations using
parameters obtained from a hardware testbed implementation. Our algorithm has
up to a 60 watt decrease in power consumption over the optimal non-parallel
approach."
"The smartphone market has grown so wide that it assumed a strategic
relevance. Today the most common smartphone OSs are Google's Android and
Apple's iOS. The former is particularly interesting due to its open source
nature, that allows everyone to deeply inspect every aspect of the OS. Android
source code is also bundled with an hardware emulator, based on the open source
software Qemu, that allows the user to run the Android OS without the need of a
physical device. We first present a procedure to extract information flows from
a generic system. We then focus on Android and Qemu architectures and their
logging infrastructures. Finally, we detail what happens inside an Android
device in a particular scenario: the system boot."
"New PCI-e flash cards and SSDs supporting over 100,000 IOPs are now
available, with several usecases in the design of a high performance storage
system. By using an array of flash chips, arranged in multiple banks, large
capacities are achieved. Such multi-banked architecture allow parallel read,
write and erase operations. In a raw PCI-e flash card, such parallelism is
directly available to the software layer. In addition, the devices have
restrictions such as, pages within a block can only be written sequentially.
The devices also have larger minimum write sizes (greater than 4KB). Current
flash translation layers (FTLs) in Linux are not well suited for such devices
due to the high device speeds, architectural restrictions as well as other
factors such as high lock contention. We present a FTL for Linux that takes
into account the hardware restrictions, that also exploits the parallelism to
achieve high speeds. We also consider leveraging the parallelism for garbage
collection by scheduling the garbage collection activities on idle banks. We
propose and evaluate an adaptive method to vary the amount of garbage
collection according to the current I/O load on the device."
"Virtualization is a term that refers to the abstraction of computer
resources. The purpose of virtual computing environment is to improve resource
utilization by providing a unified integrated operating platform for users and
applications based on aggregation of heterogeneous and autonomous resources.
More recently, virtualization at all levels (system, storage, and network)
became important again as a way to improve system security, reliability and
availability, reduce costs, and provide greater flexibility. Virtualization has
rapidly become a go-to technology for increasing efficiency in the data center.
With virtualization technologies providing tremendous flexibility, even
disparate architectures may be deployed on a single machine without
interference This paper explains the basics of server virtualization and
addresses pros and cons of virtualization"
"Personal computers have diverse and fast-evolving I/O devices, making their
I/O virtualization different from that of servers and data centers. In this
paper, we present our recent endeavors in simplifying I/O virtualization for
personal computers. Our key insight is that many operating systems, including
Unix-like ones, abstract I/O devices as device files. There is a small and
stable set of operations on device files, therefore, I/O virtualization at the
device file boundary requires a one-time effort to support various I/O devices.
  We present devirtualization, our design of I/O virtualization at the device
file boundary and its implementation for Linux/x86 systems. We are able to
virtualize various GPUs, input devices, cameras, and audio devices with fewer
than 4900 LoC, of which only about 300 are specific to I/O device classes. Our
measurements show that devirtualized devices achieve interactive performance
indistinguishable from native ones by human users, even when running 3D HD
games."
"Future MPSoCs with 1000 or more processor cores on a chip require new means
for resource-aware programming in order to deal with increasing imperfections
such as process variation, fault rates, aging effects, and power as well as
thermal problems. On the other hand, predictable program executions are
threatened if not impossible if no proper means of resource isolation and
exclusive use may be established on demand. In view of these problems and
menaces, invasive computing enables an application programmer to claim for
processing resources and spread computations to claimed processors dynamically
at certain points of the program execution.
  Such decisions may be depending on the degree of application parallelism and
the state of the underlying resources such as utilization, load, and
temperature, but also with the goal to provide predictable program execution on
MPSoCs by claiming processing resources exclusively as the default and thus
eliminating interferences and creating the necessary isolation between multiple
concurrently running applications. For achieving this goal, invasive computing
introduces new programming constructs for resource-aware programming that
meanwhile, for testing purpose, have been embedded into the parallel computing
language X10 as developed by IBM using a library-based approach.
  This paper presents major ideas and common terms of invasive computing as
investigated by the DFG Transregional Collaborative Research Centre TR89.
Moreoever, a reflection is given on the granularity of resources that may be
requested by invasive programs."
"With the advancement in the automation industry, to perform complex remote
operations is required. Advancements in the networking technology has led to
the development of different architectures to implement control from a large
distance. In various control applications of the modern industry, the agents,
such as sensors, actuators, and controllers are basically geographically
distributed. For efficient working of a control application, all of the agents
have to exchange information through a communication media. At present, an
increasing number of distributed control systems are based on platforms made up
of conventional PCs running open-source real-time operating systems. Often,
these systems needed to have networked devices supporting synchronized
operations with respect to each node. A framework is studied that relies on
standard software and protocol as RTAI, EtherCAT, RTnet and IEEE 1588. RTAI and
its various protocols are studied in network control systems environment."
"The most popular heterogeneous many-core platform, the CPU+GPU combination,
has received relatively little attention in operating systems research. This
platform is already widely deployed: GPUs can be found, in some form, in most
desktop and laptop PCs. Used for more than just graphics processing, modern
GPUs have proved themselves versatile enough to be adapted to other
applications as well. Though GPUs have strengths that can be exploited in
systems software, this remains a largely untapped resource. We argue that
augmenting the OS kernel with GPU computing power opens the door to a number of
new opportunities. GPUs can be used to speed up some kernel functions, make
other scale better, and make it feasible to bring some computation-heavy
functionality into the kernel. We present our framework for using the GPU as a
co-processor from an OS kernel, and demonstrate a prototype in Linux."
"This paper is proposing a general periodicity result concerning any
deterministic and memoryless scheduling algorithm (including
non-work-conserving algorithms), for any context, on identical multiprocessor
platforms. By context we mean the hardware architecture (uniprocessor,
multicore), as well as task constraints like critical sections, precedence
constraints, self-suspension, etc. Since the result is based only on the
releases and deadlines, it is independent from any other parameter. Note that
we do not claim that the given interval is minimal, but it is an upper bound
for any cycle of any feasible schedule provided by any deterministic and
memoryless scheduler."
"We consider the partitioned scheduling problem of multimode real-time systems
upon identical multiprocessor platforms. During the execution of a multimode
system, the system can change from one mode to another such that the current
task set is replaced with a new one. In this paper, we consider a synchronous
transition protocol in order to take into account mode-independent tasks, i.e.,
tasks of which the execution pattern must not be jeopardized by the mode
changes. We propose two methods for handling mode changes in partitioned
scheduling. The first method is offline/optimal and computes a static
allocation of tasks schedulable and respecting both tasks and transition
deadlines (if any). The second approach is subject to a sufficient condition in
order to ensure online First Fit based allocation to satisfy the timing
constraints."
"Operating systems are currently viewed ostensively. As a result they mean
different things to different people. The ostensive character makes it is hard
to understand OSes formally. An intensional view can enable better formal work,
and also offer constructive support for some important problems, e.g. OS
architecture. This work argues for an intensional view of operating systems. It
proposes to overcome the current ostensive view by defining an OS based on
formal models of computation, and also introduces some principles. Together
these are used to develop a framework of algorithms of single processor OS
structure using an approach similar to function level programming. In this
abridged paper we illustrate the essential approach, discuss some advantages
and limitations and point out some future possibilities."
"The file system provides the mechanism for online storage and access to file
contents, including data and programs. This paper covers the high-level details
of file systems, as well as related topics such as the disk cache, the file
system interface to the kernel, and the user-level APIs that use the features
of the file system. It will give you a thorough understanding of how a file
system works in general. The main component of the operating system is the file
system. It is used to create, manipulate, store, and retrieve data. At the
highest level, a file system is a way to manage information on a secondary
storage medium. There are so many layers under and above the file system. All
the layers are to be fully described here. This paper will give the explanatory
knowledge of the file system designers and the researchers in the area. The
complete path from the user process to secondary storage device is to be
mentioned. File system is the area where the researchers are doing lot of job
and there is always a need to do more work. The work is going on for the
efficient, secure, energy saving techniques for the file systems. As we know
that the hardware is going to be fast in performance and low-priced day by day.
The software is not built to comeback with the hardware technology. So there is
a need to do research in this area to bridge the technology gap."
"This is the era of High Performance Computing (HPC). There is a great demand
of the best performance evaluation techniques for the file and storage systems.
The task of evaluation is both necessary and hard. It gives in depth analysis
of the target system and that becomes the decision points for the users. That
is also helpful for the inventors or developers to find out the bottleneck in
their systems. In this paper many performance evaluation techniques are
described for file and storage system evaluation and the main stress is given
on the important one that is replay traces. A survey has been done for the
performance evaluation techniques used by the researchers and on the replay
traces. And the taxonomy of the replay traces is described. The some of the
popular replay traces are just like, Tracefs [1], //Trace [2], Replayfs [3] and
VFS Interceptor [12]. At last we have concluded all the features that must be
considered when we are going to develop the new tool for the replay traces. The
complete work of this paper shows that the storage system developers must care
about all the techniques which can be used for the performance evaluation of
the file systems. So they can develop highly efficient future file and storage
systems."
"The growing need for continuous processing capabilities has led to the
development of multicore systems with a complex cache hierarchy. Such multicore
systems are generally designed for improving the performance in average case,
while hard real-time systems must consider worst-case scenarios. An open
challenge is therefore to efficiently schedule hard real-time tasks on a
multicore architecture. In this work, we propose a mathematical formulation for
computing a static scheduling that minimize L1 data cache misses between hard
real-time tasks on a multicore architecture using communication affinities."
"Mobile systems are equipped with a diverse collection of I/O devices,
including cameras, microphones, sensors, and modems. There exist many novel use
cases for allowing an application on one mobile system to utilize I/O devices
from another. This paper presents Rio, an I/O sharing solution that supports
unmodified applications and exposes all the functionality of an I/O device for
sharing. Rio's design is common to many classes of I/O devices, thus
significantly reducing the engineering effort to support new I/O devices. Our
implementation of Rio on Android consists of 6700 total lines of code and
supports four I/O classes with fewer than 450 class-specific lines of code. Rio
also supports I/O sharing between mobile systems of different form factors,
including smartphones and tablets. We show that Rio achieves performance close
to that of local I/O for audio, sensors, and modems, but suffers noticeable
performance degradation for camera due to network throughput limitations
between the two systems, which is likely to be alleviated by emerging wireless
standards."
"Providing fault-tolerance for long-running GPU-intensive jobs requires
application-specific solutions, and often involves saving the state of complex
data structures spread among many graphics libraries. This work describes a
mechanism for transparent GPU-independent checkpoint-restart of 3D graphics.
The approach is based on a record-prune-replay paradigm: all OpenGL calls
relevant to the graphics driver state are recorded; calls not relevant to the
internal driver state as of the last graphics frame prior to checkpoint are
discarded; and the remaining calls are replayed on restart. A previous approach
for OpenGL 1.5, based on a shadow device driver, required more than 78,000
lines of OpenGL-specific code. In contrast, the new approach, based on
record-prune-replay, is used to implement the same case in just 4,500 lines of
code. The speed of this approach varies between 80 per cent and nearly 100 per
cent of the speed of the native hardware acceleration for OpenGL 1.5, as
measured when running the ioquake3 game under Linux. This approach has also
been extended to demonstrate checkpointing of OpenGL 3.0 for the first time,
with a demonstration for PyMol, for molecular visualization."
"As the performance gap between memory and processors has increased, then it
leads to the poor performance. Efficient virtual memory can overcome this
problem. And the efficiency of virtual memory depends on the replacement policy
used for cache. In this paper, our algorithm not only based on the time to last
access and frequency index but, we also consider the power consumption. We show
that Low Power Consumption Weighting Replacement Policy (LWRP) has better
performance and low power consumption."
"The contemporary development of hardware components is a prerequisite for
increasing the concentration of computing power. System software is developing
at a much slower pace. To use available resources efficiently modeling is
required. Formalization of elements, present in the material, provides the
basis for modeling. Examples are presented to demonstrate the efficiency of the
concept."
"Management of disk scheduling is a very important aspect of operating system.
Performance of the disk scheduling completely depends on how efficient is the
scheduling algorithm to allocate services to the request in a better manner.
Many algorithms (FIFO, SSTF, SCAN, C-SCAN, LOOK, etc.) are developed in the
recent years in order to optimize the system disk I/O performance. By reducing
the average seek time and transfer time, we can improve the performance of disk
I/O operation. In our proposed algorithm, Optimize Disk Scheduling Algorithm
(ODSA) is taking less average seek time and transfer time as compare to other
disk scheduling algorithms (FIFO, SSTF, SCAN, C-SCAN, LOOK, etc.), which
enhances the efficiency of the disk performance in a better manner."
"Round Robin (RR) Scheduling is the basis of time sharing environment. It is
the combination of First Come First Served (FCFS) scheduling algorithm and
preemption among processes. It is basically used in a time sharing operating
system. It switches from one process to another process in a time interval. The
time interval or Time Quantum (TQ) is fixed for all available processes. So,
the larger process suffers from Context Switches (CS). To increase efficiency,
we have to select different TQ for processes. The main objective of RR is to
reduce the CS, maximize the utilization of CPU and minimize the turn around and
the waiting time. In this paper, we have considered different TQ for a group of
processes. It reduces CS as well as enhancing the performance of RR algorithm.
TQ can be calculated using min-max dispersion measure. Our experimental
analysis shows that Group Based Time Quantum (GBTQ) RR algorithm performs
better than existing RR algorithm with respect to Average Turn Around Time
(ATAT), Average Waiting Time (AWT) and CS."
"Wireless Sensor Networks (WSNs) are used in many application fields, such as
military, healthcare, environment surveillance, etc. The WSN OS based on
event-driven model doesn't support real-time and multi-task application types
and the OSs based on thread-driven model consume much energy because of
frequent context switch. Due to the high-dense and large-scale deployment of
sensor nodes, it is very difficult to collect sensor nodes to update their
software. Furthermore, the sensor nodes are vulnerable to security attacks
because of the characteristics of broadcast communication and unattended
application. This paper presents a task and resource self-adaptive embedded
real-time microkernel, which proposes hybrid programming model and offers a
two-level scheduling strategy to support real-time multi-task correspondingly.
A communication scheme, which takes the ""tuple"" space and ""IN/OUT"" primitives
from ""LINDA"", is proposed to support some collaborative and distributed tasks.
In addition, this kernel implements a run-time over-the-air updating mechanism
and provides a security policy to avoid the attacks and ensure the reliable
operation of nodes. The performance evaluation is proposed and the experiential
results show this kernel is task-oriented and resource-aware and can be used
for the applications of event-driven and real-time multi-task."
"In this article, the file system development design approaches are discussed.
The selection of the file system design approach is done according to the needs
of the developers what are the needed requirements and specifications for the
new design. It allowed us to identify where our proposal fitted in with
relation to current and past file system development. Our experience with file
system development is limited so the research served to identify the different
techniques that can be used. The variety of file systems encountered show what
an active area of research file system development is. The file systems may be
from one of the two fundamental categories. In one category, the file system is
developed in user space and runs as a user process. Another file system may be
developed in the kernel space and runs as a privileged process. Another one is
the mixed approach in which we can take the advantages of both aforesaid
approaches. Each development option has its own pros and cons. In this article,
these design approaches are discussed."
"Due to the diversity and implicit redundancy in terms of processing units and
compute kernels, off-the-shelf heterogeneous systems offer the opportunity to
detect and tolerate faults during task execution in hardware as well as in
software. To automatically leverage this diversity, we introduce an extension
of an online-learning runtime system that combines the benefits of the existing
performance-oriented task mapping with task duplication, a diversity-oriented
mapping strategy and heterogeneity-aware majority voter. This extension uses a
new metric to dynamically rate the remaining benefit of unreliable processing
units and a memory management mechanism for automatic data transfers and
checkpointing in the host and device memories."
"Heterogeneous multicore architectures are becoming increasingly popular due
to their potential of achieving high performance and energy efficiency compared
to the homogeneous multicore architectures. In such systems, the real-time
scheduling problem becomes more challenging in that processors have different
speeds. A job executing on a processor with speed $x$ for $t$ time units
completes $(x \cdot t)$ units of execution. Prior research on heterogeneous
multiprocessor real-time scheduling has focused on hard real-time systems,
where, significant processing capacity may have to be sacrificed in the
worst-case to ensure that all deadlines are met. As meeting hard deadlines is
overkill for many soft real-time systems in practice, this paper shows that on
soft real-time heterogeneous multiprocessors, bounded response times can be
ensured for globally-scheduled sporadic task systems with no utilization loss.
A GEDF-based scheduling algorithm, namely GEDF-H, is presented and response
time bounds are established under both preemptive and non-preemptive GEDF-H
scheduling. Extensive experiments show that the magnitude of the derived
response time bound is reasonable, often smaller than three task periods. To
the best of our knowledge, this paper is the first to show that soft real-time
sporadic task systems can be supported on heterogeneous multiprocessors without
utilization loss, and with reasonable predicted response time."
"Response time is one of the characteristics of scheduler, happens to be a
prominent attribute of any CPU scheduling algorithm. The proposed New Multi
Level Feedback Queue [NMLFQ] Scheduler is compared with dynamic, real time,
Dependent Activity Scheduling Algorithm (DASA) and Lockes Best Effort
Scheduling Algorithm (LBESA). We abbreviated beneficial result of NMLFQ
scheduler in comparison with dynamic best effort schedulers with respect to
response time."
"Legacy device drivers implement both device resource management and
isolation. This results in a large code base with a wide high-level interface
making the driver vulnerable to security attacks. This is particularly
problematic for increasingly popular accelerators like GPUs that have large,
complex drivers. We solve this problem with library drivers, a new driver
architecture. A library driver implements resource management as an untrusted
library in the application process address space, and implements isolation as a
kernel module that is smaller and has a narrower lower-level interface (i.e.,
closer to hardware) than a legacy driver. We articulate a set of device and
platform hardware properties that are required to retrofit a legacy driver into
a library driver. To demonstrate the feasibility and superiority of library
drivers, we present Glider, a library driver implementation for two GPUs of
popular brands, Radeon and Intel. Glider reduces the TCB size and attack
surface by about 35% and 84% respectively for a Radeon HD 6450 GPU and by about
38% and 90% respectively for an Intel Ivy Bridge GPU. Moreover, it incurs no
performance cost. Indeed, Glider outperforms a legacy driver for applications
requiring intensive interactions with the device driver, such as applications
using the OpenGL immediate mode API."
"To deal with a large variety of workloads in different application domains in
real-time embedded systems, a number of expressive task models have been
developed. For each individual task model, researchers tend to develop
different types of techniques for deriving schedulability tests with different
computation complexity and performance. In this paper, we present a general
schedulability analysis framework, namely the k2U framework, that can be
potentially applied to analyze a large set of real-time task models under any
fixed-priority scheduling algorithm, on both uniprocessor and multiprocessor
scheduling. The key to k2U is a k-point effective schedulability test, which
can be viewed as a ""blackbox"" interface. For any task model, if a corresponding
k-point effective schedulability test can be constructed, then a sufficient
utilization-based test can be automatically derived. We show the generality of
k2U by applying it to different task models, which results in new and improved
tests compared to the state-of-the-art.
  Analogously, a similar concept by testing only k points with a different
formulation has been studied by us in another framework, called k2Q, which
provides quadratic bounds or utilization bounds based on a different
formulation of schedulability test. With the quadratic and hyperbolic forms,
k2Q and k2U frameworks can be used to provide many quantitive features to be
measured, like the total utilization bounds, speed-up factors, etc., not only
for uniprocessor scheduling but also for multiprocessor scheduling. These
frameworks can be viewed as a ""blackbox"" interface for schedulability tests and
response-time analysis."
"Failure injection in distributed systems has been an important issue to
experiment with robust, resilient distributed systems. In order to reproduce
real-life conditions, parts of the application must be killed without letting
the operating system close the existing network communications in a ""clean""
way. When a process is simply killed, the OS closes them. SystemTap is a an
infrastructure that probes the Linux kernel's internal calls. If processes are
killed at kernel-level, they can be destroyed without letting the OS do
anything else. In this paper, we present a kernel-level failure injection
system based on SystemTap. We present how it can be used to implement
deterministic and probabilistic failure scenarios."
"Soft real-time applications such as multimedia applications often show bursty
memory access patterns---regularly requiring a high memory bandwidth for a
short duration of time. Such a period is often critical for timely data
processing. Hence, we call it a memory-performance critical section.
Unfortunately, in multicore architecture, non-real-time applications on
different cores may also demand high memory bandwidth at the same time, which
can substantially increase the time spent on the memory performance critical
sections.
  In this paper, we present BWLOCK, user-level APIs and a memory bandwidth
control mechanism that can protect such memory performance critical sections of
soft real-time applications. BWLOCK provides simple lock like APIs to declare
memory-performance critical sections. If an application enters a
memory-performance critical section, the memory bandwidth control system then
dynamically limit other cores' memory access rates to protect memory
performance of the application until the critical section finishes.
  From case studies with real-world soft real-time applications, we found (1)
such memory-performance critical sections do exist and are often easy to
identify; and (2) applying BWLOCK for memory critical sections significantly
improve performance of the soft real-time applications at a small or no cost in
throughput of non real-time applications."
"This paper is a comprehensive survey of the various operating systems
available for the Internet of Things environment. At first the paper introduces
the various aspects of the operating systems designed for the IoT environment
where resource constraint poses a huge problem for the operation of the general
OS designed for the various computing devices. The latter part of the paper
describes the various OS available for the resource constraint IoT environment
along with the various platforms each OS supports, the software development
kits available for the development of applications in the respective OS along
with the various protocols implemented in these OS for the purpose of
communication and networking."
"The hardware transactional memory (HTM) implementation in Intel's i7-4770
""Haswell"" processor tracks the transactional read-set in the L1 (level-1), L2
(level-2) and L3 (level-3) caches and the write-set in the L1 cache.
Displacement or eviction of read-set entries from the cache hierarchy or
write-set entries from the L1 results in abort. We show that the placement
policies of dynamic storage allocators -- such as those found in common
""malloc"" implementations -- can influence the L1 conflict miss rate in the L1.
Conflict misses -- sometimes called mapping misses -- arise because of less
than ideal associativity and represent imbalanced distribution of active memory
blocks over the set of available L1 indices. Under transactional execution
conflict misses may manifest as aborts, representing wasted or futile effort
instead of a simple stall as would occur in normal execution mode.
  Furthermore, when HTM is used for transactional lock elision (TLE),
persistent aborts arising from conflict misses can force the offending thread
through the so-called ""slow path"". The slow path is undesirable as the thread
must acquire the lock and run the critical section in normal execution mode,
precluding the concurrent execution of threads in the ""fast path"" that monitor
that same lock and run their critical sections in transactional mode. For a
given lock, multiple threads can concurrently use the transactional fast path,
but at most one thread can use the non-transactional slow path at any given
time. Threads in the slow path preclude safe concurrent fast path execution.
Aborts rising from placement policies and L1 index imbalance can thus result in
loss of concurrency and reduced aggregate throughput."
"The massive parallelism and resource sharing embodying today's cloud business
model not only exacerbate the security challenge of timing channels, but also
undermine the viability of defenses based on resource partitioning. We propose
hypervisor-enforced timing mitigation to control timing channels in cloud
environments. This approach closes ""reference clocks"" internal to the cloud by
imposing a deterministic view of time on guest code, and uses timing mitigators
to pace I/O and rate-limit potential information leakage to external observers.
Our prototype hypervisor is the first system to mitigate timing-channel leakage
across full-scale existing operating systems such as Linux and applications in
arbitrary languages. Mitigation incurs a varying performance cost, depending on
workload and tunable leakage-limiting parameters, but this cost may be
justified for security-critical cloud applications and data."
"Wireless sensor network (WSN) has attracted researchers worldwide to explore
the research opportunities, with application mainly in health monitoring,
industry automation, battlefields, home automation and environmental
monitoring. A WSN is highly resource constrained in terms of energy,
computation and memory. WSNs deployment ranges from the normal working
environment up to hostile and hazardous environment such as in volcano
monitoring and underground mines. These characteristics of WSNs hold additional
set of challenges in front of the operating system designer. The objective of
this survey is to highlight the features and weakness of the opearting system
available for WSNs, with the focus on the current application demands. The
paper also discusses the operating system design issues in terms of
architecture, programming model, scheduling and memory management and support
for real time applications."
"Solid state disks (SSDs) have advanced to outperform traditional hard drives
significantly in both random reads and writes. However, heavy random writes
trigger fre- quent garbage collection and decrease the performance of SSDs. In
an SSD array, garbage collection of individ- ual SSDs is not synchronized,
leading to underutilization of some of the SSDs.
  We propose a software solution to tackle the unsyn- chronized garbage
collection in an SSD array installed in a host bus adaptor (HBA), where
individual SSDs are exposed to an operating system. We maintain a long I/O
queue for each SSD and flush dirty pages intelligently to fill the long I/O
queues so that we hide the performance imbalance among SSDs even when there are
few parallel application writes. We further define a policy of select- ing
dirty pages to flush and a policy of taking out stale flush requests to reduce
the amount of data written to SSDs. We evaluate our solution in a real system.
Experi- ments show that our solution fully utilizes all SSDs in an array under
random write-heavy workloads. It improves I/O throughput by up to 62% under
random workloads of mixed reads and writes when SSDs are under active garbage
collection. It causes little extra data writeback and increases the cache hit
rate."
"Today's monolithic kernels often implement a small, fixed set of policies
such as disk I/O scheduling policies, while exposing many parameters to let
users select a policy or adjust the specific setting of the policy. Ideally,
the parameters exposed should be flexible enough for users to tune for good
performance, but in practice, users lack domain knowledge of the parameters and
are often stuck with bad, default parameter settings.
  We present EOS, a system that bridges the knowledge gap between kernel
developers and users by automatically evolving the policies and parameters in
vivo on users' real, production workloads. It provides a simple policy
specification API for kernel developers to programmatically describe how the
policies and parameters should be tuned, a policy cache to make in-vivo tuning
easy and fast by memorizing good parameter settings for past workloads, and a
hierarchical search engine to effectively search the parameter space.
Evaluation of EOS on four main Linux subsystems shows that it is easy to use
and effectively improves each subsystem's performance."
"Network processing elements in virtual machines, also known as Network
Function Virtualization (NFV) often face CPU bottlenecks at the virtualization
interface. Even highly optimized paravirtual device interfaces fall short of
the throughput requirements of modern devices. Passthrough devices, together
with SR-IOV support for multiple device virtual functions (VF) and IOMMU
support, mitigate this problem somewhat, by allowing a VM to directly control a
device partition bypassing the virtualization stack. However, device
passthrough requires high-end (expensive and power-hungry) hardware, places
scalability limits on consolidation ratios, and does not support efficient
switching between multiple VMs on the same host.
  We present a paravirtual interface that securely exposes an I/O device
directly to the guest OS running inside the VM, and yet allows that device to
be securely shared among multiple VMs and the host. Compared to the best-known
paravirtualization interfaces, our paravirtual interface supports up to 2x
higher throughput, and is closer in performance to device passthrough. Unlike
device passthrough however, we do not require SR-IOV or IOMMU support, and
allow fine-grained dynamic resource allocation, significantly higher
consolidation ratios, and seamless VM migration. Our security mechanism is
based on a novel approach called dynamic binary opcode subtraction."
"Analysis of the retrieval architecture of the highly influential UNIX file
system (\cite{Ritchie}\cite{multicsfs}) provides insight into design methods,
constraints, and possible alternatives. The basic architecture can be
understood in terms of function composition and recursion by anyone with some
mathematical maturity. Expertise in operating system coding or in any
specialized ""formal method"" is not required."
"On Board Data Handling (OBDH) has functions to monitor, control, acquire,
analyze, take a decision, and execute the command. OBDH should organize the
task between sub system. OBDH like a heart which has a vital function. Because
the function is seriously important therefore designing and implementing the
OBDH should be carefully, in order to have a good reliability. Many OBDHs have
been made to support the satellite mission using primitive programming. In
handling the data from various input, OBDH should always be available to all
sub systems, when the tasks are many, it is not easy to program using primitive
programming. Sometimes the data become corrupt because the data which come to
the OBDH is in the same time. Therefore it is required to have a way to handle
the data safely and also easy in programming perspective. In this research,
OBDH is programmed using multi tasking programming perspective has been
created. The Operating System (OS) has been implemented so that can run the
tasks simultaneously. The OS is prepared by configuring the Linux Kernel for
the specific processor, creating Root File System (RFS), installing the
BusyBox. In order to do the above method, preparing the environment in our
machine has been done, they are installing the Cross Tool Chain, U-Boot,
GNU-Linux Kernel Source etc. After that, programming using c code with
multitasking programming can be implemented. By using above method, it is found
that programming is easier and the corruption data because of reentrancy can be
minimized. Keywords- Operating System, PC-104, Kernel, C Programming"
"CPU scheduling is one of the most crucial operations performed by operating
systems. Different conventional algorithms like FCFS, SJF, Priority, and RR
(Round Robin) are available for CPU Scheduling. The effectiveness of Priority
and Round Robin scheduling algorithm completely depends on selection of
priority features of processes and on the choice of time quantum. In this paper
a new CPU scheduling algorithm has been proposed, named as CSPDABRR
(Characteristic specific Prioritized Dynamic Average Burst Round Robin), that
uses seven priority features for calculating priority of processes and uses
dynamic time quantum instead of static time quantum used in RR. The performance
of the proposed algorithm is experimentally compared with traditional RR and
Priority scheduling algorithm in both uni-processor and multi-processor
environment. The results of our approach presented in this paper demonstrate
improved performance in terms of average waiting time, average turnaround time,
and optimal priority feature."
"This paper proposes to use a frequency based cache admission policy in order
to boost the effectiveness of caches subject to skewed access distributions.
Given a newly accessed item and an eviction candidate from the cache, our
scheme decides, based on the recent access history, whether it is worth
admitting the new item into the cache at the expense of the eviction candidate.
  Realizing this concept is enabled through a novel approximate LFU structure
called TinyLFU, which maintains an approximate representation of the access
frequency of a large sample of recently accessed items. TinyLFU is very compact
and light-weight as it builds upon Bloom filter theory.
  We study the properties of TinyLFU through simulations of both synthetic
workloads as well as multiple real traces from several sources. These
simulations demonstrate the performance boost obtained by enhancing various
replacement policies with the TinyLFU eviction policy. Also, a new combined
replacement and eviction policy scheme nicknamed W-TinyLFU is presented.
W-TinyLFU is demonstrated to obtain equal or better hit-ratios than other state
of the art replacement policies on these traces. It is the only scheme to
obtain such good results on all traces."
"Real-time systems are traditionally classified into hard real-time and soft
real-time: in the first category we have safety critical real-time systems
where missing a deadline can have catastrophic consequences, whereas in the
second class we find systems or which we need to optimise the Quality of
service provided to the user. However, the frontier between these two classes
is thinner than one may think, and many systems that were considered as hard
real-time in the past should now be reconsidered under a different light. In
this paper we shall first recall the fundamental notion of time-predictability
and criticality, in order to understand where the real-time deadlines that we
use in our theoretical models come from. We shall then introduce the model of a
soft real-time system and present one popular method for scheduling hard and
soft real-time tasks, the resource reservation framework. Finally, we shall
show how resource reservation techniques can be successfully applied to the
design of classical control systems, thus adding robustness to the system and
increasing resource utilisation and performance."
"When integrating hard, soft and non-real-time tasks in general purpose
operating systems, it is necessary to provide temporal isolation so that the
timing properties of one task do not depend on the behaviour of the others.
However, strict budget enforcement can lead to inefficient use of the
computational resources in the presence of tasks with variable workload. Many
resource reclaiming algorithms have been proposed in the literature for single
processor scheduling, but not enough work exists for global scheduling in
multiprocessor systems. In this report, we propose two reclaiming algorithms
for multiprocessor global scheduling and we prove their correctness."
"Large number of cores and hardware resource sharing are two characteristics
on multicore processors, which bring new challenges for the design of operating
systems. How to locate and analyze the speedup restrictive factors in operating
systems, how to simulate and avoid the phenomenon that speedup decreases with
the number of cores because of lock contention (i.e., lock thrashing) and how
to avoid the contention of shared resources such as the last level cache are
key challenges for the operating system scalability research on multicore
systems."
"Multi-core processors are becoming more and more popular in embedded and
real-time systems. While fixed-priority scheduling with task-splitting in
real-time systems are widely applied, current approaches have not taken into
consideration energy-aware aspects such as dynamic voltage/frequency scheduling
(DVS). In this paper, we propose two strategies to apply dynamic voltage
scaling (DVS) to fixed-priority scheduling algorithms with task-splitting for
periodic real-time tasks on multi-core processors. The first strategy
determines voltage scales for each processor after scheduling (Static DVS),
which ensures all tasks meet the timing requirements on synchronization. The
second strategy adaptively determines the frequency of each task before
scheduling (Adaptive DVS) according to the total utilization of task-set and
number of cores available. The combination of frequency pre-allocation and
task-splitting makes it possible to maximize energy savings with DVS.
Simulation results show that it is possible to achieve significant energy
savings with DVS while preserving the schedulability requirements of real-time
schedulers for multi-core processors."
"This paper addresses the problem of scheduling tasks with different
criticality levels in the presence of I/O requests. In mixed-criticality
scheduling, higher criticality tasks are given precedence over those of lower
criticality when it is impossible to guarantee the schedulability of all tasks.
While mixed-criticality scheduling has gained attention in recent years, most
approaches typically assume a periodic task model. This assumption does not
always hold in practice, especially for real-time and embedded systems that
perform I/O. For example, many tasks block on I/O requests until devices signal
their completion via interrupts; both the arrival of interrupts and the waking
of blocked tasks can be aperiodic. In our prior work, we developed a scheduling
technique in the Quest real-time operating system, which integrates the
time-budgeted management of I/O operations with Sporadic Server scheduling of
tasks. This paper extends our previous scheduling approach with support for
mixed-criticality tasks and I/O requests on the same processing core. Results
show the effective schedulability of different task sets in the presence of I/O
requests is superior in our approach compared to traditional methods that
manage I/O using techniques such as Sporadic Servers."
"Modern operating system kernels are written in lower-level languages such as
C. Although the low-level functionalities of C are often useful within kernels,
they also give rise to several classes of bugs. Kernels written in higher level
languages avoid many of these potential problems, at the possible cost of
decreased performance. This research evaluates the advantages and disadvantages
of a kernel written in a higher level language. To do this, the network stack
subsystem of the kernel was implemented in Go with the Communicating Sequential
Processes (CSP) style. Go is a high-level programming language that supports
the CSP style, which recommends splitting large tasks into several smaller ones
running in independent ""threads"". Modules for the major networking protocols,
including Ethernet, ARP, IPv4, ICMP, UDP, and TCP, were implemented. In this
study, the implemented Go network stack, called GoNet, was compared to a
representative network stack written in C. The GoNet code is more readable and
generally performs better than that of its C stack counterparts. From this, it
can be concluded that Go with CSP style is a viable alternative to C for the
language of kernel implementations."
"Modern datacenter (DC) workloads are characterized by increasing diversity
and differentiated QoS requirements in terms of the average or worst-case
performance. The shift towards DC calls for the new OS architectures that not
only gracefully achieve disparate performance goals, but also protect software
investments. This paper presents the ""isolate first, then share"" OS
architecture. We decompose the OS into the supervisor and several subOSes
running side by side: a subOS directly manages physical resources without
intervention from the supervisor (isolate resources first), while the
supervisor can create, destroy, resize a subOS on-the-fly (then share). We
confine state sharing among the supervisor and SubOSes (isolate states first),
and provide fast inter-subOS communication mechanisms on demand (then share).
We present the first implementation--RainForest, which supports unmodified
Linux binaries. Our comprehensive evaluations show RainForest outperforms Linux
with three different kernels, LXC, and Xen in terms of improving resource
utilization, throughput, scalability, and worst-case performance. The
RainForest source code is soon available."
"Smartphones' cameras, microphones, and device displays enable users to
capture and view memorable moments of their lives. However, adversaries can
trick users into authorizing malicious apps that exploit weaknesses in current
mobile platforms to misuse such on-board I/O devices to stealthily capture
photos, videos, and screen content without the users' consent. Contemporary
mobile operating systems fail to prevent such misuse of I/O devices by
authorized apps due to lack of binding between users' interactions and accesses
to I/O devices performed by these apps. In this paper, we propose Aware, a
security framework for authorizing app requests to perform operations using I/O
devices, which binds app requests with user intentions to make all uses of
certain I/O devices explicit. We evaluate our defense mechanisms through
laboratory-based experimentation and a user study, involving 74 human subjects,
whose ability to identify undesired operations targeting I/O devices increased
significantly. Without Aware, only 18% of the participants were able to
identify attacks from tested RAT apps. Aware systematically blocks all the
attacks in absence of user consent and supports users in identifying 82% of
social-engineering attacks tested to hijack approved requests, including some
more sophisticated forms of social engineering not yet present in available
RATs. Aware introduces only 4.79% maximum performance overhead over operations
targeting I/O devices. Aware shows that a combination of system defenses and
user interface can significantly strengthen defenses for controlling the use of
on-board I/O devices."
"CPU scheduling is one of the most crucial operations performed by operating
system. Different algorithms are available for CPU scheduling amongst them RR
(Round Robin) is considered as optimal in time shared environment. The
effectiveness of Round Robin completely depends on the choice of time quantum.
In this paper a new CPU scheduling algorithm has been proposed, named as DABRR
(Dynamic Average Burst Round Robin). That uses dynamic time quantum instead of
static time quantum used in RR. The performance of the proposed algorithm is
experimentally compared with traditional RR and some existing variants of RR.
The results of our approach presented in this paper demonstrate improved
performance in terms of average waiting time, average turnaround time, and
context switching."
"Virtualization is generally adopted in server and desktop environments to
provide for fault tolerance, resource management, and energy efficiency.
Virtualization enables parallel execution of multiple operating systems (OSs)
while sharing the hardware resources. Virtualization was previously not deemed
as feasible technology for mobile and embedded devices due to their limited
processing and memory resource. However, the enterprises are advocating Bring
Your Own Device (BYOD) applications that enable co-existence of heterogeneous
OSs on a single mobile device. Moreover, embedded device require virtualization
for logical isolation of secure and general purpose OSs on a single device. In
this paper, we investigate the processor architectures in the mobile and
embedded space while examining their formal visualizability. We also compare
the virtualization solutions enabling coexistence of multiple OSs in Multicore
Processor System-on-Chip (MPSoC) mobile and embedded systems. We advocate that
virtualization is necessary to manage resource in MPSoC designs and to enable
BYOD, security, and logical isolation use cases."
"This book describes the source code of the NetBSD Operating System Release
1.6 in SUN UltraSPARC 64-bit platform by annotating related excerpts from
references and user manuals on the NetBSD Operating System. The goal of this
book is to provide necessary information to understand the operation and the
implementation of I/O subsystems in the kernel as well as to design and
implement a new filesystem on the NetBSD platform."
"Mixed-criticality systems combine real-time components of different levels of
criticality, i.e. severity of failure, on the same processor, in order to
obtain good resource utilisation. They must guarantee deadlines of
highly-critical tasks at the expense of lower-criticality ones in the case of
overload. Present operating systems provide inadequate support for this kind of
system, which is of growing importance in avionics and other verticals. We
present an approach that provides the required asymmetric integrity and its
implementation in the high-assurance seL4 microkernel."
"Modern mobile systems use a single input-to-display path to serve all
applications. In meeting the visual goals of all applications, the path has a
latency inadequate for many important interactions. To accommodate the
different latency requirements and visual constraints by different
interactions, we present POLYPATH, a system design in which application
developers (and users) can choose from multiple path designs for their
application at any time. Because a POLYPATH system asks for two or more path
designs, we present a novel fast path design, called Presto. Presto reduces
latency by judiciously allowing frame drops and tearing.
  We report an Android 5-based prototype of POLYPATH with two path designs:
Android legacy and Presto. Using this prototype, we quantify the effectiveness,
overhead, and user experience of POLYPATH, especially Presto, through both
objective measurements and subjective user assessment. We show that Presto
reduces the latency of legacy touchscreen drawing applications by almost half;
and more importantly, this reduction is orthogonal to that of other popular
approaches and is achieved without any user-noticeable negative visual effect.
When combined with touch prediction, Presto is able to reduce the touch latency
below 10 ms, a remarkable achievement without any hardware support."
"OS-level virtualization techniques virtualize system resources at the system
call interface, has the distinct advantage of smaller run-time resource
requirements as compared to HAL-level virtualization techniques, and thus forms
an important building block for virtualizing parallel and distributed
applications such as a HPC clusters. Because the Windows operating system puts
certain critical functionalities in privileged user-level system service
processes, a complete OS-level virtualization solution for the Windows platform
requires duplication of such Windows service as Remote Procedure Call Server
Service (RPCSS). As many implementation details of the Windows system services
are proprietary, duplicating Windows system services becomes the key technical
challenge for virtualizing the Windows platform at the OS level. Moreover, as a
core component of cloud computing, IIS web server-related services need to be
duplicated in containers (i.e., OS-level virtual machines), but so far there is
no such scheme. In this paper, we thoroughly identify all issues that affect
service duplication, and then propose the first known methodology to
systematically duplicate both system and ordinary Windows services. Our
experiments show that the methodology can duplicate a set of system and
ordinary services on different versions of Windows OS."
"OS compromise is one of the most serious computer security problems today,
but still not being resolved. Although people proposed different kinds of
methods, they could not be accepted by most users who are non-expert due to the
lack of compatibility and usability. In this paper, we introduce a kind of new
mandatory access control model, named CUMAC, that aims to achieve good-enough
security, high compatibility and usability. It has two novel features. One is
access control based on tracing potential intrusion that can reduce false
negatives and facilitate security configuration, in order to improve both
compatibility and usability; the other is automatically figuring out all of the
compatibility exceptions that usually incurs incompatible problems. The
experiments performed on the prototype show that CUMAC can defense attacks from
network, mobile disk and local untrustable users while keeping good
compatibility and usability."
"As OS-level virtualization technology usually imposes little overhead on
virtual machine start-up and running, it provides an excellent choice for
building intrusion/fault tolerant applications that require redundancy and
frequent invocation. When developing Windows OS-level virtual machine, however,
people will inevitably face the challenge of confining Windows Inter-Process
Communications (IPC). As IPC on Windows platform is more complex than UNIX
style OS and most of the programs on Windows are not open-source, it is
difficult to discover all of the performed IPCs and confine them. In this
paper, we propose three general principles to confine IPC on Windows OS and a
novel IPC confinement mechanism based on the principles. With the mechanism,
for the first time from the literature, we successfully virtualized RPC System
Service (RPCSS) and Internet Information Server (IIS) on Feather-weight Virtual
Machine (FVM). Experimental results demonstrate that multiple IIS web server
instances can simultaneously run on single Windows OS with much less
performance overhead than other popular VM technology, offering a good basis
for constructing dependable system."
"OS-level virtualization incurs smaller start-up and run-time overhead than
HAL-based virtualization and thus forms an important building block for
developing fault-tolerant and intrusion-tolerant applications. A complete
implementation of OS-level virtualization on the Windows platform requires
virtualization of Windows services, such as system services like the Remote
Procedure Call Server Service (RPCSS), because they are essentially extensions
of the kernel. As Windows system services work very differently from their
counterparts on UNIX-style OS, i.e., daemons, and many of their implementation
details are proprietary, virtualizing Windows system services turned out to be
the most challenging technical barrier for OS-level virtualization for the
Windows platform. In this paper, we describe a general technique to virtualize
Windows services, and demonstrate its effectiveness by applying it to
successfully virtualize a set of important Windows system services and ordinary
services on different versions of Windows OS, including RPCSS, DcomLaunch, IIS
service group, Tlntsvr, MySQL, Apache2.2, CiSvc, ImapiService, etc."
"In this paper, the implementation of an operating system oriented RBAC model
is discussed. Firstly, on the basis of RBAC96 model, a new RBAC model named OSR
is presented. Secondly, the OSR model is enforced in RFSOS kernel by the way of
integrating GFAC method and Capability mechanism together. All parts of the OSR
implementation are described in detail."
"The trade-off between coarse- and fine-grained locking is a well understood
issue in operating systems. Coarse-grained locking provides lower overhead
under low contention, fine-grained locking provides higher scalability under
contention, though at the expense of implementation complexity and re- duced
best-case performance.
  We revisit this trade-off in the context of microkernels and tightly-coupled
cores with shared caches and low inter-core migration latencies. We evaluate
performance on two architectures: x86 and ARM MPCore, in the former case also
utilising transactional memory (Intel TSX). Our thesis is that on such
hardware, a well-designed microkernel, with short system calls, can take
advantage of coarse-grained locking on modern hardware, avoid the run-time and
complexity cost of multiple locks, enable formal verification, and still
achieve scalability comparable to fine-grained locking."
"Web application performance is heavily reliant on the hit rate of
memory-based caches. Current DRAM-based web caches statically partition their
memory across multiple applications sharing the cache. This causes under
utilization of memory which negatively impacts cache hit rates. We present
Memshare, a novel web memory cache that dynamically manages memory across
applications. Memshare provides a resource sharing model that guarantees
private memory to different applications while dynamically allocating the
remaining shared memory to optimize overall hit rate. Today's high cost of DRAM
storage and the availability of high performance CPU and memory bandwidth, make
web caches memory capacity bound. Memshare's log-structured design allows it to
provide significantly higher hit rates and dynamically partition memory among
applications at the expense of increased CPU and memory bandwidth consumption.
In addition, Memshare allows applications to use their own eviction policy for
their objects, independent of other applications. We implemented Memshare and
ran it on a week-long trace from a commercial memcached provider. We
demonstrate that Memshare increases the combined hit rate of the applications
in the trace by an 6.1% (from 84.7% hit rate to 90.8% hit rate) and reduces the
total number of misses by 39.7% without affecting system throughput or latency.
Even for single-tenant applications, Memshare increases the average hit rate of
the current state-of-the-art memory cache by an additional 2.7% on our
real-world trace."
"We introduce a user mode file system, CannyFS, that hides latency by assuming
all I/O operations will succeed. The user mode process will in turn report
errors, allowing proper cleanup and a repeated attempt to take place. We
demonstrate benefits for the model tasks of extracting archives and removing
directory trees in a real-life HPC environment, giving typical reductions in
time use of over 80%.
  This approach can be considered a view of HPC jobs and their I/O activity as
transactions. In general, file systems lack clearly defined transaction
semantics. Over time, the competing trends to add cache and maintain data
integrity have resulted in different practical tradeoffs.
  High-performance computing is a special case where overall throughput demands
are high. Latency can also be high, with non-local storage. In addition, a
theoretically possible I/O error (like permission denied, loss of connection,
exceeding disk quota) will frequently warrant the resubmission of a full job or
task, rather than traditional error reporting or handling. Therefore,
opportunistically treating each I/O operation as successful, and part of a
larger transaction, can speed up some applications that do not leverage
asynchronous I/O."
"As its price per bit drops, SSD is increasingly becoming the default storage
medium for cloud application databases. However, it has not become the
preferred storage medium for key-value caches, even though SSD offers more than
10x lower price per bit and sufficient performance compared to DRAM. This is
because key-value caches need to frequently insert, update and evict small
objects. This causes excessive writes and erasures on flash storage, since
flash only supports writes and erasures of large chunks of data. These
excessive writes and erasures significantly shorten the lifetime of flash,
rendering it impractical to use for key-value caches. We present Flashield, a
hybrid key-value cache that uses DRAM as a ""filter"" to minimize writes to SSD.
Flashield performs light-weight machine learning profiling to predict which
objects are likely to be read frequently before getting updated; these objects,
which are prime candidates to be stored on SSD, are written to SSD in large
chunks sequentially. In order to efficiently utilize the cache's available
memory, we design a novel in-memory index for the variable-sized objects stored
on flash that requires only 4 bytes per object in DRAM. We describe Flashield's
design and implementation and, we evaluate it on a real-world cache trace.
Compared to state-of-the-art systems that suffer a write amplification of 2.5x
or more, Flashield maintains a median write amplification of 0.5x without any
loss of hit rate or throughput."
"Existing memory management mechanisms used in commodity computing machines
typically adopt hardware based address interleaving and OS directed random
memory allocation to service generic application requests. These conventional
memory management mechanisms are challenged by contention at multiple memory
levels, a daunting variety of workload behaviors, and an increasingly
complicated memory hierarchy. Our ISCA-41 paper proposes vertical partitioning
to eliminate shared resource contention at multiple levels in the memory
hierarchy. Combined with horizontal memory management policies, our framework
supports a flexible policy space for tackling diverse application needs in
production environment and is suitable for future heterogeneous memory systems."
"The design of mixed-criticality systems often involvespainful tradeoffs
between safety guarantees and performance.However, the use of more detailed
architectural modelsin the design and analysis of scheduling arrangements for
mixedcriticalitysystems can provide greater confidence in the analysis,but also
opportunities for better performance. Motivated by thisview, we propose an
extension of Vestal 19s model for mixedcriticalitymulticore systems that (i)
accounts for the per-taskpartitioning of the last-level cache and (ii) supports
the dynamicreassignment, for better schedulability, of cache portions
initiallyreserved for lower-criticality tasks to the higher-criticalitytasks,
when the system switches to high-criticality mode. Tothis model, we apply
partitioned EDF scheduling with Ekbergand Yi 19s deadline-scaling technique.
Our schedulability analysisand scalefactor calculation is cognisant of the
cache resourcesassigned to each task, by using WCET estimates that take
intoaccount these resources. It is hence able to leverage the
dynamicreconfiguration of the cache partitioning, at mode change, forbetter
performance, in terms of provable schedulability. We alsopropose heuristics for
partitioning the cache in low- and highcriticalitymode, that promote
schedulability. Our experimentswith synthetic task sets, indicate tangible
improvements inschedulability compared to a baseline cache-aware
arrangementwhere there is no redistribution of cache resources from low-
tohigh-criticality tasks in the event of a mode change."
"Imagining a disk which provides baseline performance at a relatively low
price during low-load periods, but when workloads demand more resources, the
disk performance is automatically promoted in situ and in real time. In a
hardware era, this is hardly achievable. However, this imagined disk is
becoming reality due to the technical advances of software-defined storage,
which enable volume performance to be adjusted on the fly. We propose IOTune, a
resource management middleware which employs software-defined storage
primitives to implement G-states of virtual block devices. G-states enable
virtual block devices to serve at multiple performance gears, getting rid of
conflicts between immutable resource reservation and dynamic resource demands,
and always achieving resource right-provisioning for workloads. Accompanying
G-states, we also propose a new block storage pricing policy for cloud
providers. Our case study for applying G-states to cloud block storage verifies
the effectiveness of the IOTune framework. Trace-replay based evaluations
demonstrate that storage volumes with G-states adapt to workload fluctuations.
For tenants, G-states enable volumes to provide much better QoS with a same
cost of ownership, comparing with static IOPS provisioning and the I/O credit
mechanism. G-states also reduce I/O tail latencies by one to two orders of
magnitude. From the standpoint of cloud providers, G-states promote storage
utilization, creating values and benefiting competitiveness. G-states supported
by IOTune provide a new paradigm for storage resource management and pricing in
multi-tenant clouds."
"This short report raises a correctness issue in the schedulability test
presented in Kato et al., ""Gang EDF Scheduling of Parallel Task Systems"", 30th
IEEE Real-Time Systems Symposium, 2009, pp. 459-468."
"Multi-core CPUs are a standard component in many modern embedded systems.
Their virtualisation extensions enable the isolation of services, and gain
popularity to implement mixed-criticality or otherwise split systems. We
present Jailhouse, a Linux-based, OS-agnostic partitioning hypervisor that uses
novel architectural approaches to combine Linux, a powerful general-purpose
system, with strictly isolated special-purpose components. Our design goals
favour simplicity over features, establish a minimal code base, and minimise
hypervisor activity.
  Direct assignment of hardware to guests, together with a deferred
initialisation scheme, offloads any complex hardware handling and bootstrapping
issues from the hypervisor to the general purpose OS. The hypervisor
establishes isolated domains that directly access physical resources without
the need for emulation or paravirtualisation. This retains, with negligible
system overhead, Linux's feature-richness in uncritical parts, while frugal
safety and real-time critical workloads execute in isolated, safe domains."
"GPUs are becoming first-class compute citizens and are being tasked to
perform increasingly complex work. Modern GPUs increasingly support
programmability- enhancing features such as shared virtual memory and hardware
cache coherence, enabling them to run a wider variety of programs. But a key
aspect of general-purpose programming where GPUs are still found lacking is the
ability to invoke system calls. We explore how to directly invoke generic
system calls in GPU programs. We examine how system calls should be meshed with
prevailing GPGPU programming models where thousands of threads are organized in
a hierarchy of execution groups: Should a system call be invoked at the
individual GPU task, or at different execution group levels? What are
reasonable ordering semantics for GPU system calls across these hierarchy of
execution groups? To study these questions, we implemented GENESYS -- a
mechanism to allow GPU pro- grams to invoke system calls in the Linux operating
system. Numerous subtle changes to Linux were necessary, as the existing kernel
assumes that only CPUs invoke system calls. We analyze the performance of
GENESYS using micro-benchmarks and three applications that exercise the
filesystem, networking, and memory allocation subsystems of the kernel. We
conclude by analyzing the suitability of all of Linux's system calls for the
GPU."
"Shingled magnetic recording (SMR) increases the capacity of magnetic hard
drives, but it requires that each zone of a disk be written sequentially and
erased in bulk. This makes SMR a good fit for workloads dominated by large data
objects with limited churn. To explore this possibility, we have developed
SMORE, an object storage system designed to reliably and efficiently store
large, seldom-changing data objects on an array of host-managed or host-aware
SMR disks.
  SMORE uses a log-structured approach to accommodate the constraint that all
writes to an SMR drive must be sequential within large shingled zones. It
stripes data across zones on separate disks, using erasure coding to protect
against drive failure. A separate garbage collection thread reclaims space by
migrating live data out of the emptiest zones so that they can be trimmed and
reused. An index stored on flash and backed up to the SMR drives maps object
identifiers to on-disk locations. SMORE interleaves log records with object
data within SMR zones to enable index recovery after a system crash (or failure
of the flash device) without any additional logging mechanism.
  SMORE achieves full disk bandwidth when ingesting data---with a variety of
object sizes---and when reading large objects. Read performance declines for
smaller object sizes where inter- object seek time dominates. With a worst-case
pattern of random deletions, SMORE has a write amplification (not counting RAID
parity) of less than 2.0 at 80% occupancy. By taking an index snapshot every
two hours, SMORE recovers from crashes in less than a minute. More frequent
snapshots allow faster recovery."
"In the near future the SCM is predicted to modify the form of new programs,
the access form to storage, and the way that storage devices themselves are
built. Therefore, a combination between the SCM and a designated Memory
Allocation Manager (MAM) that will allow the programmer to manually control the
different memories in the memory hierarchy will be likely to achieve a new
level of performance for memory-aware data structures. Although the manual MAM
seems to be the optimal approach for multi-level memory hierarchy management,
this technique is still very far from being realistic, and the chances that it
would be implemented in current codes using High Performance Computing (HPC)
platforms is quite low. This premise means that the most reasonable way to
introduce the SCM into any usable and popular memory system would be by
implementing an automated version of the MAM using the fundamentals of paging
algorithms, as used for two-level memory hierarchy. Our hypothesis is that
achieving appropriate transferability between memory levels may be possible
using ideas of algorithms employed in current virtual memory systems, and that
the adaptation of those algorithms from a two-level memory hierarchy to an
N-level memory hierarchy is possible. In order to reach the conclusion that our
hypothesis is correct, we investigated various paging algorithms, and found the
ones that could be adapted successfully from two-level memory hierarchy to an
N-level memory hierarchy. We discovered that using an adaptation of the Aging
paging algorithm to an N-level memory hierarchy results in the best
performances in terms of Hit/Miss ratio. In order to verify our hypothesis we
build a simulator called ""DeMemory simulator"" for analyzing our algorithms as
well as for other algorithms that will be devised in the future."
"Disaggregating resources in data centers is an emerging trend. Recent work
has begun to explore memory disaggregation, but suffers limitations including
lack of consideration of the complexity of cloud-based deployment, including
heterogeneous hardware and APIs for cloud users and operators. In this paper,
we present FluidMem, a complete system to realize disaggregated memory in the
datacenter. Going beyond simply demonstrating remote memory is possible, we
create an entire Memory as a Service. We define the requirements of Memory as a
Service and build its implementation in Linux as FluidMem. We present a
performance analysis of FluidMem and demonstrate that it transparently supports
remote memory for standard applications such as MongoDB and genome sequencing
applications."
"We present the first systematic analysis of read, write, and space
amplification in Linux file systems. While many researchers are tackling write
amplification in key-value stores, IO amplification in file systems has been
largely unexplored. We analyze data and metadata operations on five widely-used
Linux file systems: ext2, ext4, XFS, btrfs, and F2FS. We find that data
operations result in significant write amplification (2-32X) and that metadata
operations have a large IO cost. For example, a single rename requires 648 KB
write IO in btrfs. We also find that small random reads result in read
amplification of 2-13X. Based on these observations, we present the CReWS
conjecture about the relationship between IO amplification, consistency, and
storage space utilization. We hope this paper spurs people to design future
file systems with less IO amplification, especially for non-volatile memory
technologies."
"Microsoft Cluster Service (MSCS) extends the Win-dows NT operating system to
support high-availability services. The goal is to offer an execution
environment where off-the-shelf server applications can continue to operate,
even in the presence of node failures. Later ver-sions of MSCS will provide
scalability via a node and application management system that allows
applications to scale to hundreds of nodes. This paper provides a de-tailed
description of the MSCS architecture and the de-sign decisions that have driven
the implementation of the service. The paper also describes how some major
appli-cations use the MSCS features, and describes features added to make it
easier to implement and manage fault-tolerant applications on MSCS."
"A working implementation of nested transactions has been produced for LOCUS,
an integrated distributed operating system which provides a high degree of
network transparency. Several aspects of our mechanism are novel. First, the
mechanism allows a transaction to access objects directly without regard to the
location of the object. Second, processes running on behalf of a single
transaction may be located at many sites. Thus there is no need to invoke a new
transaction to perform processing or access objects at a remote site. Third,
unlike other environments, LOCUS allows replication of data objects at more
than one site in the network, and this capability is incorporated into the
transaction mechanism. If the copy of an object that is currently being
accessed becomes unavailable, it is possible to continue work by using another
one of the replicated copies. Finally, an efficient orphan removal algorithm is
presented, and the problem of providing continued operation during network
partitions is addressed in detail."
"We present an open architecture for just-in-time code generation and dynamic
code optimization that is flexible, customizable, and extensible. While
previous research has primarily investigated functional aspects of such a
system, architectural aspects have so far remained unexplored. In this paper,
we argue that these properties are important to generate optimal code for a
variety of hardware architectures and different processor generations within
processor families. These properties are also important to make system-level
code generation useful in practice."
"The goal of the present HTTPFS project is to enable access to remote files,
directories, and other containers through an HTTP pipe. HTTPFS system permits
retrieval, creation and modification of these resources as if they were regular
files and directories on a local filesystem. The remote host can be any UNIX or
Win9x/WinNT box that is capable of running a Perl CGI script and accessible
either directly or via a web proxy or a gateway. HTTPFS runs entirely in user
space.
  The current implementation fully supports reading as well as creating,
writing, appending, and truncating of files on a remote HTTP host. HTTPFS
provides an isolation level for concurrent file access stronger than the one
mandated by POSIX file system semantics, closer to that of AFS. Both an API
with familiar open(), read(), write(), close(), etc. calls, and an interactive
interface, via the popular Midnight Commander file browser, are provided."
"We discuss general models of resource-sharing computations, with emphasis on
the combinatorial structures and concepts that underlie the various deadlock
models that have been proposed, the design of algorithms and deadlock-handling
policies, and concurrency issues. These structures are mostly graph-theoretic
in nature, or partially ordered sets for the establishment of priorities among
processes and acquisition orders on resources. We also discuss graph-coloring
concepts as they relate to resource sharing."
"Many dependability techniques expect certain behaviors from the underlying
subsystems and fail in chaotic ways if these expectations are not met. Under
expected circumstances, however, software tends to work quite well. This paper
suggests that, instead of fixing elusive bugs or rewriting software, we improve
the predictability of conditions faced by our programs. This approach might be
a cheaper and faster way to improve dependability of software. After
identifying some of the common triggers of unpredictability, the paper
describes three engineering principles that hold promise in combating
unpredictability, suggests a way to benchmark predictability, and outlines a
brief research agenda."
"A significant fraction of software failures in large-scale Internet systems
are cured by rebooting, even when the exact failure causes are unknown.
However, rebooting can be expensive, causing nontrivial service disruption or
downtime even when clusters and failover are employed. In this work we separate
process recovery from data recovery to enable microrebooting -- a fine-grain
technique for surgically recovering faulty application components, without
disturbing the rest of the application.
  We evaluate microrebooting in an Internet auction system running on an
application server. Microreboots recover most of the same failures as full
reboots, but do so an order of magnitude faster and result in an order of
magnitude savings in lost work. This cheap form of recovery engenders a new
approach to high availability: microreboots can be employed at the slightest
hint of failure, prior to node failover in multi-node clusters, even when
mistakes in failure detection are likely; failure and recovery can be masked
from end users through transparent call-level retries; and systems can be
rejuvenated by parts, without ever being shut down."
"Protecting data from malicious computer users continues to grow in
importance. Whether preventing unauthorized access to personal photographs,
ensuring compliance with federal regulations, or ensuring the integrity of
corporate secrets, all applications require increased security to protect data
from talented intruders. Specifically, as more and more files are preserved on
disk the requirement to provide secure storage has increased in importance.
This paper presents a survey of techniques for securely storing data, including
theoretical approaches, prototype systems, and existing systems currently
available. Due to the wide variety of potential solutions available and the
variety of techniques to arrive at a particular solution, it is important to
review the entire field prior to selecting an implementation that satisfies
particular requirements. This paper provides an overview of the prominent
characteristics of several systems to provide a foundation for making an
informed decision. Initially, the paper establishes a set of criteria for
evaluating a storage solution based on confidentiality, integrity,
availability, and performance. Then, using these criteria, the paper explains
the relevant characteristics of select storage systems and provides a
comparison of the major differences."
"A method to boot a cluster of diskless network clients from a single
write-protected NFS root file system is shown. The problems encountered when
first implementing the setup and their solution are discussed. Finally, the
setup is briefly compared to using a kernel-embedded root file system."
"In this paper, we present a system called Checkbochs, a machine simulator
that checks rules about its guest operating system and applications at the
hardware level. The properties to be checked can be implemented as `plugins' in
the Checkbochs simulator. Some of the properties that were checked using
Checkbochs include null-pointer checks, format-string vulnerabilities,
user/kernel pointer checks, and race-conditions. On implementing these checks,
we were able to uncover previously-unknown bugs in widely used Linux
distributions. We also tested our tools on undergraduate coursework, and found
numerous bugs."
"In this paper we show that the initial philosophy used in designing and
developing UNIX in early times has been forgotten due to ""fast practices"". We
question the leitmotif that microkernels, though being by design adherent to
the KISS principle, have a number of context switches higher than their
monolithic counterparts, running a test suite and verify the results with
standard statistical validation tests. We advocate a wiser distribution of
shared libraries by statistically analyzing the weight of each shared object in
a typical UNIX system, showing that the majority of shared libraries exist in a
common space for no real evidence of need. Finally we examine the UNIX heritage
with an historical point of view, noticing how habits swiftly replaced the
intents of the original authors, moving the focus from the earliest purpose of
is avoiding complications, keeping a system simple to use and maintain."
"Virtualization became recently a hot topic once again, after being dormant
for more than twenty years. In the meantime, it has been almost forgotten, that
virtual machines are not so perfect isolating environments as it seems, when
looking at the principles. These lessons were already learnt earlier when the
first virtualized systems have been exposed to real life usage.
  Contemporary virtualization software enables instant creation and destruction
of virtual machines on a host, live migration from one host to another,
execution history manipulation, etc. These features are very useful in
practice, but also causing headaches among security specialists, especially in
current hostile network environments.
  In the present contribution we discuss the principles, potential benefits and
risks of virtualization in a deja vu perspective, related to previous
experiences with virtualization in the mainframe era."
"In most modern operating systems, init (as in ""initialization"") is the
program launched by the kernel at boot time. It runs as a daemon and typically
has PID 1. Init is responsible for spawning all other processes and scavenging
zombies. It is also responsible for reboot and shutdown operations. This
document describes existing solutions that implement the init process and/or
init scripts in Unix-like systems. These solutions range from the legacy and
still-in-use BSD and SystemV schemes, to recent and promising schemes from
Ubuntu, Apple, Sun and independent developers. Our goal is to highlight their
focus and compare their sets of features."
"The development of many highly dynamic environments, like pervasive
environments, introduces the possibility to use geographically close-related
services. Dynamically integrating and unintegrating these services in running
applications is a key challenge for this use. In this article, we classify
service integration issues according to interfaces exported by services and
internal combining techniques. We also propose a contextual integration
service, IntegServ, and an interface, Integrable, for developing services."
"In this short paper, we would like to call professional community's attention
to a daring idea that is surely unhelpful, but is exciting for programmers and
anyway conflicts with the trend of energy consumption in computer systems."
"The objective of this article is to provide for the reader a basic
description of all the steps involved in the COM object life-cycle process. COM
is a software technology and process performer. The first section briefly
introduces the Component Object Model (COM), considering the process of the COM
object life cycle as the baseline of all COM issues. The second part describes
in detail the basic steps of the process - client request, server location,
object creation, interaction, and disconnection. A brief description is given
for the components involved in each step. Finally, the third section provides a
brief conclusion summarizing all the process steps."
"In this paper, we show that performance of the virtualized cluster servers
could be improved through intelligent decision over migration time of Virtual
Machines across heterogeneous physical nodes of a cluster server. The cluster
serves a variety range of services from Web Service to File Service. Some of
them are CPU-Intensive while others are RAM-Intensive and so on. Virtualization
has many advantages such as less hardware cost, cooling cost, more
manageability. One of the key benefits is better load balancing by using of VM
migration between hosts. To migrate, we must know which virtual machine needs
to be migrated and when this relocation has to be done and, moreover, which
host must be destined. To relocate VMs from overloaded servers to underloaded
ones, we need to sort nodes from the highest volume to the lowest. There are
some models to finding the most overloaded node, but they have some
shortcomings. The focus of this paper is to present a new method to migrate VMs
between cluster nodes using TOPSIS algorithm - one of the most efficient Multi
Criteria Decision Making techniques- to make more effective decision over whole
active servers of the Cluster and find the most loaded serversTo evaluate the
performance improvement resulted from this model, we used cluster Response time
and Unbalanced Factor."
"Timing side-channels represent an insidious security challenge for cloud
computing, because: (a) massive parallelism in the cloud makes timing channels
pervasive and hard to control; (b) timing channels enable one customer to steal
information from another without leaving a trail or raising alarms; (c) only
the cloud provider can feasibly detect and report such attacks, but the
provider's incentives are not to; and (d) resource partitioning schemes for
timing channel control undermine statistical sharing efficiency, and, with it,
the cloud computing business model. We propose a new approach to timing channel
control, using provider-enforced deterministic execution instead of resource
partitioning to eliminate timing channels within a shared cloud domain.
Provider-enforced determinism prevents execution timing from affecting the
results of a compute task, however large or parallel, ensuring that a task's
outputs leak no timing information apart from explicit timing inputs and total
compute duration. Experiments with a prototype OS for deterministic cloud
computing suggest that such an approach may be practical and efficient. The OS
supports deterministic versions of familiar APIs such as processes, threads,
shared memory, and file systems, and runs coarse-grained parallel tasks as
efficiently and scalably as current timing channel-ridden systems."
"Deterministic execution offers many benefits for debugging, fault tolerance,
and security. Running parallel programs deterministically is usually difficult
and costly, however - especially if we desire system-enforced determinism,
ensuring precise repeatability of arbitrarily buggy or malicious software.
Determinator is a novel operating system that enforces determinism on both
multithreaded and multi-process computations. Determinator's kernel provides
only single-threaded, ""shared-nothing"" address spaces interacting via
deterministic synchronization. An untrusted user-level runtime uses distributed
computing techniques to emulate familiar abstractions such as Unix processes,
file systems, and shared memory multithreading. The system runs parallel
applications deterministically both on multicore PCs and across nodes in a
cluster. Coarse-grained parallel benchmarks perform and scale comparably to -
sometimes better than - conventional systems, though determinism is costly for
fine-grained parallel applications."
"We propose a framework that provides a programming interface to perform
complex dynamic system-level analyses of deployed production systems. By
leveraging hardware support for virtualization available nowadays on all
commodity machines, our framework is completely transparent to the system under
analysis and it guarantees isolation of the analysis tools running on its top.
Thus, the internals of the kernel of the running system needs not to be
modified and the whole platform runs unaware of the framework. Moreover, errors
in the analysis tools do not affect the running system and the framework. This
is accomplished by installing a minimalistic virtual machine monitor and
migrating the system, as it runs, into a virtual machine. In order to
demonstrate the potentials of our framework we developed an interactive kernel
debugger, nicknamed HyperDbg. HyperDbg can be used to debug any critical kernel
component, and even to single step the execution of exception and interrupt
handlers."
"Race condition is a timing sensitive problem. A significant source of timing
variation comes from nondeterministic hardware interactions such as cache
misses. While data race detectors and model checkers can check races, the
enormous state space of complex software makes it difficult to identify all of
the races and those residual implementation errors still remain a big
challenge. In this paper, we propose deterministic real-time scheduling methods
to address scheduling nondeterminism in uniprocessor systems. The main idea is
to use timing insensitive deterministic events, e.g, an instruction counter, in
conjunction with a real-time clock to schedule threads. By introducing the
concept of Worst Case Executable Instructions (WCEI), we guarantee both
determinism and real-time performance."
"Due to its attractive characteristics in terms of performance, weight and
power consumption, NAND flash memory became the main non volatile memory (NVM)
in embedded systems. Those NVMs also present some specific
characteristics/constraints: good but asymmetric I/O performance, limited
lifetime, write/erase granularity asymmetry, etc. Those peculiarities are
either managed in hardware for flash disks (SSDs, SD cards, USB sticks, etc.)
or in software for raw embedded flash chips. When managed in software, flash
algorithms and structures are implemented in a specific flash file system
(FFS). In this paper, we present a performance study of the most widely used
FFSs in embedded Linux: JFFS2, UBIFS,and YAFFS. We show some very particular
behaviors and large performance disparities for tested FFS operations such as
mounting, copying, and searching file trees, compression, etc."
"Cloud Computing has emerged as a successful computing paradigm for
efficiently utilizing managed compute infrastructure such as high speed
rack-mounted servers, connected with high speed networking, and reliable
storage. Usually such infrastructure is dedicated, physically secured and has
reliable power and networking infrastructure. However, much of our idle compute
capacity is present in unmanaged infrastructure like idle desktops, lab
machines, physically distant server machines, and laptops. We present a scheme
to utilize this idle compute capacity on a best-effort basis and provide high
availability even in face of failure of individual components or facilities.
  We run virtual machines on the commodity infrastructure and present a cloud
interface to our end users. The primary challenge is to maintain availability
in the presence of node failures, network failures, and power failures. We run
multiple copies of a Virtual Machine (VM) redundantly on geographically
dispersed physical machines to achieve availability. If one of the running
copies of a VM fails, we seamlessly switchover to another running copy. We use
Virtual Machine Record/Replay capability to implement this redundancy and
switchover. In current progress, we have implemented VM Record/Replay for
uniprocessor machines over Linux/KVM and are currently working on VM
Record/Replay on shared-memory multiprocessor machines. We report initial
experimental results based on our implementation."
"For many years, developers could not figure out the mystery of OS kernels.
The main source of this mystery is the interaction between operating systems
and hardware while system's boot up and kernel initialization. In addition,
many operating system kernels differ in their behavior toward many situations.
For instance, kernels act differently in racing conditions, kernel
initialization and process scheduling. For such operations, kernel debuggers
were designed to help in tracing kernel behavior and solving many kernel bugs.
The importance of kernel debuggers is not limited to kernel code tracing but
also, they can be used in verification and performance comparisons. However,
developers had to be aware of debugger commands thus introducing some
difficulties to non-expert programmers. Later, several visual kernel debuggers
were presented to make it easier for programmers to trace their kernel code and
analyze kernel behavior. Nowadays, several kernel debuggers exist for solving
this mystery but only very few support line-by-line debugging at run-time. In
this paper, a generic approach for operating system source code debugging in
graphical mode with line-by-line tracing support is proposed. In the context of
this approach, system boot up and evaluation of two operating system schedulers
from several points of views will be discussed."
"We develop a practical solution to the problem of automatic verification of
the interface between device drivers and the OS. Our solution relies on a
combination of improved driver architecture and verification tools. It supports
drivers written in C and can be implemented in any existing OS, which sets it
apart from previous proposals for verification-friendly drivers. Our
Linux-based evaluation shows that this methodology amplifies the power of
existing verification tools in detecting driver bugs, making it possible to
verify properties beyond the reach of traditional techniques."
"This paper presents Flashmon version 2, a tool for monitoring embedded Linux
NAND flash memory I/O requests. It is designed for embedded boards based
devices containing raw flash chips. Flashmon is a kernel module and stands for
""flash monitor"". It traces flash I/O by placing kernel probes at the NAND
driver level. It allows tracing at runtime the 3 main flash operations: page
reads / writes and block erasures. Flashmon is (1) generic as it was
successfully tested on the three most widely used flash file systems that are
JFFS2, UBIFS and YAFFS, and several NAND chip models. Moreover, it is (2) non
intrusive, (3) has a controllable memory footprint, and (4) exhibits a low
overhead (<6%) on the traced system. Finally, it is (5) simple to integrate and
used as a standalone module or as a built-in function / module in existing
kernel sources. Monitoring flash memory operations allows a better
understanding of existing flash management systems by studying and analyzing
their behavior. Moreover it is useful in development phase for prototyping and
validating new solutions."
"FIFO queues with a single reader and writer can be insufficient for ""hard
real-time"" systems where interrupt handlers require wait-free guarantees when
writing to message queues. We present an algorithm which elegantly and
practically solves this problem on small processors that are often found in
embedded systems. The algorithm does not require special CPU instructions (such
as atomic CAS), and therefore is more robust than many existing methods that
suffer the ABA problem associated with swing pointers. The algorithm gives
""first-in, almost first-out"" guarantees under pathological interrupt
conditions, which manifests as arbitrary ""shoving"" among nearly-simultaneous
arrivals at the end of the queue."
"The Telex system is designed for sharing mutable data in a distributed
environment, particularly for collaborative applications. Users operate on
their local, persistent replica of shared documents; they can work disconnected
and suffer no network latency. The Telex approach to detect and correct
conflicts is application independent, based on an action-constraint graph (ACG)
that summarises the concurrency semantics of applications. The ACG is stored
efficiently in a multilog structure that eliminates contention and is optimised
for locality. Telex supports multiple applications and multi-document updates.
The Telex system clearly separates system logic (which includes replication,
views, undo, security, consistency, conflicts, and commitment) from application
logic. An example application is a shared calendar for managing multi-user
meetings; the system detects meeting conflicts and resolves them consistently."
"Designing protocols and formulating convenient programming units of
abstraction for sensor networks is challenging due to communication errors and
platform constraints. This paper investigates properties and implementation
reliability for a \emph{local read-write} abstraction. Local read-write is
inspired by the class of read-modify-write operations defined for shared-memory
multiprocessor architectures. The class of read-modify-write operations is
important in solving consensus and related synchronization problems for
concurrency control. Local read-write is shown to be an atomic abstraction for
synchronizing neighborhood states in sensor networks. The paper compares local
read-write to similar lightweight operations in wireless sensor networks, such
as read-all, write-all, and a transaction-based abstraction: for some
optimistic scenarios, local read-write is a more efficient neighborhood
operation. A partial implementation is described, which shows that three
outcomes characterize operation response: success, failure, and cancel. A
failure response indicates possible inconsistency for the operation result,
which is the result of a timeout event at the operation's initiator. The paper
presents experimental results on operation performance with different timeout
values and situations of no contention, with some tests also on various
neighborhood sizes."
"In year 2006 Bio-Linux with the work of Tim Booth and team gives its rising
and provide an operating system that was and still specialized in providing a
bioinformatic specific software environment for the working needs in this
corner of bioscience. It is shown that Bio-Linux is affected by a 2 year
release cycle and with this the final releases of Bio-Linux will not have the
latest bioinformatic software on board. The paper shows how to get around this
huge time gap and bring new software for Bio-Linux on board through a process
that is called backporting. A summary of within the work to this paper just
backported bioinformatic tools is given. A describtion of a workflow for
continuously integration of the newest bioinformatic tools gives an outlook to
further concrete planned developments and the influence of speeding up
scientific progress."
"Several self-stabilizing time division multiple access (TDMA) algorithms are
proposed for sensor networks. In addition to providing a collision-free
communication service, such algorithms enable the transformation of programs
written in abstract models considered in distributed computing literature into
a model consistent with sensor networks, i.e., write all with collision (WAC)
model. Existing TDMA slot assignment algorithms have one or more of the
following properties: (i) compute slots using a randomized algorithm, (ii)
assume that the topology is known upfront, and/or (iii) assign slots
sequentially. If these algorithms are used to transform abstract programs into
programs in WAC model then the transformed programs are probabilistically
correct, do not allow the addition of new nodes, and/or converge in a
sequential fashion. In this paper, we propose a self-stabilizing deterministic
TDMA algorithm where a sensor is aware of only its neighbors. We show that the
slots are assigned to the sensors in a concurrent fashion and starting from
arbitrary initial states, the algorithm converges to states where
collision-free communication among the sensors is restored. Moreover, this
algorithm facilitates the transformation of abstract programs into programs in
WAC model that are deterministically correct."
"A new style of temporal debugging is proposed. The new URDB debugger can
employ such techniques as temporal search for finding an underlying fault that
is causing a bug. This improves on the standard iterative debugging style,
which iteratively re-executes a program under debugger control in the search
for the underlying fault. URDB acts as a meta-debugger, with current support
for four widely used debuggers: gdb, MATLAB, python, and perl. Support for a
new debugger can be added in a few hours. Among its points of novelty are: (i)
the first reversible debuggers for MATLAB, python, and perl; (ii) support for
today's multi-core architectures; (iii) reversible debugging of multi-process
and distributed computations; and (iv) temporal search on changes in program
expressions. URDB gains its reversibility and temporal abilities through the
fast checkpoint-restart capability of DMTCP (Distributed MultiThreaded
CheckPointing). The recently enhanced DMTCP also adds ptrace support, enabling
one to freeze, migrate, and replicate debugging sessions."
"We consider five different peer-to-peer file sharing systems with two chunks,
with the aim of finding chunk selection algorithms that have provably stable
performance with any input rate and assuming non-altruistic peers who leave the
system immediately after downloading the second chunk. We show that many
algorithms that first looked promising lead to unstable or oscillating
behavior. However, we end up with a system with desirable properties. Most of
our rigorous results concern the corresponding deterministic large system
limits, but in two simplest cases we provide proofs for the stochastic systems
also."
"This research addresses the multiprocessor scheduling problem of hard
real-time systems, and it especially focuses on optimal and global schedulers
when practical constraints are taken into account. First, we propose an
improvement of the optimal algorithm BF. We formally prove that our adaptation
is (i) optimal, i.e., it always generates a feasible schedule as long as such a
schedule exists, and (ii) valid, i.e., it complies with the all the
requirements. We also show that it outperforms BF by providing a computing
complexity of O(n), where n is the number of tasks to be scheduled. Next, we
propose a schedulability analysis which indicates a priori whether the
real-time application can be scheduled by our improvement of BF without missing
any deadline. This analysis is, to the best of our knowledge, the first such
test for multiprocessors that takes into account all the main overheads
generated by the Operating System."
"Sensing on smartphones is known to be power-hungry. It has been shown that
this problem can be solved by adding an ultra low-power processor to execute
simple, frequent sensor data processing. While very effective in saving energy,
this resulting heterogeneous, distributed architecture poses a significant
challenge to application development.
  We present Reflex, a suite of runtime and compilation techniques to conceal
the heterogeneous, distributed nature from developers. The Reflex automatically
transforms the developer's code for distributed execution with the help of the
Reflex runtime. To create a unified system illusion, Reflex features a novel
software distributed shared memory (DSM) design that leverages the extreme
architectural asymmetry between the low-power processor and the powerful
central processor to achieve both energy efficiency and performance.
  We report a complete realization of Reflex for heterogeneous smartphones with
Maemo/Linux as the central kernel. Using a tri-processor hardware prototype and
sensing applications reported in recent literature, we evaluate the Reflex
realization for programming transparency, energy efficiency, and performance.
We show that Reflex supports a programming style that is very close to
contemporary smartphone programming. It allows existing sensing applications to
be ported with minor source code changes. Reflex reduces the system power in
sensing by up to 83%, and its runtime system only consumes 10% local memory on
a typical ultra-low power processor."
"This paper proposes a novel solution: the elimination of paged virtual memory
and partial outsourcing of memory page allocation and manipulation from the
operating system kernel into the individual process' user space - a user mode
page allocator - which allows an application to have direct, bare metal access
to the page mappings used by the hardware Memory Management Unit (MMU) for its
part of the overall address space. A user mode page allocator based emulation
of the mmap() abstraction layer of dlmalloc is then benchmarked against the
traditional kernel mode implemented mmap() in a series of synthetic Monte-Carlo
and real world application settings. Given the superb synthetic and positive
real world results from the profiling conducted, this paper proposes that with
proper operating system and API support one could gain a further order higher
performance again while keeping allocator performance invariant to the amount
of memory being allocated or freed i.e. a 100x performance improvement or more
in some common use cases. It is rare that through a simple and easy to
implement API and operating system structure change one can gain a Silver
Bullet with the potential for a second one."
"It is often said that one of the biggest limitations on computer performance
is memory bandwidth (i.e.""the memory wall problem""). In this position paper, I
argue that if historical trends in computing evolution (where growth in
available capacity is exponential and reduction in its access latencies is
linear) continue as they have, then this view is wrong - in fact we ought to be
concentrating on reducing whole system memory access latencies wherever
possible, and by ""whole system"" I mean that we ought to look at how software
can be unnecessarily wasteful with memory bandwidth due to legacy design
decisions. To this end I conduct a feasibility study to determine whether we
ought to virtualise the MMU for each application process such that it has
direct access to its own MMU page tables and the memory allocated to a process
is managed exclusively by the process and not the kernel. I find under typical
conditions that nearly scale invariant performance to memory allocation size is
possible such that hundreds of megabytes of memory can be allocated, relocated,
swapped and deallocated in almost the same time as kilobytes (e.g. allocating
8Mb is 10x quicker under this experimental allocator than a conventional
allocator, and resizing a 128Kb block to 256Kb block is 4.5x faster). I find
that first time page access latencies are improved tenfold; moreover, because
the kernel page fault handler is never called, the lack of cache pollution
improves whole application memory access latencies increasing performance by up
to 2x. Finally, I try binary patching existing applications to use the
experimental allocation technique, finding almost universal performance
improvements without having to recompile these applications to make better use
of the new facilities."
"Baker and Cirinei introduced an exact but naive algorithm, based on solving a
state reachability problem in a finite automaton, to check whether sets of
sporadic hard real-time tasks are schedulable on identical multiprocessor
platforms. However, the algorithm suffered from poor performance due to the
exponential size of the automaton relative to the size of the task set. In this
paper, we successfully apply techniques developed by the formal verification
community, specifically antichain algorithms, by defining and proving the
correctness of a simulation relation on Baker and Cirinei's automaton. We show
our improved algorithm yields dramatically improved performance for the
schedulability test and opens for many further improvements."
"""Evolution behaves like a tinkerer"" (Francois Jacob, Science, 1977). Software
systems provide a unique opportunity to understand biological processes using
concepts from network theory. The Debian GNU/Linux operating system allows us
to explore the evolution of a complex network in a novel way. The modular
design detected during its growth is based on the reuse of existing code in
order to minimize costs during programming. The increase of modularity
experienced by the system over time has not counterbalanced the increase in
incompatibilities between software packages within modules. This negative
effect is far from being a failure of design. A random process of package
installation shows that the higher the modularity the larger the fraction of
packages working properly in a local computer. The decrease in the relative
number of conflicts between packages from different modules avoids a failure in
the functionality of one package spreading throughout the entire system. Some
potential analogies with the evolutionary and ecological processes determining
the structure of ecological networks of interacting species are discussed."
"Changing functional and non-functional software implementation at runtime is
useful and even sometimes critical both in development and production
environments. JooFlux is a JVM agent that allows both the dynamic replacement
of method implementations and the application of aspect advices. It works by
doing bytecode transformation to take advantage of the new invokedynamic
instruction added in Java SE 7 to help implementing dynamic languages for the
JVM. JooFlux can be managed using a JMX agent so as to operate dynamic
modifications at runtime, without resorting to a dedicated domain-specific
language. We compared JooFlux with existing AOP platforms and dynamic
languages. Results demonstrate that JooFlux performances are close to the Java
ones --- with most of the time a marginal overhead, and sometimes a gain ---
where AOP platforms and dynamic languages present significant overheads. This
paves the way for interesting future evolutions and applications of JooFlux."
"This paper focuses on the analysis of real-time non preemptive multiprocessor
scheduling with precedence and several latency constraints. It aims to specify
a schedulability condition which enables a designer to check a priori -without
executing or simulating- if its scheduling of tasks will hold the precedences
between tasks as well as several latency constraints imposed on determined
pairs of tasks. It is shown that the required analysis is closely linked to the
topological structure of the application graph. More precisely, it depends on
the configuration of tasks paths subject to latency constraints. As a result of
the study, a sufficient schedulability condition is introduced for precedences
and latency constraints in the hardest configuration in term of complexity with
an optimal number of processors in term of applications parallelism. In
addition, the proposed conditions provides a practical lower bounds for general
cases. Performances results and comparisons with an optimal approach
demonstrate the effectiveness of the proposed approach."
"An inherent security limitation with the classic multithreaded programming
model is that all the threads share the same address space and, therefore, are
implicitly assumed to be mutually trusted. This assumption, however, does not
take into consideration of many modern multithreaded applications that involve
multiple principals which do not fully trust each other. It remains challenging
to retrofit the classic multithreaded programming model so that the security
and privilege separation in multi-principal applications can be resolved.
  This paper proposes ARBITER, a run-time system and a set of security
primitives, aimed at fine-grained and data-centric privilege separation in
multithreaded applications. While enforcing effective isolation among
principals, ARBITER still allows flexible sharing and communication between
threads so that the multithreaded programming paradigm can be preserved. To
realize controlled sharing in a fine-grained manner, we created a novel
abstraction named ARBITER Secure Memory Segment (ASMS) and corresponding OS
support. Programmers express security policies by labeling data and principals
via ARBITER's API following a unified model. We ported a widely-used, in-memory
database application (memcached) to ARBITER system, changing only around 100
LOC. Experiments indicate that only an average runtime overhead of 5.6% is
induced to this security enhanced version of application."
"With the advent of cloud computing, thousands of machines are connected and
managed collectively. This era is confronted with a new challenge: performance
variability, primarily caused by large-scale management issues such as hardware
failures, software bugs, and configuration mistakes. In our previous work we
highlighted one overlooked cause: limpware - hardware whose performance
degrades significantly compared to its specification. We showed that limpware
can cause severe impact in current scale-out systems. In this report, we
quantify how often these scenarios happen in Hadoop Distributed File System."
"Despite the attempts of well-designed anonymous communication tools to
protect users from tracking or identification, flaws in surrounding software
(such as web browsers) and mistakes in configuration may leak the user's
identity. We introduce Nymix, an anonymity-centric operating system
architecture designed ""top-to-bottom"" to strengthen identity- and
tracking-protection. Nymix's core contribution is OS support for nym-browsing:
independent, parallel, and ephemeral web sessions. Each web session, or
pseudonym, runs in a unique virtual machine (VM) instance evolving from a
common base state with support for long-lived sessions which can be anonymously
stored to the cloud, avoiding de-anonymization despite potential confiscation
or theft. Nymix allows a user to safely browse the Web using various different
transports simultaneously through a pluggable communication model that supports
Tor, Dissent, and a private browsing mode. In evaluations, Nymix consumes 600
MB per nymbox and loads within 15 to 25 seconds."
"InfiniBand is widely used for low-latency, high-throughput cluster computing.
Saving the state of the InfiniBand network as part of distributed checkpointing
has been a long-standing challenge for researchers. Because of a lack of a
solution, typical MPI implementations have included custom checkpoint-restart
services that ""tear down"" the network, checkpoint each node as if the node were
a standalone computer, and then re-connect the network again. We present the
first example of transparent, system-initiated checkpoint-restart that directly
supports InfiniBand. The new approach is independent of any particular Linux
kernel, thus simplifying the current practice of using a kernel-based module,
such as BLCR. This direct approach results in checkpoints that are found to be
faster than with the use of a checkpoint-restart service. The generality of
this approach is shown not only by checkpointing an MPI computation, but also a
native UPC computation (Berkeley Unified Parallel C), which does not use MPI.
Scalability is shown by checkpointing 2,048 MPI processes across 128 nodes
(with 16 cores per node). In addition, a cost-effective debugging approach is
also enabled, in which a checkpoint image from an InfiniBand-based production
cluster is copied to a local Ethernet-based cluster, where it can be restarted
and an interactive debugger can be attached to it. This work is based on a
plugin that extends the DMTCP (Distributed MultiThreaded CheckPointing)
checkpoint-restart package."
"In monolithic operating systems, the kernel is the piece of code that
executes with the highest privileges and has control over all the software
running on a host. A successful attack against an operating system's kernel
means a total and complete compromise of the running system. These attacks
usually end with the installation of a rootkit, a stealthy piece of software
running with kernel privileges. When a rootkit is present, no guarantees can be
made about the correctness, privacy or isolation of the operating system.
  In this paper we present \emph{Hello rootKitty}, an invariance-enforcing
framework which takes advantage of current virtualization technology to protect
a guest operating system against rootkits. \emph{Hello rootKitty} uses the idea
of invariance to detect maliciously modified kernel data structures and restore
them to their original legitimate values. Our prototype has negligible
performance and memory overhead while effectively protecting commodity
operating systems from modern rootkits."
"Myopic is a hard real-time process scheduling algorithm that selects a
suitable process based on a heuristic function from a subset (Window)of all
ready processes instead of choosing from all available processes, like original
heuristic scheduling algorithm. Performance of the algorithm significantly
depends on the chosen heuristic function that assigns weight to different
parameters like deadline, earliest starting time, processing time etc. and the
sizeof the Window since it considers only k processes from n processes (where,
k<= n). This research evaluates the performance of the Myopic algorithm for
different parameters to demonstrate the merits and constraints of the
algorithm. A comparative performance of the impact of window size in
implementing the Myopic algorithm is presented and discussed through a set of
experiments."
"We define dynamic striping as the ability to assign different Lustre striping
characteristics to contiguous segments of a file as it grows. In this paper, we
evaluate the effects of dynamic striping using a watermark-based strategy where
the stripe count or width is increased once a file's size exceeds one of the
chosen watermarks. To measure the performance of this strategy we used a
modified version of the IOR benchmark, a netflow analysis workload, and the
blastn algorithm from NCBI BLAST. The results indicate that dynamic striping is
beneficial to tasks with unpredictable data file size and large sequential
reads, but are less conclusive for workloads with significant random read
phases."
"Current generation solid-state storage devices are exposing a new bottlenecks
in the SCSI and block layers of the Linux kernel, where IO throughput is
limited by lock contention, inefficient interrupt handling, and poor memory
locality. To address these limitations, the Linux kernel block layer underwent
a major rewrite with the blk-mq project to move from a single request queue to
a multi-queue model. The Linux SCSI subsystem rework to make use of this new
model, known as scsi-mq, has been merged into the Linux kernel and work is
underway for dm-multipath support in the upcoming Linux 4.0 kernel. These
pieces were necessary to make use of the multi-queue block layer in a Lustre
parallel filesystem with high availability requirements. We undertook adding
support of the 3.18 kernel to Lustre with scsi-mq and dm-multipath patches to
evaluate the potential of these efficiency improvements. In this paper we
evaluate the block-level performance of scsi-mq with backing storage hardware
representative of a HPC-targerted Lustre filesystem. Our findings show that
SCSI write request latency is reduced by as much as 13.6%. Additionally, when
profiling the CPU usage of our prototype Lustre filesystem, we found that CPU
idle time increased by a factor of 7 with Linux 3.18 and blk-mq as compared to
a standard 2.6.32 Linux kernel. Our findings demonstrate increased efficiency
of the multi-queue block layer even with disk-based caching storage arrays used
in existing parallel filesystems."
"Malicious peripherals designed to attack their host computers are a growing
problem. Inexpensive and powerful peripherals that attach to plug-and-play
buses have made such attacks easy to mount. Making matters worse, commodity
operating systems lack coherent defenses, and users are often unaware of the
scope of the problem. We present Cinch, a pragmatic response to this threat.
Cinch uses virtualization to attach peripheral devices to a logically separate,
untrusted machine, and includes an interposition layer between the untrusted
machine and the protected one. This layer regulates interaction with devices
according to user-configured policies. Cinch integrates with existing OSes,
enforces policies that thwart real-world attacks, and has low overhead."
"Effectively protecting the Windows OS is a challenging task, since most
implementation details are not publicly known. Windows has always been the main
target of malwares that have exploited numerous bugs and vulnerabilities.
Recent trusted boot and additional integrity checks have rendered the Windows
OS less vulnerable to kernel-level rootkits. Nevertheless, guest Windows
Virtual Machines are becoming an increasingly interesting attack target. In
this work we introduce and analyze a novel Hypervisor-Based Introspection
System (HyBIS) we developed for protecting Windows OSes from malware and
rootkits. The HyBIS architecture is motivated and detailed, while targeted
experimental results show its effectiveness. Comparison with related work
highlights main HyBIS advantages such as: effective semantic introspection,
support for 64-bit architectures and for latest Windows (8.x and 10), advanced
malware disabling capabilities. We believe the research effort reported here
will pave the way to further advances in the security of Windows OSes."
"Applications written to run on conventional operating systems typically
depend on OS abstractions like processes, pipes, signals, sockets, and a shared
file system. Porting these applications to the web currently requires extensive
rewriting or hosting significant portions of code server-side because browsers
present a nontraditional runtime environment that lacks OS functionality.
  This paper presents Browsix, a framework that bridges the considerable gap
between conventional operating systems and the browser, enabling unmodified
programs expecting a Unix-like environment to run directly in the browser.
Browsix comprises two core parts: (1) a JavaScript-only system that makes core
Unix features (including pipes, concurrent processes, signals, sockets, and a
shared file system) available to web applications; and (2) extended JavaScript
runtimes for C, C++, Go, and Node.js that support running programs written in
these languages as processes in the browser. Browsix supports running a POSIX
shell, making it straightforward to connect applications together via pipes.
  We illustrate Browsix's capabilities via case studies that demonstrate how it
eases porting legacy applications to the browser and enables new functionality.
We demonstrate a Browsix-enabled LaTeX editor that operates by executing
unmodified versions of pdfLaTeX and BibTeX. This browser-only LaTeX editor can
render documents in seconds, making it fast enough to be practical. We further
demonstrate how Browsix lets us port a client-server application to run
entirely in the browser for disconnected operation. Creating these applications
required less than 50 lines of glue code and no code modifications,
demonstrating how easily Browsix can be used to build sophisticated web
applications from existing parts without modification."
"Checkpoint-restart is now a mature technology. It allows a user to save and
later restore the state of a running process. The new plugin model for the
upcoming version 3.0 of DMTCP (Distributed MultiThreaded Checkpointing) is
described here. This plugin model allows a target application to disconnect
from the hardware emulator at checkpoint time and then re-connect to a possibly
different hardware emulator at the time of restart. The DMTCP plugin model is
important in allowing three distinct parties to seamlessly inter-operate. The
three parties are: the EDA designer, who is concerned with formal verification
of a circuit design; the DMTCP developers, who are concerned with providing
transparent checkpointing during the circuit emulation; and the hardware
emulator vendor, who provides a plugin library that responds to checkpoint,
restart, and other events.
  The new plugin model is an example of process-level virtualization:
virtualization of external abstractions from within a process. This capability
is motivated by scenarios for testing circuit models with the help of a
hardware emulator. The plugin model enables a three-way collaboration: allowing
a circuit designer and emulator vendor to each contribute separate proprietary
plugins while sharing an open source software framework from the DMTCP
developers. This provides a more flexible platform, where different fault
injection models based on plugins can be designed within the DMTCP
checkpointing framework. After initialization, one restarts from a checkpointed
state under the control of the desired plugin. This restart saves the time
spent in simulating the initialization phase, while enabling fault injection
exactly at the region of interest. Upon restart, one can inject faults or
otherwise modify the remainder of the simulation. The work concludes with a
brief survey of checkpointing and process-level virtualization."
"The hardware/software boundary in modern heterogeneous multicore computers is
increasingly complex, and diverse across different platforms. A single memory
access by a core or DMA engine traverses multiple hardware translation and
caching steps, and the destination memory cell or register often appears at
different physical addresses for different cores. Interrupts pass through a
complex topology of interrupt controllers and remappers before delivery to one
or more cores, each with specific constraints on their configurations. System
software must not only correctly understand the specific hardware at hand, but
also configure it appropriately at runtime. We propose a formal model of
address spaces and resources in a system that allows us to express and verify
invariants of the system's runtime configuration, and illustrate (and motivate)
it with several real platforms we have encountered in the process of OS
implementation."
"The emerging hybrid DRAM-NVM architecture is challenging the existing memory
management mechanism in operating system. In this paper, we introduce memos,
which can schedule memory resources over the entire memory hierarchy including
cache, channels, main memory comprising DRAM and NVM simultaneously. Powered by
our newly designed kernel-level monitoring module and page migration engine,
memos can dynamically optimize the data placement at the memory hierarchy in
terms of the on-line memory patterns, current resource utilization and feature
of memory medium. Our experimental results show that memos can achieve high
memory utilization, contributing to system throughput by 19.1% and QoS by 23.6%
on average. Moreover, memos can reduce the NVM side memory latency by 3~83.3%,
energy consumption by 25.1~99%, and benefit the NVM lifetime significantly (40X
improvement on average)."
"CPU Scheduling is the base of multiprogramming. Scheduling is a process which
decides order of task from a set of multiple tasks that are ready to execute.
There are number of CPU scheduling algorithms available, but it is very
difficult task to decide which one is better. This paper discusses the design
and implementation of modified fuzzy based CPU scheduling algorithm. This paper
present a new set of fuzzy rules. It demonstrates that scheduling done with new
priority improves average waiting time and average turnaround time."
"This paper is about three virtualization modes: VMware, Parallels, and Boot
Camping. The trade off of their testing is the hardware requirements. The main
question is, among the three, which is the most suitable? The answer actually
varies from user to user. It depends on the user needs. Moreover, it is
necessary to consider its performance, graphics, efficiency and reliability,
and interoperability, and that is our major scope. In order to take the final
decision in choosing one of the modes it is important to run some tests, which
costs a lot in terms of money, complexity, and time consumption. Therefore, in
order to overcome this trade off, most of the research has been done through
online benchmarking and my own anticipation. The final solution was extracted
after comparing all previously mentioned above and after rigorous testing made
which will be introduced later in this document."
"Microreboots restart fine-grained components of software systems ""with a
clean slate,"" and only take a fraction of the time needed for full system
reboot. Microreboots provide an application-generic recovery technique for
Internet services, which can be supported entirely in middleware and requires
no changes to the applications or any a priori knowledge of application
semantics.
  This paper investigates the effect of microreboots on end-users of an
eBay-like online auction application; we find that microreboots are nearly as
effective as full reboots, but are significantly less disruptive in terms of
downtime and lost work. In our experiments, microreboots reduced the number of
failed user requests by 65% and the perceived downtime by 78% compared to a
server process restart. We also show how to replace user-visible transient
failures with transparent call-retry, at the cost of a slight increase in
end-user-visible latency during recovery. Due to their low cost, microreboots
can be used aggressively, even when their necessity is less than certain, hence
adding to the reduced recovery time a reduction in the fault detection time,
which further improves availability."
"Geometric routing algorithms like GFG (GPSR) are lightweight, scalable
algorithms that can be used to route in resource-constrained ad hoc wireless
networks. However, such algorithms run on planar graphs only. To efficiently
construct a planar graph, they require a unit-disk graph. To make the topology
unit-disk, the maximum link length in the network has to be selected
conservatively. In practical setting this leads to the designs where the node
density is rather high. Moreover, the network diameter of a planar subgraph is
greater than the original graph, which leads to longer routes. To remedy this
problem, we propose a void traversal algorithm that works on arbitrary
geometric graphs. We describe how to use this algorithm for geometric routing
with guaranteed delivery and compare its performance with GFG."
"In this paper, we revisit the design of synchronization
primitives---specifically barriers, mutexes, and semaphores---and how they
apply to the GPU. Previous implementations are insufficient due to the
discrepancies in hardware and programming model of the GPU and CPU. We create
new implementations in CUDA and analyze the performance of spinning on the GPU,
as well as a method of sleeping on the GPU, by running a set of memory-system
benchmarks on two of the most common GPUs in use, the Tesla- and Fermi-class
GPUs from NVIDIA. From our results we define higher-level principles that are
valid for generic many-core processors, the most important of which is to limit
the number of atomic accesses required for a synchronization operation because
atomic accesses are slower than regular memory accesses. We use the results of
the benchmarks to critique existing synchronization algorithms and guide our
new implementations, and then define an abstraction of GPUs to classify any GPU
based on the behavior of the memory system. We use this abstraction to create
suitable implementations of the primitives specifically targeting the GPU, and
analyze the performance of these algorithms on Tesla and Fermi. We then predict
performance on future GPUs based on characteristics of the abstraction. We also
examine the roles of spin waiting and sleep waiting in each primitive and how
their performance varies based on the machine abstraction, then give a set of
guidelines for when each strategy is useful based on the characteristics of the
GPU and expected contention."
"Nowadays, the use of embedded operating systems in different embedded
projects is subject to a tremendous growth. Embedded Linux is becoming one of
those most popular EOSs due to its modularity, efficiency, reliability, and
cost. One way to make it hard real-time is to include a real-time kernel like
Xenomai. One of the key characteristics of a Real-Time Operating System (RTOS)
is its ability to meet execution time deadlines deterministically. So, the more
precise and flexible the time management can be, the better it can handle
efficiently the determinism for different embedded applications. RTOS time
precision is characterized by a specific periodic interrupt service controlled
by a software time manager. The smaller the period of the interrupt, the better
the precision of the RTOS, the more it overloads the CPU, and though reduces
the overall efficiency of the RTOS. In this paper, we propose to drastically
reduce these overheads by migrating the time management service of Xenomai into
a configurable hardware component to relieve the CPU. The hardware component is
implemented in a Field Programmable Gate Array coupled to the CPU. This work
was achieved in a Master degree project where students could apprehend many
fields of embedded systems: RTOS programming, hardware design, performance
evaluation, etc."
"Security is a critical issue of the modern file and storage systems, it is
imperative to protect the stored data from unauthorized access. We have
developed a file security system named as Java File Security System (JFSS) [1]
that guarantee the security to files on the demand of all users. It has been
developed on Java platform. Java has been used as programming language in order
to provide portability, but it enforces some performance limitations. It is
developed in FUSE (File System in User space) [3]. Many efforts have been done
over the years for developing file systems in user space (FUSE). All have their
own merits and demerits. In this paper we have evaluated the performance of
Java File Security System (JFSS). Over and over again, the increased security
comes at the expense of user convenience, performance or compatibility with
other systems. JFSS system performance evaluations show that encryption
overheads are modest as compared to security."
"Existing caching strategies, in the storage domain, though well suited to
exploit short range spatio-temporal patterns, are unable to leverage long-range
motifs for improving hitrates. Motivated by this, we investigate novel Bayesian
non-parametric modeling(BNP) techniques for count vectors, to capture long
range correlations for cache preloading, by mining Block I/O traces. Such
traces comprise of a sequence of memory accesses that can be aggregated into
high-dimensional sparse correlated count vector sequences.
  While there are several state of the art BNP algorithms for clustering and
their temporal extensions for prediction, there has been no work on exploring
these for correlated count vectors. Our first contribution addresses this gap
by proposing a DP based mixture model of Multivariate Poisson (DP-MMVP) and its
temporal extension(HMM-DP-MMVP) that captures the full covariance structure of
multivariate count data. However, modeling full covariance structure for count
vectors is computationally expensive, particularly for high dimensional data.
Hence, we exploit sparsity in our count vectors, and as our main contribution,
introduce the Sparse DP mixture of multivariate Poisson(Sparse-DP-MMVP),
generalizing our DP-MMVP mixture model, also leading to more efficient
inference. We then discuss a temporal extension to our model for cache
preloading.
  We take the first step towards mining historical data, to capture long range
patterns in storage traces for cache preloading. Experimentally, we show a
dramatic improvement in hitrates on benchmark traces and lay the groundwork for
further research in storage domain to reduce latencies using data mining
techniques to capture long range motifs."
"High Speed computing meets ever increasing real-time computational demands
through the leveraging of flexibility and parallelism. The flexibility is
achieved when computing platform designed with heterogeneous resources to
support multifarious tasks of an application where as task scheduling brings
parallel processing. The efficient task scheduling is critical to obtain
optimized performance in heterogeneous computing Systems (HCS). In this paper,
we brought a review of various application scheduling models which provide
parallelism for homogeneous and heterogeneous computing systems. In this paper,
we made a review of various scheduling methodologies targeted to high speed
computing systems and also prepared summary chart. The comparative study of
scheduling methodologies for high speed computing systems has been carried out
based on the attributes of platform & application as well. The attributes are
execution time, nature of task, task handling capability, type of host &
computing platform. Finally a summary chart has been prepared and it
demonstrates that the need of developing scheduling methodologies for
Heterogeneous Reconfigurable Computing Systems (HRCS) which is an emerging high
speed computing platform for real time applications."
"We present a number of novel algorithms, based on mathematical optimization
formulations, in order to solve a homogeneous multiprocessor scheduling
problem, while minimizing the total energy consumption. In particular, for a
system with a discrete speed set, we propose solving a tractable linear
program. Our formulations are based on a fluid model and a global scheduling
scheme, i.e. tasks are allowed to migrate between processors. The new methods
are compared with three global energy/feasibility optimal workload allocation
formulations. Simulation results illustrate that our methods achieve both
feasibility and energy optimality and outperform existing methods for
constrained deadline tasksets. Specifically, the results provided by our
algorithm can achieve up to an 80% saving compared to an algorithm without a
frequency scaling scheme and up to 70% saving compared to a constant frequency
scaling scheme for some simulated tasksets. Another benefit is that our
algorithms can solve the scheduling problem in one step instead of using a
recursive scheme. Moreover, our formulations can solve a more general class of
scheduling problems, i.e. any periodic real-time taskset with arbitrary
deadline. Lastly, our algorithms can be applied to both online and offline
scheduling schemes."
"Real-time scheduling algorithms proposed in the literature are often based on
worst-case estimates of task parameters. The performance of an open-loop scheme
can be degraded significantly if there are uncertainties in task parameters,
such as the execution times of the tasks. Therefore, to cope with such a
situation, a closed-loop scheme, where feedback is exploited to adjust the
system parameters, can be applied. We propose an optimal control framework that
takes advantage of feeding back information of finished tasks to solve a
real-time multiprocessor scheduling problem with uncertainty in task execution
times, with the objective of minimizing the total energy consumption.
Specifically, we propose a linear programming based algorithm to solve a
workload partitioning problem and adopt McNaughton's wrap around algorithm to
find the task execution order. The simulation results illustrate that our
feedback scheduling algorithm can save energy by as much as 40% compared to an
open-loop method for two processor models, i.e. a PowerPC 405LP and an XScale
processor."
"We describe SAFIUS, a secure accountable file system that resides over an
untrusted storage. SAFIUS provides strong security guarantees like
confidentiality, integrity, prevention from rollback attacks, and
accountability. SAFIUS also enables read/write sharing of data and provides the
standard UNIX-like interface for applications. To achieve accountability with
good performance, it uses asynchronous signatures; to reduce the space required
for storing these signatures, a novel signature pruning mechanism is used.
SAFIUS has been implemented on a GNU/Linux based system modifying OpenGFS.
Preliminary performance studies show that SAFIUS has a tolerable overhead for
providing secure storage: while it has an overhead of about 50% of OpenGFS in
data intensive workloads (due to the overhead of performing
encryption/decryption in software), it is comparable (or better in some cases)
to OpenGFS in metadata intensive workloads."