summary
"The rapid and widespread adoption of Java has created a demand for reliable
and reusable mathematical software components to support the growing number of
compute-intensive applications now under development, particularly in science
and engineering. In this paper we address practical issues of the Java language
and environment which have an effect on numerical library design and
development. Benchmarks which illustrate the current levels of performance of
key numerical kernels on a variety of Java platforms are presented. Finally, a
strategy for the development of a fundamental numerical toolkit for Java is
proposed and its current status is described."
"A novel parallel algorithm for matrix multiplication is presented. The
hyper-systolic algorithm makes use of a one-dimensional processor abstraction.
The procedure can be implemented on all types of parallel systems. It can
handle matrix-vector multiplications as well as transposed matrix products."
"This paper provides some reflections on the field of mathematical software on
the occasion of John Rice's 65th birthday. I describe some of the common themes
of research in this field and recall some significant events in its evolution.
Finally, I raise a number of issues that are of concern to future developments."
"We discuss the role of automatic differentiation tools in optimization
software. We emphasize issues that are important to large-scale optimization
and that have proved useful in the installation of nonlinear solvers in the
NEOS Server. Our discussion centers on the computation of the gradient and
Hessian matrix for partially separable functions and shows that the gradient
and Hessian matrix can be computed with guaranteed bounds in time and memory
requirements"
"GPCG is an algorithm within the Toolkit for Advanced Optimization (TAO) for
solving bound constrained, convex quadratic problems. Originally developed by
More' and Toraldo, this algorithm was designed for large-scale problems but had
been implemented only for a single processor. The TAO implementation is
available for a wide range of high-performance architecture, and has been
tested on up to 64 processors to solve problems with over 2.5 million
variables."
"We propose performance profiles-distribution functions for a performance
metric-as a tool for benchmarking and comparing optimization software. We show
that performance profiles combine the best features of other tools for
performance evaluation."
"SnadiOpt is a package that supports the use of the automatic differentiation
package ADIFOR with the optimization package Snopt. Snopt is a general-purpose
system for solving optimization problems with many variables and constraints.
It minimizes a linear or nonlinear function subject to bounds on the variables
and sparse linear or nonlinear constraints. It is suitable for large-scale
linear and quadratic programming and for linearly constrained optimization, as
well as for general nonlinear programs. The method used by Snopt requires the
first derivatives of the objective and constraint functions to be available.
The SnadiOpt package allows users to avoid the time-consuming and error-prone
process of evaluating and coding these derivatives. Given Fortran code for
evaluating only the values of the objective and constraints, SnadiOpt
automatically generates the code for evaluating the derivatives and builds the
relevant Snopt input files and sparse data structures."
"Most existing implementations of multiple precision arithmetic demand that
the user sets the precision {\em a priori}. Some libraries are said adaptable
in the sense that they dynamically change the precision of each intermediate
operation individually to deliver the target accuracy according to the actual
inputs. We present in this text a new adaptable numeric core inspired both from
floating point expansions and from on-line arithmetic.
  The numeric core is cut down to four tools. The tool that contains arithmetic
operations is proved to be correct. The proofs have been formally checked by
the Coq assistant. Developing the proofs, we have formally proved many results
published in the literature and we have extended a few of them. This work may
let users (i) develop application specific adaptable libraries based on the
toolset and / or (ii) write new formal proofs based on the set of validated
facts."
"We had assembled a Java package, known as MatrixPak, of four classes for the
purpose of numerical matrix computation. The classes are matrix,
matrix_operations, StrToMatrix, and MatrixToStr; all of which are inherited
from java.lang.Object class. Class matrix defines a matrix as a two-dimensional
array of float types, and contains the following mathematical methods:
transpose, adjoint, determinant, inverse, minor and cofactor. Class
matrix_operations contains the following mathematical methods: matrix addition,
matrix subtraction, matrix multiplication, and matrix exponential. Class
StrToMatrix contains methods necessary to parse a string representation (for
example, [[2 3 4]-[5 6 7]]) of a matrix into a matrix definition, whereas class
MatrixToStr does the reverse."
"When implementing regular enough functions (e.g., elementary or special
functions) on a computing system, we frequently use polynomial approximations.
In most cases, the polynomial that best approximates (for a given distance and
in a given interval) a function has coefficients that are not exactly
representable with a finite number of bits. And yet, the polynomial
approximations that are actually implemented do have coefficients that are
represented with a finite - and sometimes small - number of bits: this is due
to the finiteness of the floating-point representations (for software
implementations), and to the need to have small, hence fast and/or inexpensive,
multipliers (for hardware implementations). We then have to consider polynomial
approximations for which the degree-$i$ coefficient has at most $m_i$
fractional bits (in other words, it is a rational number with denominator
$2^{m_i}$). We provide a general method for finding the best polynomial
approximation under this constraint. Then, we suggest refinements than can be
used to accelerate our method."
"We give a gentle introduction to using various software tools for automatic
differentiation (AD). Ready-to-use examples are discussed, and links to further
information are presented. Our target audience includes all those who are
looking for a straightforward way to get started using the available AD
technology. The document is dynamic in the sense that its content will be
updated as the AD software evolves."
"This paper presents an algorithm for computing Sine-Cosine pairs to modest
accuracy, but in a manner which contains no conditional tests or branching,
making it highly amenable to vectorization. An exemplary implementation for
PowerPC AltiVec processors is included, but the algorithm should be easily
portable to other achitectures, such as Intel SSE."
"We present two add-ons for Mathematica for teaching mathematics to
undergraduate and high school students. These two applications, M@th Desktop
(MD) and M@th Desktop Tools (MDTools), include several palettes and notebooks
covering almost every field. The underlying didactic concept is so-called
""blended learning"", in which these tools are meant to be used as a complement
to the professor or teacher rather than as a replacement, which other
e-learning applications do. They enable students to avoid the usual problem of
computer-based learning, namely that too large an amount of time is wasted
struggling with computer and program errors instead of actually learning the
mathematical concepts.
  M@th Desktop Tools is palette-based and provides easily accessible and
user-friendly templates for the most important functions in the fields of
Analysis, Algebra, Linear Algebra and Statistics. M@th Desktop, in contrast, is
a modern, interactive teaching and learning software package for mathematics
classes. It is comprised of modules for Differentiation, Integration, and
Statistics, and each module presents its topic with a combination of
interactive notebooks and palettes.
  Both packages can be obtained from Deltasoft's homepage at
http://www.deltasoft.at/ ."
"The solution of large, sparse constrained least-squares problems is a staple
in scientific and engineering applications. However, currently available codes
for such problems are proprietary or based on MATLAB. We announce a freely
available C implementation of the fast block pivoting algorithm of Portugal,
Judice, and Vicente. Our version is several times faster than Matstoms' MATLAB
implementation of the same algorithm. Further, our code matches the accuracy of
MATLAB's built-in lsqnonneg function."
"ADF95 is a tool to automatically calculate numerical first derivatives for
any mathematical expression as a function of user defined independent
variables. Accuracy of derivatives is achieved within machine precision. ADF95
may be applied to any FORTRAN 77/90/95 conforming code and requires minimal
changes by the user. It provides a new derived data type that holds the value
and derivatives and applies forward differencing by overloading all FORTRAN
operators and intrinsic functions. An efficient indexing technique leads to a
reduced memory usage and a substantially increased performance gain over other
available tools with operator overloading. This gain is especially pronounced
for sparse systems with large number of independent variables. A wide class of
numerical simulations, e.g., those employing implicit solvers, can profit from
ADF95."
"We present in this paper a library to compute with Taylor models, a technique
extending interval arithmetic to reduce decorrelation and to solve differential
equations. Numerical software usually produces only numerical results. Our
library can be used to produce both results and proofs. As seen during the
development of Fermat's last theorem reported by Aczel 1996, providing a proof
is not sufficient. Our library provides a proof that has been thoroughly
scrutinized by a trustworthy and tireless assistant. PVS is an automatic proof
assistant that has been fairly developed and used and that has no internal
connection with interval arithmetic or Taylor models. We built our library so
that PVS validates each result as it is produced. As producing and validating a
proof, is and will certainly remain a bigger task than just producing a
numerical result our library will never be a replacement to imperative
implementations of Taylor models such as Cosy Infinity. Our library should
mainly be used to validate small to medium size results that are involved in
safety or life critical applications."
"BioSig is an open source software library for biomedical signal processing.
Most users in the field are using Matlab; however, significant effort was
undertaken to provide compatibility to Octave, too. This effort has been widely
successful, only some non-critical components relying on a graphical user
interface are missing. Now, installing BioSig on Octave is as easy as on
Matlab. Moreover, a benchmark test based on BioSig has been developed and the
benchmark results of several platforms are presented."
"The subject of our talk is the correct evaluation of interval extension of
the function specified by the expression x^y without any constraints on the
values of x and y. The core of our approach is a decomposition of the graph of
x^y into a small number of parts which can be transformed into subsets of the
graph of x^y for non-negative bases x. Because of this fact, evaluation of
interval extension of x^y, without any constraints on x and y, is not much
harder than evaluation of interval extension of x^y for non-negative bases x."
"There are many classes of mathematical problems which give rise to matrices,
where a large number of the elements are zero. In this case it makes sense to
have a special matrix type to handle this class of problems where only the
non-zero elements of the matrix are stored. Not only does this reduce the
amount of memory to store the matrix, but it also means that operations on this
type of matrix can take advantage of the a-priori knowledge of the positions of
the non-zero elements to accelerate their calculations. A matrix type that
stores only the non-zero elements is generally called sparse.
  Until recently Octave has lacked a full implementation of sparse matrices.
This article address the implementation of sparse matrices within Octave,
including their storage, creation, fundamental algorithms used, their
implementations and the basic operations and functions implemented for sparse
matrices. Mathematical issues such as the return types of sparse operations,
matrix fill-in and reordering for sparse matrix factorization is discussed in
the context of a real example.
  Benchmarking of Octave's implementation of sparse operations compared to
their equivalent in Matlab are given and their implications discussed. Results
are presented for multiplication and linear algebra operations for various
matrix orders and densities. Furthermore, the use of Octave's sparse matrix
implementation is demonstrated using a real example of a finite element model
(FEM) problem. Finally, the method of using sparse matrices with Octave's
oct-files is discussed. The means of creating, using and returning sparse
matrices within oct-files is discussed as well as the differences between
Octave's Sparse and Array classes."
"This paper announces the availability of a fixed point toolbox for the Matlab
compatible software package Octave. This toolbox is released under the GNU
Public License, and can be used to model the losses in algorithms implemented
in hardware. Furthermore, this paper presents as an example of the use of this
toolbox, the effects of a fixed point implementation on the precision of an
OFDM modulator."
"Mathematica is a versatile equipment for doing numeric and symbolic
computations and it has wide spread applications in all branches of science.
Mathematica has a complete consistency to design it at every stage that gives
it multilevel capability and helps advanced usage evolve naturally. Mathematica
functions work for any precision of number and it can be easily computed with
symbols, represented graphically to get the best answer. Mathematica is a
robust software development that can be used in any popular operating systems
and it can be communicated with external programs by using proper mathlink
commands.
  Sometimes it is quite desirable to run jobs in background of a computer which
can take considerable amount of time to finish, and this allows us to do work
on other tasks, while keeping the jobs running. Most of us are very familiar to
run jobs in background for the programs written in the languages like C, C++,
F77, F90, F95, etc. But the way of running jobs, written in a mathematica
notebook, in background is quite different from the conventional method. In
this article, we explore how to create a mathematica batch-file from a
mathematica notebook and run it in background. Here we concentrate our study
only for the Unix version, but one can run mathematica programs in background
for the Windows version as well by using proper mathematica batch-file."
"Les unit\'{e}s graphiques (Graphic Processing Units- GPU) sont d\'{e}sormais
des processeurs puissants et flexibles. Les derni\`{e}res g\'{e}n\'{e}rations
de GPU contiennent des unit\'{e}s programmables de traitement des sommets
(vertex shader) et des pixels (pixel shader) supportant des op\'{e}rations en
virgule flottante sur 8, 16 ou 32 bits. La repr\'{e}sentation flottante sur 32
bits correspond \`{a} la simple pr\'{e}cision de la norme IEEE sur
l'arithm\'{e}tique en virgule flottante (IEEE-754). Les GPU sont bien
adapt\'{e}s aux applications avec un fort parall\'{e}lisme de donn\'{e}es.
Cependant ils ne sont que peu utilis\'{e}s en dehors des calculs graphiques
(General Purpose computation on GPU -- GPGPU). Une des raisons de cet \'{e}tat
de faits est la pauvret\'{e} des documentations techniques fournies par les
fabricants (ATI et Nvidia), particuli\`{e}rement en ce qui concerne
l'implantation des diff\'{e}rents op\'{e}rateurs arithm\'{e}tiques
embarqu\'{e}s dans les diff\'{e}rentes unit\'{e}s de traitement. Or ces
informations sont essentielles pour estimer et contr\^{o}ler les erreurs
d'arrondi ou pour mettre en oeuvre des techniques de r\'{e}duction ou de
compensation afin de travailler en pr\'{e}cision double, quadruple ou
arbitrairement \'{e}tendue. Nous proposons dans cet article un ensemble de
programmes qui permettent de d\'{e}couvrir les caract\'{e}ristiques principales
des GPU en ce qui concerne l'arithm\'{e}tique \`{a} virgule flottante. Nous
donnons les r\'{e}sultats obtenus sur deux cartes graphiques r\'{e}centes: la
Nvidia 7800GTX et l'ATI RX1800XL."
"This paper provides a bound on the number of numeric operations (fixed or
floating point) that can safely be performed before accuracy is lost. This work
has important implications for control systems with safety-critical software,
as these systems are now running fast enough and long enough for their errors
to impact on their functionality. Furthermore, worst-case analysis would
blindly advise the replacement of existing systems that have been successfully
running for years. We present here a set of formal theorems validated by the
PVS proof assistant. These theorems will allow code analyzing tools to produce
formal certificates of accurate behavior. For example, FAA regulations for
aircraft require that the probability of an error be below $10^{-9}$ for a 10
hour flight."
"We provide a framework to bound the probability that accumulated errors were
never above a given threshold on hybrid systems. Such systems are used for
example to model an aircraft or a nuclear power plant on one side and its
software on the other side. This report contains simple formulas based on
L\'evy's and Markov's inequalities and it presents a formal theory of random
variables with a special focus on producing concrete results. We selected four
very common applications that fit in our framework and cover the common
practices of hybrid systems that evolve for a long time. We compute the number
of bits that remain continuously significant in the first two applications with
a probability of failure around one against a billion, where worst case
analysis considers that no significant bit remains. We are using PVS as such
formal tools force explicit statement of all hypotheses and prevent incorrect
uses of theorems."
"Gappa uses interval arithmetic to certify bounds on mathematical expressions
that involve rounded as well as exact operators. Gappa generates a theorem with
its proof for each bound treated. The proof can be checked with a higher order
logic automatic proof checker, either Coq or HOL Light, and we have developed a
large companion library of verified facts for Coq dealing with the addition,
multiplication, division, and square root, in fixed- and floating-point
arithmetics. Gappa uses multiple-precision dyadic fractions for the endpoints
of intervals and performs forward error analysis on rounded operators when
necessary. When asked, Gappa reports the best bounds it is able to reach for a
given expression in a given context. This feature is used to quickly obtain
coarse bounds. It can also be used to identify where the set of facts and
automatic techniques implemented in Gappa becomes insufficient. Gappa handles
seamlessly additional properties expressed as interval properties or rewriting
rules in order to establish more intricate bounds. Recent work showed that
Gappa is perfectly suited to the proof of correctness of small pieces of
software. Proof obligations can be written by designers, produced by
third-party tools or obtained by overloading arithmetic operators."
"The basic statistical methods of data representation did not change since
their emergence. Their simplicity was dictated by the intricacies of
computations in the before computers epoch. It turns out that such approach is
not uniquely possible in the presence of quick computers. The suggested here
method improves significantly the reliability of data processing and their
graphical representation. In this paper we show problems of the standard data
processing which can bring to incorrect results. A method solving these
problems is proposed. It is based on modification of data representation. The
method was implemented in a computer program Consensus5. The program
performances are illustrated through varied examples."
"We describe an algorithm for evaluation of the interval extension of the
power function of variables x and y given by the expression x^y. Our algorithm
reduces the general case to the case of non-negative bases."
"We propose several new schedules for Strassen-Winograd's matrix
multiplication algorithm, they reduce the extra memory allocation requirements
by three different means: by introducing a few pre-additions, by overwriting
the input matrices, or by using a first recursive level of classical
multiplication. In particular, we show two fully in-place schedules: one having
the same number of operations, if the input matrices can be overwritten; the
other one, slightly increasing the constant of the leading term of the
complexity, if the input matrices are read-only. Many of these schedules have
been found by an implementation of an exhaustive search algorithm based on a
pebble game."
"This brief paper: (1) Discusses strategies to generate random test cases that
can be used to extensively test any Linear Distance Program (LDP) software. (2)
Gives three numerical examples of input cases generated by this strategy that
cause problems in the Lawson and Hanson LDP module. (3) Proposes, as a standard
matter of acceptable implementation procedures, that (unless it is done
internally in the software itself, but, in general, this seems to be much rarer
than one would expect) all users should test the returned output from any LDP
module for self-consistency since it incurs only a small amount of added
computational overhead and it is not hard to do."
"The notion of complex systems is common to many domains, from Biology to
Economy, Computer Science, Physics, etc. Often, these systems are made of sets
of entities moving in an evolving environment. One of their major
characteristics is the emergence of some global properties stemmed from local
interactions between the entities themselves and between the entities and the
environment. The structure of these systems as sets of interacting entities
leads researchers to model them as graphs. However, their understanding
requires most often to consider the dynamics of their evolution. It is indeed
not relevant to study some properties out of any temporal consideration. Thus,
dynamic graphs seem to be a very suitable model for investigating the emergence
and the conservation of some properties. GraphStream is a Java-based library
whose main purpose is to help researchers and developers in their daily tasks
of dynamic problem modeling and of classical graph management tasks: creation,
processing, display, etc. It may also be used, and is indeed already used, for
teaching purpose. GraphStream relies on an event-based engine allowing several
event sources. Events may be included in the core of the application, read from
a file or received from an event handler."
"We present a systematic, algebraically based, design methodology for
efficient implementation of computer programs optimized over multiple levels of
the processor/memory and network hierarchy. Using a common formalism to
describe the problem and the partitioning of data over processors and memory
levels allows one to mathematically prove the efficiency and correctness of a
given algorithm as measured in terms of a set of metrics (such as
processor/network speeds, etc.). The approach allows the average programmer to
achieve high-level optimizations similar to those used by compiler writers
(e.g. the notion of ""tiling"").
  The approach presented in this monograph makes use of A Mathematics of Arrays
(MoA, Mullin 1988) and an indexing calculus (i.e. the psi-calculus) to enable
the programmer to develop algorithms using high-level compiler-like
optimizations through the ability to algebraically compose and reduce sequences
of array operations. Extensive discussion and benchmark results are presented
for the Fast Fourier Transform and other important algorithms."
"We describe an efficient implementation of a hierarchy of algorithms for
multiplication of dense matrices over the field with two elements (GF(2)). In
particular we present our implementation -- in the M4RI library -- of
Strassen-Winograd matrix multiplication and the ""Method of the Four Russians""
multiplication (M4RM) and compare it against other available implementations.
Good performance is demonstrated on on AMD's Opteron and particulary good
performance on Intel's Core 2 Duo. The open-source M4RI library is available
stand-alone as well as part of the Sage mathematics software.
  In machine terms, addition in GF(2) is logical-XOR, and multiplication is
logical-AND, thus a machine word of 64-bits allows one to operate on 64
elements of GF(2) in parallel: at most one CPU cycle for 64 parallel additions
or multiplications. As such, element-wise operations over GF(2) are relatively
cheap. In fact, in this paper, we conclude that the actual bottlenecks are
memory reads and writes and issues of data locality. We present our empirical
findings in relation to minimizing these and give an analysis thereof."
"We present a method of computing with matrices over very small finite fields
of size larger than 2. Specifically, we show how the Method of Four Russians
can be efficiently adapted to these larger fields, and introduce a row-wise
matrix compression scheme that both reduces memory requirements and allows one
to vectorize element operations. We also present timings which confirm the
efficiency of these methods and exceed the speed of the fastest implementations
the authors are aware of."
"NetEvo is a computational framework designed to help understand the evolution
of dynamical complex networks. It provides flexible tools for the simulation of
dynamical processes on networks and methods for the evolution of underlying
topological structures. The concept of a supervisor is used to bring together
both these aspects in a coherent way. It is the job of the supervisor to rewire
the network topology and alter model parameters such that a user specified
performance measure is minimised. This performance measure can make use of
current topological information and simulated dynamical output from the system.
Such an abstraction provides a suitable basis in which to study many
outstanding questions related to complex system design and evolution."
"We introduce a new OpenMath content dictionary, named tensor1, containing
symbols for the expression of tensor formulas. These symbols support the
expression of non-Cartesian coordinates and invariant, multilinear expressions
in the context of coordinate transformations. While current OpenMath symbols
support the expression of linear algebra formulas using matrices and vectors,
we find that there is an underlying assumption of Cartesian, or standard,
coordinates that makes the expression of general tensor formulas difficult, if
not impossible. In introducing these new OpenMath symbols for the expression of
tensor formulas, we attempt to maintain, as much as possible, consistency with
prior OpenMath symbol definitions for linear algebra."
"Mathematical learning environments help students in mastering mathematical
knowledge. Mature environments typically offer thousands of interactive
exercises. Providing feedback to students solving interactive exercises
requires domain reasoners for doing the exercise-specific calculations. Since a
domain reasoner has to solve an exercise in the same way a student should solve
it, the structure of domain reasoners should follow the layered structure of
the mathematical domains. Furthermore, learners, teachers, and environment
builders have different requirements for adapting domain reasoners, such as
providing more details, disallowing or enforcing certain solutions, and
combining multiple mathematical domains in a new domain. In previous work we
have shown how domain reasoners for solving interactive exercises can be
expressed in terms of rewrite strategies, rewrite rules, and views. This paper
shows how users can adapt and configure such domain reasoners to their own
needs. This is achieved by enabling users to explicitly communicate the
components that are used for solving an exercise."
"This paper proposes a type of pseudorandom number generator, Mersenne Twister
for Graphic Processor (MTGP), for efficient generation on graphic processessing
units (GPUs). MTGP supports large state sizes such as 11213 bits, and uses the
high parallelism of GPUs in computing many steps of the recursion in parallel.
The second proposal is a parameter-set generator for MTGP, named MTGP Dynamic
Creator (MTGPDC). MT- GPDC creates up to 2^32 distinct parameter sets which
generate sequences with high-dimensional uniformity. This facility is suitable
for a large grid of GPUs where each GPU requires separate random number
streams. MTGP is based on linear recursion over the two-element field, and has
better high-dimensional equidistribution than the Mersenne Twister pseudorandom
number generator."
"The exact computation of orbits of discrete dynamical systems on the interval
is considered. Therefore, a multiple-precision floating point approach based on
error analysis is chosen and a general algorithm is presented. The correctness
of the algorithm is shown and the computational complexity is analyzed. As a
main result, the computational complexity measure considered here is related to
the Ljapunow exponent of the dynamical system under consideration."
"We present a Compression Tool, ""GenBit Compress"", for genetic sequences based
on our new proposed ""GenBit Compress Algorithm"". Our Tool achieves the best
compression ratios for Entire Genome (DNA sequences) . Significantly better
compression results show that GenBit compress algorithm is the best among the
remaining Genome compression algorithms for non-repetitive DNA sequences in
Genomes. The standard Compression algorithms such as gzip or compress cannot
compress DNA sequences but only expand them in size. In this paper we consider
the problem of DNA compression. It is well known that one of the main features
of DNA Sequences is that they contain substrings which are duplicated except
for a few random Mutations. For this reason most DNA compressors work by
searching and encoding approximate repeats. We depart from this strategy by
searching and encoding only exact repeats. our proposed algorithm achieves the
best compression ratio for DNA sequences for larger genome. As long as 8 lakh
characters can be given as input While achieving the best compression ratios
for DNA sequences, our new GenBit Compress program significantly improves the
running time of all previous DNA compressors. Assigning binary bits for
fragments of DNA sequence is also a unique concept introduced in this program
for the first time in DNA compression."
"In this work we describe an efficient implementation of a hierarchy of
algorithms for the decomposition of dense matrices over the field with two
elements (GF(2)). Matrix decomposition is an essential building block for
solving dense systems of linear and non-linear equations and thus much research
has been devoted to improve the asymptotic complexity of such algorithms. In
this work we discuss an implementation of both well-known and improved
algorithms in the M4RI library. The focus of our discussion is on a new variant
of the M4RI algorithm - denoted MMPF in this work -- which allows for
considerable performance gains in practice when compared to the previously
fastest implementation. We provide performance figures on x86_64 CPUs to
demonstrate the viability of our approach."
"Computing on graphics processors is maybe one of the most important
developments in computational science to happen in decades. Not since the
arrival of the Beowulf cluster, which combined open source software with
commodity hardware to truly democratize high-performance computing, has the
community been so electrified. Like then, the opportunity comes with
challenges. The formulation of scientific algorithms to take advantage of the
performance offered by the new architecture requires rethinking core methods.
Here, we have tackled fast summation algorithms (fast multipole method and fast
Gauss transform), and applied algorithmic redesign for attaining performance on
gpus. The progression of performance improvements attained illustrates the
exercise of formulating algorithms for the massively parallel architecture of
the gpu. The end result has been gpu kernels that run at over 500 Gigaflops on
one nvidia Tesla C1060 card, thereby reaching close to practical peak. We can
confidently say that gpu computing is not just a vogue, it is truly an
irresistible trend in high-performance computing."
"We examine aspects of the computation of finite element matrices and vectors
which are made possible by automated code generation. Given a variational form
in a syntax which resembles standard mathematical notation, the low-level
computer code for building finite element tensors, typically matrices, vectors
and scalars, can be generated automatically via a form compiler. In particular,
the generation of code for computing finite element matrices using a quadrature
approach is addressed. For quadrature representations, a number of optimisation
strategies which are made possible by automated code generation are presented.
The relative performance of two different automatically generated
representations of finite element matrices is examined, with a particular
emphasis on complicated variational forms. It is shown that approaches which
perform best for simple forms are not tractable for more complicated problems
in terms of run time performance, the time required to generate the code or the
size of the generated code. The approach and optimisations elaborated here are
effective for a range of variational forms."
"A compiler approach for generating low-level computer code from high-level
input for discontinuous Galerkin finite element forms is presented. The input
language mirrors conventional mathematical notation, and the compiler generates
efficient code in a standard programming language. This facilitates the rapid
generation of efficient code for general equations in varying spatial
dimensions. Key concepts underlying the compiler approach and the automated
generation of computer code are elaborated. The approach is demonstrated for a
range of common problems, including the Poisson, biharmonic,
advection--diffusion and Stokes equations."
"This paper describes a new accumulate-and-add multiplication algorithm. The
method partitions one of the operands and re-combines the results of
computations done with each of the partitions. The resulting design turns-out
to be both compact and fast.
  When the operands' bit-length $m$ is 1024, the new algorithm requires only
$0.194m+56$ additions (on average), this is about half the number of additions
required by the classical accumulate-and-add multiplication algorithm
($\frac{m}2$)."
"In this overview article we present several methods for multiplying matrices
and the implementation of these methods in C. Also a little test program is
given to compare their running time and the numerical stability.
  The methods are: naive method, naive method working on arrays, naive method
with the \textsc{Kahan} trick, three methods with loop unrolling, winograd
method and the scaled variant, original \textsc{Strassen} method and the
\textsc{Strassen}-\textsc{Winograd} variant.
  Please note, that this is the FIRST version. The algorithms are not well
tested and the implementation is not optimized. If you like to join the
project, please contact me."
"Vector operations play an important role in high performance computing and
are typically provided by highly optimized libraries that implement the BLAS
(Basic Linear Algebra Subprograms) interface. In C++ templates and operator
overloading allow the implementation of these vector operations as expression
templates which construct custom loops at compile time and providing a more
abstract interface. Unfortunately existing expression template libraries lack
the performance of fast BLAS(Basic Linear Algebra Subprograms) implementations.
This paper presents a new approach - Statically Accelerated Loop Templates
(SALT) - to close this performance gap by combining expression templates with
an aggressive loop unrolling technique. Benchmarks were conducted using the
Intel C++ compiler and GNU Compiler Collection to assess the performance of our
library relative to Intel's Math Kernel Library as well as the Eigen template
library. The results show that the approach is able to provide optimization
comparable to the fastest available BLAS implementations, while retaining the
convenience and flexibility of a template library."
"In this article we discuss the presentation of a random binary matrix using
sequence of whole nonnegative numbers. We examine some advantages and
disadvantages of this presentation as an alternative of the standard
presentation using two-dimensional array. It is shown that the presentation of
binary matrices using ordered n-tuples of natural numbers makes the algorithms
faster and saves a lot of memory. In this work we use object-oriented
programming using the syntax and the semantic of C++ programming language."
"In this document, we show how the different quantities necessary to compute
kernel quantum probabilities can be computed. This document form the basis of
the implementation of the Kernel Quantum Probability (KQP) open source project"
"This tutorial (based on the talk at the TeXmacs workshop in Faro, Portugal,
February 26 - March 2, 2012) describes the new and improved Reduce plugin in
GNU TeXmacs."
"In this paper we demonstrate a new technique for deriving discrete adjoint
and tangent linear models of finite element models. The technique is
significantly more efficient and automatic than standard algorithmic
differentiation techniques. The approach relies on a high-level symbolic
representation of the forward problem. In contrast to developing a model
directly in Fortran or C++, high-level systems allow the developer to express
the variational problems to be solved in near-mathematical notation. As such,
these systems have a key advantage: since the mathematical structure of the
problem is preserved, they are more amenable to automated analysis and
manipulation. The framework introduced here is implemented in a freely
available software package named dolfin-adjoint, based on the FEniCS Project.
Our approach to automated adjoint derivation relies on run-time annotation of
the temporal structure of the model, and employs the FEniCS finite element form
compiler to automatically generate the low-level code for the derived models.
The approach requires only trivial changes to a large class of forward models,
including complicated time-dependent nonlinear models. The adjoint model
automatically employs optimal checkpointing schemes to mitigate storage
requirements for nonlinear models, without any user management or intervention.
Furthermore, both the tangent linear and adjoint models naturally work in
parallel, without any need to differentiate through calls to MPI or to parse
OpenMP directives. The generality, applicability and efficiency of the approach
are demonstrated with examples from a wide range of scientific applications."
"This manual describes the library of conjugate gradients codes CCGPAK, which
solves system of complex linear system of equations. The library is written in
FORTRAN90 and is highly portable. The codes are general and provide mechanism
for matrix times vector multiplication which is separated from the conjugate
gradient iterations itself. It is simple to switch between single and double
precisions. All codes follow the same naming conventions."
"The traditional approach to investigating the stability of a physical system
is to linearise the equations about a steady base solution, and to examine the
eigenvalues of the linearised operator. Over the past several decades, it has
been recognised that this approach only determines the asymptotic stability of
the system, and neglects the possibility of transient perturbation growth
arising due to the nonnormality of the system. This observation motivated the
development of a more powerful generalised stability theory (GST), which
focusses instead on the singular value decomposition of the linearised
propagator of the system. While GST has had significant successes in
understanding the stability of phenomena in geophysical fluid dynamics, its
more widespread applicability has been hampered by the fact that computing the
SVD requires both the tangent linear operator and its adjoint: deriving the
tangent linear and adjoint models is usually a considerable challenge, and
manually embedding them inside an eigensolver is laborious. In this paper, we
present a framework for the automation of generalised stability theory, which
overcomes these difficulties. Given a compact high-level symbolic
representation of a finite element discretisation implemented in the FEniCS
system, efficient C++ code is automatically generated to assemble the forward,
tangent linear and adjoint models; these models are then used to calculate the
optimally growing perturbations to the forward model, and their growth rates.
By automating the stability computations, we hope to make these powerful tools
a more routine part of computational analysis. The efficiency and generality of
the framework is demonstrated with applications drawn from geophysical fluid
dynamics, phase separation and quantum mechanics."
"We introduce the Declaratron, a system which takes a declarative approach to
specifying mathematically based scientific computation. This uses displayable
mathematical notation (Content MathML) and is both executable and semantically
well defined. We combine domain specific representations of physical science
(e.g. CML, Chemical Markup Language), MathML formulae and computational
specifications (DeXML) to create executable documents which include scientific
data and mathematical formulae. These documents preserve the provenance of the
data used, and build tight semantic links between components of mathematical
formulae and domain objects---in effect grounding the mathematical semantics in
the scientific domain. The Declaratron takes these specifications and i)
carries out entity resolution and decoration to prepare for computation ii)
uses a MathML execution engine to run calculations over the revised tree iii)
outputs domain objects and the complete document to give both results and an
encapsulated history of the computation. A short description of a case study is
given to illustrate how the system can be used. Many scientific problems
require frequent change of the mathematical functional form and the Declaratron
provides this without requiring changes to code. Additionally, it supports
reproducible science, machine indexing and semantic search of computations,
makes implicit assumptions visible, and separates domain knowledge from
computational techniques. We believe that the Declaratron could replace much
conventional procedural code in science."
"All but a few digital computers used for scientific computations have
supported floating-point and digital arithmetic of rather limited numerical
precision. The underlying assumptions were that the systems being studied were
basically deterministic and of limited complexity. The ideal scientific
paradigm was the orbits of the major planets, which could be observed with high
precision, predicted for thousands of years into the future, and extrapolated
for thousands of years into the past. Much the same technology that has made
computers possible has also provided instrumentation that has vastly expanded
the scope and precision of scientific analysis. Complex nonlinear systems
exhibiting so-called chaotic dynamics are now fair game for scientists and
engineers in every discipline. Today it seems that computers need to enhance
the precision of their numerical computations to support the needs of science.
However, there is no need to wait for the necessary updates in both hardware
and software; it is easy enough to monitor numerical precision with a few minor
modifications to existing software."
"In this paper, we propose a procedure for designing controlled test problems
for single-objective bilevel optimization. The construction procedure is
flexible and allows its user to control the different complexities that are to
be included in the test problems independently of each other. In addition to
properties that control the difficulty in convergence, the procedure also
allows the user to introduce difficulties caused by interaction of the two
levels. As a companion to the test problem construction framework, the paper
presents a standard test suite of twelve problems, which includes eight
unconstrained and four constrained problems. Most of the problems are scalable
in terms of variables and constraints. To provide baseline results, we have
solved the proposed test problems using a nested bilevel evolutionary
algorithm. The results can be used for comparison, while evaluating the
performance of any other bilevel optimization algorithm. The codes related to
the paper may be accessed from the website \url{http://bilevel.org}."
"The article presents the general notions and algorithm about the Gauss-Jordan
method. An eloquent example is given and the Turbo C program illustrated this
method. We conclude that we can obtain by this method the determinant, by
simple calculations and reducing the rounding errors"
"We present HONEI, an open-source collection of libraries offering a hardware
oriented approach to numerical calculations. HONEI abstracts the hardware, and
applications written on top of HONEI can be executed on a wide range of
computer architectures such as CPUs, GPUs and the Cell processor. We
demonstrate the flexibility and performance of our approach with two test
applications, a Finite Element multigrid solver for the Poisson problem and a
robust and fast simulation of shallow water waves. By linking against HONEI's
libraries, we achieve a twofold speedup over straight forward C++ code using
HONEI's SSE backend, and additional 3-4 and 4-16 times faster execution on the
Cell and a GPU. A second important aspect of our approach is that the full
performance capabilities of the hardware under consideration can be exploited
by adding optimised application-specific operations to the HONEI libraries.
HONEI provides all necessary infrastructure for development and evaluation of
such kernels, significantly simplifying their development."
"Mathematical educational soft explore, investigating in a dynamical way, some
algebraically, geometrically problems, the expected results being used to
involve a lot of mathematical results. One such software soft is GeoGebra. The
software is free and multi-platform dynamic mathematics software for learning
and teaching, awards in Europe and the USA. This paper describes some critical
but constructive investigation using the platform for graph functions and
dynamic geometry."
"This work wishes to support various mathematical issues concerning the
iterative methods with the help of new programming languages. We consider a way
to show how problems in math have an answer by using different academic
resources and different thoughts. Here we treat methods like Gauss-Seidel's,
Cramer's and Gauss-Jordan's."
"In the Python world, NumPy arrays are the standard representation for
numerical data. Here, we show how these arrays enable efficient implementation
of numerical computations in a high-level language. Overall, three techniques
are applied to improve performance: vectorizing calculations, avoiding copying
data in memory, and minimizing operation counts. We first present the NumPy
array structure, then show how to use it for efficient computation, and finally
how to share array data with other libraries."
"We present an XML-based simulation authoring environment. The proposed
description language allows to describe mathematical objects such as systems of
ordinary differential equations, partial differential equations in two
dimensions, or simple curves and surfaces. It also allows to describe the
parameters on which these objects depend. This language is independent of the
target software and allows to ensure the perennity of author's work, as well as
collaborative work and content reuse. The actual implementation of XMLlab
allows to run the generated simulations within the open source mathematical
software Scilab, either locally when Scilab is installed on the client
machines, or on thin clients running a simple web browser, when XMLlab and
Scilab are installed on a distant server running a standard HTTP server."
"As users and developers, we are witnessing the opening of a new computing
scenario: the introduction of hybrid processors into a single die, such as an
accelerated processing unit (APU) processor, and the plug-and-play of
additional graphics processing units (GPUs) onto a single motherboard. These
APU processors provide multiple symmetric cores with their memory hierarchies
and an integrated GPU. Moreover, these processors are designed to work with
external GPUs that can push the peak performance towards the TeraFLOPS
boundary. We present a case study for the development of dense Matrix
Multiplication (MM) codes for matrix sizes up to 19K\times19K, thus using all
of the above computational engines, and an achievable peak performance of 200
GFLOPS for, literally, a made- at-home built. We present the results of our
experience, the quirks, the pitfalls, the achieved performance, and the
achievable peak performance."
"The paper considers the problem of implementation on graphics processors of
numerical integration routines for higher order finite element approximations.
The design of suitable GPU kernels is investigated in the context of general
purpose integration procedures, as well as particular example applications. The
most important characteristic of the problem investigated is the large
variation of required processor and memory resources associated with different
degrees of approximating polynomials. The questions that we try to answer are
whether it is possible to design a single integration kernel for different GPUs
and different orders of approximation and what performance can be expected in
such a case."
"In our work we analyze computational aspects of the problem of numerical
integration in finite element calculations and consider an OpenCL
implementation of related algorithms for processors with wide vector registers.
  As a platform for testing the implementation we choose the PowerXCell
processor, being an example of the Cell Broadband Engine (CellBE) architecture.
Although the processor is considered old for today's standards (its design
dates back to year 2001), we investigate its performance due to two features
that it shares with recent Xeon Phi family of coprocessors: wide vector units
and relatively slow connection of computing cores with main global memory. The
performed analysis of parallelization options can also be used for designing
numerical integration algorithms for other processors with vector registers,
such as contemporary x86 microprocessors."
"This dissertation focuses on the design and the implementation of
domain-specific compilers for linear algebra matrix equations. The development
of efficient libraries for such equations, which lie at the heart of most
software for scientific computing, is a complex process that requires expertise
in a variety of areas, including the application domain, algorithms, numerical
analysis and high-performance computing. Moreover, the process involves the
collaboration of several people for a considerable amount of time. With our
compilers, we aim to relieve the developers from both designing algorithms and
writing code, and to generate routines that match or even surpass the
performance of those written by human experts."
"It is shown how the Python library Sympy can be used to compute symbolically
the coefficients of the power series solution of the Lane-Emden equation (LEE).
Sympy is an open source Python library for symbolic mathematics. The power
series solutions are compared to the numerically computed solutions using
matplotlib. The results of a run time measurement of the implemented algorithm
are discussed at the end."
"The aim of this paper is to describe a Matlab toolbox, called $\mu$-diff, for
modeling and numerically solving two-dimensional complex multiple scattering by
a large collection of circular cylinders. The approximation methods in
$\mu$-diff are based on the Fourier series expansions of the four basic
integral operators arising in scattering theory. Based on these expressions, an
efficient spectrally accurate finite-dimensional solution of multiple
scattering problems can be simply obtained for complex media even when many
scatterers are considered as well as large frequencies. The solution of the
global linear system to solve can use either direct solvers or preconditioned
iterative Krylov subspace solvers for block Toeplitz matrices. Based on this
approach, this paper explains how the code is built and organized. Some
complete numerical examples of applications (direct and inverse scattering) are
provided to show that $\mu$-diff is a flexible, efficient and robust toolbox
for solving some complex multiple scattering problems."
"On modern architectures, the performance of 32-bit operations is often at
least twice as fast as the performance of 64-bit operations. By using a
combination of 32-bit and 64-bit floating point arithmetic, the performance of
many dense and sparse linear algebra algorithms can be significantly enhanced
while maintaining the 64-bit accuracy of the resulting solution. The approach
presented here can apply not only to conventional processors but also to other
technologies such as Field Programmable Gate Arrays (FPGA), Graphical
Processing Units (GPU), and the STI Cell BE processor. Results on modern
processor architectures and the STI Cell BE are presented."
"This paper presents the graphic representation in the z-plane of the first
three iterations of the algorithm that generates the Sierpinski Gasket. It
analyzes the influence of the f(z) map when we represent fractal images."
"The present study represents ""The Fislab package of programs meant to develop
the fuzzy regulators in the Scilab environment"" in which we present some
general issues, usage requirements and the working mode of the Fislab
environment. In the second part of the article some features of the Scilab
functions from the Fislab package are described."
"The present article is a sequel of the article ""Fislab the Fuzzy Inference
Tool-Box for Scilab"" and it represents the practical application of:""The
development of the Fuzzy regulator with an input and an output in Fislab"". The
article contains, besides this application, some functions to be used in the
program, namely Scilab functions for the fuzzification of the firm information,
functions for the operation of de-fuzzification and functions for the
implementation of."
"The study deals with the parallelization of 2D and 3D finite element based
Navier-Stokes codes using direct solvers. Development of sparse direct solvers
using multifrontal solvers has significantly reduced the computational time of
direct solution methods. Although limited by its stringent memory requirements,
multifrontal solvers can be computationally efficient. First the performance of
MUltifrontal Massively Parallel Solver (MUMPS) is evaluated for both 2D and 3D
codes in terms of memory requirements and CPU times. The scalability of both
Newton and modified Newton algorithms is tested."
"In this paper we present a method for matrix inversion based on Cholesky
decomposition with reduced number of operations by avoiding computation of
intermediate results; further, we use fixed point simulations to compare the
numerical accuracy of the method."
"In this work, we present the M4RIE library which implements efficient
algorithms for linear algebra with dense matrices over GF(2^e) for 2 <= 2 <=
10. As the name of the library indicates, it makes heavy use of the M4RI
library both directly (i.e., by calling it) and indirectly (i.e., by using its
concepts). We provide an open-source GPLv2+ C library for efficient linear
algebra over GF(2^e) for e small. In this library we implemented an idea due to
Bradshaw and Boothby which reduces matrix multiplication over GF(p^k) to a
series of matrix multiplications over GF(p). Furthermore, we propose a caching
technique - Newton-John tables - to avoid finite field multiplications which is
inspired by Kronrod's method (""M4RM"") for matrix multiplication over GF(2).
Using these two techniques we provide asymptotically fast triangular solving
with matrices (TRSM) and PLE-based Gaussian elimination. As a result, we are
able to significantly improve upon the state of the art in dense linear algebra
over GF(2^e) with 2 <= e <= 10."
"Sparse storage formats are techniques for storing and processing the sparse
matrix data efficiently. The performance of these storage formats depend upon
the distribution of non-zeros, within the matrix in different dimensions. In
order to have better results we need a technique that suits best the
organization of data in a particular matrix. So the decision of selecting a
better technique is the main step towards improving the system's results
otherwise the efficiency can be decreased. The purpose of this research is to
help identify the best storage format in case of reduced storage size and high
processing efficiency for a sparse matrix."
"This article discusses an efficient implementation of tensors of arbitrary
rank by using some of the idioms introduced by the recently published C++ ISO
Standard (C++11). With the aims at providing a basic building block for
high-performance computing, a single Array class template is carefully crafted,
from which vectors, matrices, and even higher-order tensors can be created. An
expression template facility is also built around the array class template to
provide convenient mathematical syntax. As a result, by using templates, an
extra high-level layer is added to the C++ language when dealing with algebraic
objects and their operations, without compromising performance. The
implementation is tested running on both CPU and GPU."
"A generic framework for the solution of PDE-constrained optimisation problems
based on the FEniCS system is presented. Its main features are an intuitive
mathematical interface, a high degree of automation, and an efficient
implementation of the generated adjoint model. The framework is based upon the
extension of a domain-specific language for variational problems to cleanly
express complex optimisation problems in a compact, high-level syntax. For
example, optimisation problems constrained by the time-dependent Navier-Stokes
equations can be written in tens of lines of code. Based on this high-level
representation, the framework derives the associated adjoint equations in the
same domain-specific language, and uses the FEniCS code generation technology
to emit parallel optimised low-level C++ code for the solution of the forward
and adjoint systems. The functional and gradient information so computed is
then passed to the optimisation algorithm to update the parameter values. This
approach works both for steady-state as well as transient, and for linear as
well as nonlinear governing PDEs and a wide range of functionals and control
parameters. We demonstrate the applicability and efficiency of this approach on
classical textbook optimisation problems and advanced examples."
"We present a new hybrid paradigm for parallel adaptive mesh refinement (AMR)
that combines the scalability and lightweight architecture of tree-based AMR
with the computational efficiency of patch-based solvers for hyperbolic
conservation laws. The key idea is to interpret each leaf of the AMR hierarchy
as one uniform compute patch in $\sR^d$ with $m^d$ degrees of freedom, where
$m$ is customarily between 8 and 32. Thus, computation on each patch can be
optimized for speed, while we inherit the flexibility of adaptive meshes. In
our work we choose to integrate with the p4est AMR library since it allows us
to compose the mesh from multiple mapped octrees and enables the cubed sphere
and other nontrivial multiblock geometries. We describe aspects of the parallel
implementation and close with scalings for both MPI-only and OpenMP/MPI hybrid
runs, where the largest MPI run executes on 16,384 CPU cores."
"Conversion between binary and decimal floating-point representations is
ubiquitous. Floating-point radix conversion means converting both the exponent
and the mantissa. We develop an atomic operation for FP radix conversion with
simple straight-line algorithm, suitable for hardware design. Exponent
conversion is performed with a small multiplication and a lookup table. It
yields the correct result without error. Mantissa conversion uses a few
multiplications and a small lookup table that is shared amongst all types of
conversions. The accuracy changes by adjusting the computing precision."
"The mean and variance of the number of appearances of a given subgraph $H$ in
an Erd\H{o}s--R\'enyi random graph over $n$ nodes are rational polynomials in
$n$. We present a piece of software named Polcovar (from ""polynomial"" and
""covariance"") that computes the exact rational coefficients of these
polynomials in function of $H$."
"The Ziggurat Algorithm is a very fast rejection sampling method for
generating PseudoRandom Numbers (PRNs) from common statistical distributions.
The algorithm divides a distribution into rectangular layers that stack on top
of each other (resembling a Ziggurat), subsuming the desired distribution.
Random values within these rectangular layers are then sampled by rejection.
This implementation splits layers into two types: those constituting the
majority that fall completely under the distribution and can be sampled
extremely fast without a rejection test, and a few additional layers that
encapsulate the fringe of the distribution and require a rejection test. This
method offers speedups of 65% for exponentially- and 82% for
normally-distributed PRNs when compared to the best available C implementations
of these generators. Even greater speedups are obtained when the algorithm is
extended to the Python and MATLAB/OCTAVE programming environments."
"Many problems in computational science and engineering involve partial
differential equations and thus require the numerical solution of large, sparse
(non)linear systems of equations. Multigrid is known to be one of the most
efficient methods for this purpose. However, the concrete multigrid algorithm
and its implementation highly depend on the underlying problem and hardware.
Therefore, changes in the code or many different variants are necessary to
cover all relevant cases. In this article we provide a prototype implementation
in Scala for a framework that allows abstract descriptions of PDEs, their
discretization, and their numerical solution via multigrid algorithms. From
these, one is able to generate data structures and implementations of multigrid
components required to solve elliptic PDEs on structured grids. Two different
test problems showcase our proposed automatic generation of multigrid solvers
for both CPU and GPU target platforms."
"The presented work is part of a larger research program dealing with
developing tools for coupling biogeochemical models in contaminated landscapes.
The specific objective of this article is to provide the researchers a tool to
build hexagonal raster using information from a rectangular raster data (e.g.
GIS format), data porting. This tool involves a computational algorithm and an
open source software (written in C). The method of extending the reticulated
functions defined on 2D networks is an essential key of this algorithm and can
also be used for other purposes than data porting. The algorithm allows one to
build the hexagonal raster with a cell size independent from the geometry of
the rectangular raster. The extended function is a bi-cubic spline which can
exactly reconstruct polynomials up to degree three in each variable. We
validate the method by analyzing errors in some theoretical case studies
followed by other studies with real terrain elevation data. We also introduce
and briefly present an iterative water routing method and use it for validation
on a case with concrete terrain data."
"Modular integer arithmetic occurs in many algorithms for computer algebra,
cryptography, and error correcting codes. Although recent microprocessors
typically offer a wide range of highly optimized arithmetic functions, modular
integer operations still require dedicated implementations. In this article, we
survey existing algorithms for modular integer arithmetic, and present detailed
vectorized counterparts. We also present several applications, such as fast
modular Fourier transforms and multiplication of integer polynomials and
matrices. The vectorized algorithms have been implemented in C++ inside the
free computer algebra and analysis system Mathemagix. The performance of our
implementation is illustrated by various benchmarks."
"Various fields of science and engineering rely on linear algebra for large
scale data analysis, modeling and simulation, machine learning, and other
applied problems. Linear algebra computations often dominate the execution time
of such applications. Meanwhile, experts in these domains typically lack the
training or time required to develop efficient, high-performance
implementations of linear algebra algorithms. In the Lighthouse project, we
enable developers with varied backgrounds to readily discover and effectively
apply the best available numerical software for their problems. We have
developed a search-based expert system that combines expert knowledge, machine
learningbased classification of existing numerical software collections, and
automated code generation and optimization. Lighthouse provides a novel
software engineering environment aimed at maximizing both developer
productivity and application performance for dense and sparse linear algebra
computations."
"Revisionist integral deferred correction (RIDC) methods are a family of
parallel--in--time methods to solve systems of initial values problems. The
approach is able to bootstrap lower order time integrators to provide high
order approximations in approximately the same wall clock time, hence providing
a multiplicative increase in the number of compute cores utilized. Here we
provide a C++ framework which automatically produces a parallel--in--time
solution of a system of initial value problems given user supplied code for the
right hand side of the system and a sequential code for a first-order time
step. The user supplied time step routine may be explicit or implicit and may
make use of any auxiliary libraries which take care of the solution of any
nonlinear algebraic systems which may arise or the numerical linear algebra
required. The code contains six examples of increasing complexity which also
serve as templates to solve user defined problems."
"KBLAS is a new open source high performance library that provides optimized
kernels for a subset of Level 2 BLAS functionalities on CUDA-enabled GPUs.
Since performance of dense matrix-vector multiplication is hindered by the
overhead of memory accesses, a double-buffering optimization technique is
employed to overlap data motion with computation. After identifying a proper
set of tuning parameters, KBLAS is able to efficiently run on various GPU
architectures across different generations, avoiding the time-consuming step of
code rewriting, while still being compliant with the standard BLAS API. Another
advanced optimization technique allows to ensure coalesced memory access when
dealing with submatrices, especially in the context of high level dense linear
algebra algorithms. All four precisions KBLAS kernels have been leveraged to
multi-GPUs environment, which requires the introduction of new APIs to ease
users' experiences on these challenging systems. The KBLAS performance
outperforms existing state-of-the-art implementations on all matrix sizes,
achieves asymptotically up to 50% and 60% speedup on single GPU and multi-GPUs
systems, respectively, and validates our performance model. A subset of KBLAS
high performance kernels has been integrated into NVIDIA's standard BLAS
implementation (cuBLAS) for larger dissemination, starting version 6.0."
"Bridging cultures that have often been distant, Julia combines expertise from
the diverse fields of computer science and computational science to create a
new approach to numerical computing. Julia is designed to be easy and fast.
Julia questions notions generally held as ""laws of nature"" by practitioners of
numerical computing:
  1. High-level dynamic programs have to be slow.
  2. One must prototype in one language and then rewrite in another language
for speed or deployment, and
  3. There are parts of a system for the programmer, and other parts best left
untouched as they are built by the experts.
  We introduce the Julia programming language and its design --- a dance
between specialization and abstraction. Specialization allows for custom
treatment. Multiple dispatch, a technique from computer science, picks the
right algorithm for the right circumstance. Abstraction, what good computation
is really about, recognizes what remains the same after differences are
stripped away. Abstractions in mathematics are captured as code through another
technique from computer science, generic programming.
  Julia shows that one can have machine performance without sacrificing human
convenience."
"Here I propose C and C++ interfaces and experimental implementation for
twofolds arithmetic. I introduce twofolds in my previous article entitled
""Twofold fast arithmetic"" for tracking floating-point inaccuracy. Testing
shows, plain C enables high-performance computing with twofolds. C++ interface
enables coding as easily as ordinary floating-point numbers. My goal is
convincing you to try twofolds; I think assuring accuracy of math computations
is worth its cost. Code and use examples available at my web site, references
inside."
"A theorem which is named after the American Mathematician Moris Marden states
a very surprising and interesting fact concerning the relationship between the
points of a triangle in the complex plane and the zeros of two complex
polynomials related to this triangle: ""Suppose the zeroes z1, z2, and z3 of a
third-degree polynomial p(z) are non-collinear. There is a unique ellipse
inscribed in the triangle with vertices z1, z2, z3 and tangent to the sides at
their midpoints: the Steiner in-ellipse. The foci of that ellipse are the
zeroes of the derivative p'(z)."" (Wikipedia contributors, ""Marden's theorem"",
http://en.wikipedia.org/wiki/Marden%27s_theorem). This document describes how
Scilab, a popular and powerful open source alternative to MATLAB, can be used
to visualize the above stated theorem for arbitrary complex numbers z1, z2, and
z3 which are not collinear. It is further demonstrated how the equations of the
Steiner ellipses of a triangle in the complex plane can be calculated and
plotted by applying this theorem."
"This article is about twofold arithmetic. Here I introduce algorithms and
experimental code for twofold variant of C/C++ standard functions exp() and
log(), and expm1() and log1p(). Twofold function $y_0+y_1 \approx f(x_0+x_1)$
is nearly 2x-precise so can assess accuracy of standard one. Performance allows
assessing on-fly: twofold texp() over double is ~10x times faster than expq()
by GNU quadmath."
"We present a sparse linear system solver that is based on a multifrontal
variant of Gaussian elimination, and exploits low-rank approximation of the
resulting dense frontal matrices. We use hierarchically semiseparable (HSS)
matrices, which have low-rank off-diagonal blocks, to approximate the frontal
matrices. For HSS matrix construction, a randomized sampling algorithm is used
together with interpolative decompositions. The combination of the randomized
compression with a fast ULV HSS factorization leads to a solver with lower
computational complexity than the standard multifrontal method for many
applications, resulting in speedups up to 7 fold for problems in our test
suite. The implementation targets many-core systems by using task parallelism
with dynamic runtime scheduling. Numerical experiments show performance
improvements over state-of-the-art sparse direct solvers. The implementation
achieves high performance and good scalability on a range of modern shared
memory parallel systems, including the Intel Xeon Phi (MIC). The code is part
of a software package called STRUMPACK -- STRUctured Matrices PACKage, which
also has a distributed memory component for dense rank-structured matrices."
"The Sch\""onhage-Strassen algorithm (SSA) is the de-facto standard for
multiplication of large integers. For $N$-bit numbers it has a time bound of
$O(N \cdot \log N \cdot \log \log N)$. De, Kurur, Saha and Saptharishi (DKSS)
presented an asymptotically faster algorithm with a better time bound of $N
\cdot \log N \cdot 2^{O(\log^* N)}$. In this diploma thesis, results of an
implementation of DKSS multiplication are presented: run-time is about 30 times
larger than SSA, while memory requirements are about 3.75 times higher than
SSA. A possible crossover point is estimated to be out of reach even if we
utilized the whole universe for computer memory."
"We present a distributed-memory library for computations with dense
structured matrices. A matrix is considered structured if its off-diagonal
blocks can be approximated by a rank-deficient matrix with low numerical rank.
Here, we use Hierarchically Semi-Separable representations (HSS). Such matrices
appear in many applications, e.g., finite element methods, boundary element
methods, etc. Exploiting this structure allows for fast solution of linear
systems and/or fast computation of matrix-vector products, which are the two
main building blocks of matrix computations. The compression algorithm that we
use, that computes the HSS form of an input dense matrix, relies on randomized
sampling with a novel adaptive sampling mechanism. We discuss the
parallelization of this algorithm and also present the parallelization of
structured matrix-vector product, structured factorization and solution
routines. The efficiency of the approach is demonstrated on large problems from
different academic and industrial applications, on up to 8,000 cores.
  This work is part of a more global effort, the STRUMPACK (STRUctured Matrices
PACKage) software package for computations with sparse and dense structured
matrices. Hence, although useful on their own right, the routines also
represent a step in the direction of a distributed-memory sparse solver."
"Automatic and adaptive approximation, optimization, or integration of
functions in a cone with guarantee of accuracy is a relatively new paradigm.
Our purpose is to create an open-source MATLAB package, Guaranteed Automatic
Integration Library (GAIL), following the philosophy of reproducible research
and sustainable practices of robust scientific software development. For our
conviction that true scholarship in computational sciences are characterized by
reliable reproducibility, we employ the best practices in mathematical research
and software engineering known to us and available in MATLAB. This document
describes the key features of functions in GAIL, which includes one-dimensional
function approximation and minimization using linear splines, one-dimensional
numerical integration using trapezoidal rule, and last but not least, mean
estimation and multidimensional integration by Monte Carlo methods or Quasi
Monte Carlo methods."
"The paper presents investigations on the implementation and performance of
the finite element numerical integration algorithm for first order
approximations and three processor architectures, popular in scientific
computing, classical CPU, Intel Xeon Phi and NVIDIA Kepler GPU. A unifying
programming model and portable OpenCL implementation is considered for all
architectures. Variations of the algorithm due to different problems solved and
different element types are investigated and several optimizations aimed at
proper optimization and mapping of the algorithm to computer architectures are
demonstrated. Performance models of execution are developed for different
processors and tested in practical experiments. The results show the varying
levels of performance for different architectures, but indicate that the
algorithm can be effectively ported to all of them. The general conclusion is
that the finite element numerical integration can achieve sufficient
performance on different multi- and many-core architectures and should not
become a performance bottleneck for finite element simulation codes. Specific
observations lead to practical advises on how to optimize the kernels and what
performance can be expected for the tested architectures."
"In this paper we present two different variants of method for symmetric
matrix inversion, based on modified Gaussian elimination. Both methods avoid
computation of square roots and have a reduced machine time's spending.
Further, both of them can be used efficiently not only for positive (semi-)
definite, but for any non-singular symmetric matrix inversion. We use
simulation to verify results, which represented in this paper."
"Most numerical solvers and libraries nowadays are implemented to use
mathematical models created with language-specific built-in data types (e.g.
real in Fortran or double in C) and their respective elementary algebra
implementations. However, built-in elementary algebra typically has limited
functionality and often restricts flexibility of mathematical models and
analysis types that can be applied to those models. To overcome this
limitation, a number of domain-specific languages with more feature-rich
built-in data types have been proposed. In this paper, we argue that if
numerical libraries and solvers are designed to use abstract elementary algebra
rather than language-specific built-in algebra, modern mainstream languages can
be as effective as any domain-specific language. We illustrate our ideas using
the example of sparse Jacobian matrix computation. We implement an automatic
differentiation method that takes advantage of sparse system structures and is
straightforward to parallelize in MPI setting. Furthermore, we show that the
computational cost scales linearly with the size of the system."
"The purpose of this project is to collect symbol information in the Mizar
Mathematical Library and manipulate it into practical and organized
documentation. Inspired by the MathWiki project and API reference systems for
computer programs, we developed a documentation generator focusing on symbols
for the HTML-ized Mizar library. The system has several helpful features,
including a symbol list, incremental search, and a referrer list. It targets
those who use proof assistance systems, the volume of whose libraries has been
rapidly increasing year by year."
"Designing a scientific software stack to meet the needs of the
next-generation of mesh-based simulation demands, not only scalable and
efficient mesh and data management on a wide range of platforms, but also an
abstraction layer that makes it useful for a wide range of application codes.
Common utility tasks, such as file I/O, mesh distribution, and work
partitioning, should be delegated to external libraries in order to promote
code re-use, extensibility and software interoperability. In this paper we
demonstrate the use of PETSc's DMPlex data management API to perform mesh input
and domain partitioning in Fluidity, a large scale CFD application. We
demonstrate that raising the level of abstraction adds new functionality to the
application code, such as support for additional mesh file formats and mesh re-
ordering, while improving simulation startup cost through more efficient mesh
distribution. Moreover, the separation of concerns accomplished through this
interface shifts critical performance and interoperability issues, such as
scalable I/O and file format support, to a widely used and supported open
source community library, improving the sustainability, performance, and
functionality of Fluidity."
"This paper introduces a binary encoding that supports arbitrarily large,
small and precise decimals. It completely preserves information and order. It
does not rely on any arbitrary use-case-based choice of calibration and is
readily implementable and usable, as is. Finally, it is also simple to explain
and understand."
"We introduce the third generation of Peano, a framework for dynamically
adaptive Cartesian meshes derived from spacetrees. Peano ties the mesh
traversal to the mesh storage and supports only one particular element-wise
traversal order resulting from space-filling curves. Its traversal thus can
exploit regular grid subregions and shared memory as well as distributed memory
systems with almost no modifications to a serial application code. Relying on a
formalism of the software design at hands of two interacting automata---one
automaton for the multiscale grid traversal and one for the
application-specific algorithmic steps---we discuss Peano's callback-based
programming paradigm, supported application types and the two data storage
schemes realised, before we detail high-performance computing aspects of the
software. Benchmarks highlight the code's potential. We put special emphasis on
a classification of the realised programming and algorithmic concepts against
alternative approaches candidating for spacetree meshes. This transforms our
ideas from a ""one way to implement things"" discussion into generic patterns
which can be used in other adaptive mesh refinement software."
"The use of composable abstractions allows the application of new and
established algorithms to a wide range of problems while automatically
inheriting the benefits of well-known performance optimisations. This work
highlights the composition of the PETSc DMPlex domain topology abstraction with
the Firedrake automated finite element system to create a PDE solving
environment that combines expressiveness, flexibility and high performance. We
describe how Firedrake utilises DMPlex to provide the indirection maps required
for finite element assembly, while supporting various mesh input formats and
runtime domain decomposition. In particular, we describe how DMPlex and its
accompanying data structures allow the generic creation of user-defined
discretisations, while utilising data layout optimisations that improve cache
coherency and ensure overlapped communication during assembly computation."
"Linear algebra routines are basic building blocks for the statistical
software. In this paper we analyzed how can we can improve R performance for
matrix computations. We benchmarked few matrix operations using the standard
linear algebra libraries included in the R distribution and high performance
libraries like OpenBLAS, GotoBLAS and MKL. Our tests showed the the best
results are obtained with the MKL library, the other two libraries having
similar performances, but lower than MKL"
"PETSc's DMPlex interface for unstructured meshes has been extended to support
non-conformal meshes. The topological construct that DMPlex implements---the
CW-complex---is by definition conformal, so representing non- conformal meshes
in a way that hides complexity requires careful attention to the interface
between DMPlex and numerical methods such as the finite element method. Our
approach---which combines a tree structure for subset- superset relationships
and a ""reference tree"" describing the types of non-conformal
interfaces---allows finite element code written for conformal meshes to extend
automatically: in particular, all ""hanging-node"" constraint calculations are
handled behind the scenes. We give example code demonstrating the use of this
extension, and use it to convert forests of quadtrees and forests of octrees
from the p4est library to DMPlex meshes."
"We introduce a family of implementations of low order, additive, geometric
multilevel solvers for systems of Helmholtz equations. Both grid spacing and
arithmetics may comprise complex numbers and we thus can apply complex scaling
techniques to the indefinite Helmholtz operator. Our implementations are based
upon the notion of a spacetree and work exclusively with a finite number of
precomputed local element matrices. They are globally matrix-free.
  Combining various relaxation factors with two grid transfer operators allows
us to switch from pure additive multigrid over a hierarchical basis method into
BPX with several multiscale smoothing variants within one code base. Pipelining
allows us to realise a full approximation storage (FAS) scheme within the
additive environment where, amortised, each grid vertex carrying degrees of
freedom is read/written only once per iteration. The codes thus realise a
single-touch policy. Among the features facilitated by matrix-free FAS is
arbitrary dynamic mesh refinement (AMR) for all solver variants. AMR as enabler
for full multigrid (FMG) cycling---the grid unfolds throughout the
computation---allows us to reduce the cost per unknown per order of accuracy.
  The present paper primary contributes towards software realisation and design
questions. Our experiments show that the consolidation of single-touch FAS,
dynamic AMR and vectorisation-friendly, complex scaled, matrix-free FMG cycles
delivers a mature implementation blueprint for solvers for a non-trivial class
of problems such as Helmholtz equations. Besides this validation, we put
particular emphasis on a strict implementation formalism as well as some
implementation correctness proofs."
"We present an application for the calculation of radial distribution
functions for molecular centres of mass, based on trajectories generated by
molecular simulation methods (Molecular Dynamics, Monte Carlo). When designing
this application, the emphasis was placed on ease of use as well as ease of
further development. In its current version, the program can read trajectories
generated by the well-known DL_POLY package, but it can be easily extended to
treat other formats. It is also very easy to 'hack' the program so it can
compute intermolecular radial distribution functions for groups of interaction
sites rather than whole molecules."
"This article describes our experience developing and maintaining automated
tests for scientific applications. The main idea evolves around building on
already existing tests by cloning and grafting. The idea is demonstrated on a
minimal model problem written in Python."
"We present Rust-Bio, the first general purpose bioinformatics library for the
innovative Rust programming language. Rust-Bio leverages the unique combination
of speed, memory safety and high-level syntax offered by Rust to provide a fast
and safe set of bioinformatics algorithms and data structures with a focus on
sequence analysis."
"As computational challenges in optimization and statistical inference grow
ever harder, algorithms that utilize derivatives are becoming increasingly more
important. The implementation of the derivatives that make these algorithms so
powerful, however, is a substantial user burden and the practicality of these
algorithms depends critically on tools like automatic differentiation that
remove the implementation burden entirely. The Stan Math Library is a C++,
reverse-mode automatic differentiation library designed to be usable, extensive
and extensible, efficient, scalable, stable, portable, and redistributable in
order to facilitate the construction and utilization of such algorithms.
  Usability is achieved through a simple direct interface and a cleanly
abstracted functional interface. The extensive built-in library includes
functions for matrix operations, linear algebra, differential equation solving,
and most common probability functions. Extensibility derives from a
straightforward object-oriented framework for expressions, allowing users to
easily create custom functions. Efficiency is achieved through a combination of
custom memory management, subexpression caching, traits-based metaprogramming,
and expression templates. Partial derivatives for compound functions are
evaluated lazily for improved scalability. Stability is achieved by taking care
with arithmetic precision in algebraic expressions and providing stable,
compound functions where possible. For portability, the library is
standards-compliant C++ (03) and has been tested for all major compilers for
Windows, Mac OS X, and Linux."
"Block operations during simulation in Scicos and VSS environments can
naturally be described as Nsp functions. But the direct use of Nsp functions
for simulation leads to poor performance since the Nsp language is interpreted,
not compiled. The methodology presented in this paper is used to develop a tool
for generating efficient compilable code, such as C and ADA, for Scicos and VSS
models from these block Nsp functions. Operator overloading and partial
evaluation are the key elements of this novel approach. This methodology may be
used in other simulation environments such as Matlab/Simulink."
"The efficiency of boundary element methods depends crucially on the time
required for setting up the stiffness matrix. The far-field part of the matrix
can be approximated by compression schemes like the fast multipole method or
$\mathcal{H}$-matrix techniques. The near-field part is typically approximated
by special quadrature rules like the Sauter-Schwab technique that can handle
the singular integrals appearing in the diagonal and near-diagonal matrix
elements.
  Since computing one element of the matrix requires only a small amount of
data but a fairly large number of operations, we propose to use GPUs to handle
vectorizable portions of the computation: near-field computations are ideally
suited for vectorization and can therefore be handled very well by GPUs. Modern
far-field compression schemes can be split into a small adaptive portion that
exhibits divergent control flows and is handled by the CPU and a vectorizable
portion that can again be sent to GPUs.
  We propose a hybrid algorithm that splits the computation into tasks for CPUs
and GPUs. Our method presented in this article is able to speedup the setup
time of boundary integral operators by a significant factor of 19-30 for both
the Laplace and the Helmholtz equation in 3D when using two consumer GPGPUs
compared to a quad-core CPU."
"BOAT is a free cross-platform software for statistical data analysis and
numerical computing. Thanks to its multiple-precision floating point engine, it
allows arbitrary-precision calculations, whose digits of precision are only
limited by the amount of memory of the host machine. At the core of the
software is a simple and efficient expression language, whose use is
facilitated by the assisted typing, the auto-complete engine and the built-in
help for the syntax. In this paper a quick overview of the software is given.
Detailed information, together with its applications to some case studies, is
available at the BOAT web page."
"This document is the manual for a free Mathematica package for computing with
harmonic functions. This package allows the user to make calculations that
would take a prohibitive amount of time if done without a computer. For
example, the Poisson integral of any polynomial can be computed exactly. This
software can find exact solutions to Dirichlet, Neumann, and biDirichlet
problems in R^n with polynomial data on balls, ellipsoids, and annular regions.
It can also find bases for spaces of spherical harmonics, compute projections
onto the harmonic Bergman space, and perform other manipulations with harmonic
functions."
"In this paper we introduce DiffSharp, an automatic differentiation (AD)
library designed with machine learning in mind. AD is a family of techniques
that evaluate derivatives at machine precision with only a small constant
factor of overhead, by systematically applying the chain rule of calculus at
the elementary operator level. DiffSharp aims to make an extensive array of AD
techniques available, in convenient form, to the machine learning community.
These including arbitrary nesting of forward/reverse AD operations, AD with
linear algebra primitives, and a functional API that emphasizes the use of
higher-order functions and composition. The library exposes this functionality
through an API that provides gradients, Hessians, Jacobians, directional
derivatives, and matrix-free Hessian- and Jacobian-vector products. Bearing the
performance requirements of the latest machine learning techniques in mind, the
underlying computations are run through a high-performance BLAS/LAPACK backend,
using OpenBLAS by default. GPU support is currently being implemented."
"Dense and sparse tensors allow the representation of most bulk data
structures in computational science applications. We show that sparse tensor
algebra can also be used to express many of the transformations on these
datasets, especially those which are parallelizable. Tensor computations are a
natural generalization of matrix and graph computations. We extend the usual
basic operations of tensor summation and contraction to arbitrary functions,
and further operations such as reductions and mapping. The expression of these
transformations in a high-level sparse linear algebra domain specific language
allows our framework to understand their properties at runtime to select the
preferred communication-avoiding algorithm. To demonstrate the efficacy of our
approach, we show how key graph algorithms as well as common numerical kernels
can be succinctly expressed using our interface and provide performance results
of a general library implementation."
"The dune-functions dune module introduces a new programmer interface for
discrete and non-discrete functions. Unlike the previous interfaces considered
in the existing dune modules, it is based on overloading operator(), and
returning values by-value. This makes user code much more readable, and allows
the incorporation of newer C++ features such as lambda expressions. Run-time
polymorphism is implemented not by inheritance, but by type erasure,
generalizing the ideas of the std::function class from the C++11 standard
library. We describe the new interface, show its possibilities, and measure the
performance impact of type erasure and return-by-value."
"Differential equations arise in mathematics, physics,medicine, pharmacology,
communications, image processing and animation, etc. An Ordinary Differential
Equation (ODE) is a differential equation if it involves derivatives with
respect to only one independent variable which can be studied from different
perspectives, such as: analytical methods, graphical methods and numerical
methods. This research paper therefore revises the standard Runge - Kutta
fourth order algorithm by using compiler techniques to dynamically evaluate the
inputs and implement the algorithm for both first and second order derivatives
of the ODE. We have been able to develop and implement the software that can be
used to evaluate inputs and compute solutions (approximately and analytically)
for the ODE function at a more efficient rate than the traditional method."
"We introduce a task-parallel algorithm for sparse incomplete Cholesky
factorization that utilizes a 2D sparse partitioned-block layout of a matrix.
Our factorization algorithm follows the idea of algorithms-by-blocks by using
the block layout. The algorithm-by-blocks approach induces a task graph for the
factorization. These tasks are inter-related to each other through their data
dependences in the factorization algorithm. To process the tasks on various
manycore architectures in a portable manner, we also present a portable tasking
API that incorporates different tasking backends and device-specific features
using an open-source framework for manycore platforms i.e., Kokkos. A
performance evaluation is presented on both Intel Sandybridge and Xeon Phi
platforms for matrices from the University of Florida sparse matrix collection
to illustrate merits of the proposed task-based factorization. Experimental
results demonstrate that our task-parallel implementation delivers about 26.6x
speedup (geometric mean) over single-threaded incomplete Cholesky-by-blocks and
19.2x speedup over serial Cholesky performance which does not carry tasking
overhead using 56 threads on the Intel Xeon Phi processor for sparse matrices
arising from various application problems."
"We propose a scheme for reduced-precision representation of floating point
data on a continuum between IEEE-754 floating point types. Our scheme enables
the use of lower precision formats for a reduction in storage space
requirements and data transfer volume. We describe how our scheme can be
accelerated using existing hardware vector units on a general-purpose processor
(GPP). Exploiting native vector hardware allows us to support reduced precision
floating point with low overhead. We demonstrate that supporting reduced
precision in the compiler as opposed to using a library approach can yield a
low overhead solution for GPPs."
"Oasis is a high-level/high-performance finite element Navier-Stokes solver
written from scratch in Python using building blocks from the FEniCS project
(fenicsproject.org). The solver is unstructured and targets large-scale
applications in complex geometries on massively parallel clusters. Oasis
utilizes MPI and interfaces, through FEniCS, to the linear algebra backend
PETSc. Oasis advocates a high-level, programmable user interface through the
creation of highly flexible Python modules for new problems. Through the
high-level Python interface the user is placed in complete control of every
aspect of the solver. A version of the solver, that is using piecewise linear
elements for both velocity and pressure, is shown reproduce very well the
classical, spectral, turbulent channel simulations of Moser, Kim and Mansour at
$Re_{\tau}=180$ [Phys. Fluids, vol 11(4), p. 964]. The computational speed is
strongly dominated by the iterative solvers provided by the linear algebra
backend, which is arguably the best performance any similar implicit solver
using PETSc may hope for. Higher order accuracy is also demonstrated and new
solvers may be easily added within the same framework."
"We present a mathematical analysis of transformations used in fast
calculation of inverse square root for single-precision floating-point numbers.
Optimal values of the so called magic constants are derived in a systematic
way, minimizing either absolute or relative errors at subsequent stages of the
discussed algorithm."
"OpenDreamKit --- ""Open Digital Research Environment Toolkit for the
Advancement of Mathematics"" --- is an H2020 EU Research Infrastructure project
that aims at supporting, over the period 2015--2019, the ecosystem of
open-source mathematical software systems. From that, OpenDreamKit will deliver
a flexible toolkit enabling research groups to set up Virtual Research
Environments, customised to meet the varied needs of research projects in pure
mathematics and applications.
  An important step in the OpenDreamKit endeavor is to foster the
interoperability between a variety of systems, ranging from computer algebra
systems over mathematical databases to front-ends. This is the mission of the
integration work package (WP6). We report on experiments and future plans with
the \emph{Math-in-the-Middle} approach. This information architecture consists
in a central mathematical ontology that documents the domain and fixes a joint
vocabulary, combined with specifications of the functionalities of the various
systems. Interaction between systems can then be enriched by pivoting off this
information architecture."
"SimOutUtils is a suite of MATLAB/Octave functions for studying and analyzing
time series-like output from stochastic simulation models. More specifically,
SimOutUtils allows modelers to study and visualize simulation output dynamics,
perform distributional analysis of output statistical summaries, as well as
compare these summaries in order to assert the statistical equivalence of two
or more model implementations. Additionally, the provided functions are able to
produce publication quality figures and tables showcasing results from the
specified simulation output studies."
"We describe here the package {\tt subdivision\\_solver} for the mathematical
software {\tt SageMath}. It provides a solver on real numbers for square
systems of large dense polynomials. By large polynomials we mean multivariate
polynomials with large degrees, which coefficients have large bit-size. While
staying robust, symbolic approaches to solve systems of polynomials see their
performances dramatically affected by high degree and bit-size of input
polynomials.Available numeric approaches suffer from the cost of the evaluation
of large polynomials and their derivatives.Our solver is based on interval
analysis and bisections of an initial compact domain of $\R^n$ where solutions
are sought. Evaluations on intervals with Horner scheme is performed by the
package {\tt fast\\_polynomial} for {\tt SageMath}.The non-existence of a
solution within a box is certified by an evaluation scheme that uses a Taylor
expansion at order 2, and existence and uniqueness of a solution within a box
is certified with krawczyk operator.The precision of the working arithmetic is
adapted on the fly during the subdivision process and we present a new
heuristic criterion to decide if the arithmetic precision has to be increased."
"Given a sparse matrix $A$, the selected inversion algorithm is an efficient
method for computing certain selected elements of $A^{-1}$. These selected
elements correspond to all or some nonzero elements of the LU factors of $A$.
In many ways, the type of matrix updates performed in the selected inversion
algorithm is similar to that performed in the LU factorization, although the
sequence of operation is different. In the context of LU factorization, it is
known that the left-looking and right-looking algorithms exhibit different
memory access and data communication patterns, and hence different behavior on
shared memory and distributed memory parallel machines. Corresponding to
right-looking and left-looking LU factorization, selected inversion algorithm
can be organized as a left-looking and a right-looking algorithm. The parallel
right-looking version of the algorithm has been developed in [1]. The sequence
of operations performed in this version of the selected inversion algorithm is
similar to those performed in a left-looking LU factorization algorithm. In
this paper, we describe the left-looking variant of the selected inversion
algorithm, and based on task parallel method, present an efficient
implementation of the algorithm for shared memory machines. We demonstrate that
with the task scheduling features provided by OpenMP 4.0, the left-looking
selected inversion algorithm can scale well both on the Intel Haswell multicore
architecture and on the Intel Knights Corner (KNC) manycore architecture.
Compared to the right-looking selected inversion algorithm, the left-looking
formulation facilitates pipelining of work along different branches of the
elimination tree, and can be a promising candidate for future development of
massively parallel selected inversion algorithms on heterogeneous architecture."
"We present an algorithm for the optimization of a class of finite element
integration loop nests. This algorithm, which exploits fundamental mathematical
properties of finite element operators, is proven to achieve a locally optimal
operation count. In specified circumstances the optimum achieved is global.
Extensive numerical experiments demonstrate significant performance
improvements over the state of the art in finite element code generation in
almost all cases. This validates the effectiveness of the algorithm presented
here, and illustrates its limitations."
"We present a generic algorithm for numbering and then efficiently iterating
over the data values attached to an extruded mesh. An extruded mesh is formed
by replicating an existing mesh, assumed to be unstructured, to form layers of
prismatic cells. Applications of extruded meshes include, but are not limited
to, the representation of 3D high aspect ratio domains employed by geophysical
finite element simulations. These meshes are structured in the extruded
direction. The algorithm presented here exploits this structure to avoid the
performance penalty traditionally associated with unstructured meshes. We
evaluate the implementation of this algorithm in the Firedrake finite element
system on a range of low compute intensity operations which constitute worst
cases for data layout performance exploration. The experiments show that having
structure along the extruded direction enables the cost of the indirect data
accesses to be amortized after 10-20 layers as long as the underlying mesh is
well-ordered. We characterise the resulting spatial and temporal reuse in a
representative set of both continuous-Galerkin and discontinuous-Galerkin
discretisations. On meshes with realistic numbers of layers the performance
achieved is between 70% and 90% of a theoretical hardware-specific limit."
"This paper provides full \Matlab-code and informal correctness proofs for the
lexicographic reverse search algorithm for convex hull calculations. The
implementation was tested on a 1993 486-PC for various small and some larger,
partially highly degenerate combinatorial polytopes, one of which (a certain
13-dimensional 24 vertex polyhedron) occurs naturally in the study of a well
known problem posed by Professor Graciano de Oliveira: see end of section 1."
"Elliptic partial differential equations (PDEs) frequently arise in continuum
descriptions of physical processes relevant to science and engineering.
Multilevel preconditioners represent a family of scalable techniques for
solving discrete PDEs of this type and thus are the method of choice for
high-resolution simulations. The scalability and time-to-solution of massively
parallel multilevel preconditioners can be adversely effected by using a
coarse-level solver with sub-optimal algorithmic complexity. To maintain
scalability, agglomeration techniques applied to the coarse level have been
shown to be necessary.
  In this work, we present a new software component introduced within the
Portable Extensible Toolkit for Scientific computation (PETSc) which permits
agglomeration. We provide an overview of the design and implementation of this
functionality, together with several use cases highlighting the benefits of
agglomeration. Lastly, we demonstrate via numerical experiments employing
geometric multigrid with structured meshes, the flexibility and performance
gains possible using our MPI-rank agglomeration implementation."
"In this paper we describe generic algorithms and data structures for the
implementation of $hp$-adaptive discontinuous finite element methods in the
Dune-Fem library. Special attention is given to the often tedious and
error-prone task of transferring user data during adaptation. Simultaneously,
we generalize the approach to the restriction and prolongation of data
currently implemented in Dune-Fem to the case of $p$- and $hp$-adaptation. The
dune-fem-hpdg module described in this paper provides an extensible reference
implementation of $hp$-adaptive discontinuous discrete function spaces. We give
details on its implementation and the extended adaptive interface. As proof of
concept we present the practical realization of an $hp$-adaptive interior
penalty method for elliptic problems."
"We dispel with ""street wisdom"" regarding the practical implementation of
Strassen's algorithm for matrix-matrix multiplication (DGEMM). Conventional
wisdom: it is only practical for very large matrices. Our implementation is
practical for small matrices. Conventional wisdom: the matrices being
multiplied should be relatively square. Our implementation is practical for
rank-k updates, where k is relatively small (a shape of importance for
libraries like LAPACK). Conventional wisdom: it inherently requires substantial
workspace. Our implementation requires no workspace beyond buffers already
incorporated into conventional high-performance DGEMM implementations.
Conventional wisdom: a Strassen DGEMM interface must pass in workspace. Our
implementation requires no such workspace and can be plug-compatible with the
standard DGEMM interface. Conventional wisdom: it is hard to demonstrate
speedup on multi-core architectures. Our implementation demonstrates speedup
over conventional DGEMM even on an Intel(R) Xeon Phi(TM) coprocessor utilizing
240 threads. We show how a distributed memory matrix-matrix multiplication also
benefits from these advances."
"We describe an XML file format for storing data from computations in algebra
and geometry. We also present a formal specification based on a RELAX-NG
schema."
"In this project, we introduce OPESCI-FD, a Python package built on symbolic
mathematics to automatically generate Finite Difference models from a
high-level description of the model equations. We investigate applying this
framework to generate the propagator program used in seismic imaging. We
implement the 3D velocity-stress FD scheme as an example and demonstrate the
advantages of usability, flexibility and accuracy of the framework. The design
of OPESCI-FD aims to allow rapid development, analysis and optimisation of
Finite Difference programs. OPESCI-FD is the foundation for continuing
development by the OPESCI project team, building on the research presented in
this report. This report concludes by reviewing the further developments that
are already under way, as well as the scope for extension to cater for other
equations and numerical schemes."
"In this paper we compare several Python tools for automatic differentiation.
In order to assess the difference in performance and precision, the problem of
finding the optimal geometrical structure of the cluster with identical atoms
is used as follows. First, we compare performance of calculating gradients for
the objective function. We showed that the PyADOL-C and PyCppAD tools have much
better performance for big clusters than the other ones. Second, we assess
precision of these two tools by calculating the difference between the obtained
at the optimal configuration gradient norms. We conclude that PyCppAD has the
best performance among others, while having almost the same precision as the
second- best performing tool - PyADOL-C."
"Estimating parameters of Partial Differential Equations (PDEs) from noisy and
indirect measurements often requires solving ill-posed inverse problems. These
so called parameter estimation or inverse medium problems arise in a variety of
applications such as geophysical, medical imaging, and nondestructive testing.
Their solution is computationally intense since the underlying PDEs need to be
solved numerous times until the reconstruction of the parameters is
sufficiently accurate. Typically, the computational demand grows significantly
when more measurements are available, which poses severe challenges to
inversion algorithms as measurement devices become more powerful.
  In this paper we present jInv, a flexible framework and open source software
that provides parallel algorithms for solving parameter estimation problems
with many measurements. Being written in the expressive programming language
Julia, jInv is portable, easy to understand and extend, cross-platform tested,
and well-documented. It provides novel parallelization schemes that exploit the
inherent structure of many parameter estimation problems and can be used to
solve multiphysics inversion problems as is demonstrated using numerical
experiments motivated by geophysical imaging."
"We present ""GEMM-like Tensor-Tensor multiplication"" (GETT), a novel approach
to tensor contractions that mirrors the design of a high-performance general
matrix-matrix multiplication (GEMM). The critical insight behind GETT is the
identification of three index sets, involved in the tensor contraction, which
enable us to systematically reduce an arbitrary tensor contraction to loops
around a highly tuned ""macro-kernel"". This macro-kernel operates on suitably
prepared (""packed"") sub-tensors that reside in a specified level of the cache
hierarchy. In contrast to previous approaches to tensor contractions, GETT
exhibits desirable features such as unit-stride memory accesses,
cache-awareness, as well as full vectorization, without requiring auxiliary
memory. To compare our technique with other modern tensor contractions, we
integrate GETT alongside the so called Transpose-Transpose-GEMM-Transpose and
Loops-over-GEMM approaches into an open source ""Tensor Contraction Code
Generator"" (TCCG). The performance results for a wide range of tensor
contractions suggest that GETT has the potential of becoming the method of
choice: While GETT exhibits excellent performance across the board, its
effectiveness for bandwidth-bound tensor contractions is especially impressive,
outperforming existing approaches by up to $12.4\times$. More precisely, GETT
achieves speedups of up to $1.41\times$ over an equivalent-sized GEMM for
bandwidth-bound tensor contractions while attaining up to $91.3\%$ of peak
floating-point performance for compute-bound tensor contractions."
"PyFR is an open-source high-order accurate computational fluid dynamics
solver for unstructured grids. It is designed to efficiently solve the
compressible Navier-Stokes equations on a range of hardware platforms,
including GPUs and CPUs. In this paper we will describe how the Python Offload
Infrastructure for the Intel Many Integrated Core Architecture (pyMIC) was used
to enable PyFR to run with near native performance on the Intel Xeon Phi
coprocessor. We will introduce the architecture of both pyMIC and PyFR and
present a variety of examples showcasing the capabilities of pyMIC. Further, we
will also compare the contrast pyMIC to other approaches including native
execution and OpenCL. The process of adding support for pyMIC into PyFR will be
described in detail. Benchmark results show that for a standard cylinder flow
problem PyFR with pyMIC is able achieve 240 GFLOP/s of sustained double
precision floating point performance; for a 1.85 times improvement over PyFR
with C/OpenMP on a 12 core Intel Xeon E5-2697 v2 CPU."
"Direct Numerical Simulations (DNS) of the Navier Stokes equations is a
valuable research tool in fluid dynamics, but there are very few publicly
available codes and, due to heavy number crunching, codes are usually written
in low-level languages. In this work a \textasciitilde{}100 line standard
scientific Python DNS code is described that nearly matches the performance of
pure C for thousands of processors and billions of unknowns. With optimization
of a few routines in Cython, it is found to match the performance of a more or
less identical solver implemented from scratch in C++. Keys to the efficiency
of the solver are the mesh decomposition and three dimensional FFT routines,
implemented directly in Python using MPI, wrapped through MPI for Python, and a
serial FFT module (both numpy.fft or pyFFTW may be used). Two popular
decomposition strategies, slab and pencil, have been implemented and tested."
"We summarise some of the key statements made at the workshop Form Follows
Function at ISC High Performance 2016. The summary highlights what type of
co-design the presented projects experience; often in the absence of an
explicit co-design agenda. Their software development picks up hardware trends
but it also influences the hardware development. Observations illustrate that
this cycle not always is optimal for both sides as it is not proactively
steered. Key statements characterise ideas how it might be possible to
integrate both hardware and software creation closer to the best of both
worlds---again even without classic co-design in mind where new pieces of
hardware are created. The workshop finally identified three development idioms
that might help to improve software and system design with respect to emerging
hardware."
"Generalized sampling is a numerically stable framework for obtaining
reconstructions of signals in different bases and frames from their samples. In
this paper, we will introduce a carefully documented toolbox for performing
generalized sampling in Julia. Julia is a new language for technical computing
with focus on performance, which is ideally suited to handle the large size
problems often encountered in generalized sampling. The toolbox provides
specialized solutions for the setup of Fourier bases and wavelets. The
performance of the toolbox is compared to existing implementations of
generalized sampling in MATLAB."
"We present a novel, quadrature-based finite element integration method for
low-order elements on GPUs, using a pattern we call \textit{thread
transposition} to avoid reductions while vectorizing aggressively. On the
NVIDIA GTX580, which has a nominal single precision peak flop rate of 1.5 TF/s
and a memory bandwidth of 192 GB/s, we achieve close to 300 GF/s for element
integration on first-order discretization of the Laplacian operator with
variable coefficients in two dimensions, and over 400 GF/s in three dimensions.
From our performance model we find that this corresponds to 90\% of our
measured achievable bandwidth peak of 310 GF/s. Further experimental results
also match the predicted performance when used with double precision (120 GF/s
in two dimensions, 150 GF/s in three dimensions). Results obtained for the
linear elasticity equations (220 GF/s and 70 GF/s in two dimensions, 180 GF/s
and 60 GF/s in three dimensions) also demonstrate the applicability of our
method to vector-valued partial differential equations."
"We present ForwardDiff, a Julia package for forward-mode automatic
differentiation (AD) featuring performance competitive with low-level languages
like C++. Unlike recently developed AD tools in other popular high-level
languages such as Python and MATLAB, ForwardDiff takes advantage of
just-in-time (JIT) compilation to transparently recompile AD-unaware user code,
enabling efficient support for higher-order differentiation and differentiation
using custom number types (including complex numbers). For gradient and
Jacobian calculations, ForwardDiff provides a variant of vector-forward mode
that avoids expensive heap allocation and makes better use of memory bandwidth
than traditional vector mode. In our numerical experiments, we demonstrate that
for nontrivially large dimensions, ForwardDiff's gradient computations can be
faster than a reverse-mode implementation from the Python-based autograd
package. We also illustrate how ForwardDiff is used effectively within JuMP, a
modeling language for optimization. According to our usage statistics, 41
unique repositories on GitHub depend on ForwardDiff, with users from diverse
fields such as astronomy, optimization, finite element analysis, and
statistics.
  This document is an extended abstract that has been accepted for presentation
at the AD2016 7th International Conference on Algorithmic Differentiation."
"Systems of linear equations arise at the heart of many scientific and
engineering applications. Many of these linear systems are sparse; i.e., most
of the elements in the coefficient matrix are zero. Direct methods based on
matrix factorizations are sometimes needed to ensure accurate solutions. For
example, accurate solution of sparse linear systems is needed in shift-invert
Lanczos to compute interior eigenvalues. The performance and resource usage of
sparse matrix factorizations are critical to time-to-solution and maximum
problem size solvable on a given platform. In many applications, the
coefficient matrices are symmetric, and exploiting symmetry will reduce both
the amount of work and storage cost required for factorization. When the
factorization is performed on large-scale distributed memory platforms,
communication cost is critical to the performance of the algorithm. At the same
time, network topologies have become increasingly complex, so that modern
platforms exhibit a high level of performance variability. This makes
scheduling of computations an intricate and performance-critical task. In this
paper, we investigate the use of an asynchronous task paradigm, one-sided
communication and dynamic scheduling in implementing sparse Cholesky
factorization (symPACK) on large-scale distributed memory platforms. Our solver
symPACK relies on efficient and flexible communication primitives provided by
the UPC++ library. Performance evaluation shows good scalability and that
symPACK outperforms state-of-the-art parallel distributed memory factorization
packages, validating our approach on practical cases."
"Matrix-matrix multiplication is a fundamental operation of great importance
to scientific computing and, increasingly, machine learning. It is a simple
enough concept to be introduced in a typical high school algebra course yet in
practice important enough that its implementation on computers continues to be
an active research topic. This note describes a set of exercises that use this
operation to illustrate how high performance can be attained on modern CPUs
with hierarchical memories (multiple caches). It does so by building on the
insights that underly the BLAS-like Library Instantiation Software (BLIS)
framework by exposing a simplified ""sandbox"" that mimics the implementation in
BLIS. As such, it also becomes a vehicle for the ""crowd sourcing"" of the
optimization of BLIS. We call this set of exercises BLISlab."
"Modular arithmetic is widely used in crytography and symbolic computation.
This paper presents a vectorized Montgomery algorithm for modular
multiplication, the key to fast modular arithmetic, that fully utilizes the
SIMD instructions. We further show how the vectorized algorithm can be
automatically generated by the {\SPIRAL} system, as part of the effort for
automatic generation of a modular polynomial multiplication library."
"Inference on time series data is a common requirement in many scientific
disciplines and internet of things (IoT) applications, yet there are few
resources available to domain scientists to easily, robustly, and repeatably
build such complex inference workflows: traditional statistical models of time
series are often too rigid to explain complex time domain behavior, while
popular machine learning packages require already-featurized dataset inputs.
Moreover, the software engineering tasks required to instantiate the
computational platform are daunting. cesium is an end-to-end time series
analysis framework, consisting of a Python library as well as a web front-end
interface, that allows researchers to featurize raw data and apply modern
machine learning techniques in a simple, reproducible, and extensible way.
Users can apply out-of-the-box feature engineering workflows as well as save
and replay their own analyses. Any steps taken in the front end can also be
exported to a Jupyter notebook, so users can iterate between possible models
within the front end and then fine-tune their analysis using the additional
capabilities of the back-end library. The open-source packages make us of many
use modern Python toolkits, including xarray, dask, Celery, Flask, and
scikit-learn."
"Matrix multiplication (GEMM) is a core operation to numerous scientific
applications. Traditional implementations of Strassen-like fast matrix
multiplication (FMM) algorithms often do not perform well except for very large
matrix sizes, due to the increased cost of memory movement, which is
particularly noticeable for non-square matrices. Such implementations also
require considerable workspace and modifications to the standard BLAS
interface. We propose a code generator framework to automatically implement a
large family of FMM algorithms suitable for multiplications of arbitrary matrix
sizes and shapes. By representing FMM with a triple of matrices [U,V,W] that
capture the linear combinations of submatrices that are formed, we can use the
Kronecker product to define a multi-level representation of Strassen-like
algorithms. Incorporating the matrix additions that must be performed for
Strassen-like algorithms into the inherent packing and micro-kernel operations
inside GEMM avoids extra workspace and reduces the cost of memory movement.
Adopting the same loop structures as high-performance GEMM implementations
allows parallelization of all FMM algorithms with simple but efficient data
parallelism without the overhead of task parallelism. We present a simple
performance model for general FMM algorithms and compare actual performance of
20+ FMM algorithms to modeled predictions. Our implementations demonstrate a
performance benefit over conventional GEMM on single core and multi-core
systems. This study shows that Strassen-like fast matrix multiplication can be
incorporated into libraries for practical use."
"The R package GFA provides a full pipeline for factor analysis of multiple
data sources that are represented as matrices with co-occurring samples. It
allows learning dependencies between subsets of the data sources, decomposed
into latent factors. The package also implements sparse priors for the
factorization, providing interpretable biclusters of the multi-source data"
"High performance dense linear algebra (DLA) libraries often rely on a general
matrix multiply (Gemm) kernel that is implemented using assembly or with vector
intrinsics. In particular, the real-valued Gemm kernels provide the
overwhelming fraction of performance for the complex-valued Gemm kernels, along
with the entire level-3 BLAS and many of the real and complex LAPACK routines.
Thus,achieving high performance for the Gemm kernel translates into a high
performance linear algebra stack above this kernel. However, it is a monumental
task for a domain expert to manually implement the kernel for every
library-supported architecture. This leads to the belief that the craft of a
Gemm kernel is more dark art than science. It is this premise that drives the
popularity of autotuning with code generation in the domain of DLA.
  This paper, instead, focuses on an analytical approach to code generation of
the Gemm kernel for different architecture, in order to shed light on the
details or voo-doo required for implementing a high performance Gemm kernel. We
distill the implementation of the kernel into an even smaller kernel, an
outer-product, and analytically determine how available SIMD instructions can
be used to compute the outer-product efficiently. We codify this approach into
a system to automatically generate a high performance SIMD implementation of
the Gemm kernel. Experimental results demonstrate that our approach yields
generated kernels with performance that is competitive with kernels implemented
manually or using empirical search."
"We present the library Moore, which implements Interval Arithmetic in modern
C++. This library is based on a new feature in the C++ language called
concepts, which reduces the problems caused by template meta programming, and
leads to a new approach for implementing interval arithmetic libraries in C++."
"This paper presents our work on designing scalable linear solvers for
large-scale reservoir simulations. The main objective is to support
implementation of parallel reservoir simulators on distributed-memory parallel
systems, where MPI (Message Passing Interface) is employed for communications
among computation nodes. Distributed matrix and vector modules are designed,
which are the base of our parallel linear systems. Commonly-used Krylov
subspace linear solvers are implemented, including the restarted GMRES method,
the LGMRES method, and the BiCGSTAB method. It also has an interface to a
parallel algebraic multigrid solver, BoomerAMG from HYPRE. Parallel
general-purpose preconditioners and special preconditioners for reservoir
simulations are also developed. The numerical experiments show that our linear
solvers have excellent scalability using thousands of CPU cores."
"Simflowny is an open platform which automatically generates parallel code of
scientific dynamical models for different simulation frameworks. Here we
present major upgrades on this software to support an extended set of families
of models, in particular: i) a new generic family for partial differential
equations, which can include spatial derivatives of any order, ii) a new family
for agent based models to study complex phenomena --either on a spatial domain
or on a graph--. Additionally we introduce a flexible graphical user interface
(GUI) to accommodate these and future families of equations. This paper
describes the new GUI architecture and summarizes the formal representation and
implementation of these new families, providing several validation results."
"Extreme-scale computational science increasingly demands multiscale and
multiphysics formulations. Combining software developed by independent groups
is imperative: no single team has resources for all predictive science and
decision support capabilities. Scientific libraries provide high-quality,
reusable software components for constructing applications with improved
robustness and portability. However, without coordination, many libraries
cannot be easily composed. Namespace collisions, inconsistent arguments, lack
of third-party software versioning, and additional difficulties make
composition costly.
  The Extreme-scale Scientific Software Development Kit (xSDK) defines
community policies to improve code quality and compatibility across
independently developed packages (hypre, PETSc, SuperLU, Trilinos, and
Alquimia) and provides a foundation for addressing broader issues in software
interoperability, performance portability, and sustainability. The xSDK
provides turnkey installation of member software and seamless combination of
aggregate capabilities, and it marks first steps toward extreme-scale
scientific software ecosystems from which future applications can be composed
rapidly with assured quality and scalability."
"We describe a parallel, adaptive, multi-block algorithm for explicit
integration of time dependent partial differential equations on two-dimensional
Cartesian grids. The grid layout we consider consists of a nested hierarchy of
fixed size, non-overlapping, logically Cartesian grids stored as leaves in a
quadtree. Dynamic grid refinement and parallel partitioning of the grids is
done through the use of the highly scalable quadtree/octree library p4est.
Because our concept is multi-block, we are able to easily solve on a variety of
geometries including the cubed sphere. In this paper, we pay special attention
to providing details of the parallel ghost-filling algorithm needed to ensure
that both corner and edge ghost regions around each grid hold valid values.
  We have implemented this algorithm in the ForestClaw code using single-grid
solvers from ClawPack, a software package for solving hyperbolic PDEs using
finite volumes methods. We show weak and strong scalability results for scalar
advection problems on two-dimensional manifold domains on 1 to 64Ki MPI
processes, demonstrating neglible regridding overhead."
"Web developers use base64 formats to include images, fonts, sounds and other
resources directly inside HTML, JavaScript, JSON and XML files. We estimate
that billions of base64 messages are decoded every day. We are motivated to
improve the efficiency of base64 encoding and decoding. Compared to
state-of-the-art implementations, we multiply the speeds of both the encoding
(~10x) and the decoding (~7x). We achieve these good results by using the
single-instruction-multiple-data (SIMD) instructions available on recent Intel
processors (AVX2). Our accelerated software abides by the specification and
reports errors when encountering characters outside of the base64 set. It is
available online as free software under a liberal license."
"BLASFEO is a dense linear algebra library providing high-performance
implementations of BLAS- and LAPACK-like routines for use in embedded
optimization. A key difference with respect to existing high-performance
implementations of BLAS is that the computational performance is optimized for
small to medium scale matrices, i.e., for sizes up to a few hundred. BLASFEO
comes with three different implementations: a high-performance implementation
aiming at providing the highest performance for matrices fitting in cache, a
reference implementation providing portability and embeddability and optimized
for very small matrices, and a wrapper to standard BLAS and LAPACK providing
high-performance on large matrices. The three implementations of BLASFEO
together provide high-performance dense linear algebra routines for matrices
ranging from very small to large. Compared to both open-source and proprietary
highly-tuned BLAS libraries, for matrices of size up to about one hundred the
high-performance implementation of BLASFEO is about 20-30\% faster than the
corresponding level 3 BLAS routines and 2-3 times faster than the corresponding
LAPACK routines."
"Tensor contraction (TC) is an important computational kernel widely used in
numerous applications. It is a multi-dimensional generalization of matrix
multiplication (GEMM). While Strassen's algorithm for GEMM is well studied in
theory and practice, extending it to accelerate TC has not been previously
pursued. Thus, we believe this to be the first paper to demonstrate how one can
in practice speed up tensor contraction with Strassen's algorithm. By adopting
a Block-Scatter-Matrix format, a novel matrix-centric tensor layout, we can
conceptually view TC as GEMM for a general stride storage, with an implicit
tensor-to-matrix transformation. This insight enables us to tailor a recent
state-of-the-art implementation of Strassen's algorithm to TC, avoiding
explicit transpositions (permutations) and extra workspace, and reducing the
overhead of memory movement that is incurred. Performance benefits are
demonstrated with a performance model as well as in practice on modern single
core, multicore, and distributed memory parallel architectures, achieving up to
1.3x speedup. The resulting implementations can serve as a drop-in replacement
for various applications with significant speedup."
"A flexible and highly-extensible data assimilation testing suite, named
DATeS, is described in this paper. DATeS aims to offer a unified testing
environment that allows researchers to compare different data assimilation
methodologies and understand their performance in various settings. The core of
DATeS is implemented in Python and takes advantage of its object-oriented
capabilities. The main components of the package (the numerical models, the
data assimilation algorithms, the linear algebra solvers, and the time
discretization routines) are independent of each other, which offers great
flexibility to configure data assimilation applications. DATeS can interface
easily with large third-party numerical models written in Fortran or in C, and
with a plethora of external solvers."
"This paper describes fast sorting techniques using the recent AVX-512
instruction set. Our implementations benefit from the latest possibilities
offered by AVX-512 to vectorize a two-parts hybrid algorithm: we sort the small
arrays using a branch- free Bitonic variant, and we provide a vectorized
partitioning kernel which is the main component of the well-known Quicksort.
Our algorithm sorts in-place and is straightforward to implement thanks to the
new instructions. Meanwhile, we also show how an algorithm can be adapted and
implemented with AVX-512. We report a performance study on the Intel KNL where
our approach is faster than the GNU C++ sort algorithm for any size in both
integer and double floating-point arithmetics by a factor of 4 in average."
"We introduce the CUDA Tensor Transpose (cuTT) library that implements
high-performance tensor transposes for NVIDIA GPUs with Kepler and above
architectures. cuTT achieves high performance by (a) utilizing two
GPU-optimized transpose algorithms that both use a shared memory buffer in
order to reduce global memory access scatter, and by (b) computing memory
positions of tensor elements using a thread-parallel algorithm. We evaluate the
performance of cuTT on a variety of benchmarks with tensor ranks ranging from 2
to 12 and show that cuTT performance is independent of the tensor rank and that
it performs no worse than an approach based on code generation. We develop a
heuristic scheme for choosing the optimal parameters for tensor transpose
algorithms by implementing an analytical GPU performance model that can be used
at runtime without need for performance measurements or profiling. Finally, by
integrating cuTT into the tensor algebra library TAL-SH, we significantly
reduce the tensor transpose overhead in tensor contractions, achieving as low
as just one percent overhead for arithmetically intensive tensor contractions."
"Designing software systems for Geometric Computing applications can be a
challenging task. Software engineers typically use software abstractions to
hide and manage the high complexity of such systems. Without the presence of a
unifying algebraic system to describe geometric models, the use of software
abstractions alone can result in many design and maintenance problems.
Geometric Algebra (GA) can be a universal abstract algebraic language for
software engineering geometric computing applications. Few sources, however,
provide enough information about GA-based software implementations targeting
the software engineering community. In particular, successfully introducing GA
to software engineers requires quite different approaches from introducing GA
to mathematicians or physicists. This article provides a high-level
introduction to the abstract concepts and algebraic representations behind the
elegant GA mathematical structure. The article focuses on the conceptual and
representational abstraction levels behind GA mathematics with sufficient
references for more details. In addition, the article strongly recommends
applying the methods of Computational Thinking in both introducing GA to
software engineers, and in using GA as a mathematical language for developing
Geometric Computing software systems."
"Sparse matrix multiplication is an important component of linear algebra
computations. Implementing sparse matrix multiplication on an associative
processor (AP) enables high level of parallelism, where a row of one matrix is
multiplied in parallel with the entire second matrix, and where the execution
time of vector dot product does not depend on the vector size. Four sparse
matrix multiplication algorithms are explored in this paper, combining AP and
baseline CPU processing to various levels. They are evaluated by simulation on
a large set of sparse matrices. The computational complexity of sparse matrix
multiplication on AP is shown to be an O(nnz) where nnz is the number of
nonzero elements. The AP is found to be especially efficient in binary sparse
matrix multiplication. AP outperforms conventional solutions in power
efficiency."
"Domain-specific high-productivity environments are playing an increasingly
important role in scientific computing due to the levels of abstraction and
automation they provide. In this paper we introduce Devito, an open-source
domain-specific framework for solving partial differential equations from
symbolic problem definitions by the finite difference method. We highlight the
generation and automated execution of highly optimized stencil code from only a
few lines of high-level symbolic Python for a set of scientific equations,
before exploring the use of Devito operators in seismic inversion problems."
"We construct an algorithm for implementing the discrete wavelet transform by
means of matrices in SO_2(R) for orthonormal compactly supported wavelets and
matrices in SL_m(R), m > = 2, for compactly supported biorthogonal wavelets. We
show that in 1 dimension the total operation count using this algorithm can be
reduced to about 50% of the conventional convolution and downsampling by
2-operation for both orthonormal and biorthogonal filters. In the special case
of biorthogonal symmetric odd-odd filters, we show an implementation yielding a
total operation count of about 38% of the conventional method. In 2 dimensions
we show an implementation of this algorithm yielding a reduction in the total
operation count of about 70% when the filters are orthonormal, a reduction of
about 62% for general biorthogonal filters, and a reduction of about 70% if the
filters are symmetric odd-odd length filters. We further extend these results
to 3 dimensions. We also show how the SO_2(R)-method for implementing the
discrete wavelet transform may be exploited to compute short FIR filters, and
we construct edge mappings where we try to improve upon the degree of
preservation of regularity in the conventional methods. We also consider a
two-class waveform discrimination problem. A statistical space-frequency
analysis is performed on a training data set using the LDB-algorithm of N.Saito
and R.Coifman. The success of the algorithm on this particular problem is
evaluated on a disjoint test data set."
"We show how VRML (Virtual Reality Modeling Language) can provide potentially
powerful insight into the 3x + 1 problem via the introduction of a unique
geometrical object, called the 'G-cell', akin to a fractal generator. We
present an example of a VRML world developed programmatically with the G-cell.
The role of VRML as a tool for furthering the understanding the 3x+1 problem is
potentially significant for several reasons: a) VRML permits the observer to
zoom into the geometric structure at all scales (up to limitations of the
computing platform). b) VRML enables rotation to alter comparative visual
perspective (similar to Tukey's data-spinning concept). c) VRML facilitates the
demonstration of interesting tree features between collaborators on the
internet who might otherwise have difficulty conveying their ideas
unambiguously. d) VRML promises to reveal any dimensional dependencies among
3x+1 sequences."
"Adaptive simulated annealing (ASA) is a global optimization algorithm based
on an associated proof that the parameter space can be sampled much more
efficiently than by using other previous simulated annealing algorithms. The
author's ASA code has been publicly available for over two years. During this
time the author has volunteered to help people via e-mail, and the feedback
obtained has been used to further develop the code. Some lessons learned, in
particular some which are relevant to other simulated annealing algorithms, are
described."
"Special orthogonal matrices with rational elements form the group SO(n,Q),
where Q is the field of rational numbers. A theorem describing the structure of
an arbitrary matrix from this group is proved. This theorem yields an algorithm
for generating such matrices by means of random number routines."
"The article deals with a kind of recursive function templates in C++, where
the recursion is realized corresponding template parameters to achieve better
computational performance. Some specialization of these template functions ends
the recursion and can be implemented using optimized hardware dependent or
independent routines. The method is applied in addition to the known expression
templates technique to solve linear algebra expressions with the help of the
BLAS library. The whole implementation produces a new library, which keeps
object-oriented benefits and has a higher computational speed represented in
the tests."
"This article presents an implementation of a graphical software with various
algorithms in Operations research, like minimum path, minimum tree, chinese
postman problem and travelling salesman."
"Fully automatic worst-case complexity analysis has a number of applications
in computer-assisted program manipulation. A classical and powerful approach to
complexity analysis consists in formally deriving, from the program syntax, a
set of constraints expressing bounds on the resources required by the program,
which are then solved, possibly applying safe approximations. In several
interesting cases, these constraints take the form of recurrence relations.
While techniques for solving recurrences are known and implemented in several
computer algebra systems, these do not completely fulfill the needs of fully
automatic complexity analysis: they only deal with a somewhat restricted class
of recurrence relations, or sometimes require user intervention, or they are
restricted to the computation of exact solutions that are often so complex to
be unmanageable, and thus useless in practice. In this paper we briefly
describe PURRS, a system and software library aimed at providing all the
computer algebra services needed by applications performing or exploiting the
results of worst-case complexity analyses. The capabilities of the system are
illustrated by means of examples derived from the analysis of programs written
in a domain-specific functional programming language for real-time embedded
systems."
"Starting from the basic ideas of mathematica, we give a detailed description
about the way of linking of external programs with mathematica through proper
mathlink commands. This article may be quite helpful for the beginners to start
with and write programs in mathematica.
  In the first part, we illustrate how to use a mathemtica notebook and write a
complete program in the notebook. Following with this, we also mention
elaborately about the utility of the local and global variables those are very
essential for writing a program in mathematica. All the commands needed for
doing different mathematical operations can be found with some proper examples
in the mathematica book written by Stephen Wolfram \cite{wolfram}.
  In the rest of this article, we concentrate our study on the most significant
issue which is the process of linking of {\em external programs} with
mathematica, so-called the mathlink operation. By using proper mathlink
commands one can run very tedious jobs efficiently and the operations become
extremely fast."
"In this short paper we present a linear constraint solver for the UniCalc
system, an environment for reliable solution of mathematical modeling problems."
"Starting from the basic level of mathematica here we illustrate how to use a
mathematica notebook and write a program in the notebook. Next, we investigate
elaborately the way of linking of external programs with mathematica, so-called
the mathlink operation. Using this technique we can run very tedious jobs quite
efficiently, and the operations become extremely fast. Sometimes it is quite
desirable to run jobs in background of a computer which can take considerable
amount of time to finish, and this allows us to do work on other tasks, while
keeping the jobs running. The way of running jobs, written in a mathematica
notebook, in background is quite different from the conventional methods i.e.,
the techniques for the programs written in other languages like C, C++, F77,
F90, F95, etc. To illustrate it, in the present article we study how to create
a mathematica batch-file from a mathematica notebook and run it in the
background. Finally, we explore the most significant issue of this article.
Here we describe the basic ideas for parallelizing a mathematica program by
sharing its independent parts into all other remote computers available in the
network. Doing the parallelization, we can perform large computational
operations within a very short period of time, and therefore, the efficiency of
the numerical works can be achieved. Parallel computation supports any version
of mathematica and it also works significantly well even if different versions
of mathematica are installed in different computers. All the operations studied
in this article run under any supported operating system like Unix, Windows,
Macintosh, etc. For the sake of our illustrations, here we concentrate all the
discussions only for the Unix based operating system."
"Mathematica is a powerful application package for doing mathematics and is
used almost in all branches of science. It has widespread applications ranging
from quantum computation, statistical analysis, number theory, zoology,
astronomy, and many more. Mathematica gives a rich set of programming
extensions to its end-user language, and it permits us to write programs in
procedural, functional, or logic (rule-based) style, or a mixture of all three.
For tasks requiring interfaces to the external environment, mathematica
provides mathlink, which allows us to communicate mathematica programs with
external programs written in C, C++, F77, F90, F95, Java, or other languages.
It has also extensive capabilities for editing graphics, equations, text, etc.
  In this article, we explore the basic mechanisms of parallelization of a
mathematica program by sharing different parts of the program into all other
computers available in the network. Doing the parallelization, we can perform
large computational operations within a very short period of time, and
therefore, the efficiency of the numerical works can be achieved. Parallel
computation supports any version of mathematica and it also works as well even
if different versions of mathematica are installed in different computers. The
whole operation can run under any supported operating system like Unix,
Windows, Macintosh, etc. Here we focus our study only for the Unix based
operating system, but this method works as well for all other cases."
"In the field of holomorphic dynamics in one complex variable, hedgehog is the
local invariant set arising about a Cremer point and endowed with a very
complicate shape as well as relating to very weak numerical conditions. We give
a solution to the open problem of its digital visualization, featuring either a
time saving approach and a far-reaching insight."
"CEA, ANDRA and EDF are jointly developing the software platform ALLIANCES
which aim is to produce a tool for the simulation of nuclear waste storage and
disposal repository. This type of simulations deals with highly coupled
thermo-hydro-mechanical and chemical (T-H-M-C) processes. A key objective of
Alliances is to give the capability for coupling algorithms development between
existing codes. The aim of this paper is to present coupling methodology use in
the context of this software platform."
"Since its inception as a student project in 2001, initially just for the
handling (as the name implies) of convex polyhedra, the Parma Polyhedra Library
has been continuously improved and extended by joining scrupulous research on
the theoretical foundations of (possibly non-convex) numerical abstractions to
a total adherence to the best available practices in software development. Even
though it is still not fully mature and functionally complete, the Parma
Polyhedra Library already offers a combination of functionality, reliability,
usability and performance that is not matched by similar, freely available
libraries. In this paper, we present the main features of the current version
of the library, emphasizing those that distinguish it from other similar
libraries and those that are important for applications in the field of
analysis and verification of hardware and software systems."
"We describe our software package Block Locally Optimal Preconditioned
Eigenvalue Xolvers (BLOPEX) publicly released recently. BLOPEX is available as
a stand-alone serial library, as an external package to PETSc (``Portable,
Extensible Toolkit for Scientific Computation'', a general purpose suite of
tools for the scalable solution of partial differential equations and related
problems developed by Argonne National Laboratory), and is also built into {\it
hypre} (``High Performance Preconditioners'', scalable linear solvers package
developed by Lawrence Livermore National Laboratory). The present BLOPEX
release includes only one solver--the Locally Optimal Block Preconditioned
Conjugate Gradient (LOBPCG) method for symmetric eigenvalue problems. {\it
hypre} provides users with advanced high-quality parallel preconditioners for
linear systems, in particular, with domain decomposition and multigrid
preconditioners. With BLOPEX, the same preconditioners can now be efficiently
used for symmetric eigenvalue problems. PETSc facilitates the integration of
independently developed application modules with strict attention to component
interoperability, and makes BLOPEX extremely easy to compile and use with
preconditioners that are available via PETSc. We present the LOBPCG algorithm
in BLOPEX for {\it hypre} and PETSc. We demonstrate numerically the scalability
of BLOPEX by testing it on a number of distributed and shared memory parallel
systems, including a Beowulf system, SUN Fire 880, an AMD dual-core Opteron
workstation, and IBM BlueGene/L supercomputer, using PETSc domain decomposition
and {\it hypre} multigrid preconditioning. We test BLOPEX on a model problem,
the standard 7-point finite-difference approximation of the 3-D Laplacian, with
the problem size in the range $10^5-10^8$."
"Real number calculations on elementary functions are remarkably difficult to
handle in mechanical proofs. In this paper, we show how these calculations can
be performed within a theorem prover or proof assistant in a convenient and
highly automated as well as interactive way. First, we formally establish upper
and lower bounds for elementary functions. Then, based on these bounds, we
develop a rational interval arithmetic where real number calculations take
place in an algebraic setting. In order to reduce the dependency effect of
interval arithmetic, we integrate two techniques: interval splitting and taylor
series expansions. This pragmatic approach has been developed, and formally
verified, in a theorem prover. The formal development also includes a set of
customizable strategies to automate proofs involving explicit calculations over
real numbers. Our ultimate goal is to provide guaranteed proofs of numerical
properties with minimal human theorem-prover interaction."
"Cody & Waite argument reduction technique works perfectly for reasonably
large arguments but as the input grows there are no bit left to approximate the
constant with enough accuracy. Under mild assumptions, we show that the result
computed with a fused-multiply-add provides a fully accurate result for many
possible values of the input with a constant almost accurate to the full
working precision. We also present an algorithm for a fully accurate second
reduction step to reach double full accuracy (all the significand bits of two
numbers are significant) even in the worst cases of argument reduction. Our
work recalls the common algorithms and presents proofs of correctness. All the
proofs are formally verified using the Coq automatic proof checker."
"The ocean general circulation model OPA is developed by the LODYC team at
Paris VI university. OPA has recently undergone a major rewriting, migrating to
FORTRAN95, and its adjoint code needs to be rebuilt. For earlier versions, the
adjoint of OPA was written by hand at a high development cost. We use the
Automatic Differentiation tool TAPENADE to build mechanicaly the tangent and
adjoint codes of OPA. We validate the differentiated codes by comparison with
divided differences, and also with an identical twin experiment. We apply
state-of-the-art methods to improve the performance of the adjoint code. In
particular we implement the Griewank and Walther's binomial checkpointing
algorithm which gives us an optimal trade-off between time and memory
consumption. We apply a specific strategy to differentiate the iterative linear
solver that comes from the implicit time stepping scheme"
"A method for solving cyclic block three-diagonal systems of equations is
generalized for solving a block cyclic penta-diagonal system of equations.
Introducing a special form of two new variables the original system is split
into three block pentagonal systems, which can be solved by the known methods.
As such method belongs to class of direct methods without pivoting.
Implementation of the algorithm is discussed in some details and the numerical
examples are present."
"We describe a new data format for storing triangular, symmetric, and
Hermitian matrices called RFPF (Rectangular Full Packed Format). The standard
two dimensional arrays of Fortran and C (also known as full format) that are
used to represent triangular and symmetric matrices waste nearly half of the
storage space but provide high performance via the use of Level 3 BLAS.
Standard packed format arrays fully utilize storage (array space) but provide
low performance as there is no Level 3 packed BLAS. We combine the good
features of packed and full storage using RFPF to obtain high performance via
using Level 3 BLAS as RFPF is a standard full format representation. Also, RFPF
requires exactly the same minimal storage as packed format. Each LAPACK full
and/or packed triangular, symmetric, and Hermitian routine becomes a single new
RFPF routine based on eight possible data layouts of RFPF. This new RFPF
routine usually consists of two calls to the corresponding LAPACK full format
routine and two calls to Level 3 BLAS routines. This means {\it no} new
software is required. As examples, we present LAPACK routines for Cholesky
factorization, Cholesky solution and Cholesky inverse computation in RFPF to
illustrate this new work and to describe its performance on several commonly
used computer platforms. Performance of LAPACK full routines using RFPF versus
LAPACK full routines using standard format for both serial and SMP parallel
processing is about the same while using half the storage. Performance gains
are roughly one to a factor of 43 for serial and one to a factor of 97 for SMP
parallel times faster using vendor LAPACK full routines with RFPF than with
using vendor and/or reference packed routines."
"This paper presents a generalization of the ""weighted least-squares"" (WLS),
named ""weighted pairing least-squares"" (WPLS), which uses a rectangular weight
matrix and is suitable for data alignment problems. Two fast solving methods,
suitable for solving full rank systems as well as rank deficient systems, are
studied. Computational experiments clearly show that the best method, in terms
of speed, accuracy, and numerical stability, is based on a special {1, 2,
3}-inverse, whose computation reduces to a very simple generalization of the
usual ""Cholesky factorization-backward substitution"" method for solving linear
systems."
"We present a rejection method based on recursive covering of the probability
density function with equal tiles. The concept works for any probability
density function that is pointwise computable or representable by tabular data.
By the implicit construction of piecewise constant majorizing and minorizing
functions that are arbitrarily close to the density function the production of
random variates is arbitrarily independent of the computation of the density
function and extremely fast. The method works unattended for probability
densities with discontinuities (jumps and poles). The setup time is short,
marginally independent of the shape of the probability density and linear in
table size. Recently formulated requirements to a general and automatic
non-uniform random number generator are topped. We give benchmarks together
with a similar rejection method and with a transformation method."
"The speed of many one-line transformation methods for the production of, for
example, Levy alpha-stable random numbers, which generalize Gaussian ones, and
Mittag-Leffler random numbers, which generalize exponential ones, is very high
and satisfactory for most purposes. However, for the class of decreasing
probability densities fast rejection implementations like the Ziggurat by
Marsaglia and Tsang promise a significant speed-up if it is possible to
complement them with a method that samples the tails of the infinite support.
This requires the fast generation of random numbers greater or smaller than a
certain value. We present a method to achieve this, and also to generate random
numbers within any arbitrary interval. We demonstrate the method showing the
properties of the transform maps of the above mentioned distributions as
examples of stable and geometric stable random numbers used for the stochastic
solution of the space-time fractional diffusion equation."
"Mathematical semantic web services are very useful in practice, but only a
small number of research results are reported in this area. In this paper we
present a method of obtaining an approximation of a mathematical semantic web
service, from its semantic description, using existing mathematical semantic
web services, approximation formulas, and numerical methods techniques. We also
give a method for automatic comparison of two complexity functions. In
addition, we present a method for classifying the numerical methods
mathematical semantic web services from a library."
"We describe an algorithm for the factorization of non-commutative polynomials
over a field. The first sketch of this algorithm appeared in an unpublished
manuscript (literally hand written notes) by James H. Davenport more than 20
years ago. This version of the algorithm contains some improvements with
respect to the original sketch. An improved version of the algorithm has been
fully implemented in the Axiom computer algebra system."
"The algorithms in the current sequential numerical linear algebra libraries
(e.g. LAPACK) do not parallelize well on multicore architectures. A new family
of algorithms, the tile algorithms, has recently been introduced. Previous
research has shown that it is possible to write efficient and scalable tile
algorithms for performing a Cholesky factorization, a (pseudo) LU
factorization, and a QR factorization. In this extended abstract, we attack the
problem of the computation of the inverse of a symmetric positive definite
matrix. We observe that, using a dynamic task scheduler, it is relatively
painless to translate existing LAPACK code to obtain a ready-to-be-executed
tile algorithm. However we demonstrate that non trivial compiler techniques
(array renaming, loop reversal and pipelining) need then to be applied to
further increase the parallelism of our application. We present preliminary
experimental results."
"A \emph{Mathematica} Notebook is presented which allows for the transfer or
any kind of polynomial expression to \emph{Matlab}. The output is formatted in
such a way that \emph{Matlab} routines such as ""Root"" can be readily
implemented. Once the Notebook has been executed, only one copy-paste operation
in necessary."
"We outline some of Chris Wallace's contributions to pseudo-random number
generation. In particular, we consider his idea for generating normally
distributed variates without relying on a source of uniform random numbers, and
compare it with more conventional methods for generating normal random numbers.
Implementations of Wallace's idea can be very fast (approximately as fast as
good uniform generators). We discuss the statistical quality of the output, and
mention how certain pitfalls can be avoided."
"We consider the solution of initial value problems within the context of
hybrid systems and emphasise the use of high precision approximations (in
software for exact real arithmetic). We propose a novel algorithm for the
computation of trajectories up to the area where discontinuous jumps appear,
applicable for holomorphic flow functions. Examples with a prototypical
implementation illustrate that the algorithm might provide results with higher
precision than well-known ODE solvers at a similar computation time."
"An iterative method LSMR is presented for solving linear systems $Ax=b$ and
least-squares problem $\min \norm{Ax-b}_2$, with $A$ being sparse or a fast
linear operator. LSMR is based on the Golub-Kahan bidiagonalization process. It
is analytically equivalent to the MINRES method applied to the normal equation
$A\T Ax = A\T b$, so that the quantities $\norm{A\T r_k}$ are monotonically
decreasing (where $r_k = b - Ax_k$ is the residual for the current iterate
$x_k$). In practice we observe that $\norm{r_k}$ also decreases monotonically.
Compared to LSQR, for which only $\norm{r_k}$ is monotonic, it is safer to
terminate LSMR early. Improvements for the new iterative method in the presence
of extra available memory are also explored."
"Since its introduction by Erik Winfree in 1998, the abstract Tile Assembly
Model (aTAM) has inspired a wealth of research. As an abstract model for tile
based self-assembly, it has proven to be remarkably powerful and expressive in
terms of the structures which can self-assemble within it. As research has
progressed in the aTAM, the self-assembling structures being studied have
become progressively more complex. This increasing complexity, along with a
need for standardization of definitions and tools among researchers, motivated
the development of the Iowa State University Tile Assembly Simulator (ISU TAS).
ISU TAS is a graphical simulator and tile set editor for designing and building
2-D and 3-D aTAM tile assembly systems and simulating their self-assembly. This
paper reviews the features and functionality of ISU TAS and describes how it
can be used to further research into the complexities of the aTAM. Software and
source code are available at http://www.cs.iastate.edu/~lnsa."
"We present a set of tools for rewriting modulo associativity and
commutativity (AC) in Coq, solving a long-standing practical problem. We use
two building blocks: first, an extensible reflexive decision procedure for
equality modulo AC; second, an OCaml plug-in for pattern matching modulo AC. We
handle associative only operations, neutral elements, uninterpreted function
symbols, and user-defined equivalence relations. By relying on type-classes for
the reification phase, we can infer these properties automatically, so that
end-users do not need to specify which operation is A or AC, or which constant
is a neutral element."
"The generic matrix multiply (GEMM) function is the core element of
high-performance linear algebra libraries used in many
computationally-demanding digital signal processing (DSP) systems. We propose
an acceleration technique for GEMM based on dynamically adjusting the
imprecision (distortion) of computation. Our technique employs adaptive scalar
companding and rounding to input matrix blocks followed by two forms of packing
in floating-point that allow for concurrent calculation of multiple results.
Since the adaptive companding process controls the increase of concurrency (via
packing), the increase in processing throughput (and the corresponding increase
in distortion) depends on the input data statistics. To demonstrate this, we
derive the optimal throughput-distortion control framework for GEMM for the
broad class of zero-mean, independent identically distributed, input sources.
Our approach converts matrix multiplication in programmable processors into a
computation channel: when increasing the processing throughput, the output
noise (error) increases due to (i) coarser quantization and (ii) computational
errors caused by exceeding the machine-precision limitations. We show that,
under certain distortion in the GEMM computation, the proposed framework can
significantly surpass 100% of the peak performance of a given processor. The
practical benefits of our proposal are shown in a face recognition system and a
multi-layer perceptron system trained for metadata learning from a large music
feature database."
"Transforming a matrix over a field to echelon form, or decomposing the matrix
as a product of structured matrices that reveal the rank profile, is a
fundamental building block of computational exact linear algebra. This paper
surveys the well known variations of such decompositions and transformations
that have been proposed in the literature. We present an algorithm to compute
the CUP decomposition of a matrix, adapted from the LSP algorithm of Ibarra,
Moran and Hui (1982), and show reductions from the other most common Gaussian
elimination based matrix transformations and decompositions to the CUP
decomposition. We discuss the advantages of the CUP algorithm over other
existing algorithms by studying time and space complexities: the asymptotic
time complexity is rank sensitive, and comparing the constants of the leading
terms, the algorithms for computing matrix invariants based on the CUP
decomposition are always at least as good except in one case. We also show that
the CUP algorithm, as well as the computation of other invariants such as
transformation to reduced column echelon form using the CUP algorithm, all work
in place, allowing for example to compute the inverse of a matrix on the same
storage as the input matrix."
"In order to obtain more accurate solutions of polynomial systems with
numerical continuation methods we use multiprecision arithmetic. Our goal is to
offset the overhead of double double arithmetic accelerating the path trackers
and in particular Newton's method with a general purpose graphics processing
unit. In this paper we describe algorithms for the massively parallel
evaluation and differentiation of sparse polynomials in several variables. We
report on our implementation of the algorithmic differentiation of products of
variables on the NVIDIA Tesla C2050 Computing Processor using the NVIDIA CUDA
compiler tools."
"The Eureqa symbolic regression program has recently received extensive press
praise. A representative quote is
  ""There are very clever 'thinking machines' in existence today, such as
Watson, the IBM computer that conquered Jeopardy! last year. But next to
Eureqa, Watson is merely a glorified search engine.""
  The program was designed to work with noisy experimental data. However, if
the data is generated from an expression for which there exists more concise
equivalent expressions, sometimes some of the Eureqa results are one or more of
those more concise equivalents. If not, perhaps one or more of the returned
Eureqa results might be a sufficiently accurate approximation that is more
concise than the given expression. Moreover, when there is no known closed form
expression, the data points can be generated by numerical methods, enabling
Eureqa to find expressions that concisely fit those data points with sufficient
accuracy. In contrast to typical regression software, the user does not have to
explicitly or implicitly provide a specific expression or class of expressions
containiing unknown constants for the software to determine.
  Is Eureqa useful enough in these regards to provide an additional tool for
experimental mathematics, computer algebra users and numerical analysis? Yes if
used carefully. Can computer algebra and numerical methods help Eureqa?
Definitely."
"This paper is an overview of Image Processing and Analysis using Scilab, a
free prototyping environment for numerical calculations similar to Matlab. We
demonstrate the capabilities of SIP -- the Scilab Image Processing Toolbox --
which extends Scilab with many functions to read and write images in over 100
major file formats, including PNG, JPEG, BMP, and TIFF. It also provides
routines for image filtering, edge detection, blurring, segmentation, shape
analysis, and image recognition. Basic directions to install Scilab and SIP are
given, and also a mini-tutorial on Scilab. Three practical examples of image
analysis are presented, in increasing degrees of complexity, showing how
advanced image analysis techniques seems uncomplicated in this environment."
"Direct discretization of continuum kinetic equations, like the Vlasov
equation, are under-utilized because the distribution function generally exists
in a high-dimensional (>3D) space and computational cost increases
geometrically with dimension. We propose to use high-order finite-volume
techniques with block-structured adaptive mesh refinement (AMR) to reduce the
computational cost. The primary complication comes from a solution state
comprised of variables of different dimensions. We develop the algorithms
required to extend standard single-dimension block structured AMR to the
multi-dimension case. Specifically, algorithms for reduction and injection
operations that transfer data between mesh hierarchies of different dimensions
are explained in detail. In addition, modifications to the basic AMR algorithm
that enable the use of high-order spatial and temporal discretizations are
discussed. Preliminary results for a standard 1D+1V Vlasov-Poisson test problem
are presented. Results indicate that there is potential for significant savings
for some classes of Vlasov problems."
"This paper describes the design and implementation of mechanisms for
light-weight inclusion of formal mathematics in informal mathematical writings,
particularly in a Web-based setting. This is conceptually done in three stages:
(i) by choosing a suitable representation layer (based on RDF) for encoding the
information about available resources of formal mathematics, (ii) by exporting
this information from formal libraries, and (iii) by providing syntax and
implementation for including formal mathematics in informal writings.
  We describe the use case of an author referring to formal text from an
informal narrative, and discuss design choices entailed by this use case.
Furthermore, we describe an implementation of the use case within the Agora
prototype: a Wiki for collaborating on formalized mathematics."
"This paper surveys and describes the implementation of parallelization of the
Mizar proof checking and of related Mizar utilities. The implementation makes
use of Mizar's compiler-like division into several relatively independent
passes, with typically quite different processing speeds. The information
produced in earlier (typically much faster) passes can be used to parallelize
the later (typically much slower) passes. The parallelization now works by
splitting the formalization into a suitable number of pieces that are processed
in parallel, assembling from them together the required results. The
implementation is evaluated on examples from the Mizar library, and future
extensions are discussed."
"Discontinuous Galerkin (DG) methods for the numerical solution of partial
differential equations have enjoyed considerable success because they are both
flexible and robust: They allow arbitrary unstructured geometries and easy
control of accuracy without compromising simulation stability. In a recent
publication, we have shown that DG methods also adapt readily to execution on
modern, massively parallel graphics processors (GPUs). A number of qualities of
the method contribute to this suitability, reaching from locality of reference,
through regularity of access patterns, to high arithmetic intensity. In this
article, we illuminate a few of the more practical aspects of bringing DG onto
a GPU, including the use of a Python-based metaprogramming infrastructure that
was created specifically to support DG, but has found many uses across all
disciplines of computational science."
"In this work we solve a special case of the problem of building an
n-dimensional parallelepiped using a given set of n-dimensional
parallelepipeds. Consider the identity x^3 = x(x-1)(x-2)+3x(x-1+x). For
sufficiently large x, we associate with x^3 a cube with edges of size x, with
x(x-1)(x-2) a parallelepiped with edges x, x-1, x-2, with 3x(x-1+x) three
parallelepipeds of edges x, x-1, 1, and with x a parallelepiped of edges x, 1,
1. The problem we takle is the actual construction of the cube using the given
parallelepipeds. In [DDNP90] it was shown how to solve this specific problem
and all similar instances in which a (monic) polynomial is expressed as a
linear combination of a persistent basis. That is to say a sequence of
polynomials q_0 = 1, and q_k(x) = q_{k-1}(x)(x-r_k) for k > 0. Here, after
[Fil10], we deal with a multivariate version of the problem with respect to a
basis of polynomials of the same degree (binomial basis). We show that it is
possible to build the parallelepiped associated with a multivariate polynomial
P(x_1, ..., x_n)=(x_1- s_1)...(x_n-s_n) with integer roots, using the
parallelepipeds described by the elements of the basis. We provide an algorithm
in Mathematica to solve the problem for each n. Moreover, for n = 2, 3, 4 (in
the latter case, only when a projection is possible) we use Mathematica to
display a step by step construction of the parallelepiped P(x1,...,x_n)."
"An open partition \pi{} [Cod09a, Cod09b] of a tree T is a partition of the
vertices of T with the property that, for each block B of \pi, the upset of B
is a union of blocks of \pi. This paper deals with the number, NP(n), of open
partitions of the tree, V_n, made of two chains with n points each, that share
the root."
"Mathematica offers, by way of the package Combinatorics, many useful
functions to work on graphs and ordered structures, but none of these functions
was specific enough to meet the needs of our research group. Moreover, the
existing functions are not always helpful when one has to work on new concepts.
  In this paper we present a package of features developed in Mathematica which
we consider particularly useful for the study of certain categories of
partially ordered sets. Among the features offered, the package includes: (1)
some basic features to treat partially ordered sets; (2) the ability to
enumerate, create, and display monotone and regular partitions of partially
ordered sets; (3) the capability of constructing the lattices of partitions of
a poset, and of doing some useful computations on these structures; (4) the
possibility of computing products and coproducts in the category of partially
ordered sets and monotone maps; (5) the possibility of computing products and
coproducts in the category of forests (disjoint union of trees) and open maps
(cf. [DM06] for the product between forests)."
"Mathematical operators whose transformation rules constitute the building
blocks of a multi-linear algebra are widely used in physics and engineering
applications where they are very often represented as tensors. In the last
century, thanks to the advances in tensor calculus, it was possible to uncover
new research fields and make remarkable progress in the existing ones, from
electromagnetism to the dynamics of fluids and from the mechanics of rigid
bodies to quantum mechanics of many atoms. By now, the formal mathematical and
geometrical properties of tensors are well defined and understood; conversely,
in the context of scientific and high-performance computing, many tensor-
related problems are still open. In this paper, we address the problem of
efficiently computing contractions among two tensors of arbitrary dimension by
using kernels from the highly optimized BLAS library. In particular, we
establish precise conditions to determine if and when GEMM, the kernel for
matrix products, can be used. Such conditions take into consideration both the
nature of the operation and the storage scheme of the tensors, and induce a
classification of the contractions into three groups. For each group, we
provide a recipe to guide the users towards the most effective use of BLAS."
"Sparse matrix-vector multiplication (spMVM) is the most time-consuming kernel
in many numerical algorithms and has been studied extensively on all modern
processor and accelerator architectures. However, the optimal sparse matrix
data storage format is highly hardware-specific, which could become an obstacle
when using heterogeneous systems. Also, it is as yet unclear how the wide
single instruction multiple data (SIMD) units in current multi- and many-core
processors should be used most efficiently if there is no structure in the
sparsity pattern of the matrix. We suggest SELL-C-sigma, a variant of Sliced
ELLPACK, as a SIMD-friendly data format which combines long-standing ideas from
General Purpose Graphics Processing Units (GPGPUs) and vector computer
programming. We discuss the advantages of SELL-C-sigma compared to established
formats like Compressed Row Storage (CRS) and ELLPACK and show its suitability
on a variety of hardware platforms (Intel Sandy Bridge, Intel Xeon Phi and
Nvidia Tesla K20) for a wide range of test matrices from different application
areas. Using appropriate performance models we develop deep insight into the
data transfer properties of the SELL-C-sigma spMVM kernel. SELL-C-sigma comes
with two tuning parameters whose performance impact across the range of test
matrices is studied and for which reasonable choices are proposed. This leads
to a hardware-independent (""catch-all"") sparse matrix format, which achieves
very high efficiency for all test matrices across all hardware platforms."
"Python implementation of permutations is presented. Three classes are
introduced: Perm for permutations, Group for permutation groups, and PermError
to report any errors for both classes. The class Perm is based on Python
dictionaries and utilize cycle notation. The methods of calculation for the
perm order, parity, ranking and unranking are given. A random permutation
generation is also shown. The class Group is very simple and it is also based
on dictionaries. It is mainly the presentation of the permutation groups
interface with methods for the group order, subgroups (normalizer, centralizer,
center, stabilizer), orbits, and several tests. The corresponding Python code
is contained in the modules perms and groups."
"We examine residual evaluation, perhaps the most basic operation in numerical
simulation. By raising the level of abstraction in this operation, we can
eliminate specialized code, enable optimization, and greatly increase the
extensibility of existing code."
"In this paper we describe how DUNE, an open source scientific software
framework, is developed. Having a sustainable software framework for the
solution of partial differential equations is the main driver of DUNE's
development. We take a look how DUNE strives to stay sustainable software."
"These notes outline a formal method for program verification of numerical
computation. It forms the basis of the software package VPC in its initial
phase of development. Much of the style of presentation is in the form of notes
that outline the definitions and rules upon which VPC is based. The initial
motivation of this project was to address some practical issues of computation,
especially of numerically intensive programs that are commonplace in computer
models. The project evolved into a wider area for program construction as
proofs leading to a model of inference in a more general sense. Some basic
results of machine arithmetic are derived as a demonstration of VPC."
"We describe the construction of quantum gates (unitary operators) from
boolean functions and give a number of applications. Both non-reversible and
reversible boolean functions are considered. The construction of the Hamilton
operator for a quantum gate is also described with the Hamilton operator
expressed as spin system. Computer algebra implementations are provided."
"As multicore systems continue to gain ground in the High Performance
Computing world, linear algebra algorithms have to be reformulated or new
algorithms have to be developed in order to take advantage of the architectural
features on these new processors. Fine grain parallelism becomes a major
requirement and introduces the necessity of loose synchronization in the
parallel execution of an operation. This paper presents an algorithm for the
Cholesky, LU and QR factorization where the operations can be represented as a
sequence of small tasks that operate on square blocks of data. These tasks can
be dynamically scheduled for execution based on the dependencies among them and
on the availability of computational resources. This may result in an out of
order execution of the tasks which will completely hide the presence of
intrinsically sequential tasks in the factorization. Performance comparisons
are presented with the LAPACK algorithms where parallelism can only be
exploited at the level of the BLAS operations and vendor implementations."
"Quantum anticipation explorer is a computer program allowing the numerical
exploration of quantum anticipation which has been analyzed in arXiv:0810.183v1
and arXiv:1003.1090v1 for H-Atom, equidistant, random and custom spectra. This
tool determines the anticipation strength at those times orthogonal evolution
is possible. This paper is the user's guide explaining its capabilities,
installation and usage, and documenting the mathematics and algorithms
implemented in the software. A zip file containing the setup and documentation
can be downloaded from
http://www.thomannconsulting.ch/public/aboutus/aboutus-en.htm free of cost."
"An approach for incorporating embedded simulation and analysis capabilities
in complex simulation codes through template-based generic programming is
presented. This approach relies on templating and operator overloading within
the C++ language to transform a given calculation into one that can compute a
variety of additional quantities that are necessary for many state-of-the-art
simulation and analysis algorithms. An approach for incorporating these ideas
into complex simulation codes through general graph-based assembly is also
presented. These ideas have been implemented within a set of packages in the
Trilinos framework and are demonstrated on a simple problem from chemical
engineering."
"We introduce a new collection of solvers - subsequently called EleMRRR - for
large-scale dense Hermitian eigenproblems. EleMRRR solves various types of
problems: generalized, standard, and tridiagonal eigenproblems. Among these,
the last is of particular importance as it is a solver on its own right, as
well as the computational kernel for the first two; we present a fast and
scalable tridiagonal solver based on the Algorithm of Multiple Relatively
Robust Representations - referred to as PMRRR. Like the other EleMRRR solvers,
PMRRR is part of the freely available Elemental library, and is designed to
fully support both message-passing (MPI) and multithreading parallelism (SMP).
As a result, the solvers can equally be used in pure MPI or in hybrid MPI-SMP
fashion. We conducted a thorough performance study of EleMRRR and ScaLAPACK's
solvers on two supercomputers. Such a study, performed with up to 8,192 cores,
provides precise guidelines to assemble the fastest solver within the ScaLAPACK
framework; it also indicates that EleMRRR outperforms even the fastest solvers
built from ScaLAPACK's components."
"Expression templates are a well-known set of techniques for improving the
efficiency of operator overloading-based forward mode automatic differentiation
schemes in the C++ programming language by translating the differentiation from
individual operators to whole expressions. However standard expression template
approaches result in a large amount of duplicate computation, particularly for
large expression trees, degrading their performance. In this paper we describe
several techniques for improving the efficiency of expression templates and
their implementation in the automatic differentiation package Sacado. We
demonstrate their improved efficiency through test functions as well as their
application to differentiation of a large-scale fluid dynamics simulation code."
"A template-based generic programming approach was presented in a previous
paper that separates the development effort of programming a physical model
from that of computing additional quantities, such as derivatives, needed for
embedded analysis algorithms. In this paper, we describe the implementation
details for using the template-based generic programming approach for
simulation and analysis of partial differential equations (PDEs). We detail
several of the hurdles that we have encountered, and some of the software
infrastructure developed to overcome them. We end with a demonstration where we
present shape optimization and uncertainty quantification results for a 3D PDE
application."
"The main purpose of this paper is to propose five programs in C++ for matrix
computations and solving recurrent equations systems with entries in max plus
algebra."
"We describe a general method for verifying inequalities between real-valued
expressions, especially the kinds of straightforward inferences that arise in
interactive theorem proving. In contrast to approaches that aim to be complete
with respect to a particular language or class of formulas, our method
establishes claims that require heterogeneous forms of reasoning, relying on a
Nelson-Oppen-style architecture in which special-purpose modules collaborate
and share information. The framework is thus modular and extensible. A
prototype implementation shows that the method works well on a variety of
examples, and complements techniques that are used by contemporary interactive
provers."
"This paper introduces the Bloscpack file format and the accompanying Python
reference implementation. Bloscpack is a lightweight, compressed binary
file-format based on the Blosc codec and is designed for lightweight, fast
serialization of numerical data. This article presents the features of the
file-format and some some API aspects of the reference implementation, in
particular the ability to handle Numpy ndarrays. Furthermore, in order to
demonstrate its utility, the format is compared both feature- and
performance-wise to a few alternative lightweight serialization solutions for
Numpy ndarrays. The performance comparisons take the form of some comprehensive
benchmarks over a range of different artificial datasets with varying size and
complexity, the results of which are presented as the last section of this
article."
"The Python library FatGHol FatGHoL used in Murri2012 to reckon the rational
homology of the moduli space of Riemann surfaces is an example of a non-numeric
scientific code: most of the processing it does is generating graphs
(represented by complex Python objects) and computing their isomorphisms (a
triple of Python lists; again a nested data structure). These operations are
repeated many times over: for example, the spaces and are triangulated by
4'583'322 and 747'664 graphs, respectively. This is an opportunity for every
Python runtime to prove its strength in optimization. The purpose of this
experiment was to assess the maturity of alternative Python runtimes, in terms
of: compatibility with the language as implemented in CPython 2.7, and
performance speedup. This paper compares the results and experiences from
running FatGHol with different Python runtimes: CPython 2.7.5, PyPy 2.1, Cython
0.19, Numba 0.11, Nuitka 0.4.4 and Falcon."
"We propose an effective and flexible way to assemble finite element stiffness
and mass matrices in MATLAB. We apply this for problems discretized by edge
finite elements. Typical edge finite elements are Raviart-Thomas elements used
in discretizations of H(div) spaces and Nedelec elements in discretizations of
H(curl) spaces. We explain vectorization ideas and comment on a freely
available MATLAB code which is fast and scalable with respect to time."
"Tensor operations are surging as the computational building blocks for a
variety of scientific simulations and the development of high-performance
kernels for such operations is known to be a challenging task. While for
operations on one- and two-dimensional tensors there exist standardized
interfaces and highly-optimized libraries (BLAS), for higher dimensional
tensors neither standards nor highly-tuned implementations exist yet. In this
paper, we consider contractions between two tensors of arbitrary dimensionality
and take on the challenge of generating high-performance implementations by
resorting to sequences of BLAS kernels. The approach consists in breaking the
contraction down into operations that only involve matrices or vectors. Since
in general there are many alternative ways of decomposing a contraction, we are
able to methodically derive a large family of algorithms. The main contribution
of this paper is a systematic methodology to accurately identify the fastest
algorithms in the bunch, without executing them. The goal is instead
accomplished with the help of a set of cache-aware micro-benchmarks for the
underlying BLAS kernels. The predictions we construct from such benchmarks
allow us to reliably single out the best-performing algorithms in a tiny
fraction of the time taken by the direct execution of the algorithms."
"Linear systems with large differences between coefficients (""discontinuous
coefficients"") arise in many cases in which partial differential
equations(PDEs) model physical phenomena involving heterogeneous media. The
standard approach to solving such problems is to use domain decomposition
techniques, with domain boundaries conforming to the boundaries between the
different media. This approach can be difficult to implement when the geometry
of the domain boundaries is complicated or the grid is unstructured. This work
examines the simple preconditioning technique of scaling the equations by
dividing each equation by the Lp-norm of its coefficients. This preconditioning
is called geometric scaling (GS). It has long been known that diagonal scaling
can be useful in improving convergence, but there is no study on the general
usefulness of this approach for discontinuous coefficients. GS was tested on
several nonsymmetric linear systems with discontinuous coefficients derived
from convection-diffusion elliptic PDEs with small to moderate convection
terms. It is shown that GS improved the convergence properties of restarted
GMRES and Bi-CGSTAB, with and without the ILUT preconditioner. GS was also
shown to improve the distribution of the eigenvalues by reducing their
concentration around the origin very significantly."
"An algorithm has been devised to compute the inner and outer product between
two arbitrary multi-dimensional arrays A and B in a single piece of code. It
was derived using A Mathematics of Arrays (MoA) and the $\psi$-calculus.
Extensive tests of the new algorithm are presented for running in sequential as
well as OpenMP multiple processor modes."
"The Kronecker product is a key algorithm and is ubiquitous across the
physical, biological, and computation social sciences. Thus considerations of
optimal implementation are important. The need to have high performance and
computational reproducibility is paramount. Moreover, due to the need to
compose multiple Kronecker products, issues related to data structures, layout
and indexing algebra require a new look at an old problem. This paper discusses
the outer product/tensor product and a special case of the tensor product: the
Kronecker product, along with optimal implementation when composed, and mapped
to complex processor/memory hierarchies. We discuss how the use of ``A
Mathematics of Arrays"" (MoA), and the psi-Calculus, (a calculus of indexing
with shapes), provides optimal, verifiable, reproducible, scalable, and
portable implementations of both hardware and software."
"We present a novel finite element integration method for low order elements
on GPUs. We achieve more than 100GF for element integration on first order
discretizations of both the Laplacian and Elasticity operators."
"We give a link to a page on the Web on which we deposited a set of eight huge
Linear Programming (LP) problems for Intensity-Modulated Proton Therapy (IMPT)
treatment planning. These huge LP problems were employed in our recent research
and we were asked to make them public."
A study of the existing linear algebra libraries that you can use from C++
"We describe here a library aimed at automating the solution of partial
differential equations using the finite element method. By employing novel
techniques for automated code generation, the library combines a high level of
expressiveness with efficient computation. Finite element variational forms may
be expressed in near mathematical notation, from which low-level code is
automatically generated, compiled and seamlessly integrated with efficient
implementations of computational meshes and high-performance linear algebra.
Easy-to-use object-oriented interfaces to the library are provided in the form
of a C++ library and a Python module. This paper discusses the mathematical
abstractions and methods used in the design of the library and its
implementation. A number of examples are presented to demonstrate the use of
the library in application code."
"A C++ library, named ZKCM, has been developed for the purpose of
multiprecision matrix calculations, which is based on the GNU MP and MPFR
libraries. It is especially convenient for writing programs involving
tensor-product operations, tracing-out operations, and singular-value
decompositions. Its extension library, ZKCM_QC, for simulating quantum
computing has been developed using the time-dependent matrix-product-state
simulation method. This report gives a brief introduction to the libraries with
sample programs."
"In this work we describe an efficient implementation of a hierarchy of
algorithms for Gaussian elimination upon dense matrices over the field with two
elements. We discuss both well-known and new algorithms as well as our
implementations in the M4RI library, which has been adopted into Sage. The
focus of our discussion is a block iterative algorithm for PLE decomposition
which is inspired by the M4RI algorithm. The implementation presented in this
work provides considerable performance gains in practice when compared to the
previously fastest implementation. We provide performance figures on x86_64
CPUs to demonstrate the alacrity of our approach."
"In this paper two ways to compute singular values are presented which use
Cholesky decomposition as their basic operation."
"We present a symbolic tool that provides robust algebraic methods to handle
automatic deduction tasks for a dynamic geometry construction. The main
prototype has been developed as two different worksheets for the open source
computer algebra system Sage, corresponding to two different ways of coding a
geometric construction. In one worksheet, diagrams constructed with the open
source dynamic geometry system GeoGebra are accepted. In this worksheet,
Groebner bases are used to either compute the equation of a geometric locus in
the case of a locus construction or to determine the truth of a general
geometric statement included in the GeoGebra construction as a boolean
variable. In the second worksheet, locus constructions coded using the common
file format for dynamic geometry developed by the Intergeo project are accepted
for computation. The prototype and several examples are provided for testing.
Moreover, a third Sage worksheet is presented in which a novel algorithm to
eliminate extraneous parts in symbolically computed loci has been implemented.
The algorithm, based on a recent work on the Groebner cover of parametric
systems, identifies degenerate components and extraneous adherence points in
loci, both natural byproducts of general polynomial algebraic methods. Detailed
examples are discussed."
"This paper is devoted to present the Mathematics Grammar Library, a system
for multilingual mathematical text processing. We explain the context in which
it originated, its current design and functionality and the current development
goals. We also present two prototype services and comment on possible future
applications in the area of artificial mathematics assistants."
"In this article we test the accuracy of three platforms used in computational
modelling: MatLab, Octave and Scilab, running on i386 architecture and three
operating systems (Windows, Ubuntu and Mac OS). We submitted them to numerical
tests using standard data sets and using the functions provided by each
platform. A Monte Carlo study was conducted in some of the datasets in order to
verify the stability of the results with respect to small departures from the
original input. We propose a set of operations which include the computation of
matrix determinants and eigenvalues, whose results are known. We also used data
provided by NIST (National Institute of Standards and Technology), a protocol
which includes the computation of basic univariate statistics (mean, standard
deviation and first-lag correlation), linear regression and extremes of
probability distributions. The assessment was made comparing the results
computed by the platforms with certified values, that is, known results,
computing the number of correct significant digits."
"This paper is an example-based demonstration of our initial results on the
formal specification of programs written in the computer algebra language
MiniMaple (a substantial subset of Maple with slight extensions). The main goal
of this work is to define a verification framework for MiniMaple. Formal
specification of MiniMaple programs is rather complex task as it supports
non-standard types of objects, e.g. symbols and unevaluated expressions, and
additional functions and predicates, e.g. runtime type tests etc. We have used
the specification language to specify various computer algebra concepts
respective objects of the Maple package DifferenceDifferential developed at our
institute."
"Digital Geometry software should reflect the generality of the underlying
mathe- matics: mapping the latter to the former requires genericity. By
designing generic solutions, one can effectively reuse digital geometry data
structures and algorithms. We propose an image processing framework focused on
the Generic Programming paradigm in which an algorithm on the paper can be
turned into a single code, written once and usable with various input types.
This approach enables users to design and implement new methods at a lower
cost, try cross-domain experiments and help generalize results"
"Scientists spend an increasing amount of time building and using software.
However, most scientists are never taught how to do this efficiently. As a
result, many are unaware of tools and practices that would allow them to write
more reliable and maintainable code with less effort. We describe a set of best
practices for scientific software development that have solid foundations in
research and experience, and that improve scientists' productivity and the
reliability of their software."
"Sparse matrix vector multiplication (SpMV) is an important kernel in
scientific and engineering applications. The previous optimizations are sparse
matrix format specific and expose the choice of the best format to application
programmers. In this work we develop an auto-tuning framework to bridge gap
between the specific optimized kernels and their general-purpose use. We
propose an SpMV auto-tuner (SMAT) that provides an unified interface based on
compressed sparse row (CSR) to programmers by implicitly choosing the best
format and the fastest implementation of any input sparse matrix in runtime.
SMAT leverage a data mining model, which is formulated based on a set of
performance parameters extracted from 2373 matrices in UF sparse matrix
collection, to fast search the best combination. The experiments show that SMAT
achieves the maximum performance of 75 GFLOP/s in single-precision and 33
GFLOP/s in double-precision on Intel, and 41 GFLOP/s in single-precision and 34
GFLOP/s in double-precision on AMD. Compared with the sparse functions in MKL
library, SMAT runs faster by more than 3 times."
"The most widely used algorithm for floating point complex division, known as
Smith's method, may fail more often than expected. This document presents two
improved complex division algorithms. We present a proof of the robustness of
the first improved algorithm. Numerical simulations show that this algorithm
performs well in practice and is significantly more robust than other known
implementations. By combining additionnal scaling methods with this first
algorithm, we were able to create a second algorithm, which rarely fails."
"We present efficient algorithms to build data structures and the lists needed
for fast multipole methods. The algorithms are capable of being efficiently
implemented on both serial, data parallel GPU and on distributed architectures.
With these algorithms it is possible to map the FMM efficiently on to the GPU
or distributed heterogeneous CPU-GPU systems. Further, in dynamic problems, as
the distribution of the particles change, the reduced cost of building the data
structures improves performance. Using these algorithms, we demonstrate example
high fidelity simulations with large problem sizes by using FMM on both single
and multiple heterogeneous computing facilities equipped with multi-core CPU
and many-core GPUs."
"Waves are all around us--be it in the form of sound, electromagnetic
radiation, water waves, or earthquakes. Their study is an important basic tool
across engineering and science disciplines. Every wave solver serving the
computational study of waves meets a trade-off of two figures of merit--its
computational speed and its accuracy. Discontinuous Galerkin (DG) methods fall
on the high-accuracy end of this spectrum. Fortuitously, their computational
structure is so ideally suited to GPUs that they also achieve very high
computational speeds. In other words, the use of DG methods on GPUs
significantly lowers the cost of obtaining accurate solutions. This article
aims to give the reader an easy on-ramp to the use of this technology, based on
a sample implementation which demonstrates a highly accurate, GPU-capable,
real-time visualizing finite element solver in about 1500 lines of code."
"While there is no lack of efficient Krylov subspace solvers for Hermitian
systems, there are few for complex symmetric, skew symmetric, or skew Hermitian
systems, which are increasingly important in modern applications including
quantum dynamics, electromagnetics, and power systems. For a large consistent
complex symmetric system, one may apply a non-Hermitian Krylov subspace method
disregarding the symmetry of $A$, or a Hermitian Krylov solver on the
equivalent normal equation or an augmented system twice the original dimension.
These have the disadvantages of increasing either memory, conditioning, or
computational costs. An exception is a special version of QMR by Freund (1992),
but that may be affected by non-benign breakdowns unless look-ahead is
implemented; furthermore, it is designed for only consistent and nonsingular
problems. For skew symmetric systems, Greif and Varah (2009) adapted CG for
nonsingular skew symmetric linear systems that are necessarily and
restrictively of even order.
  We extend the symmetric and Hermitian algorithms MINRES and MINRES-QLP by
Choi, Paige and Saunders (2011) to complex symmetric, skew symmetric, and skew
Hermitian systems. In particular, MINRES-QLP uses a rank-revealing QLP
decomposition of the tridiagonal matrix from a three-term recurrent
complex-symmetric Lanczos process. Whether the systems are real or complex,
singular or invertible, compatible or inconsistent, MINRES-QLP computes the
unique minimum-length, i.e., pseudoinverse, solutions. It is a significant
extension of MINRES by Paige and Saunders (1975) with enhanced stability and
capability."
"We assume some standard choices for the branch cuts of a group of functions
and consider the problem of then calculating the branch cuts of expressions
involving those functions. Typical examples include the addition formulae for
inverse trigonometric functions. Understanding these cuts is essential for
working with the single-valued counterparts, the common approach to encoding
multi-valued functions in computer algebra systems. While the defining choices
are usually simple (typically portions of either the real or imaginary axes)
the cuts induced by the expression may be surprisingly complicated. We have
made explicit and implemented techniques for calculating the cuts in the
computer algebra programme Maple. We discuss the issues raised, classifying the
different cuts produced. The techniques have been gathered in the BranchCuts
package, along with tools for visualising the cuts. The package is included in
Maple 17 as part of the FunctionAdvisor tool."
"We present PetIGA, a code framework to approximate the solution of partial
differential equations using isogeometric analysis. PetIGA can be used to
assemble matrices and vectors which come from a Galerkin weak form, discretized
with Non-Uniform Rational B-spline basis functions. We base our framework on
PETSc, a high-performance library for the scalable solution of partial
differential equations, which simplifies the development of large-scale
scientific codes, provides a rich environment for prototyping, and separates
parallelism from algorithm choice. We describe the implementation of PetIGA,
and exemplify its use by solving a model nonlinear problem. To illustrate the
robustness and flexibility of PetIGA, we solve some challenging nonlinear
partial differential equations that include problems in both solid and fluid
mechanics. We show strong scaling results on up to 4096 cores, which confirm
the suitability of PetIGA for large scale simulations."
"The Agora system is a prototype ""Wiki for Formal Mathematics"", with an aim to
support developing and documenting large formalizations of mathematics in a
proof assistant. The functions implemented in Agora include in-browser editing,
strong AI/ATP proof advice, verification, and HTML rendering. The HTML
rendering contains hyperlinks and provides on-demand explanation of the proof
state for each proof step. In the present paper we show the prototype Flyspeck
Wiki as an instance of Agora for HOL Light formalizations. The wiki can be used
for formalizations of mathematics and for writing informal wiki pages about
mathematics. Such informal pages may contain islands of formal text, which is
used here for providing an initial cross-linking between Hales's informal
Flyspeck book, and the formal Flyspeck development.
  The Agora platform intends to address distributed wiki-style collaboration on
large formalization projects, in particular both the aspect of immediate
editing, verification and rendering of formal code, and the aspect of gradual
and mutual refactoring and correspondence of the initial informal text and its
formalization. Here, we highlight these features within the Flyspeck Wiki."
"Methods and an algorithm for computing the generalized Marcum $Q-$function
($Q_{\mu}(x,y)$) and the complementary function ($P_{\mu}(x,y)$) are described.
These functions appear in problems of different technical and scientific areas
such as, for example, radar detection and communications, statistics and
probability theory, where they are called the non-central chi-square or the non
central gamma cumulative distribution functions.
  The algorithm for computing the Marcum functions combines different methods
of evaluation in different regions: series expansions, integral
representations, asymptotic expansions, and use of three-term homogeneous
recurrence relations. A relative accuracy close to $10^{-12}$ can be obtained
in the parameter region $(x,y,\mu) \in [0,\,A]\times [0,\,A]\times [1,\,A]$,
$A=200$, while for larger parameters the accuracy decreases (close to
$10^{-11}$ for $A=1000$ and close to $5\times 10^{-11}$ for $A=10000$)."
"Over the past decade, the high performance computing community has become
increasingly concerned that preserving the reliable, digital machine model will
become too costly or infeasible. In this paper we discuss four approaches for
developing new algorithms that are resilient to hard and soft failures."
"We present our public-domain software for the following tasks in sparse (or
toric) elimination theory, given a well-constrained polynomial system. First, C
code for computing the mixed volume of the system. Second, Maple code for
defining an overconstrained system and constructing a Sylvester-type matrix of
its sparse resultant. Third, C code for a Sylvester-type matrix of the sparse
resultant and a superset of all common roots of the initial well-constrained
system by computing the eigen-decomposition of a square matrix obtained from
the resultant matrix. We conclude with experiments in computing molecular
conformations."
"We describe here a rudimentary sage implementation of the Bhattacharya-Mesner
hypermatrix algebra package."
"The RngStreams software package provides one viable solution to the problem
of creating independent random number streams for simulations in parallel
processing environments. Techniques are presented for effectively using
RngStreams with C++ programs that are parallelized via OpenMP or MPI. Ways to
access the backbone generator from RngStreams in R through the parallel and
rstream packages are also described. The ideas in the paper are illustrated
with both a simple running example and a Monte Carlo integration application."
"Power awareness is fast becoming immensely important in computing, ranging
from the traditional High Performance Computing applications, to the new
generation of data centric workloads.
  In this work we describe our efforts towards a power efficient computing
paradigm that combines low precision and high precision arithmetic. We showcase
our ideas for the widely used kernel of solving systems of linear equations
that finds numerous applications in scientific and engineering disciplines as
well as in large scale data analytics, statistics and machine learning.
  Towards this goal we developed tools for the seamless power profiling of
applications at a fine grain level. In addition, we verify here previous work
on post FLOPS/Watt metrics and show that these can shed much more light in the
power/energy profile of important applications."
"Since there are different ways of axiomatizing and developing a mathematical
theory, knowledge about a such a theory may reside in many places and in many
forms within a library of formalized mathematics. We introduce the notion of a
realm as a structure for consolidating knowledge about a mathematical theory. A
realm contains several axiomatizations of a theory that are separately
developed. Views interconnect these developments and establish that the
axiomatizations are equivalent in the sense of being mutually interpretable. A
realm also contains an external interface that is convenient for users of the
library who want to apply the concepts and facts of the theory without delving
into the details of how the concepts and facts were developed. We illustrate
the utility of realms through a series of examples. We also give an outline of
the mechanisms that are needed to create and maintain realms."
"The Isabelle proof assistant comes equipped with a very powerful tactic for
term simplification. While tremendously useful, the results of simplifying a
term do not always match the user's expectation: sometimes, the resulting term
is not in the form the user expected, or the simplifier fails to apply a rule.
We describe a new, interactive tracing facility which offers insight into the
hierarchical structure of the simplification with user-defined filtering,
memoization and search. The new simplifier trace is integrated into the
Isabelle/jEdit Prover IDE."
"We study novel arithmetic algorithms on a canonical number representation
based on the Catalan family of combinatorial objects.
  Our algorithms work on a generic representation that we illustrate on
instances like ordered binary and multiway trees, balanced parentheses
languages as well as the usual bitstring-based natural numbers seen through the
same generic interface as members of the Catalan family.
  For numbers corresponding to Catalan objects of low representation
complexity, our algorithms provide super-exponential gains while their average
and worst case complexity is within constant factors of their traditional
counterparts."
"ViDaExpert is a tool for visualization and analysis of multidimensional
vectorial data. ViDaExpert is able to work with data tables of ""object-feature""
type that might contain numerical feature values as well as textual labels for
rows (objects) and columns (features). ViDaExpert implements several
statistical methods such as standard and weighted Principal Component Analysis
(PCA) and the method of elastic maps (non-linear version of PCA), Linear
Discriminant Analysis (LDA), multilinear regression, K-Means clustering, a
variant of decision tree construction algorithm. Equipped with several
user-friendly dialogs for configuring data point representations (size, shape,
color) and fast 3D viewer, ViDaExpert is a handy tool allowing to construct an
interactive 3D-scene representing a table of data in multidimensional space and
perform its quick and insightfull statistical analysis, from basic to advanced
methods."
"The paper describes a SageTeX implementation of an integer encoding
procedures."
"scikit-image is an image processing library that implements algorithms and
utilities for use in research, education and industry applications. It is
released under the liberal ""Modified BSD"" open source license, provides a
well-documented API in the Python programming language, and is developed by an
active, international team of collaborators. In this paper we highlight the
advantages of open source to achieve the goals of the scikit-image library, and
we showcase several real-world image processing applications that use
scikit-image."
"In this paper we present the new DUNE-ALUGrid module. This module contains a
major overhaul of the sources from the ALUgrid library and the binding to the
DUNE software framework. The main changes include user defined load balancing,
parallel grid construction, and an redesign of the 2d grid which can now also
be used for parallel computations. In addition many improvements have been
introduced into the code to increase the parallel efficiency and to decrease
the memory footprint.
  The original ALUGrid library is widely used within the DUNE community due to
its good parallel performance for problems requiring local adaptivity and
dynamic load balancing. Therefore, this new model will benefit a number of DUNE
users. In addition we have added features to increase the range of problems for
which the grid manager can be used, for example, introducing a 3d tetrahedral
grid using a parallel newest vertex bisection algorithm for conforming grid
refinement. In this paper we will discuss the new features, extensions to the
DUNE interface, and explain for various examples how the code is used in
parallel environments."
"The spheroidal wave functions, which are the solutions to the Helmholtz
equation in spheroidal coordinates, are notoriously difficult to compute.
Because of this, practically no programming language comes equipped with the
means to compute them. This makes problems that require their use hard to
tackle. We have developed computational software for calculating these special
functions. Our software is called spheroidal and includes several novel
features, such as: using arbitrary precision arithmetic; adaptively choosing
the number of expansion coefficients to compute and use; and using the
Wronskian to choose from several different methods for computing the spheroidal
radial functions to improve their accuracy. There are two types of spheroidal
wave functions: the prolate kind when prolate spheroidal coordinates are used;
and the oblate kind when oblate spheroidal coordinate are used. In this paper,
we describe both, methods for computing them, and our software. We have made
our software freely available on our webpage."
"In recent years it has been shown that for many linear algebra operations it
is possible to create families of algorithms following a very systematic
procedure. We do not refer to the fine tuning of a known algorithm, but to a
methodology for the actual generation of both algorithms and routines to solve
a given target matrix equation. Although systematic, the methodology relies on
complex algebraic manipulations and non-obvious pattern matching, making the
procedure challenging to be performed by hand, our goal is the development of a
fully automated system that from the sole description of a target equation
creates multiple algorithms and routines. We present CL1ck, a symbolic system
written in Mathematica, that starts with an equation, decomposes it into
multiple equations, and returns a set of loop-invariants for the algorithms --
yet to be generated -- that will solve the equation. In a successive step each
loop-invariant is then mapped to its corresponding algorithm and routine. For a
large class of equations, the methodology generates known algorithms as well as
many previously unknown ones. Most interestingly, the methodology unifies
algorithms traditionally developed in isolation. As an example, the five well
known algorithms for the LU factorization are for the first time unified under
a common root."
"In a series of papers it has been shown that for many linear algebra
operations it is possible to generate families of algorithms by following a
systematic procedure. Although powerful, such a methodology involves complex
algebraic manipulation, symbolic computations and pattern matching, making the
generation a process challenging to be performed by hand. We aim for a fully
automated system that from the sole description of a target operation creates
multiple algorithms without any human intervention. Our approach consists of
three main stages. The first stage yields the core object for the entire
process, the Partitioned Matrix Expression (PME), which establishes how the
target problem may be decomposed in terms of simpler sub-problems. In the
second stage the PME is inspected to identify predicates, the Loop-Invariants,
to be used to set up the skeleton of a family of proofs of correctness. In the
third and last stage the actual algorithms are constructed so that each of them
satisfies its corresponding proof of correctness. In this paper we focus on the
first stage of the process, the automatic generation of Partitioned Matrix
Expressions. In particular, we discuss the steps leading to a PME and the
knowledge necessary for a symbolic system to perform such steps. We also
introduce Cl1ck, a prototype system written in Mathematica that generates PMEs
automatically."
"Modern HPC architectures consist of heterogeneous multi-core, many-node
systems with deep memory hierarchies. Modern applications employ ever more
advanced discretisation methods to study multi-physics problems. Developing
such applications that explore cutting-edge physics on cutting-edge HPC systems
has become a complex task that requires significant HPC knowledge and
experience. Unfortunately, this combined knowledge is currently out of reach
for all but a few groups of application developers.
  Chemora is a framework for solving systems of Partial Differential Equations
(PDEs) that targets modern HPC architectures. Chemora is based on Cactus, which
sees prominent usage in the computational relativistic astrophysics community.
In Chemora, PDEs are expressed either in a high-level \LaTeX-like language or
in Mathematica. Discretisation stencils are defined separately from equations,
and can include Finite Differences, Discontinuous Galerkin Finite Elements
(DGFE), Adaptive Mesh Refinement (AMR), and multi-block systems.
  We use Chemora in the Einstein Toolkit to implement the Einstein Equations on
CPUs and on accelerators, and study astrophysical systems such as black hole
binaries, neutron stars, and core-collapse supernovae."
"We describe a new implementation of the elementary transcendental functions
exp, sin, cos, log and atan for variable precision up to approximately 4096
bits. Compared to the MPFR library, we achieve a maximum speedup ranging from a
factor 3 for cos to 30 for atan. Our implementation uses table-based argument
reduction together with rectangular splitting to evaluate Taylor series. We
collect denominators to reduce the number of divisions in the Taylor series,
and avoid overhead by doing all multiprecision arithmetic using the mpn layer
of the GMP library. Our implementation provides rigorous error bounds."
"GPTIPS is a free, open source MATLAB based software platform for symbolic
data mining (SDM). It uses a multigene variant of the biologically inspired
machine learning method of genetic programming (MGGP) as the engine that drives
the automatic model discovery process. Symbolic data mining is the process of
extracting hidden, meaningful relationships from data in the form of symbolic
equations. In contrast to other data-mining methods, the structural
transparency of the generated predictive equations can give new insights into
the physical systems or processes that generated the data. Furthermore, this
transparency makes the models very easy to deploy outside of MATLAB. The
rationale behind GPTIPS is to reduce the technical barriers to using,
understanding, visualising and deploying GP based symbolic models of data,
whilst at the same time remaining highly customisable and delivering robust
numerical performance for power users. In this chapter, notable new features of
the latest version of the software are discussed with these aims in mind.
Additionally, a simplified variant of the MGGP high level gene crossover
mechanism is proposed. It is demonstrated that the new functionality of GPTIPS
2 (a) facilitates the discovery of compact symbolic relationships from data
using multiple approaches, e.g. using novel gene-centric visualisation analysis
to mitigate horizontal bloat and reduce complexity in multigene symbolic
regression models (b) provides numerous methods for visualising the properties
of symbolic models (c) emphasises the generation of graphically navigable
libraries of models that are optimal in terms of the Pareto trade off surface
of model performance and complexity and (d) expedites real world applications
by the simple, rapid and robust deployment of symbolic models outside the
software environment they were developed in."
"Performing massive data mining experiments with multiple datasets and methods
is a common task faced by most bioinformatics and computational biology
laboratories. WEKA is a machine learning package designed to facilitate this
task by providing tools that allow researchers to select from several
classification methods and specific test strategies. Despite its popularity,
the current WEKA environment for batch experiments, namely Experimenter, has
four limitations that impact its usability: the selection of value ranges for
methods options lacks flexibility and is not intuitive; there is no support for
parallelisation when running large-scale data mining tasks; the XML schema is
difficult to read, necessitating the use of the Experimenter's graphical user
interface for generation and modification; and robustness is limited by the
fact that results are not saved until the last test has concluded.
  FlexDM implements an interface to WEKA to run batch processing tasks in a
simple and intuitive way. In a short and easy-to-understand XML file, one can
define hundreds of tests to be performed on several datasets. FlexDM also
allows those tests to be executed asynchronously in parallel to take advantage
of multi-core processors, significantly increasing usability and productivity.
Results are saved incrementally for better robustness and reliability.
  FlexDM is implemented in Java and runs on Windows, Linux and OSX. As we
encourage other researchers to explore and adopt our software, FlexDM is made
available as a pre-configured bootable reference environment. All code,
supporting documentation and usage examples are also available for download at
http://sourceforge.net/projects/flexdm."
"We present SClib, a simple hack that allows easy and straightforward
evaluation of C functions within Python code, boosting flexibility for better
trade-off between computation power and feature availability, such as
visualization and existing computation routines in SciPy. We also present two
cases were SClib has been used. In the first set of applications we use SClib
to write a port to Python of a Schr\""odinger equation solver that has been
extensively used the literature, the resulting script presents a speed-up of
about 150x with respect to the original one. A review of the situations where
the speeded-up script has been used is presented. We also describe the solution
to the related problem of solving a set of coupled Schr\""odinger-like equations
where SClib is used to implement the speed-critical parts of the code. We argue
that when using SClib within IPython we can use NumPy and Matplotlib for the
manipulation and visualization of the solutions in an interactive environment
with no performance compromise. The second case is an engineering application.
We use SClib to evaluate the control and system derivatives in a feedback
control loop for electrical motors. With this and the integration routines
available in SciPy, we can run simulations of the control loop a la Simulink.
The use of C code not only boosts the speed of the simulations, but also
enables to test the exact same code that we use in the test rig to get
experimental results. Again, integration with IPython gives us the flexibility
to analyze and visualize the data."
"Recently, graphics processors (GPUs) have been increasingly leveraged in a
variety of scientific computing applications. However, architectural
differences between CPUs and GPUs necessitate the development of algorithms
that take advantage of GPU hardware. As sparse matrix vector multiplication
(SPMV) operations are commonly used in finite element analysis, a new SPMV
algorithm and several variations are developed for unstructured finite element
meshes on GPUs. The effective bandwidth of current GPU algorithms and the newly
proposed algorithms are measured and analyzed for 15 sparse matrices of varying
sizes and varying sparsity structures. The effects of optimization and
differences between the new GPU algorithm and its variants are then
subsequently studied. Lastly, both new and current SPMV GPU algorithms are
utilized in the GPU CG Solver in GPU finite element simulations of the heart.
These results are then compared against parallel PETSc finite element
implementation results. The effective bandwidth tests indicate that the new
algorithms compare very favorably with current algorithms for a wide variety of
sparse matrices and can yield very notable benefits. GPU finite element
simulation results demonstrate the benefit of using GPUs for finite element
analysis, and also show that the proposed algorithms can yield speedup factors
up to 12-fold for real finite element applications."
"The fast Fourier transform (FFT) is a primitive kernel in numerous fields of
science and engineering. OpenFFT is an open-source parallel package for 3-D
FFTs, built on a communication-optimal domain decomposition method for
achieving minimal volume of communication. In this paper, we analyze and tune
the performance of OpenFFT, paying a particular attention to tuning of
communication that dominates the run time of large-scale calculations. We first
analyze its performance on different machines for an understanding of the
behaviors of the package and machines. Based on the performance analysis, we
develop six communication methods for performing communication with the aim of
covering varied calculation scales on a variety of computational platforms.
OpenFFT is then augmented with an auto-tuning of communication to select the
best method in run time depending on their performance. Numerical results
demonstrate that the optimized OpenFFT is able to deliver relatively good
performance in comparison with other state-of-the-art packages at different
computational scales on a number of parallel machines."
"We are interested in the asymptotic behavior of orthogonal polynomials of the
generalized Jacobi type as their degree $n$ goes to $\infty$. These are defined
on the interval $[-1,1]$ with weight function
$w(x)=(1-x)^{\alpha}(1+x)^{\beta}h(x)$, $\alpha,\beta>-1$ and $h(x)$ a real,
analytic and strictly positive function on $[-1,1]$. This information is
available in the work of Kuijlaars, McLaughlin, Van Assche and Vanlessen, where
the authors use the Riemann--Hilbert formulation and the Deift--Zhou non-linear
steepest descent method. We show that computing higher-order terms can be
simplified, leading to their efficient construction. The resulting asymptotic
expansions in every region of the complex plane are implemented both
symbolically and numerically, and the code is made publicly available. The main
advantage of these expansions is that they lead to increasing accuracy for
increasing degree of the polynomials, at a computational cost that is actually
independent of the degree. In contrast, the typical use of the recurrence
relation for orthogonal polynomials in computations leads to a cost that is at
least linear in the degree. Furthermore, the expansions may be used to compute
Gaussian quadrature rules in $\mathcal{O}(n)$ operations, rather than
$\mathcal{O}(n^2)$ based on the recurrence relation."
"Monte Carlo (MC) simulation includes a wide range of stochastic techniques
used to quantitatively evaluate the behavior of complex systems or processes.
Microsoft Excel spreadsheets with Visual Basic for Applications (VBA) software
is, arguably, the most commonly employed general purpose tool for MC
simulation. Despite the popularity of the Excel in many industries and
educational institutions, it has been repeatedly criticized for its flaws and
often described as questionable, if not completely unsuitable, for statistical
problems. The purpose of this study is to assess suitability of the Excel
(specifically its 2010 and 2013 versions) with VBA programming as a tool for MC
simulation. The results of the study indicate that Microsoft Excel (versions
2010 and 2013) is a strong Monte Carlo simulation application offering a solid
framework of core simulation components including spreadsheets for data input
and output, VBA development environment and summary statistics functions. This
framework should be complemented with an external high-quality pseudo-random
number generator added as a VBA module. A large and diverse category of Excel
incidental simulation components that includes statistical distributions,
linear and non-linear regression and other statistical, engineering and
business functions require execution of due diligence to determine their
suitability for a specific MC project."
"One approach to achieving correct finite element assembly is to ensure that
the local orientation of facets relative to each cell in the mesh is consistent
with the global orientation of that facet. Rognes et al. have shown how to
achieve this for any mesh composed of simplex elements, and deal.II contains a
serial algorithm to construct a consistent orientation of any quadrilateral
mesh of an orientable manifold.
  The core contribution of this paper is the extension of this algorithm for
distributed memory parallel computers, which facilitates its seamless
application as part of a parallel simulation system.
  Furthermore, our analysis establishes a link between the well-known
Union-Find algorithm and the construction of a consistent orientation of a
quadrilateral mesh. As a result, existing work on the parallelisation of the
Union-Find algorithm can be easily adapted to construct further parallel
algorithms for mesh orientations."
"Matrix operations such as matrix inversion, eigenvalue decomposition,
singular value decomposition are ubiquitous in real-world applications.
Unfortunately, many of these matrix operations so time and memory expensive
that they are prohibitive when the scale of data is large. In real-world
applications, since the data themselves are noisy, machine-precision matrix
operations are not necessary at all, and one can sacrifice a reasonable amount
of accuracy for computational efficiency.
  In recent years, a bunch of randomized algorithms have been devised to make
matrix computations more scalable. Mahoney (2011) and Woodruff (2014) have
written excellent but very technical reviews of the randomized algorithms.
Differently, the focus of this manuscript is on intuition, algorithm
derivation, and implementation. This manuscript should be accessible to people
with knowledge in elementary matrix algebra but unfamiliar with randomized
matrix computations. The algorithms introduced in this manuscript are all
summarized in a user-friendly way, and they can be implemented in lines of
MATLAB code. The readers can easily follow the implementations even if they do
not understand the maths and algorithms."
"Study of general purpose computation by GPU (Graphics Processing Unit) can
improve the image processing capability of micro-computer system. This paper
studies the parallelism of the different stages of decimation in time radix 2
FFT algorithm, designs the butterfly and scramble kernels and implements 2D FFT
on GPU. The experiment result demonstrates the validity and advantage over
general CPU, especially in the condition of large input size. The approach can
also be generalized to other transforms alike."
"In this paper, we report on an implementation in the free software Mathemagix
of lacunary factorization algorithms, distributed as a library called
Lacunaryx. These algorithms take as input a polynomial in sparse
representation, that is as a list of nonzero monomials, and an integer $d$, and
compute its irreducible degree-$\le d$ factors. The complexity of these
algorithms is polynomial in the sparse size of the input polynomial and $d$."
"This paper introduces the Encog library for Java and C#, a scalable,
adaptable, multiplatform machine learning framework that was 1st released in
2008. Encog allows a variety of machine learning models to be applied to
datasets using regression, classification, and clustering. Various supported
machine learning models can be used interchangeably with minimal recoding.
Encog uses efficient multithreaded code to reduce training time by exploiting
modern multicore processors. The current version of Encog can be downloaded
from http://www.encog.org."
"The progression of scientific computing resources has enabled the numerical
approximation of mathematical models describing complex physical phenomena. A
significant portion of researcher time is typically dedicated to the
development of software to compute the numerical solutions. This work describes
a flexible C++ software framework, built on the libMesh finite element library,
designed to alleviate developer burden and provide easy access to modern
computational algorithms, including quantity-of-interest-driven parallel
adaptive mesh refinement on unstructured grids and adjoint-based sensitivities.
Other software environments are highlighted and the current work motivated; in
particular, the present work is an attempt to balance software infrastructure
and user flexibility. The applicable class of problems and design of the
software components is discussed in detail. Several examples demonstrate the
effectiveness of the design, including applications that incorporate
uncertainty. Current and planned developments are discussed."
"Fault tolerant algorithms for the numerical approximation of elliptic partial
differential equations on modern supercomputers play a more and more important
role in the future design of exa-scale enabled iterative solvers. Here, we
combine domain partitioning with highly scalable geometric multigrid schemes to
obtain fast and fault-robust solvers in three dimensions. The recovery strategy
is based on a hierarchical hybrid concept where the values on lower dimensional
primitives such as faces are stored redundantly and thus can be recovered
easily in case of a failure. The lost volume unknowns in the faulty region are
re-computed approximately with multigrid cycles by solving a local Dirichlet
problem on the faulty subdomain. Different strategies are compared and
evaluated with respect to performance, computational cost, and speed up.
Especially effective are strategies in which the local recovery in the faulty
region is executed in parallel with global solves and when the local recovery
is additionally accelerated. This results in an asynchronous multigrid
iteration that can fully compensate faults. Excellent parallel performance on a
current peta-scale system is demonstrated."
"Software realization of the complex spectra decomposition on unknown number
of similarcomponents is proposed.The algorithm is based on non-linear
minimizing the sum of squared residuals of the spectrum model. For the adequacy
checking the complex of criteria is used.It tests the model residuals
correspondence with the normal distribution, equality to zero of their mean
value and autocorrelation. Also the closeness of residuals and experimental
data variances is checked."
"Reduced basis methods are projection-based model order reduction techniques
for reducing the computational complexity of solving parametrized partial
differential equation problems. In this work we discuss the design of pyMOR, a
freely available software library of model order reduction algorithms, in
particular reduced basis methods, implemented with the Python programming
language. As its main design feature, all reduction algorithms in pyMOR are
implemented generically via operations on well-defined vector array, operator
and discretization interface classes. This allows for an easy integration with
existing open-source high-performance partial differential equation solvers
without adding any model reduction specific code to these solvers. Besides an
in-depth discussion of pyMOR's design philosophy and architecture, we present
several benchmark results and numerical examples showing the feasibility of our
approach."
"The Parameter-less Genetic Algorithm was first presented by Harik and Lobo in
1999 as an alternative to the usual trial-and-error method of finding, for each
given problem, an acceptable set-up of the parameter values of the genetic
algorithm. Since then, the same strategy has been successfully applied to
create parameter-less versions of other population-based search algorithms such
as the Extended Compact Genetic Algorithm and the Hierarchical Bayesian
Optimization Algorithm. This report describes a Java implementation,
Parameter-less Evolutionary Algorithm (P-EAJava), that integrates several
parameter-less evolutionary algorithms into a single platform. Along with a
brief description of P-EAJava, we also provide detailed instructions on how to
use it, how to implement new problems, and how to generate new parameter-less
versions of evolutionary algorithms.
  At present time, P-EAJava already includes parameter-less versions of the
Simple Genetic Algorithm, the Extended Compact Genetic Algorithm, the
Univariate Marginal Distribution Algorithm, and the Hierarchical Bayesian
Optimization Algorithm. The source and binary files of the Java implementation
of P-EAJava are available for free download at
https://github.com/JoseCPereira/2015ParameterlessEvolutionaryAlgorithmsJava."
"The Java implementation of a portfolio of parameter-less evolutionary
algorithms is presented. The Parameter-less Evolutionary Portfolio implements a
heuristic that performs adaptive selection of parameter-less evolutionary
algorithms in accordance with performance criteria that are measured during
running time. At present time, the portfolio includes three parameter-less
evolutionary algorithms: Parameter-less Univariate Marginal Distribution
Algorithm, Parameter-less Extended Compact Genetic Algorithm, and
Parameter-less Hierarchical Bayesian Optimization Algorithm. Initial
experiments showed that the parameter-less portfolio can solve various classes
of problems without the need for any prior parameter setting technique and with
an increase in computational effort that can be considered acceptable."
"This document describes a library for similarity searching. Even though the
library contains a variety of metric-space access methods, our main focus is on
search methods for non-metric spaces. Because there are fewer exact solutions
for non-metric spaces, many of our methods give only approximate answers. Thus,
the methods are evaluated in terms of efficiency-effectiveness trade-offs
rather than merely in terms of their efficiency. Our goal is, therefore, to
provide not only state-of-the-art approximate search methods for both
non-metric and metric spaces, but also the tools to measure search quality. We
concentrate on technical details, i.e., how to compile the code, run the
benchmarks, evaluate results, and use our code in other applications.
Additionally, we explain how to extend the code by adding new search methods
and spaces."
"Numerical accuracy of floating point computation is a well studied topic
which has not made its way to the end-user in scientific computing. Yet, it has
become a critical issue with the recent requirements for code modernization to
harness new highly parallel hardware and perform higher resolution computation.
To democratize numerical accuracy analysis, it is important to propose tools
and methodologies to study large use cases in a reliable and automatic way. In
this paper, we propose verificarlo, an extension to the LLVM compiler to
automatically use Monte Carlo Arithmetic in a transparent way for the end-user.
It supports all the major languages including C, C++, and Fortran. Unlike
source-to-source approaches, our implementation captures the influence of
compiler optimizations on the numerical accuracy. We illustrate how Monte Carlo
Arithmetic using the verificarlo tool outperforms the existing approaches on
various use cases and is a step toward automatic numerical analysis."
"We report some computational results comparing parallel and sequential codes
for vertex/facet enumeration problems for convex polyhedra. The problems chosen
span the range from simple to highly degenerate polytopes. We tested one code
(lrs) based on pivoting and four codes (cddr+, ppl, normaliz, PORTA) based on
the double description method. normaliz employs parallelization as do the codes
plrs and mplrs which are based on lrs. We tested these codes using various
hardware configurations with up to 1200 cores. Major speedups were obtained by
parallelization, particularly by the code mplrs which uses MPI and can operate
on clusters of machines."
"Dense linear algebra libraries, such as BLAS and LAPACK, provide a relevant
collection of numerical tools for many scientific and engineering applications.
While there exist high performance implementations of the BLAS (and LAPACK)
functionality for many current multi-threaded architectures,the adaption of
these libraries for asymmetric multicore processors (AMPs)is still pending. In
this paper we address this challenge by developing an asymmetry-aware
implementation of the BLAS, based on the BLIS framework, and tailored for AMPs
equipped with two types of cores: fast/power hungry versus slow/energy
efficient. For this purpose, we integrate coarse-grain and fine-grain
parallelization strategies into the library routines which, respectively,
dynamically distribute the workload between the two core types and statically
repartition this work among the cores of the same type.
  Our results on an ARM big.LITTLE processor embedded in the Exynos 5422 SoC,
using the asymmetry-aware version of the BLAS and a plain migration of the
legacy version of LAPACK, experimentally assess the benefits, limitations, and
potential of this approach."
"We present FoamGrid, a new implementation of the DUNE grid interface.
FoamGrid implements one- and two-dimensional grids in a physical space of
arbitrary dimension, which allows for grids for curved domains. Even more, the
grids are not expected to have a manifold structure, i.e., more than two
elements can share a common facet. This makes FoamGrid the grid data structure
of choice for simulating structures such as foams, discrete fracture networks,
or network flow problems. FoamGrid implements adaptive non-conforming
refinement with element parametrizations. As an additional feature it allows
removal and addition of elements in an existing grid, which makes FoamGrid
suitable for network growth problems. We show how to use FoamGrid, with
particular attention to the extensions of the grid interface needed to handle
non-manifold topology and grid growth. Three numerical examples demonstrate the
possibilities offered by FoamGrid."
"Quantifying simulation uncertainties is a critical component of rigorous
predictive simulation. A key component of this is forward propagation of
uncertainties in simulation input data to output quantities of interest.
Typical approaches involve repeated sampling of the simulation over the
uncertain input data, and can require numerous samples when accurately
propagating uncertainties from large numbers of sources. Often simulation
processes from sample to sample are similar and much of the data generated from
each sample evaluation could be reused. We explore a new method for
implementing sampling methods that simultaneously propagates groups of samples
together in an embedded fashion, which we call embedded ensemble propagation.
We show how this approach takes advantage of properties of modern computer
architectures to improve performance by enabling reuse between samples,
reducing memory bandwidth requirements, improving memory access patterns,
improving opportunities for fine-grained parallelization, and reducing
communication costs. We describe a software technique for implementing embedded
ensemble propagation based on the use of C++ templates and describe its
integration with various scientific computing libraries within Trilinos. We
demonstrate improved performance, portability and scalability for the approach
applied to the simulation of partial differential equations on a variety of
CPU, GPU, and accelerator architectures, including up to 131,072 cores on a
Cray XK7 (Titan)."
"The generic matrix-matrix multiplication (GEMM) is arguably the most popular
computational kernel of the 20th century. Yet, surprisingly, no common
methodology for evaluating GEMM performance has been established over the many
decades of using GEMM for comparing architectures, compilers and ninja-class
programmers.
  We introduce GEMMbench, a framework and methodology for evaluating
performance of GEMM implementations. GEMMbench is implemented on top of
Collective Knowledge (CK), a lightweight framework for reproducible and
collaborative R&D in computer systems. Using CK allows the R&D community to
crowdsource hand-written and compiler-generated GEMM implementations and to
study their performance across multiple platforms, data sizes and data types.
  Our initial implementation supports hand-written OpenCL kernels operating on
matrices consisting of single- and double-precision floating-point values, and
producing single or multiple output elements per work-item (via thread
coarsening and vectorization)."
"We survey some general-purpose symbolic software packages that implement
algorithms from enumerative and analytic combinatorics. Software for the
following areas is covered: basic combinatorial objects, symbolic
combinatorics, P\'olya theory, combinatorial species, and asymptotics. We
describe the capabilities that the packages offer as well as some of the
algorithms used, and provide links to original documentation. Most of the
packages are freely downloadable from the web."
"Direct Numerical Simulations (DNS) of the Navier Stokes equations is an
invaluable research tool in fluid dynamics. Still, there are few publicly
available research codes and, due to the heavy number crunching implied,
available codes are usually written in low-level languages such as C/C++ or
Fortran. In this paper we describe a pure scientific Python pseudo-spectral DNS
code that nearly matches the performance of C++ for thousands of processors and
billions of unknowns. We also describe a version optimized through Cython, that
is found to match the speed of C++. The solvers are written from scratch in
Python, both the mesh, the MPI domain decomposition, and the temporal
integrators. The solvers have been verified and benchmarked on the Shaheen
supercomputer at the KAUST supercomputing laboratory, and we are able to show
very good scaling up to several thousand cores.
  A very important part of the implementation is the mesh decomposition (we
implement both slab and pencil decompositions) and 3D parallel Fast Fourier
Transforms (FFT). The mesh decomposition and FFT routines have been implemented
in Python using serial FFT routines (either NumPy, pyFFTW or any other serial
FFT module), NumPy array manipulations and with MPI communications handled by
MPI for Python (mpi4py). We show how we are able to execute a 3D parallel FFT
in Python for a slab mesh decomposition using 4 lines of compact Python code,
for which the parallel performance on Shaheen is found to be slightly better
than similar routines provided through the FFTW library. For a pencil mesh
decomposition 7 lines of code is required to execute a transform."
"To exploit both memory locality and the full performance potential of highly
tuned kernels, dense linear algebra libraries such as LAPACK commonly implement
operations as blocked algorithms. However, to achieve next-to-optimal
performance with such algorithms, significant tuning is required. On the other
hand, recursive algorithms are virtually tuning free, and yet attain similar
performance. In this paper, we first analyze and compare blocked and recursive
algorithms in terms of performance, and then introduce ReLAPACK, an open-source
library of recursive algorithms to seamlessly replace most of LAPACK's blocked
algorithms. In many scenarios, ReLAPACK clearly outperforms reference LAPACK,
and even improves upon the performance of optimizes libraries."
"We present our effort to extend and complement the core modules of the
Distributed and Unified Numerics Environment DUNE (http://dune-project.org) by
a well tested and structured collection of utilities and concepts. We describe
key elements of our four modules dune-xt-common, dune-xt-grid, dune-xt-la and
dune-xt-functions, which aim at further enabling the programming of generic
algorithms within DUNE as well as adding an extra layer of usability and
convenience."
"The R package micompr implements a procedure for assessing if two or more
multivariate samples are drawn from the same distribution. The procedure uses
principal component analysis to convert multivariate observations into a set of
linearly uncorrelated statistical measures, which are then compared using a
number of statistical methods. This technique is independent of the
distributional properties of samples and automatically selects features that
best explain their differences. The procedure is appropriate for comparing
samples of time series, images, spectrometric measures or similar
high-dimension multivariate observations."
"In this paper we introduce a block-structured adaptive mesh refinement (AMR)
software framework that incorporates tiling, a well-known loop transformation.
Because the multiscale, multiphysics codes built in BoxLib are designed to
solve complex systems at high resolution, performance on current and next
generation architectures is essential. With the expectation of many more cores
per node on next generation architectures, the ability to effectively utilize
threads within a node is essential, and the current model for parallelization
will not be sufficient. We describe a new version of BoxLib in which the tiling
constructs are embedded so that BoxLib-based applications can easily realize
expected performance gains without extra effort on the part of the application
developer. We also discuss a path forward to enable future versions of BoxLib
to take advantage of NUMA-aware optimizations using the TiDA portable library."
"This note provides a description of a procedure that is designed to
efficiently optimize expensive black-box functions. It uses the response
surface methodology by incorporating radial basis functions as the response
model. A simple method based on a Latin hypercube is used for initial sampling.
A modified version of CORS algorithm with space rescaling is used for the
subsequent sampling. The procedure is able to scale on multicore processors by
performing multiple function evaluations in parallel. The source code of the
procedure is written in Python."
"We present an implementation in the functional programming language Haskell
of the PLE decomposition of matrices over division rings. We discover in our
benchmarks that in a relevant number of cases it is significantly faster than
the C-based implementation provided in FLINT. Describing the guiding principles
of our work, we introduce the reader to basic ideas from high performance
functional programming."
"In this paper, we investigate GPU based parallel triangular solvers
systematically. The parallel triangular solvers are fundamental to incomplete
LU factorization family preconditioners and algebraic multigrid solvers. We
develop a new matrix format suitable for GPU devices. Parallel lower triangular
solvers and upper triangular solvers are developed for this new data structure.
With these solvers, ILU preconditioners and domain decomposition
preconditioners are developed. Numerical results show that we can speed
triangular solvers around seven times faster."
"This research introduce our work on developing Krylov subspace and AMG
solvers on NVIDIA GPUs. As SpMV is a crucial part for these iterative methods,
SpMV algorithms for single GPU and multiple GPUs are implemented. A HEC matrix
format and a communication mechanism are established. And also, a set of
specific algorithms for solving preconditioned systems in parallel environments
are designed, including ILU(k), RAS and parallel triangular solvers. Based on
these work, several Krylov solvers and AMG solvers are developed. According to
numerical experiments, favorable acceleration performance is acquired from our
Krylov solver and AMG solver under various parameter conditions."
"We introduce D2O, a Python module for cluster-distributed multi-dimensional
numerical arrays. It acts as a layer of abstraction between the algorithm code
and the data-distribution logic. The main goal is to achieve usability without
losing numerical performance and scalability. D2O's global interface is similar
to the one of a numpy.ndarray, whereas the cluster node's local data is
directly accessible for use in customized high-performance modules. D2O is
written in pure Python which makes it portable and easy to use and modify.
Expensive operations are carried out by dedicated external libraries like numpy
and mpi4py. The performance of D2O is on a par with numpy for serial
applications and scales well when moving to an MPI cluster. D2O is open-source
software available under the GNU General Public License v3 (GPL-3) at
https://gitlab.mpcdf.mpg.de/ift/D2O"
"Over the recent years the importance of numerical experiments has gradually
been more recognized. Nonetheless, sufficient documentation of how
computational results have been obtained is often not available. Especially in
the scientific computing and applied mathematics domain this is crucial, since
numerical experiments are usually employed to verify the proposed hypothesis in
a publication. This work aims to propose standards and best practices for the
setup and publication of numerical experiments. Naturally, this amounts to a
guideline for development, maintenance, and publication of numerical research
software. Such a primer will enable the replicability and reproducibility of
computer-based experiments and published results and also promote the
reusability of the associated software."
"We consider the problem of transposing tensors of arbitrary dimension and
describe TTC, an open source domain-specific parallel compiler. TTC generates
optimized parallel C++/CUDA C code that achieves a significant fraction of the
system's peak memory bandwidth. TTC exhibits high performance across multiple
architectures, including modern AVX-based systems (e.g.,~Intel Haswell, AMD
Steamroller), Intel's Knights Corner as well as different CUDA-based GPUs such
as NVIDIA's Kepler and Maxwell architectures. We report speedups of TTC over a
meaningful baseline implementation generated by external C++ compilers; the
results suggest that a domain-specific compiler can outperform its general
purpose counterpart significantly: For instance, comparing with Intel's latest
C++ compiler on the Haswell and Knights Corner architecture, TTC yields
speedups of up to $8\times$ and $32\times$, respectively. We also showcase
TTC's support for multiple leading dimensions, making it a suitable candidate
for the generation of performance-critical packing functions that are at the
core of the ubiquitous BLAS 3 routines."
"Automatic code generation for low-dimensional geometric algorithms is capable
of producing efficient low-level software code through a high-level geometric
domain specific language. Geometric Algebra (GA) is one of the most suitable
algebraic systems for being the base for such code generator. This work
presents an attempt at realizing such idea in practice. A novel GA-based
geometric code generator, called GMac, is proposed. Comparisons to similar
GA-based code generators are provided. The possibility of fully benefiting from
the symbolic power of GA while obtaining good performance and maintainability
of software implementations is illustrated through a ray tracing application."
"[abridged] Context: Multidimensional arrays are used by many different
algorithms. As such, indexing and broadcasting complex operations over
multidimensional arrays are ubiquitous tasks and can be performance limiting.
Inquiry: Simultaneously indexing two or more multidimensional arrays with
different shapes (e.g., copying data from one tensor to another larger, zero
padded tensor in anticipation of a convolution) is difficult to do efficiently:
Hard-coded nested for loops in C, Fortran, and Go cannot be applied when the
dimension of a tensor is unknown at compile time. Likewise, boost::multi_array
cannot be used unless the dimensions of the array are known at compile time,
and the style of implementation restricts the user from using the index tuple
inside a vectorized operation (as would be required to compute an expected
value of a multidimensional distribution). On the other hand, iteration methods
that do not require the dimensionality or shape to be known at compile time
(e.g., incrementing and applying carry operations to index tuples or remapping
integer indices in the flat array), can be substantially slower than hard-coded
nested for loops. ... Importance: Manipulation of multidimensional arrays is a
common task in software, especially in high performance numerical methods. This
paper proposes a novel way to leverage template recursion to iterate over and
apply operations to multidimensional arrays, and then demonstrates the superior
performance and flexibility of operations that can be achieved using this new
approach."
"An algorithm for computing the incomplete gamma function $\gamma^*(a,z)$ for
real values of the parameter $a$ and negative real values of the argument $z$
is presented. The algorithm combines the use of series expansions,
Poincar\'e-type expansions, uniform asymptotic expansions and recurrence
relations, depending on the parameter region. A relative accuracy $\sim
10^{-13}$ in the parameter region $(a,z) \in [-500,\,500] \times [-500,\,0)$
can be obtained when computing the function $\gamma^*(a,z)$ with the Fortran 90
module IncgamNEG implementing the algorithm."
"We present a Python module named PyCheb, to solve the ordinary differential
equations by using spectral collocation method. PyCheb incorporates
discretization using Chebyshev points, barycentric interpolation and iterate
methods. With this Python module, users can initialize the ODEsolver class by
passing attributes, including the both sides of a given differential equation,
boundary conditions, and the number of Chebyshev points, which can also be
generated automatically by the ideal precision, to the constructor of ODEsolver
class. Then, the instance of the ODEsolver class can be used to automatically
determine the resolution of the differential equation as well as generate the
graph of the high-precision approximate solution. (If you have any questions,
please send me an email and I will reply ASAP.
e-mail:shaohui_liu@qq.com/2013141482143@stu.scu.edu.cn)"
"Domain specific languages have successfully been used in a variety of fields
to cleanly express scientific problems as well as to simplify implementation
and performance opti- mization on different computer architectures. Although a
large number of stencil languages are available, finite differ- ence domain
specific languages have proved challenging to design because most practical use
cases require additional features that fall outside the finite difference
abstraction. Inspired by the complexity of real-world seismic imaging problems,
we introduce Devito, a domain specific language in which high level equations
are expressed using symbolic expressions from the SymPy package. Complex
equations are automatically manipulated, optimized, and translated into highly
optimized C code that aims to perform compa- rably or better than hand-tuned
code. All this is transpar- ent to users, who only see concise symbolic
mathematical expressions."
"Domain specific languages (DSL) have been used in a variety of fields to
express complex scientific problems in a concise manner and provide automated
performance optimization for a range of computational architectures. As such
DSLs provide a powerful mechanism to speed up scientific Python computation
that goes beyond traditional vectorization and pre-compilation approaches,
while allowing domain scientists to build applications within the comforts of
the Python software ecosystem. In this paper we present Devito, a new finite
difference DSL that provides optimized stencil computation from high-level
problem specifications based on symbolic Python expressions. We demonstrate
Devito's symbolic API and performance advantages over traditional Python
acceleration methods before highlighting its use in the scientific context of
seismic inversion problems."
"Parallel finite element algorithms based on object-oriented concepts are
presented. Moreover, the design and implementation of a data structure proposed
are utilized in realizing a parallel geometric multigrid method. The
ParFEMapper and the ParFECommunicator are the key components of the data
structure in the proposed parallel scheme. These classes are constructed based
on the type of finite elements (continuous or nonconforming or discontinuous)
used. The proposed solver is compared with the open source direct solvers,
MUMPS and PasTiX. Further, the performance of the parallel multigrid solver is
analyzed up to 1080 processors. The solver shows a very good speedup up to 960
processors and the problem size has to be increased in order to maintain the
good speedup when the number of processors are increased further. As a result,
the parallel solver is able to handle large scale problems on massively
parallel supercomputers. The proposed parallel finite element algorithms and
multigrid solver are implemented in our in-house package ParMooN."
"DiffSharp is an algorithmic differentiation or automatic differentiation (AD)
library for the .NET ecosystem, which is targeted by the C# and F# languages,
among others. The library has been designed with machine learning applications
in mind, allowing very succinct implementations of models and optimization
routines. DiffSharp is implemented in F# and exposes forward and reverse AD
operators as general nestable higher-order functions, usable by any .NET
language. It provides high-performance linear algebra primitives---scalars,
vectors, and matrices, with a generalization to tensors underway---that are
fully supported by all the AD operators, and which use a BLAS/LAPACK backend
via the highly optimized OpenBLAS library. DiffSharp currently uses operator
overloading, but we are developing a transformation-based version of the
library using F#'s ""code quotation"" metaprogramming facility. Work on a
CUDA-based GPU backend is also underway."
"Iterative methods on irregular grids have been used widely in all areas of
comptational science and engineering for solving partial differential equations
with complex geometry. They provide the flexibility to express complex shapes
with relatively low computational cost. However, the direction of the evolution
of high-performance processors in the last two decades have caused serious
degradation of the computational efficiency of iterative methods on irregular
grids, because of relatively low memory bandwidth. Data compression can in
principle reduce the necessary memory memory bandwidth of iterative methods and
thus improve the efficiency. We have implemented several data compression
algorithms on the PEZY-SC processor, using the matrix generated for the HPCG
benchmark as an example. For the SpMV (Sparse Matrix-Vector multiplication)
part of the HPCG benchmark, the best implementation without data compression
achieved 11.6Gflops/chip, close to the theoretical limit due to the memory
bandwidth. Our implementation with data compression has achieved 32.4Gflops.
This is of course rather extreme case, since the grid used in HPCG is
geometrically regular and thus its compression efficiency is very high.
However, in real applications, it is in many cases possible to make a large
part of the grid to have regular geometry, in particular when the resolution is
high. Note that we do not need to change the structure of the program, except
for the addition of the data compression/decompression subroutines. Thus, we
believe the data compression will be very useful way to improve the performance
of many applications which rely on the use of irregular grids."
"This is the user manual for the software package BSEPACK (Bethe--Salpeter
Eigenvalue Solver Package)."
"Large scale parameter estimation problems are among some of the most
computationally demanding problems in numerical analysis. An academic
researcher's domain-specific knowledge often precludes that of software design,
which results in inversion frameworks that are technically correct, but not
scalable to realistically-sized problems. On the other hand, the computational
demands for realistic problems result in industrial codebases that are geared
solely for high performance, rather than comprehensibility or flexibility. We
propose a new software design for inverse problems constrained by partial
differential equations that bridges the gap between these two seemingly
disparate worlds. A hierarchical and modular design allows a user to delve into
as much detail as she desires, while exploiting high performance primitives at
the lower levels. Our code has the added benefit of actually reflecting the
underlying mathematics of the problem, which lowers the cognitive load on user
using it and reduces the initial startup period before a researcher can be
fully productive. We also introduce a new preconditioner for the 3D Helmholtz
equation that is suitable for fault-tolerant distributed systems. Numerical
experiments on a variety of 2D and 3D test problems demonstrate the
effectiveness of this approach on scaling algorithms from small to large scale
problems with minimal code changes."
"Background: Component-based modeling language Modelica (OpenModelica is open
source implementation) is used for the numerical simulation of complex
processes of different nature represented by ODE system. However, in
OpenModelica standard library there is no routines for pseudo-random numbers
generation, which makes it impossible to use for stochastic modeling processes.
Purpose: The goal of this article is a brief overview of a number of algorithms
for generation a sequence of uniformly distributed pseudo random numbers and
quality assessment of the sequence given by them, as well as the ways to
implement some of these algorithms in OpenModelica system. Methods: All the
algorithms are implemented in C language, and the results of their work tested
using open source package DieHarder. For those algorithms that do not use bit
operations, we describe there realisation using OpwnModelica. The other
algorithms can be called in OpenModelica as C functions Results: We have
implemented and tested about nine algorithms. DieHarder testing revealed the
highest quality pseudo-random number generators. Also we have reviewed
libraries Noise and AdvancedNoise, who claim to be adding to the Modelica
Standard Library. Conclusions: In OpenModelica system can be implemented
generators of uniformly distributed pseudo-random numbers, which is the first
step towards to make OpenModelica suitable for simulation of stochastic
processes."
"Conical functions appear in a large number of applications in physics and
engineering. In this paper we describe an extension of our module CONICAL for
the computation of conical functions. Specifically, the module includes now a
routine for computing the function ${{\rm R}}^{m}_{-\frac{1}{2}+i\tau}(x)$, a
real-valued numerically satisfactory companion of the function ${\rm
P}^m_{-\tfrac12+i\tau}(x)$ for $x>1$. In this way, a natural basis for solving
Dirichlet problems bounded by conical domains is provided."
"We describe an algorithm to evaluate all the complex branches of the Lambert
W function with rigorous error bounds in interval arithmetic, which has been
implemented in the Arb library. The classic 1996 paper on the Lambert W
function by Corless et al. provides a thorough but partly heuristic numerical
analysis which needs to be complemented with some explicit inequalities and
practical observations about managing precision and branch cuts."
"Important computational physics problems are often large-scale in nature, and
it is highly desirable to have robust and high performing computational
frameworks that can quickly address these problems. However, it is no trivial
task to determine whether a computational framework is performing efficiently
or is scalable. The aim of this paper is to present various strategies for
better understanding the performance of any parallel computational frameworks
for solving PDEs. Important performance issues that negatively impact
time-to-solution are discussed, and we propose a performance spectrum analysis
that can enhance one's understanding of critical aforementioned performance
issues. As proof of concept, we examine commonly used finite element simulation
packages and software and apply the performance spectrum to quickly analyze the
performance and scalability across various hardware platforms, software
implementations, and numerical discretizations. It is shown that the proposed
performance spectrum is a versatile performance model that is not only
extendable to more complex PDEs such as hydrostatic ice sheet flow equations,
but also useful for understanding hardware performance in a massively parallel
computing environment. Potential applications and future extensions of this
work are also discussed."
"A form compiler takes a high-level description of the weak form of partial
differential equations and produces low-level code that carries out the finite
element assembly. In this paper we present the Two-Stage Form Compiler (TSFC),
a new form compiler with the main motivation to maintain the structure of the
input expression as long as possible. This facilitates the application of
optimizations at the highest possible level of abstraction. TSFC features a
novel, structure-preserving method for separating the contributions of a form
to the subblocks of the local tensor in discontinuous Galerkin problems. This
enables us to preserve the tensor structure of expressions longer through the
compilation process than other form compilers. This is also achieved in part by
a two-stage approach that cleanly separates the lowering of finite element
constructs to tensor algebra in the first stage, from the scheduling of those
tensor operations in the second stage. TSFC also efficiently traverses
complicated expressions, and experimental evaluation demonstrates good
compile-time performance even for highly complex forms."
"We introduce two new packages, Nemo and Hecke, written in the Julia
programming language for computer algebra and number theory. We demonstrate
that high performance generic algorithms can be implemented in Julia, without
the need to resort to a low-level C implementation. For specialised algorithms,
we use Julia's efficient native C interface to wrap existing C/C++ libraries
such as Flint, Arb, Antic and Singular. We give examples of how to use Hecke
and Nemo and discuss some algorithms that we have implemented to provide high
performance basic arithmetic."
"Besides tensor contractions, one of the most pronounced computational
bottlenecks in the non-orthogonally spin-adapted forms of the quantum chemistry
methods CCSDT and CCSDTQ, and their approximate forms---including CCSD(T) and
CCSDT(Q)---are spin summations. At a first sight, spin summations are
operations similar to tensor transpositions; a closer look instead reveals
additional challenges to high-performance calculations, including temporal
locality as well as scattered memory accesses. This publication explores a
sequence of algorithmic solutions for spin summations, each exploiting
individual properties of either the underlying hardware (e.g. caches,
vectorization), or the problem itself (e.g. factorizability). The final
algorithm combines the advantages of all the solutions, while avoiding their
drawbacks; this algorithm, achieves high-performance through parallelization,
vectorization, and by exploiting the temporal locality inherent to spin
summations. Combined, these optimizations result in speedups between 2.4x and
5.5x over the NCC quantum chemistry software package. In addition to such a
performance boost, our algorithm can perform the spin summations in-place, thus
reducing the memory footprint by 2x over an out-of-place variant."
"Sparse tensors appear in many large-scale applications with multidimensional
and sparse data. While multidimensional sparse data often need to be processed
on manycore processors, attempts to develop highly-optimized GPU-based
implementations of sparse tensor operations are rare. The irregular computation
patterns and sparsity structures as well as the large memory footprints of
sparse tensor operations make such implementations challenging. We leverage the
fact that sparse tensor operations share similar computation patterns to
propose a unified tensor representation called F-COO. Combined with
GPU-specific optimizations, F-COO provides highly-optimized implementations of
sparse tensor computations on GPUs. The performance of the proposed unified
approach is demonstrated for tensor-based kernels such as the Sparse Matricized
Tensor- Times-Khatri-Rao Product (SpMTTKRP) and the Sparse Tensor- Times-Matrix
Multiply (SpTTM) and is used in tensor decomposition algorithms. Compared to
state-of-the-art work we improve the performance of SpTTM and SpMTTKRP up to
3.7 and 30.6 times respectively on NVIDIA Titan-X GPUs. We implement a
CANDECOMP/PARAFAC (CP) decomposition and achieve up to 14.9 times speedup using
the unified method over state-of-the-art libraries on NVIDIA Titan-X GPUs."
"Ordinary differential equations (ODEs) are the primary means to modelling
dynamical systems in many natural and engineering sciences. The number of
equations required to describe a system with high heterogeneity limits our
capability of effectively performing analyses. This has motivated a large body
of research, across many disciplines, into abstraction techniques that provide
smaller ODE systems while preserving the original dynamics in some appropriate
sense. In this paper we give an overview of a recently proposed
computer-science perspective to this problem, where ODE reduction is recast to
finding an appropriate equivalence relation over ODE variables, akin to
classical models of computation based on labelled transition systems."
"We provide spatial discretizations of nonlinear incompressible Navier-Stokes
equations with inputs and outputs in the form of matrices ready to use in any
numerical linear algebra package. We discuss the assembling of the system
operators and the realization of boundary conditions and inputs and outputs. We
describe the two benchmark problems - the driven cavity and the cylinder wake -
and provide the corresponding data. The use of the data is illustrated by
numerous example setups. The test cases are provided as plain PYTHON or
OCTAVE/MATLAB script files for immediate replication."
"Modelling of multivariate densities is a core component in many signal
processing, pattern recognition and machine learning applications. The
modelling is often done via Gaussian mixture models (GMMs), which use
computationally expensive and potentially unstable training algorithms. We
provide an overview of a fast and robust implementation of GMMs in the C++
language, employing multi-threaded versions of the Expectation Maximisation
(EM) and k-means training algorithms. Multi-threading is achieved through
reformulation of the EM and k-means algorithms into a MapReduce-like framework.
Furthermore, the implementation uses several techniques to improve numerical
stability and modelling accuracy. We demonstrate that the multi-threaded
implementation achieves a speedup of an order of magnitude on a recent 16 core
machine, and that it can achieve higher modelling accuracy than a previously
well-established publically accessible implementation. The multi-threaded
implementation is included as a user-friendly class in recent releases of the
open source Armadillo C++ linear algebra library. The library is provided under
the permissive Apache~2.0 license, allowing unencumbered use in commercial
products."
"Owl is a new numerical library developed in the OCaml language. It focuses on
providing a comprehensive set of high-level numerical functions so that
developers can quickly build up data analytical applications. In this abstract,
we will present Owl's design, core components, and its key functionality."
"Fortran 77 programs for the computation of modified Bessel functions of
purely imaginary order are presented. The codes compute the functions
$K_{ia}(x)$, $L_{ia}(x)$ and their derivatives for real $a$ and positive $x$;
these functions are independent solutions of the differential equation $x^2 w''
+x w' +(a^2 -x^2)w=0$. The code also computes exponentially scaled functions.
The range of computation is $(x,a)\in (0,1500]\times [-1500,1500]$ when scaled
functions are considered and it is larger than $(0,500]\times [-400,400]$ for
standard IEEE double precision arithmetic. The relative accuracy is better than
$10^{-13}$ in the range $(0,200]\times [-200,200]$ and close to $10^{-12}$ in
$(0,1500]\times [-1500,1500]$."
"This example of Clifford algebras calculations uses GiNaC
(http://www.ginac.de/) library, which includes a support for generic Clifford
algebra starting from version~1.3.0. Both symbolic and numeric calculation are
possible and can be blended with other functions of GiNaC. This calculations
was made for the paper math.CV/0410399.
  Described features of GiNaC are already available at PyGiNaC
(http://sourceforge.net/projects/pyginac/) and due to course should propagate
into other software like GNU Octave (http://www.octave.org/), gTybalt
(http://www.fis.unipr.it/~stefanw/gtybalt.html), which use GiNaC library as
their back-end."
"This paper presents an implementation of the
Schwerdtfeger-Fillmore-Springer-Cnops construction (SFSCc) along with
illustrations of its usage. SFSCc linearises the linear-fraction action of the
Moebius group in R^n. This has clear advantages in several theoretical and
applied fields including engineering. Our implementation is based on the
Clifford algebra capacities of the GiNaC computer algebra system
(http://www.ginac.de/), which were described in cs.MS/0410044.
  The core of this realisation of SFSCc is done for an arbitrary dimension of
R^n with a metric given by an arbitrary bilinear form. We also present a
subclass for two dimensional cycles (i.e. circles, parabolas and hyperbolas),
which add some 2D specific routines including a visualisation to PostScript
files through the MetaPost (http://www.tug.org/metapost.html) or Asymptote
(http://asymptote.sourceforge.net/) packages.
  This software is the backbone of many results published in math.CV/0512416
and we use its applications their for demonstration. The library can be ported
(with various level of required changes) to other CAS with Clifford algebras
capabilities similar to GiNaC.
  There is an ISO image of a Live Debian DVD attached to this paper as an
auxiliary file, a copy is stored on Google Drive as well."
"We present a straightforward and verified method of deciding whether the
n-dimensional point x (n>=1), such that \nabla f(x)=0, is the local minimizer,
maximizer or just a saddle point of a real-valued function f.
  The method scales linearly with dimensionality of the problem and never
produces false results."
"Object-oriented programming languages such as Java and Objective C have
become popular for implementing agent-based and other object-based simulations
since objects in those languages can {\em reflect} (i.e. make runtime queries
of an object's structure). This allows, for example, a fairly trivial {\em
serialisation} routine (conversion of an object into a binary representation
that can be stored or passed over a network) to be written. However C++ does
not offer this ability, as type information is thrown away at compile time. Yet
C++ is often a preferred development environment, whether for performance
reasons or for its expressive features such as operator overloading.
  In scientific coding, changes to a model's codes takes place constantly, as
the model is refined, and different phenomena are studied. Yet traditionally,
facilities such as checkpointing, routines for initialising model parameters
and analysis of model output depend on the underlying model remaining static,
otherwise each time a model is modified, a whole slew of supporting routines
needs to be changed to reflect the new data structures. Reflection offers the
advantage of the simulation framework adapting to the underlying model without
programmer intervention, reducing the effort of modifying the model.
  In this paper, we present the {\em Classdesc} system which brings many of the
benefits of object reflection to C++, {\em ClassdescMP} which dramatically
simplifies coding of MPI based parallel programs and {\em
  Graphcode} a general purpose data parallel programming environment."
"The Libopt environment is both a methodology and a set of tools that can be
used for testing, comparing, and profiling solvers on problems belonging to
various collections. These collections can be heterogeneous in the sense that
their problems can have common features that differ from one collection to the
other. Libopt brings a unified view on this composite world by offering, for
example, the possibility to run any solver on any problem compatible with it,
using the same Unix/Linux command. The environment also provides tools for
comparing the results obtained by solvers on a specified set of problems. Most
of the scripts going with the Libopt environment have been written in Perl."
"We have developed a parallel algorithm for radial basis function (RBF)
interpolation that exhibits O(N) complexity,requires O(N) storage, and scales
excellently up to a thousand processes. The algorithm uses a GMRES iterative
solver with a restricted additive Schwarz method (RASM) as a preconditioner and
a fast matrix-vector algorithm. Previous fast RBF methods, --,achieving at most
O(NlogN) complexity,--, were developed using multiquadric and polyharmonic
basis functions. In contrast, the present method uses Gaussians with a small
variance (a common choice in particle methods for fluid simulation, our main
target application). The fast decay of the Gaussian basis function allows rapid
convergence of the iterative solver even when the subdomains in the RASM are
very small. The present method was implemented in parallel using the PETSc
library (developer version). Numerical experiments demonstrate its capability
in problems of RBF interpolation with more than 50 million data points, timing
at 106 seconds (19 iterations for an error tolerance of 10^-15 on 1024
processors of a Blue Gene/L (700 MHz PowerPC processors). The parallel code is
freely available in the open-source model."
"This short note presents the Lambert W(x) function and its possible
application in the framework of physics related to the Pierre Auger
Observatory. The actual numerical implementation in C++ consists of Halley's
and Fritsch's iteration with branch-point expansion, asymptotic series and
rational fits as initial approximations."
"In this paper we present a Java implementation of the algorithm that computes
Buchbereger's and reduced Groebner's basis step by step. The Java application
enables graphical representation of the intersection of two surfaces in
3-dimensional space and determines conditions of existence and planarity of the
intersection."
"This article introduces yet another representation of rotations in 3-space.
The rotations form a 3-dimensional projective space, which fact has not been
exploited in Computer Science. We use the four affine patches of this
projective space to parametrize the rotations. This affine patch representation
is more compact than quaternions (which require 4 components for calculations),
encompasses the entire rotation group without singularities (unlike the Euler
angles and rotation vector approaches), and requires only ratios of linear or
quadratic polynomials for basic computations (unlike the Euler angles and
rotation vector approaches which require transcendental functions).
  As an example, we derive the differential equation for the integration of
angular velocity using this affine patch representation of rotations. We remark
that the complexity of this equation is the same as the corresponding
quaternion equation, but has advantages over the quaternion approach e.g.
renormalization to unit length is not required, and state space has no dead
directions."
"We present an exact and complete algorithm to isolate the real solutions of a
zero-dimensional bivariate polynomial system. The proposed algorithm
constitutes an elimination method which improves upon existing approaches in a
number of points. First, the amount of purely symbolic operations is
significantly reduced, that is, only resultant computation and square-free
factorization is still needed. Second, our algorithm neither assumes generic
position of the input system nor demands for any change of the coordinate
system. The latter is due to a novel inclusion predicate to certify that a
certain region is isolating for a solution. Our implementation exploits
graphics hardware to expedite the resultant computation. Furthermore, we
integrate a number of filtering techniques to improve the overall performance.
Efficiency of the proposed method is proven by a comparison of our
implementation with two state-of-the-art implementations, that is, LPG and
Maple's isolate. For a series of challenging benchmark instances, experiments
show that our implementation outperforms both contestants."
"We present some of the experiments we have performed to best test our design
for a library for MathScheme, the mechanized mathematics software system we are
building. We wish for our library design to use and reflect, as much as
possible, the mathematical structure present in the objects which populate the
library."
"Many physical, biological or chemical systems are modeled by ordinary
differential equations (ODEs) and finding their solution is an every-day-task
for many scientists. Here, we introduce a new C++ library dedicated to find
numerical solutions of initial value problems of ODEs: odeint (www.odeint.com).
odeint is implemented in a highly generic way and provides extensive
interoperability at top performance. For example, due to it's modular design it
can be easily parallized with OpenMP and even runs on CUDA GPUs. Despite that,
it provides a convenient interface that allows for a simple and easy usage."
"The last several years have seen major enhancements to ACL2 functionality,
largely driven by requests from its user community, including utilities now in
common use such as 'make-event', 'mbe', and trust tags. In this paper we
provide user-level summaries of some ACL2 enhancements introduced after the
release of Version 3.5 (in May, 2009, at about the time of the 2009 ACL2
workshop) up through the release of Version 4.3 in July, 2011, roughly a couple
of years later. Many of these features are not particularly well known yet, but
most ACL2 users could take advantage of at least some of them. Some of the
changes could affect existing proof efforts, such as a change that treats pairs
of functions such as 'member' and 'member-equal' as the same function."
"The library LINPRO which provides solution to the linear inverse problem for
data contaminated by a statistical noise is presented. The library makes use of
two methods: Maximum Entropy Method and Singular Value Decomposition. As an
example it has been applied to perform an analytic continuation of the
imaginary time propagator obtained within the Quantum Monte Carlo method."
"ProofPeer strives to be a system for cloud-based interactive theorem proving.
After illustrating why such a system is needed, the paper presents some of the
design challenges that ProofPeer needs to meet to succeed. Contexts are
presented as a solution to the problem of sharing proof state among the users
of ProofPeer. Chronicles are introduced as a way to organize and version
contexts."
"An equivalence relation in the symmetric group, where is a positive integer
has been considered. An algorithm for calculation of the number of the
equivalence classes by this relation for arbitrary integer has been described."
"We present a simple to use, yet powerful code package called NLSEmagic to
numerically integrate the nonlinear Schr\""odinger equation in one, two, and
three dimensions. NLSEmagic is a high-order finite-difference code package
which utilizes graphic processing unit (GPU) parallel architectures. The codes
running on the GPU are many times faster than their serial counterparts, and
are much cheaper to run than on standard parallel clusters. The codes are
developed with usability and portability in mind, and therefore are written to
interface with MATLAB utilizing custom GPU-enabled C codes with the
MEX-compiler interface. The packages are freely distributed, including user
manuals and set-up files."
"In this paper, an idea to solve nonlinear equations is presented. During the
solution of any problem with Newton's Method, it might happen that some of the
unknowns satisfy the convergence criteria where the others fail. The
convergence happens only when all variables reach to the convergence limit. A
method to reduce the dimension of the overall system by excluding some of the
unknowns that satisfy an intermediate tolerance is introduced. In this
approach, a smaller system is solved in less amount of time and already
established local solutions are preserved and kept as constants while the other
variables that belong to the ""set"" will be relaxed. To realize the idea, an
algorithm is given that utilizes applications of pointers to reduce and
evaluate the sets. Matrix-free Newton-Krylov Techniques are used on a test
problem and it is shown that proposed idea improves the overall convergence."
"The FEAST eigensolver package is a free high-performance numerical library
for solving the Hermitian and non-Hermitian eigenvalue problems, and obtaining
all the eigenvalues and (right/left) eigenvectors within a given search
interval or arbitrary contour in the complex plane. Its originality lies with a
new transformative numerical approach to the traditional eigenvalue algorithm
design - the FEAST algorithm. The FEAST eigensolver combines simplicity and
efficiency and it offers many important capabilities for achieving high
performance, robustness, accuracy, and scalability on parallel architectures.
FEAST is both a comprehensive library package, and an easy to use software. It
includes flexible reverse communication interfaces and ready to use predefined
interfaces for dense, banded and sparse systems. The current version v3.0 of
the FEAST package can address both Hermitian and non-Hermitian eigenvalue
problems (real symmetric, real non-symmetric, complex Hermitian, complex
symmetric, or complex general systems) on both shared-memory and distributed
memory architectures (i.e contains both FEAST-SMP and FEAST-MPI packages). This
User's guide provides instructions for installation setup, a detailed
description of the FEAST interfaces and a large number of examples."
"We motivate and give semantics to theory presentation combinators as the
foundational building blocks for a scalable library of theories. The key
observation is that the category of contexts and fibered categories are the
ideal theoretical tools for this purpose."
"To find the discrete symmetries of a Hamilton operator $\hat H$ is of central
importance in quantum theory. Here we describe and implement a brute force
method to determine the discrete symmetries given by permutation matrices for
Hamilton operators acting in a finite-dimensional Hilbert space. Spin and Fermi
systems are considered as examples. A computer algebra implementation in
SymbolicC++ is provided."
"The IEEE 754-2008 standard recommends the correct rounding of some elementary
functions. This requires to solve the Table Maker's Dilemma which implies a
huge amount of CPU computation time. We consider in this paper accelerating
such computations, namely Lefe'vre algorithm on Graphics Processing Units
(GPUs) which are massively parallel architectures with a partial SIMD execution
(Single Instruction Multiple Data). We first propose an analysis of the
Lef\`evre hard-to-round argument search using the concept of continued
fractions. We then propose a new parallel search algorithm much more efficient
on GPU thanks to its more regular control flow. We also present an efficient
hybrid CPU-GPU deployment of the generation of the polynomial approximations
required in Lef\`evre algorithm. In the end, we manage to obtain overall
speedups up to 53.4x on one GPU over a sequential CPU execution, and up to 7.1x
over a multi-core CPU, which enable a much faster solving of the Table Maker's
Dilemma for the double precision format."
"We present the Unified Form Language (UFL), which is a domain-specific
language for representing weak formulations of partial differential equations
with a view to numerical approximation. Features of UFL include support for
variational forms and functionals, automatic differentiation of forms and
expressions, arbitrary function space hierarchies for multi-field problems,
general differential operators and flexible tensor algebra. With these
features, UFL has been used to effortlessly express finite element methods for
complex systems of partial differential equations in near-mathematical
notation, resulting in compact, intuitive and readable programs. We present in
this work the language and its construction. An implementation of UFL is freely
available as an open-source software library. The library generates abstract
syntax tree representations of variational problems, which are used by other
software libraries to generate concrete low-level implementations. Some
application examples are presented and libraries that support UFL are
highlighted."
"In this paper, we tackle the problem of automatically generating algorithms
for linear algebra operations by taking advantage of problem-specific
knowledge. In most situations, users possess much more information about the
problem at hand than what current libraries and computing environments accept;
evidence shows that if properly exploited, such information leads to
uncommon/unexpected speedups. We introduce a knowledge-aware linear algebra
compiler that allows users to input matrix equations together with properties
about the operands and the problem itself; for instance, they can specify that
the equation is part of a sequence, and how successive instances are related to
one another. The compiler exploits all this information to guide the generation
of algorithms, to limit the size of the search space, and to avoid redundant
computations. We applied the compiler to equations arising as part of
sensitivity and genome studies; the algorithms produced exhibit, respectively,
100- and 1000-fold speedups."
"With this work we aim to show how Mathematica can be a useful tool to
investigate properties of combinatorial structures. Specifically, we will face
enumeration problems on independent subsets of powers of paths and cycles,
trying to highlight the correspondence with other combinatorial objects with
the same cardinality. Then we will study the structures obtained by ordering
properly independent subsets of paths and cycles. We will approach some
enumeration problems on the resulting partially ordered sets, putting in
evidence the correspondences with structures known as Fibonacci and Lucas
Cubes."
"Theorema 2.0 stands for a re-design including a complete re-implementation of
the Theorema system, which was originally designed, developed, and implemented
by Bruno Buchberger and his Theorema group at RISC. In this paper, we present
the first prototype of a graphical user interface (GUI) for the new system. It
heavily relies on powerful interactive capabilities introduced in recent
releases of the underlying Mathematica system, most importantly the possibility
of having dynamic objects connected to interface elements like sliders, menus,
check-boxes, radio-buttons and the like. All these features are fully
integrated into the Mathematica programming environment and allow the
implementation of a modern user interface."
"The Trilinos Project is an effort to facilitate the design, development,
integration and ongoing support of mathematical software libraries within an
object-oriented framework. It is intended for large-scale, complex multiphysics
engineering and scientific applications. Epetra is one of its basic packages.
It provides serial and parallel linear algebra capabilities. Before Trilinos
version 11.0, released in 2012, Epetra used the C++ int data-type for storing
global and local indices for degrees of freedom (DOFs). Since int is typically
32-bit, this limited the largest problem size to be smaller than approximately
two billion DOFs. This was true even if a distributed memory machine could
handle larger problems. We have added optional support for C++ long long
data-type, which is at least 64-bit wide, for global indices. To save memory,
maintain the speed of memory-bound operations, and reduce further changes to
the code, the local indices are still 32-bit. We document the changes required
to achieve this feature and how the new functionality can be used. We also
report on the lessons learned in modifying a mature and popular package from
various perspectives -- design goals, backward compatibility, engineering
decisions, C++ language features, effects on existing users and other packages,
and build integration."
"It is commonly assumed that calculating third order information is too
expensive for most applications. But we show that the directional derivative of
the Hessian ($D^3f(x)\cdot d$) can be calculated at a cost proportional to that
of a state-of-the-art method for calculating the Hessian matrix. We do this by
first presenting a simple procedure for designing high order reverse methods
and applying it to deduce several methods including a reverse method that
calculates $D^3f(x)\cdot d$. We have implemented this method taking into
account symmetry and sparsity, and successfully calculated this derivative for
functions with a million variables. These results indicate that the use of
third order information in a general nonlinear solver, such as Halley-Chebyshev
methods, could be a practical alternative to Newton's method."
"This article focuses on the application of model development and opening the
source code available and implemented by the Free Software and Open Source
FLOSS to the instructional and teaching has both mathematics and computer by
the read-write(R/W) of mathematical software, including the most famous cases
are numerical and symbolic computation. The article analysis the development of
the mathematical model of Free/Open Source(math FLOSS) software has proven its
importance in the area of research in mathematics and computer science .
However, although their actual use, is very readable in higher education
courses. We discuss the feasibility of this model to the characteristics of the
domain, actors, interaction they have and the communities they form during the
development of the software. Finally, we propose a mathematical example of
Free/Open Source(Math FlOSS) software as analysis device ."
"Future extreme-scale computer systems may expose silent data corruption (SDC)
to applications, in order to save energy or increase performance. However,
resilience research struggles to come up with useful abstract programming
models for reasoning about SDC. Existing work randomly flips bits in running
applications, but this only shows average-case behavior for a low-level,
artificial hardware model. Algorithm developers need to understand worst-case
behavior with the higher-level data types they actually use, in order to make
their algorithms more resilient. Also, we know so little about how SDC may
manifest in future hardware, that it seems premature to draw conclusions about
the average case. We argue instead that numerical algorithms can benefit from a
numerical unreliability fault model, where faults manifest as unbounded
perturbations to floating-point data. Algorithms can use inexpensive ""sanity""
checks that bound or exclude error in the results of computations. Given a
selective reliability programming model that requires reliability only when and
where needed, such checks can make algorithms reliable despite unbounded
faults. Sanity checks, and in general a healthy skepticism about the
correctness of subroutines, are wise even if hardware is perfectly reliable."
"Efficient Matlab codes in 2D and 3D have been proposed recently to assemble
finite element matrices. In this paper we present simple, compact and efficient
vectorized algorithms, which are variants of these codes, in arbitrary
dimension, without the use of any lower level language. They can be easily
implemented in many vector languages (e.g. Matlab, Octave, Python, Scilab, R,
Julia, C++ with STL,...). The principle of these techniques is general, we
present it for the assembly of several finite element matrices in arbitrary
dimension, in the P1 finite element case. We also provide an extension of the
algorithms to the case of a system of PDE's. Then we give an extension to
piecewise polynomials of higher order. We compare numerically the performance
of these algorithms in Matlab, Octave and Python, with that in FreeFEM++ and in
a compiled language such as C. Examples show that, unlike what is commonly
believed, the performance is not radically worse than that of C : in the
best/worst cases, selected vector languages are respectively 2.3/3.5 and
2.9/4.1 times slower than C in the scalar and vector cases. We also present
numerical results which illustrate the computational costs of these algorithms
compared to standard algorithms and to other recent ones."
"The real symmetric tridiagonal eigenproblem is of outstanding importance in
numerical computations; it arises frequently as part of eigensolvers for
standard and generalized dense Hermitian eigenproblems that are based on a
reduction to tridiagonal form. For its solution, the algorithm of Multiple
Relatively Robust Representations (MRRR or MR3 in short) - introduced in the
late 1990s - is among the fastest methods. To compute k eigenpairs of a real
n-by-n tridiagonal T, MRRR only requires O(kn) arithmetic operations; in
contrast, all the other practical methods require O(k^2 n) or O(n^3) operations
in the worst case. This thesis centers around the performance and accuracy of
MRRR."
"We document the MATLAB code used in the following study: Numerical proof of
stability of roll waves in the small-amplitude limit for inclined thin film
flow."
"A general method to produce uniformly distributed pseudorandom numbers with
extended precision by combining two pseudorandom numbers with lower precision
is proposed. In particular, this method can be used for pseudorandom number
generation with extended precision on graphics processing units (GPU), where
the performance of single and double precision operations can vary
significantly."
"Open source bioinformatics tools running under MS Windows are rare to find,
and those running under Windows HPC cluster are almost non-existing. This is
despite the fact that the Windows is the most popular operating system used
among life scientists. Therefore, we introduce in this initiative
WinBioinfTools, a toolkit containing a number of bioinformatics tools running
under Windows High Performance Computing Server 2008. It is an open source code
package, where users and developers can share and add to. We currently start
with three programs from the area of sequence analysis: 1) CoCoNUT for pairwise
genome comparison, 2) parallel BLAST for biological database search, and 3)
parallel global pairwise sequence alignment. In this report, we focus on
technical aspects concerning how some components of these tools were ported
from Linux/Unix environment to run under Windows. We also show the advantages
of using the Windows HPC Cluster 2008. We demonstrate by experiments the
performance gain achieved when using a computer cluster against a single
machine. Furthermore, we show the results of comparing the performance of
WinBioinfTools on the Windows and Linux Cluster."
"Scientific programmers often turn to vendor-tuned Basic Linear Algebra
Subprograms (BLAS) to obtain portable high performance. However, many numerical
algorithms require several BLAS calls in sequence, and those successive calls
result in suboptimal performance. The entire sequence needs to be optimized in
concert. Instead of vendor-tuned BLAS, a programmer could start with source
code in Fortran or C (e.g., based on the Netlib BLAS) and use a
state-of-the-art optimizing compiler. However, our experiments show that
optimizing compilers often attain only one-quarter the performance of
hand-optimized code. In this paper we present a domain-specific compiler for
matrix algebra, the Build to Order BLAS (BTO), that reliably achieves high
performance using a scalable search algorithm for choosing the best combination
of loop fusion, array contraction, and multithreading for data parallelism. The
BTO compiler generates code that is between 16% slower and 39% faster than
hand-optimized code."
"We present a prototypical linear algebra compiler that automatically exploits
domain-specific knowledge to generate high-performance algorithms. The input to
the compiler is a target equation together with knowledge of both the structure
of the problem and the properties of the operands. The output is a variety of
high-performance algorithms, and the corresponding source code, to solve the
target equation. Our approach consists in the decomposition of the input
equation into a sequence of library-supported kernels. Since in general such a
decomposition is not unique, our compiler returns not one but a number of
algorithms. The potential of the compiler is shown by means of its application
to a challenging equation arising within the genome-wide association study. As
a result, the compiler produces multiple ""best"" algorithms that outperform the
best existing libraries."
"PHCpack is a large software package for solving systems of polynomial
equations. The executable phc is menu driven and file oriented. This paper
describes the development of phcpy, a Python interface to PHCpack. Instead of
navigating through menus, users of phcpy solve systems in the Python shell or
via scripts. Persistent objects replace intermediate files."
"In many scientific applications the solution of non-linear differential
equations are obtained through the set-up and solution of a number of
successive eigenproblems. These eigenproblems can be regarded as a sequence
whenever the solution of one problem fosters the initialization of the next. In
addition, in some eigenproblem sequences there is a connection between the
solutions of adjacent eigenproblems. Whenever it is possible to unravel the
existence of such a connection, the eigenproblem sequence is said to be
correlated. When facing with a sequence of correlated eigenproblems the current
strategy amounts to solving each eigenproblem in isolation. We propose a
alternative approach which exploits such correlation through the use of an
eigensolver based on subspace iteration and accelerated with Chebyshev
polynomials (ChFSI). The resulting eigensolver is optimized by minimizing the
number of matrix-vector multiplications and parallelized using the Elemental
library framework. Numerical results show that ChFSI achieves excellent
scalability and is competitive with current dense linear algebra parallel
eigensolvers."
"The performance portability of OpenCL kernel implementations for common
memory bandwidth limited linear algebra operations across different hardware
generations of the same vendor as well as across vendors is studied. Certain
combinations of kernel implementations and work sizes are found to exhibit good
performance across compute kernels, hardware generations, and, to a lesser
degree, vendors. As a consequence, it is demonstrated that the optimization of
a single kernel is often sufficient to obtain good performance for a large
class of more complicated operations."
"In this paper we demonstrate the methodology for parallelizing the
computation of large one-dimensional discrete fast Fourier transforms (DFFTs)
on multi-core Intel Xeon processors. DFFTs based on the recursive Cooley-Tukey
method have to control cache utilization, memory bandwidth and vector hardware
usage, and at the same time scale across multiple threads or compute nodes. Our
method builds on single-threaded Intel Math Kernel Library (MKL) implementation
of DFFT, and uses the Intel Cilk Plus framework for thread parallelism. We
demonstrate the ability of Intel Cilk Plus to handle parallel recursion with
nested loop-centric parallelism without tuning the code to the number of cores
or cache metrics. The result of our work is a library called EFFT that performs
1D DFTs of size 2^N for N>=21 faster than the corresponding Intel MKL parallel
DFT implementation by up to 1.5x, and faster than FFTW by up to 2.5x. The code
of EFFT is available for free download under the GPLv3 license. This work
provides a new efficient DFFT implementation, and at the same time demonstrates
an educational example of how computer science problems with complex parallel
patterns can be optimized for high performance using the Intel Cilk Plus
framework."
"The paper is organized as a self-contained literate Haskell program that
implements elements of an executable finite set theory with focus on
combinatorial generation and arithmetic encodings. The code, tested under GHC
6.6.1, is available at http://logic.csci.unt.edu/tarau/research/2008/fSET.zip .
  We introduce ranking and unranking functions generalizing Ackermann's
encoding to the universe of Hereditarily Finite Sets with Urelements. Then we
build a lazy enumerator for Hereditarily Finite Sets with Urelements that
matches the unranking function provided by the inverse of Ackermann's encoding
and we describe functors between them resulting in arithmetic encodings for
powersets, hypergraphs, ordinals and choice functions. After implementing a
digraph representation of Hereditarily Finite Sets we define {\em decoration
functions} that can recover well-founded sets from encodings of their
associated acyclic digraphs. We conclude with an encoding of arbitrary digraphs
and discuss a concept of duality induced by the set membership relation.
  Keywords: hereditarily finite sets, ranking and unranking functions,
executable set theory, arithmetic encodings, Haskell data representations,
functional programming and computational mathematics"
"JBotSim is a java library that offers basic primitives for prototyping,
running, and visualizing distributed algorithms in dynamic networks. With
JBotSim, one can implement an idea in minutes and interact with it ({\it e.g.},
add, move, or delete nodes) while it is running. JBotSim is well suited to
prepare live demonstrations of your algorithms to colleagues or students; it
can also be used to evaluate performance at the algorithmic level (number of
messages, number of rounds, etc.). Unlike most tools, JBotSim is not an
integrated environment. It is a lightweight library to be used in your program.
In this paper, we present an overview of its distinctive features and
architecture."
"MP is a package of ANSI Standard Fortran (ANS X3.9-1966) subroutines for
performing multiple-precision floating-point arithmetic and evaluating
elementary and special functions. The subroutines are machine independent and
the precision is arbitrary, subject to storage limitations. The User's Guide
describes the routines and their calling sequences, example and test programs,
use of the Augment precompiler, and gives installation instructions for the
package."
"We describe a new algorithm for Gaussian Elimination suitable for general
(unsymmetric and possibly singular) sparse matrices, of any entry type, which
has a natural parallel and distributed-memory formulation but degrades
gracefully to sequential execution.
  We present a sample MPI implementation of a program computing the rank of a
sparse integer matrix using the proposed algorithm. Some preliminary
performance measurements are presented and discussed, and the performance of
the algorithm is compared to corresponding state-of-the-art algorithms for
floating-point and integer matrices."
"Key questions that scientists and engineers typically want to address can be
formulated in terms of predictive science. Questions such as: ""How well does my
computational model represent reality?"", ""What are the most important
parameters in the problem?"", and ""What is the best next experiment to perform?""
are fundamental in solving scientific problems. Mystic is a framework for
massively-parallel optimization and rigorous sensitivity analysis that enables
these motivating questions to be addressed quantitatively as global
optimization problems. Often realistic physics, engineering, and materials
models may have hundreds of input parameters, hundreds of constraints, and may
require execution times of seconds or longer. In more extreme cases, realistic
models may be multi-scale, and require the use of high-performance computing
clusters for their evaluation. Predictive calculations, formulated as a global
optimization over a potential surface in design parameter space, may require an
already prohibitively large simulation to be performed hundreds, if not
thousands, of times. The need to prepare, schedule, and monitor thousands of
model evaluations, and dynamically explore and analyze results, is a
challenging problem that requires a software infrastructure capable of
distributing and managing computations on large-scale heterogeneous resources.
In this paper, we present the design behind an optimization framework, and also
a framework for heterogeneous computing, that when utilized together, can make
computationally intractable sensitivity and optimization problems much more
tractable."
"mlpy is a Python Open Source Machine Learning library built on top of
NumPy/SciPy and the GNU Scientific Libraries. mlpy provides a wide range of
state-of-the-art machine learning methods for supervised and unsupervised
problems and it is aimed at finding a reasonable compromise among modularity,
maintainability, reproducibility, usability and efficiency. mlpy is
multiplatform, it works with Python 2 and 3 and it is distributed under GPL3 at
the website http://mlpy.fbk.eu."
"A software library for constructing and learning probabilistic models is
presented. The library offers a set of building blocks from which a large
variety of static and dynamic models can be built. These include hierarchical
models for variances of other variables and many nonlinear models. The
underlying variational Bayesian machinery, providing for fast and robust
estimation but being mathematically rather involved, is almost completely
hidden from the user thus making it very easy to use the library. The building
blocks include Gaussian, rectified Gaussian and mixture-of-Gaussians variables
and computational nodes which can be combined rather freely."
"In this era of diverse and heterogeneous computer architectures, the
programmability issues, such as productivity and portable efficiency, are
crucial to software development and algorithm design. One way to approach the
problem is to step away from traditional sequential programming languages and
move toward domain specific programming environments to balance between
expressivity and efficiency. In order to demonstrate this principle, we
developed a domain specific C++ generic library for stencil computations, like
PDE solvers. The library features high level constructs to specify computation
and allows the development of parallel stencil computations with very limited
effort. The high abstraction constructs (like do_all and do_reduce) make the
program shorter and cleaner with increased contextual information for better
performance exploitation. The results show good performance from Windows
multicores, to HPC clusters and machines with accelerators, like GPUs."
"In this paper, we present our ongoing work and initial results on the formal
specification and verification of MiniMaple (a substantial subset of Maple with
slight extensions) programs. The main goal of our work is to find behavioral
errors in such programs w.r.t. their specifications by static analysis. This
task is more complex for widely used computer algebra languages like Maple as
these are fundamentally different from classical languages: they support
non-standard types of objects such as symbols, unevaluated expressions and
polynomials and require abstract computer algebraic concepts and objects such
as rings and orderings etc. As a starting point we have defined and formalized
a syntax, semantics, type system and specification language for MiniMaple."
"The Lambert W(x) function and its possible applications in physics are
presented. The actual numerical implementation in C++ consists of Halley's and
Fritsch's iterations with initial approximations based on branch-point
expansion, asymptotic series, rational fits, and continued-logarithm recursion."
"It is well known that the behavior of dense linear algebra algorithms is
greatly influenced by factors like target architecture, underlying libraries
and even problem size; because of this, the accurate prediction of their
performance is a real challenge. In this article, we are not interested in
creating accurate models for a given algorithm, but in correctly ranking a set
of equivalent algorithms according to their performance. Aware of the
hierarchical structure of dense linear algebra routines, we approach the
problem by developing a framework for the automatic generation of statistical
performance models for BLAS and LAPACK libraries. This allows us to obtain
predictions through evaluating and combining such models. We demonstrate that
our approach is successful in both single- and multi-core environments, not
only in the ranking of algorithms but also in tuning their parameters."
"Our problem is to accurately solve linear systems on a general purpose
graphics processing unit with double double and quad double arithmetic. The
linear systems originate from the application of Newton's method on polynomial
systems. Newton's method is applied as a corrector in a path following method,
so the linear systems are solved in sequence and not simultaneously. One
solution path may require the solution of thousands of linear systems. In
previous work we reported good speedups with our implementation to evaluate and
differentiate polynomial systems on the NVIDIA Tesla C2050. Although the cost
of evaluation and differentiation often dominates the cost of linear system
solving in Newton's method, because of the limited bandwidth of the
communication between CPU and GPU, we cannot afford to send the linear system
to the CPU for solving during path tracking.
  Because of large degrees, the Jacobian matrix may contain extreme values,
requiring extended precision, leading to a significant overhead. This overhead
of multiprecision arithmetic is our main motivation to develop a massively
parallel algorithm. To allow overdetermined linear systems we solve linear
systems in the least squares sense, computing the QR decomposition of the
matrix by the modified Gram-Schmidt algorithm. We describe our implementation
of the modified Gram-Schmidt orthogonalization method for the NVIDIA Tesla
C2050, using double double and quad double arithmetic. Our experimental results
show that the achieved speedups are sufficiently high to compensate for the
overhead of one extra level of precision."
"MLPACK is a state-of-the-art, scalable, multi-platform C++ machine learning
library released in late 2011 offering both a simple, consistent API accessible
to novice users and high performance and flexibility to expert users by
leveraging modern features of C++. MLPACK provides cutting-edge algorithms
whose benchmarks exhibit far better performance than other leading machine
learning libraries. MLPACK version 1.0.3, licensed under the LGPL, is available
at http://www.mlpack.org."
"Generalized linear mixed-effects models in the context of genome-wide
association studies (GWAS) represent a formidable computational challenge: the
solution of millions of correlated generalized least-squares problems, and the
processing of terabytes of data. We present high performance in-core and
out-of-core shared-memory algorithms for GWAS: By taking advantage of
domain-specific knowledge, exploiting multi-core parallelism, and handling data
efficiently, our algorithms attain unequalled performance. When compared to
GenABEL, one of the most widely used libraries for GWAS, on a 12-core processor
we obtain 50-fold speedups. As a consequence, our routines enable genome
studies of unprecedented size."
"CAELinux is a Linux distribution which is bundled with free software packages
related to Computer Aided Engineering (CAE). The free software packages include
software that can build a three dimensional solid model, programs that can mesh
a geometry, software for carrying out Finite Element Analysis (FEA), programs
that can carry out image processing etc. Present work has two goals: 1) To give
a brief description of CAELinux 2) To demonstrate that CAELinux could be useful
for Computer Aided Engineering, using an example of the three dimensional
reconstruction of a pig liver from a stack of CT-scan images. One can note that
instead of using CAELinux, using commercial software for reconstructing the
liver would cost a lot of money. One can also note that CAELinux is a free and
open source operating system and all software packages that are included in the
operating system are also free. Hence one can conclude that CAELinux could be a
very useful tool in application areas like surgical simulation which require
three dimensional reconstructions of biological organs. Also, one can see that
CAELinux could be a very useful tool for Computer Aided Engineering, in
general."
"We present a comparison of several modern C++ libraries providing high-level
interfaces for programming multi- and many-core architectures on top of CUDA or
OpenCL. The comparison focuses on the solution of ordinary differential
equations and is based on odeint, a framework for the solution of systems of
ordinary differential equations. Odeint is designed in a very flexible way and
may be easily adapted for effective use of libraries such as Thrust, MTL4,
VexCL, or ViennaCL, using CUDA or OpenCL technologies. We found that CUDA and
OpenCL work equally well for problems of large sizes, while OpenCL has higher
overhead for smaller problems. Furthermore, we show that modern high-level
libraries allow to effectively use the computational resources of many-core
GPUs or multi-core CPUs without much knowledge of the underlying technologies."
"We describe arithmetic computations in terms of operations on some well known
free algebras (S1S, S2S and ordered rooted binary trees) while emphasizing the
common structure present in all them when seen as isomorphic with the set of
natural numbers.
  Constructors and deconstructors seen through an initial algebra semantics are
generalized to recursively defined functions obeying similar laws.
  Implementation using Scala's apply and unapply are discussed together with an
application to a realistic arbitrary size arithmetic package written in Scala,
based on the free algebra of rooted ordered binary trees, which also supports
rational number operations through an extension to signed rationals of the
Calkin-Wilf bijection."
"We describe two general mechanisms for producing pairing bijections
(bijective functions defined from N x N to N).
  The first mechanism, using n-adic valuations results in parameterized
algorithms generating a countable family of distinct pairing bijections.
  The second mechanism, using characteristic functions of subsets of N provides
2^N distinct pairing bijections.
  Mechanisms to combine such pairing functions and their application to
generate families of permutations of N are also described.
  The paper uses a small subset of the functional language Haskell to provide
type checked executable specifications of all the functions defined in a
literate programming style. The self-contained Haskell code extracted from the
paper is available at http://logic.cse.unt.edu/tarau/research/2012/infpair.hs ."
"We describe algorithm MINRES-QLP and its FORTRAN 90 implementation for
solving symmetric or Hermitian linear systems or least-squares problems. If the
system is singular, MINRES-QLP computes the unique minimum-length solution
(also known as the pseudoinverse solution), which generally eludes MINRES. In
all cases, it overcomes a potential instability in the original MINRES
algorithm. A positive-definite preconditioner may be supplied. Our FORTRAN 90
implementation illustrates a design pattern that allows users to make problem
data known to the solver but hidden and secure from other program units. In
particular, we circumvent the need for reverse communication. While we focus
here on a FORTRAN 90 implementation, we also provide and maintain MATLAB
versions of MINRES and MINRES-QLP."
"Modelling, parameter identification, and simulation play an important role in
systems biology. Usually, the goal is to determine parameter values that
minimise the difference between experimental measurement values and model
predictions in a least-squares sense. Large-scale biological networks, however,
often suffer from missing data for parameter identification. Thus, the
least-squares problems are rank-deficient and solutions are not unique. Many
common optimisation methods ignore this detail because they do not take into
account the structure of the underlying inverse problem. These algorithms
simply return a ""solution"" without additional information on identifiability or
uniqueness. This can yield misleading results, especially if parameters are
co-regulated and data are noisy."
"ZKCM is a C++ library developed for the purpose of multiprecision matrix
computation, on the basis of the GNU MP and MPFR libraries. It provides an
easy-to-use syntax and convenient functions for matrix manipulations including
those often used in numerical simulations in quantum physics. Its extension
library, ZKCM_QC, is developed for simulating quantum computing using the
time-dependent matrix-product-state simulation method. This paper gives an
introduction about the libraries with practical sample programs."
"Modern platforms used for high-performance computing (HPC) include machines
with both general-purpose CPUs, and ""accelerators"", often in the form of
graphical processing units (GPUs). StarPU is a C library to exploit such
platforms. It provides users with ways to define ""tasks"" to be executed on CPUs
or GPUs, along with the dependencies among them, and by automatically
scheduling them over all the available processing units. In doing so, it also
relieves programmers from the need to know the underlying architecture details:
it adapts to the available CPUs and GPUs, and automatically transfers data
between main memory and GPUs as needed. While StarPU's approach is successful
at addressing run-time scheduling issues, being a C library makes for a poor
and error-prone programming interface. This paper presents an effort started in
2011 to promote some of the concepts exported by the library as C language
constructs, by means of an extension of the GCC compiler suite. Our main
contribution is the design and implementation of language extensions that map
to StarPU's task programming paradigm. We argue that the proposed extensions
make it easier to get started with StarPU,eliminate errors that can occur when
using the C library, and help diagnose possible mistakes. We conclude on future
work."
"Graph rewrite systems are powerful tools to model and study complex problems
in various fields of research. Their successful application to chemical
reaction modelling on a molecular level was shown but no appropriate and simple
system is available at the moment.
  The presented Graph Grammar Library (GGL) implements a generic Double Push
Out approach for general graph rewrite systems. The framework focuses on a high
level of modularity as well as high performance, using state-of-the-art
algorithms and data structures, and comes with extensive documentation. The
large GGL chemistry module enables extensive and detailed studies of chemical
systems. It well meets the requirements and abilities envisioned by Yadav et
al. (2004) for such chemical rewrite systems. Here, molecules are represented
as undirected labeled graphs while chemical reactions are described by
according graph grammar rules. Beside the graph transformation, the GGL offers
advanced cheminformatics algorithms for instance to estimate energies
ofmolecules or aromaticity perception. These features are illustrated using a
set of reactions from polyketide chemistry a huge class of natural compounds of
medical relevance.
  The graph grammar based simulation of chemical reactions offered by the GGL
is a powerful tool for extensive cheminformatics studies on a molecular level.
The GGL already provides rewrite rules for all enzymes listed in the KEGG
LIGAND database is freely available at
http://www.tbi.univie.ac.at/software/GGL/."
"We present an interface and an implementation of the General Matrix Multiply
(GEMM) routine for multiple small matrices processed simultaneously on NVIDIA
graphics processing units (GPUs). We focus on matrix sizes under 16. The
implementation can be easily extended to larger sizes. For single precision
matrices, our implementation is 30% to 600% faster than the batched cuBLAS
implementation distributed in the CUDA Toolkit 5.0 on NVIDIA Tesla K20c. For
example, we obtain 104 GFlop/s and 216 GFlop/s when multiplying 100,000
independent matrix pairs of size 10 and 16, respectively. Similar improvement
in performance is obtained for other sizes, in single and double precision for
real and complex types, and when the number of matrices is smaller. Apart from
our implementation, our different function interface also plays an important
role in the improved performance. Applications of this software include Finite
Element computation on GPUs."
"We describe an interface and an implementation for performing Kronecker
product actions on NVIDIA GPUs for multiple small 2-D matrices and 3-D arrays
processed in parallel as a batch. This method is suited to cases where the
Kronecker product component matrices are identical but the operands in a
matrix-free application vary in the batch. Any batched GEMM (General Matrix
Multiply) implementation, for example ours [1] or the one in cuBLAS, can also
be used for performing batched Kronecker products on GPUs. However, the
specialized implementation presented here is faster and uses less memory.
Partly this is because a simple GEMM based approach would require extra copies
to and from main memory. We focus on matrix sizes less than or equal to 16,
since these are the typical polynomial degrees in Finite Elements, but the
implementation can be easily extended for other sizes. We obtain 143 and 285
GFlop/s for single precision real when processing matrices of size 10 and 16,
respectively on NVIDIA Tesla K20c using CUDA 5.0. The corresponding speeds for
3-D array Kronecker products are 126 and 268 GFlop/s, respectively. Double
precision is easily supported using the C++ template mechanism."
"We report on highlights of the ACL2 enhancements introduced in ACL2 releases
since the 2011 ACL2 Workshop. Although many enhancements are critical for
soundness or robustness, we focus in this paper on those improvements that
could benefit users who are aware of them, but that might not be discovered in
everyday practice."
"Optimization on manifolds is a rapidly developing branch of nonlinear
optimization. Its focus is on problems where the smooth geometry of the search
space can be leveraged to design efficient numerical algorithms. In particular,
optimization on manifolds is well-suited to deal with rank and orthogonality
constraints. Such structured constraints appear pervasively in machine learning
applications, including low-rank matrix completion, sensor network
localization, camera network registration, independent component analysis,
metric learning, dimensionality reduction and so on. The Manopt toolbox,
available at www.manopt.org, is a user-friendly, documented piece of software
dedicated to simplify experimenting with state of the art Riemannian
optimization algorithms. We aim particularly at reaching practitioners outside
our field."
"A hierarchy of semidefinite programming (SDP) relaxations approximates the
global optimum of polynomial optimization problems of noncommuting variables.
Generating the relaxation, however, is a computationally demanding task, and
only problems of commuting variables have efficient generators. We develop an
implementation for problems of noncommuting problems that creates the
relaxation to be solved by SDPA -- a high-performance solver that runs in a
distributed environment. We further exploit the inherent sparsity of
optimization problems in quantum physics to reduce the complexity of the
resulting relaxations. Constrained problems with a relaxation of order two may
contain up to a hundred variables. The implementation is available in Python.
The tool helps solve problems such as finding the ground state energy or
testing quantum correlations."
"Principal component analysis (PCA) is a statistical technique commonly used
in multivariate data analysis. However, PCA can be difficult to interpret and
explain since the principal components (PCs) are linear combinations of the
original variables. Sparse PCA (SPCA) aims to balance statistical fidelity and
interpretability by approximating sparse PCs whose projections capture the
maximal variance of original data. In this paper we present an efficient and
paralleled method of SPCA using graphics processing units (GPUs), which can
process large blocks of data in parallel. Specifically, we construct parallel
implementations of the four optimization formulations of the generalized power
method of SPCA (GP-SPCA), one of the most efficient and effective SPCA
approaches, on a GPU. The parallel GPU implementation of GP-SPCA (using CUBLAS)
is up to eleven times faster than the corresponding CPU implementation (using
CBLAS), and up to 107 times faster than a MatLab implementation. Extensive
comparative experiments in several real-world datasets confirm that SPCA offers
a practical advantage."
"It is universally known that caching is critical to attain high- performance
implementations: In many situations, data locality (in space and time) plays a
bigger role than optimizing the (number of) arithmetic floating point
operations. In this paper, we show evidence that at least for linear algebra
algorithms, caching is also a crucial factor for accurate performance modeling
and performance prediction."
"NLCertify is a software package for handling formal certification of
nonlinear inequalities involving transcendental multivariate functions. The
tool exploits sparse semialgebraic optimization techniques with approximation
methods for transcendental functions, as well as formal features. Given a box
and a transcendental multivariate function as input, NLCertify provides OCaml
libraries that produce nonnegativity certificates for the function over the
box, which can be ultimately proved correct inside the Coq proof assistant."
"We describe a proof of the Central Limit Theorem that has been formally
verified in the Isabelle proof assistant. Our formalization builds upon and
extends Isabelle's libraries for analysis and measure-theoretic probability.
The proof of the theorem uses characteristic functions, which are a kind of
Fourier transform, to demonstrate that, under suitable hypotheses, sums of
random variables converge weakly to the standard normal distribution. We also
discuss the libraries and infrastructure that supported the formalization, and
reflect on some of the lessons we have learned from the effort."
"The numerical solution of partial differential equations using the finite
element method is one of the key applications of high performance computing.
Local assembly is its characteristic operation. This entails the execution of a
problem-specific kernel to numerically evaluate an integral for each element in
the discretized problem domain. Since the domain size can be huge, executing
efficient kernels is fundamental. Their op- timization is, however, a
challenging issue. Even though affine loop nests are generally present, the
short trip counts and the complexity of mathematical expressions make it hard
to determine a single or unique sequence of successful transformations.
Therefore, we present the design and systematic evaluation of COF- FEE, a
domain-specific compiler for local assembly kernels. COFFEE manipulates
abstract syntax trees generated from a high-level domain-specific language for
PDEs by introducing domain-aware composable optimizations aimed at improving
instruction-level parallelism, especially SIMD vectorization, and register
locality. It then generates C code including vector intrinsics. Experiments
using a range of finite-element forms of increasing complexity show that
significant performance improvement is achieved."
"We describe in this paper new design techniques used in the \cpp exact linear
algebra library \linbox, intended to make the library safer and easier to use,
while keeping it generic and efficient. First, we review the new simplified
structure for containers, based on our \emph{founding scope allocation} model.
We explain design choices and their impact on coding: unification of our matrix
classes, clearer model for matrices and submatrices, \etc Then we present a
variation of the \emph{strategy} design pattern that is comprised of a
controller--plugin system: the controller (solution) chooses among plug-ins
(algorithms) that always call back the controllers for subtasks. We give
examples using the solution \mul. Finally we present a benchmark architecture
that serves two purposes: Providing the user with easier ways to produce
graphs; Creating a framework for automatically tuning the library and
supporting regression testing."
"It is our view that the state of the art in constructing a large collection
of graph algorithms in terms of linear algebraic operations is mature enough to
support the emergence of a standard set of primitive building blocks. This
paper is a position paper defining the problem and announcing our intention to
launch an open effort to define this standard."
"Analytical solutions to acoustic scattering problems involving nonspherical
shapes, such as spheroids and disks, have long been known and have many
applications. However, these solutions require special functions that are not
easily computable. For this reason, their asymptotic forms are typically used
since they are more readily available. We explore these solutions and provide
computational software for calculating their nonasymptotic forms, which are
accurate over a wide range of frequencies and distances. This software, which
runs in MATLAB, computes the solutions to acoustic scattering problems
involving spheroids and disks by semi-analytical means, and is freely available
from our webpage."
"Emergence of stochastic simulations as an extensively used computational tool
for scientific purposes intensified the need for more accurate ways of
generating sufficiently long sequences of uncorrelated random numbers. Even
though several different methods have been proposed for this end, deterministic
algorithms known as pseudo-random number generators (PRNGs) emerged to be the
most widely used tool as a replicable, portable and easy to use method to
generate such random number sequences. Here, we introduce a simple Poisson
process whose simulation gives systematic errors when the very commonly used
random number generator of the GNU C Library (Glibc) is utilised. The PRNG of
Glibc is an additive lagged Fibonacci generator, the family of such PRNGs are
accepted as relatively safe among other PRNGs. The systematic errors indicate
complex correlation relations among random numbers which requires a further
explanation."
"We revisit the implementation of iterative solvers on discrete graphics
processing units and demonstrate the benefit of implementations using extensive
kernel fusion for pipelined formulations over conventional implementations of
classical formulations. The proposed implementations with both CUDA and OpenCL
are freely available in ViennaCL and are shown to be competitive with or even
superior to other solver packages for graphics processing units. Highest
performance gains are obtained for small to medium-sized systems, while our
implementations are on par with vendor-tuned implementations for very large
systems. Our results are especially beneficial for transient problems, where
many small to medium-sized systems instead of a single big system need to be
solved."
"We present a short tutorial and introduction to using the R package TDA,
which provides some tools for Topological Data Analysis. In particular, it
includes implementations of functions that, given some data, provide
topological information about the underlying space, such as the distance
function, the distance to a measure, the kNN density estimator, the kernel
density estimator, and the kernel distance. The salient topological features of
the sublevel sets (or superlevel sets) of these functions can be quantified
with persistent homology. We provide an R interface for the efficient
algorithms of the C++ libraries GUDHI, Dionysus and PHAT, including a function
for the persistent homology of the Rips filtration, and one for the persistent
homology of sublevel sets (or superlevel sets) of arbitrary functions evaluated
over a grid of points. The significance of the features in the resulting
persistence diagrams can be analyzed with functions that implement recently
developed statistical methods. The R package TDA also includes the
implementation of an algorithm for density clustering, which allows us to
identify the spatial organization of the probability mass associated to a
density function and visualize it by means of a dendrogram, the cluster tree."
"This document describes an infra-structure provided by the R package
performanceEstimation that allows to estimate the predictive performance of
different approaches (workflows) to predictive tasks. The infra-structure is
generic in the sense that it can be used to estimate the values of any
performance metrics, for any workflow on different predictive tasks, namely,
classification, regression and time series tasks. The package also includes
several standard workflows that allow users to easily set up their experiments
limiting the amount of work and information they need to provide. The overall
goal of the infra-structure provided by our package is to facilitate the task
of estimating the predictive performance of different modeling approaches to
predictive tasks in the R environment."
"In the paper a recent enhancement to the open source package SfePy (Simple
Finite Elements in Python, http://sfepy.org) is introduced, namely the addition
of another numerical discretization scheme, the isogeometric analysis, to the
original implementation based on the nowadays standard and well-established
numerical solution technique, the finite element method. The isogeometric
removes the need of the solution domain approximation by a piece-wise polygonal
domain covered by the finite element mesh, and allows approximation of unknown
fields with a higher smoothness then the finite element method, which can be
advantageous in many applications. Basic numerical examples illustrating the
implementation and use of the isogeometric analysis in SfePy are shown."
"A Fortran 90 module (GammaCHI) for computing and inverting the gamma and
chi-square cumulative distribution functions (central and noncentral) is
presented. The main novelty of this package are the reliable and accurate
inversion routines for the noncentral cumulative distribution functions.
Additionally, the package also provides routines for computing the gamma
function, the error function and other functions related to the gamma function.
The module includes the routines cdfgamC, invcdfgamC, cdfgamNC, invcdfgamNC,
errorfunction, inverfc, gamma, loggam, gamstar and quotgamm for the computation
of the central gamma distribution function (and its complementary function),
the inversion of the central gamma distribution function, the computation of
the noncentral gamma distribution function (and its complementary function),
the inversion of the noncentral gamma distribution function, the computation of
the error function and its complementary function, the inversion of the
complementary error function, the computation of: the gamma function, the
logarithm of the gamma function, the regulated gamma function and the ratio of
two gamma functions, respectively."
"Firedrake is a new tool for automating the numerical solution of partial
differential equations. Firedrake adopts the domain-specific language for the
finite element method of the FEniCS project, but with a pure Python
runtime-only implementation centred on the composition of several existing and
new abstractions for particular aspects of scientific computing. The result is
a more complete separation of concerns which eases the incorporation of
separate contributions from computer scientists, numerical analysts and
application specialists. These contributions may add functionality, or improve
performance.
  Firedrake benefits from automatically applying new optimisations. This
includes factorising mixed function spaces, transforming and vectorising inner
loops, and intrinsically supporting block matrix operations. Importantly,
Firedrake presents a simple public API for escaping the UFL abstraction. This
allows users to implement common operations that fall outside pure variational
formulations, such as flux-limiters."
This is a user manual for the software package FASTA.
"T3PS is a program that can be used to quickly design and perform parameter
scans while easily taking advantage of the multi-core architecture of current
processors. It takes an easy to read and write parameter scan definition file
format as input. Based on the parameter ranges and other options contained
therein, it distributes the calculation of the parameter space over multiple
processes and possibly computers. The derived data is saved in a plain text
file format readable by most plotting software. The supported scanning
strategies include: grid scan, random scan, Markov Chain Monte Carlo, numerical
optimization. Several example parameter scans are shown and compared with
results in the literature."
"Sparse matrix-vector multiplication (SpMV) is a fundamental building block
for numerous applications. In this paper, we propose CSR5 (Compressed Sparse
Row 5), a new storage format, which offers high-throughput SpMV on various
platforms including CPUs, GPUs and Xeon Phi. First, the CSR5 format is
insensitive to the sparsity structure of the input matrix. Thus the single
format can support an SpMV algorithm that is efficient both for regular
matrices and for irregular matrices. Furthermore, we show that the overhead of
the format conversion from the CSR to the CSR5 can be as low as the cost of a
few SpMV operations. We compare the CSR5-based SpMV algorithm with 11
state-of-the-art formats and algorithms on four mainstream processors using 14
regular and 10 irregular matrices as a benchmark suite. For the 14 regular
matrices in the suite, we achieve comparable or better performance over the
previous work. For the 10 irregular matrices, the CSR5 obtains average
performance improvement of 17.6\%, 28.5\%, 173.0\% and 293.3\% (up to 213.3\%,
153.6\%, 405.1\% and 943.3\%) over the best existing work on dual-socket Intel
CPUs, an nVidia GPU, an AMD GPU and an Intel Xeon Phi, respectively. For
real-world applications such as a solver with only tens of iterations, the CSR5
format can be more practical because of its low-overhead for format conversion.
The source code of this work is downloadable at
https://github.com/bhSPARSE/Benchmark_SpMV_using_CSR5"
"General sparse matrix-matrix multiplication (SpGEMM) is a fundamental
building block for numerous applications such as algebraic multigrid method
(AMG), breadth first search and shortest path problem. Compared to other sparse
BLAS routines, an efficient parallel SpGEMM implementation has to handle extra
irregularity from three aspects: (1) the number of nonzero entries in the
resulting sparse matrix is unknown in advance, (2) very expensive parallel
insert operations at random positions in the resulting sparse matrix dominate
the execution time, and (3) load balancing must account for sparse data in both
input matrices.
  In this work we propose a framework for SpGEMM on GPUs and emerging CPU-GPU
heterogeneous processors. This framework particularly focuses on the above
three problems. Memory pre-allocation for the resulting matrix is organized by
a hybrid method that saves a large amount of global memory space and
efficiently utilizes the very limited on-chip scratchpad memory. Parallel
insert operations of the nonzero entries are implemented through the GPU merge
path algorithm that is experimentally found to be the fastest GPU merge
approach. Load balancing builds on the number of necessary arithmetic
operations on the nonzero entries and is guaranteed in all stages.
  Compared with the state-of-the-art CPU and GPU SpGEMM methods, our approach
delivers excellent absolute performance and relative speedups on various
benchmarks multiplying matrices with diverse sparsity structures. Furthermore,
on heterogeneous processors, our SpGEMM approach achieves higher throughput by
using re-allocatable shared virtual memory.
  The source code of this work is available at
https://github.com/bhSPARSE/Benchmark_SpGEMM_using_CSR"
"Sparse matrix-vector multiplication (SpMV) is a central building block for
scientific software and graph applications. Recently, heterogeneous processors
composed of different types of cores attracted much attention because of their
flexible core configuration and high energy efficiency. In this paper, we
propose a compressed sparse row (CSR) format based SpMV algorithm utilizing
both types of cores in a CPU-GPU heterogeneous processor. We first
speculatively execute segmented sum operations on the GPU part of a
heterogeneous processor and generate a possibly incorrect results. Then the CPU
part of the same chip is triggered to re-arrange the predicted partial sums for
a correct resulting vector. On three heterogeneous processors from Intel, AMD
and nVidia, using 20 sparse matrices as a benchmark suite, the experimental
results show that our method obtains significant performance improvement over
the best existing CSR-based SpMV algorithms. The source code of this work is
downloadable at https://github.com/bhSPARSE/Benchmark_SpMV_using_CSR"
"In non-linear systems, where explicit analytic solutions usually can't be
found, visualisation is a powerful approach which can give insights into the
dynamical behaviour of models; it is also crucial for teaching this area of
mathematics. In this paper we present new software, Fireflies, which exploits
the power of graphical processing unit (GPU) computing to produce spectacular
interactive visualisations of arbitrary systems of ordinary differential
equations. In contrast to typical phase portraits, Fireflies draws the current
position of trajectories (projected onto 2D or 3D space) as single points of
light, which move as the system is simulated. Due to the massively parallel
nature of GPU hardware, Fireflies is able to simulate millions of trajectories
in parallel (even on standard desktop computer hardware), producing ""swarms"" of
particles that move around the screen in real-time according to the equations
of the system. Particles that move forwards in time reveal stable attractors
(e.g. fixed points and limit cycles), while the option of integrating another
group of trajectories backwards in time can reveal unstable objects
(repellers). Fireflies allows the user to change the parameters of the system
as it is running, in order to see the effect that they have on the dynamics and
to observe bifurcations. We demonstrate the capabilities of the software with
three examples: a two-dimensional ""mean field"" model of neuronal activity, the
classical Lorenz system, and a 15-dimensional model of three interacting
biologically realistic neurons."
"Polynomial systems occur in many areas of science and engineering. Unlike
general nonlinear systems, the algebraic structure enables to compute all
solutions of a polynomial system. We describe our massive parallel
predictor-corrector algorithms to track many solution paths of a polynomial
homotopy. The data parallelism that provides the speedups stems from the
evaluation and differentiation of the monomials in the same polynomial system
at different data points, which are the points on the solution paths.
Polynomial homotopies that have tens of thousands of solution paths can keep a
sufficiently large amount of threads occupied. Our accelerated code combines
the reverse mode of algorithmic differentiation with double double and quad
double precision to compute more accurate results faster."
"SYM-ILDL is a numerical software package that computes incomplete $LDL^{T}$
(or `ILDL') factorizations of symmetric indefinite and real skew-symmetric
matrices. The core of the algorithm is a Crout variant of incomplete LU (ILU),
originally introduced and implemented for symmetric matrices by [Li and Saad,
Crout versions of ILU factorization with pivoting for sparse symmetric
matrices, Transactions on Numerical Analysis 20, pp. 75--85, 2005]. Our code is
economical in terms of storage and it deals with real skew-symmetric matrices
as well, in addition to symmetric ones. The package is written in C++ and it is
templated, open source, and includes a MATLAB interface. The code includes
built-in RCM and AMD reordering, two equilibration strategies, threshold
Bunch-Kaufman pivoting and rook pivoting, as well as a wrapper to MC64, a
popular matching based equilibration and reordering algorithm. We also include
two built-in iterative solvers: SQMR preconditioned with ILDL, or MINRES
preconditioned with a symmetric positive definite preconditioner based on the
ILDL factorization."
"General-purpose multiprocessors (as, in our case, Intel IvyBridge and Intel
Haswell) increasingly add GPU computing power to the former multicore
architectures. When used for embedded applications (for us, Synthetic aperture
radar) with intensive signal processing requirements, they must constantly
compute convolution algorithms, such as the famous Fast Fourier Transform. Due
to its ""fractal"" nature (the typical butterfly shape, with larger FFTs defined
as combination of smaller ones with auxiliary data array transpose functions),
one can hope to compute analytically the size of the largest FFT that can be
performed locally on an elementary GPU compute block. Then, the full
application must be organized around this given building block size. Now, due
to phenomena involved in the data transfers between various memory levels
across CPUs and GPUs, the optimality of such a scheme is only loosely
predictable (as communications tend to overcome in time the complexity of
computations). Therefore a mix of (theoretical) analytic approach and
(practical) runtime validation is here needed. As we shall illustrate, this
occurs at both stage, first at the level of deciding on a given elementary FFT
block size, then at the full application level."
"We present a simple mathematical framework and API for parallel mesh and data
distribution, load balancing, and overlap generation. It relies on viewing the
mesh as a Hasse diagram, abstracting away information such as cell shape,
dimension, and coordinates. The high level of abstraction makes our interface
both concise and powerful, as the same algorithm applies to any representable
mesh, such as hybrid meshes, meshes embedded in higher dimension, and
overlapped meshes in parallel. We present evidence, both theoretical and
experimental, that the algorithms are scalable and efficient. A working
implementation can be found in the latest release of the PETSc libraries."
"MADNESS (multiresolution adaptive numerical environment for scientific
simulation) is a high-level software environment for solving integral and
differential equations in many dimensions that uses adaptive and fast harmonic
analysis methods with guaranteed precision based on multiresolution analysis
and separated representations. Underpinning the numerical capabilities is a
powerful petascale parallel programming environment that aims to increase both
programmer productivity and code scalability. This paper describes the features
and capabilities of MADNESS and briefly discusses some current applications in
chemistry and several areas of physics."
"The paper introduces an OpenMP implementation of pipelined Parareal and
compares it to a standard MPI-based implementation. Both versions yield
essentially identical runtimes, but, depending on the compiler, the OpenMP
variant consumes about 7% less energy. However, its key advantage is a
significantly smaller memory footprint. The higher implementation complexity,
including manual control of locks, might make it difficult to use in legacy
codes, though."
"We describe a new parallel implementation, mplrs, of the vertex enumeration
code lrs that uses the MPI parallel environment and can be run on a network of
computers. The implementation makes use of a C wrapper that essentially uses
the existing lrs code with only minor modifications. mplrs was derived from the
earlier parallel implementation plrs, written by G. Roumanis in C++. plrs uses
the Boost library and runs on a shared memory machine. In developing mplrs we
discovered a method of balancing the parallel tree search, called budgeting,
that greatly improves parallelization beyond the bottleneck encountered
previously at around 32 cores.
  This method can be readily adapted for use in other reverse search
enumeration codes. We also report some preliminary computational results
comparing parallel and sequential codes for vertex/facet enumeration problems
for convex polyhedra. The problems chosen span the range from simple to highly
degenerate polytopes. For most problems tested, the results clearly show the
advantage of using the parallel implementation mplrs of the reverse search
based code lrs, even when as few as 8 cores are available. For some problems
almost linear speedup was observed up to 1200 cores, the largest number of
cores tested."
"We present TTC, an open-source parallel compiler for multidimensional tensor
transpositions. In order to generate high-performance C++ code, TTC explores a
number of optimizations, including software prefetching, blocking,
loop-reordering, and explicit vectorization. To evaluate the performance of
multidimensional transpositions across a range of possible use-cases, we also
release a benchmark covering arbitrary transpositions of up to six dimensions.
Performance results show that the routines generated by TTC achieve close to
peak memory bandwidth on both the Intel Haswell and the AMD Steamroller
architectures, and yield significant performance gains over modern compilers.
By implementing a set of pruning heuristics, TTC allows users to limit the
number of potential solutions; this option is especially useful when dealing
with high-dimensional tensors, as the search space might become prohibitively
large. Experiments indicate that when only 100 potential solutions are
considered, the resulting performance is about 99% of that achieved with
exhaustive search."
"Optimization on manifolds is a class of methods for optimization of an
objective function, subject to constraints which are smooth, in the sense that
the set of points which satisfy the constraints admits the structure of a
differentiable manifold. While many optimization problems are of the described
form, technicalities of differential geometry and the laborious calculation of
derivatives pose a significant barrier for experimenting with these methods.
  We introduce Pymanopt (available at https://pymanopt.github.io), a toolbox
for optimization on manifolds, implemented in Python, that---similarly to the
Manopt Matlab toolbox---implements several manifold geometries and optimization
algorithms. Moreover, we lower the barriers to users further by using automated
differentiation for calculating derivative information, saving users time and
saving them from potential calculation and implementation errors."
"In this paper we propose a mixed precision algorithm in the context of the
semi-Lagrangian discontinuous Galerkin method. The performance of this approach
is evaluated on a traditional dual socket workstation as well as on a Xeon Phi
and an NVIDIA K80. We find that the mixed precision algorithm can be
implemented efficiently on these architectures. This implies that, in addition
to the considerable reduction in memory, a substantial increase in performance
can be observed as well. Moreover, we discuss the relative performance of our
implementations."
"This document describes the R package UBL that allows the use of several
methods for handling utility-based learning problems. Classification and
regression problems that assume non-uniform costs and/or benefits pose serious
challenges to predictive analytic tasks. In the context of meteorology,
finance, medicine, ecology, among many other, specific domain information
concerning the preference bias of the users must be taken into account to
enhance the models predictive performance. To deal with this problem, a large
number of techniques was proposed by the research community for both
classification and regression tasks. The main goal of UBL package is to
facilitate the utility-based predictive analytic task by providing a set of
methods to deal with this type of problems in the R environment. It is a
versatile tool that provides mechanisms to handle both regression and
classification (binary and multiclass) tasks. Moreover, UBL package allows the
user to specify his domain preferences, but it also provides some automatic
methods that try to infer those preference bias from the domain, considering
some common known settings."
"Very recent work introduces an asymptotically fast subdivision algorithm,
denoted ANewDsc, for isolating the real roots of a univariate real polynomial.
The method combines Descartes' Rule of Signs to test intervals for the
existence of roots, Newton iteration to speed up convergence against clusters
of roots, and approximate computation to decrease the required precision. It
achieves record bounds on the worst-case complexity for the considered problem,
matching the complexity of Pan's method for computing all complex roots and
improving upon the complexity of other subdivision methods by several
magnitudes.
  In the article at hand, we report on an implementation of ANewDsc on top of
the RS root isolator. RS is a highly efficient realization of the classical
Descartes method and currently serves as the default real root solver in Maple.
We describe crucial design changes within ANewDsc and RS that led to a
high-performance implementation without harming the theoretical complexity of
the underlying algorithm.
  With an excerpt of our extensive collection of benchmarks, available online
at http://anewdsc.mpi-inf.mpg.de/, we illustrate that the theoretical gain in
performance of ANewDsc over other subdivision methods also transfers into
practice. These experiments also show that our new implementation outperforms
both RS and mature competitors by magnitudes for notoriously hard instances
with clustered roots. For all other instances, we avoid almost any overhead by
integrating additional optimizations and heuristics."
"The implementation of efficient multigrid preconditioners for elliptic
partial differential equations (PDEs) is a challenge due to the complexity of
the resulting algorithms and corresponding computer code. For sophisticated
finite element discretisations on unstructured grids an efficient
implementation can be very time consuming and requires the programmer to have
in-depth knowledge of the mathematical theory, parallel computing and
optimisation techniques on manycore CPUs. In this paper we show how the
development of bespoke multigrid preconditioners can be simplified
significantly by using a framework which allows the expression of the each
component of the algorithm at the correct abstraction level. Our approach (1)
allows the expression of the finite element problem in a language which is
close to the mathematical formulation of the problem, (2) guarantees the
automatic generation and efficient execution of parallel optimised low-level
computer code and (3) is flexible enough to support different abstraction
levels and give the programmer control over details of the preconditioner. We
use the composable abstractions of the Firedrake/PyOP2 package to demonstrate
the efficiency of this approach for the solution of strongly anisotropic PDEs
in atmospheric modelling. The weak formulation of the PDE is expressed in
Unified Form Language (UFL) and the lower PyOP2 abstraction layer allows the
manual design of computational kernels for a bespoke geometric multigrid
preconditioner. We compare the performance of this preconditioner to a
single-level method and hypre's BoomerAMG algorithm. The Firedrake/PyOP2 code
is inherently parallel and we present a detailed performance analysis for a
single node (24 cores) on the ARCHER supercomputer. Our implementation utilises
a significant fraction of the available memory bandwidth and shows very good
weak scaling on up to 6,144 compute cores."
"The GraphBLAS standard (GraphBlas.org) is being developed to bring the
potential of matrix based graph algorithms to the broadest possible audience.
Mathematically the Graph- BLAS defines a core set of matrix-based graph
operations that can be used to implement a wide class of graph algorithms in a
wide range of programming environments. This paper provides an introduction to
the mathematics of the GraphBLAS. Graphs represent connections between vertices
with edges. Matrices can represent a wide range of graphs using adjacency
matrices or incidence matrices. Adjacency matrices are often easier to analyze
while incidence matrices are often better for representing data. Fortunately,
the two are easily connected by matrix mul- tiplication. A key feature of
matrix mathematics is that a very small number of matrix operations can be used
to manipulate a very wide range of graphs. This composability of small number
of operations is the foundation of the GraphBLAS. A standard such as the
GraphBLAS can only be effective if it has low performance overhead. Performance
measurements of prototype GraphBLAS implementations indicate that the overhead
is low."
"We present an efficient implementation of hypergeometric functions in
arbitrary-precision interval arithmetic. The functions ${}_0F_1$, ${}_1F_1$,
${}_2F_1$ and ${}_2F_0$ (or the Kummer $U$-function) are supported for
unrestricted complex parameters and argument, and by extension, we cover
exponential and trigonometric integrals, error functions, Fresnel integrals,
incomplete gamma and beta functions, Bessel functions, Airy functions, Legendre
functions, Jacobi polynomials, complete elliptic integrals, and other special
functions. The output can be used directly for interval computations or to
generate provably correct floating-point approximations in any format.
Performance is competitive with earlier arbitrary-precision software, and
sometimes orders of magnitude faster. We also partially cover the generalized
hypergeometric function ${}_pF_q$ and computation of high-order parameter
derivatives."
"Tensor computations--in particular tensor contraction (TC)--are important
kernels in many scientific computing applications. Due to the fundamental
similarity of TC to matrix multiplication (MM) and to the availability of
optimized implementations such as the BLAS, tensor operations have
traditionally been implemented in terms of BLAS operations, incurring both a
performance and a storage overhead. Instead, we implement TC using the flexible
BLIS framework, which allows for transposition (reshaping) of the tensor to be
fused with internal partitioning and packing operations, requiring no explicit
transposition operations or additional workspace. This implementation, TBLIS,
achieves performance approaching that of MM, and in some cases considerably
higher than that of traditional TC. Our implementation supports multithreading
using an approach identical to that used for MM in BLIS, with similar
performance characteristics. The complexity of managing tensor-to-matrix
transformations is also handled automatically in our approach, greatly
simplifying its use in scientific applications."
"The increasing number of applications requiring the solution of large scale
singular value problems have rekindled interest in iterative methods for the
SVD. Some promising recent ad- vances in large scale iterative methods are
still plagued by slow convergence and accuracy limitations for computing
smallest singular triplets. Furthermore, their current implementations in
MATLAB cannot address the required large problems. Recently, we presented a
preconditioned, two-stage method to effectively and accurately compute a small
number of extreme singular triplets. In this research, we present a
high-performance software, PRIMME SVDS, that implements our hybrid method based
on the state-of-the-art eigensolver package PRIMME for both largest and
smallest singular values. PRIMME SVDS fills a gap in production level software
for computing the partial SVD, especially with preconditioning. The numerical
experiments demonstrate its superior performance compared to other
state-of-the-art software and its good parallel performance under strong and
weak scaling."
"Multi-shift triangular solves are basic linear algebra calculations with
applications in eigenvector and pseudospectra computation. We propose blocked
algorithms that efficiently exploit Level 3 BLAS to perform multi-shift
triangular solves and safe multi-shift triangular solves. Numerical experiments
indicate that computing triangular eigenvectors with a safe multi-shift
triangular solve achieves speedups by a factor of 60 relative to LAPACK. This
algorithm accelerates the calculation of general eigenvectors threefold. When
using multi-shift triangular solves to compute pseudospectra, we report
ninefold speedups relative to EigTool."
"Julia is a new language for writing data analysis programs that are easy to
implement and run at high performance. Similarly, the Dynamic Distributed
Dimensional Data Model (D4M) aims to clarify data analysis operations while
retaining strong performance. D4M accomplishes these goals through a
composable, unified data model on associative arrays. In this work, we present
an implementation of D4M in Julia and describe how it enables and facilitates
data analysis. Several experiments showcase scalable performance in our new
Julia version as compared to the original Matlab implementation."
"We describe GTApprox - a new tool for medium-scale surrogate modeling in
industrial design. Compared to existing software, GTApprox brings several
innovations: a few novel approximation algorithms, several advanced methods of
automated model selection, novel options in the form of hints. We demonstrate
the efficiency of GTApprox on a large collection of test problems. In addition,
we describe several applications of GTApprox to real engineering problems."
"Exascale computing will feature novel and potentially disruptive hardware
architectures. Exploiting these to their full potential is non-trivial.
Numerical modelling frameworks involving finite difference methods are
currently limited by the 'static' nature of the hand-coded discretisation
schemes and repeatedly may have to be re-written to run efficiently on new
hardware. In contrast, OpenSBLI uses code generation to derive the model's code
from a high-level specification. Users focus on the equations to solve, whilst
not concerning themselves with the detailed implementation. Source-to-source
translation is used to tailor the code and enable its execution on a variety of
hardware."
"Gramian matrices are a well-known encoding for properties of input-output
systems such as controllability, observability or minimality. These so called
system Gramian matrices were developed in linear system theory for applications
such as model order reduction of control systems. Empirical Gramian matrices
are an extension to the system Gramians for parametric and nonlinear systems as
well as a data-driven method of computation. The empirical Gramian framework
\emgr implements the empirical Gramians in a uniform and configurable manner,
with applications such as Gramian-based (nonlinear) model reduction,
decentralized control, sensitivity analysis, parameter identification and
combined state and parameter reduction."
"The task of integrating a large number of independent ODE systems arises in
various scientific and engineering areas. For nonstiff systems, common explicit
integration algorithms can be used on GPUs, where individual GPU threads
concurrently integrate independent ODEs with different initial conditions or
parameters. One example is the fifth-order adaptive Runge-Kutta-Cash-Karp
(RKCK) algorithm. In the case of stiff ODEs, standard explicit algorithms
require impractically small time-step sizes for stability reasons, and implicit
algorithms are therefore commonly used instead to allow larger time steps and
reduce the computational expense. However, typical high-order implicit
algorithms based on backwards differentiation formulae (e.g., VODE, LSODE)
involve complex logical flow that causes severe thread divergence when
implemented on GPUs, limiting the performance. Therefore, alternate algorithms
are needed. A GPU-based Runge-Kutta-Chebyshev (RKC) algorithm can handle
moderate levels of stiffness and performs significantly faster than not only an
equivalent CPU version but also a CPU-based implicit algorithm (VODE) based on
results shown in the literature. In this chapter, we present the mathematical
background, implementation details, and source code for the RKCK and RKC
algorithms for use integrating large numbers of independent systems of ODEs on
GPUs. In addition, brief performance comparisons are shown for each algorithm,
demonstrating the potential benefit of moving to GPU-based ODE integrators."
"Arb is a C library for arbitrary-precision interval arithmetic using the
midpoint-radius representation, also known as ball arithmetic. It supports real
and complex numbers, polynomials, power series, matrices, and evaluation of
many special functions. The core number types are designed for versatility and
speed in a range of scenarios, allowing performance that is competitive with
non-interval arbitrary-precision types such as MPFR and MPC floating-point
numbers. We discuss the low-level number representation, strategies for
precision and error bounds, and the implementation of efficient polynomial
arithmetic with interval coefficients."
"We consider algorithms for going from a ""full"" matrix to a condensed ""band
bidiagonal"" form using orthogonal transformations. We use the framework of
""algorithms by tiles"". Within this framework, we study: (i) the tiled
bidiagonalization algorithm BiDiag, which is a tiled version of the standard
scalar bidiagonalization algorithm; and (ii) the R-bidiagonalization algorithm
R-BiDiag, which is a tiled version of the algorithm which consists in first
performing the QR factorization of the initial matrix, then performing the
band-bidiagonalization of the R-factor. For both bidiagonalization algorithms
BiDiag and R-BiDiag, we use four main types of reduction trees, namely FlatTS,
FlatTT, Greedy, and a newly introduced auto-adaptive tree, Auto. We provide a
study of critical path lengths for these tiled algorithms, which shows that (i)
R-BiDiag has a shorter critical path length than BiDiag for tall and skinny
matrices, and (ii) Greedy based schemes are much better than earlier proposed
variants with unbounded resources. We provide experiments on a single multicore
node, and on a few multicore nodes of a parallel distributed shared-memory
system, to show the superiority of the new algorithms on a variety of matrix
sizes, matrix shapes and core counts."
"SimTensor is a multi-platform, open-source software for generating artificial
tensor data (either with CP/PARAFAC or Tucker structure) for reproducible
research on tensor factorization algorithms. SimTensor is a stand-alone
application based on MATALB. It provides a wide range of facilities for
generating tensor data with various configurations. It comes with a
user-friendly graphical user interface, which enables the user to generate
tensors with complicated settings in an easy way. It also has this facility to
export generated data to universal formats such as CSV and HDF5, which can be
imported via a wide range of programming languages (C, C++, Java, R, Fortran,
MATLAB, Perl, Python, and many more). The most innovative part of SimTensor is
this that can generate temporal tensors with periodic waves, seasonal effects
and streaming structure. it can apply constraints such as non-negativity and
different kinds of sparsity to the data. SimTensor also provides this facility
to simulate different kinds of change-points and inject various types of
anomalies. The source code and binary versions of SimTensor is available for
download in http://www.simtensor.org."
"In this paper, an efficient divide-and-conquer (DC) algorithm is proposed for
the symmetric tridiagonal matrices based on ScaLAPACK and the hierarchically
semiseparable (HSS) matrices. HSS is an important type of rank-structured
matrices.Most time of the DC algorithm is cost by computing the eigenvectors
via the matrix-matrix multiplications (MMM). In our parallel hybrid DC (PHDC)
algorithm, MMM is accelerated by using the HSS matrix techniques when the
intermediate matrix is large. All the HSS algorithms are done via the package
STRUMPACK. PHDC has been tested by using many different matrices. Compared with
the DC implementation in MKL, PHDC can be faster for some matrices with few
deflations when using hundreds of processes. However, the gains decrease as the
number of processes increases. The comparisons of PHDC with ELPA (the
Eigenvalue soLvers for Petascale Applications library) are similar. PHDC is
usually slower than MKL and ELPA when using 300 or more processes on Tianhe-2
supercomputer."
"Regional hydrology studies are often supported by high resolution simulations
of subsurface flow that require expensive and extensive computations. Efficient
usage of the latest high performance parallel computing systems becomes a
necessity. The simulation software ParFlow has been demonstrated to meet this
requirement and shown to have excellent solver scalability for up to 16,384
processes. In the present work we show that the code requires further
enhancements in order to fully take advantage of current petascale machines. We
identify ParFlow's way of parallelization of the computational mesh as a
central bottleneck. We propose to reorganize this subsystem using fast mesh
partition algorithms provided by the parallel adaptive mesh refinement library
p4est. We realize this in a minimally invasive manner by modifying selected
parts of the code to reinterpret the existing mesh data structures. We evaluate
the scaling performance of the modified version of ParFlow, demonstrating good
weak and strong scaling up to 458k cores of the Juqueen supercomputer, and test
an example application at large scale."
"The contraction method is a procedure that allows to establish non-trivial
relations between Lie algebras and has had succesful applications in both
mathematics and theoretical physics. This work deals with generalizations of
the contraction procedure with a main focus in the so called S-expansion method
as it includes most of the other generalized contractions. Basically, the
S-exansion combines a Lie algebra $\mathcal{G}$ with a finite abelian semigroup
$S$ in order to define new S-expanded algebras. After giving a description of
the main ingredients used in this paper, we present a Java library that
automatizes the S-expansion procedure. With this computational tool we are able
to represent Lie algebras and semigroups, so we can perform S-expansions of Lie
algebras using arbitrary semigroups. We explain how the library methods has
been constructed and how they work; then we give a set of example programs
aimed to solve different problems. They are presented so that any user can
easily modify them to perform his own calculations, without being necessarily
an expert in Java. Finally, some comments about further developements and
possible new applications are made."
"A novel and scalable geometric multi-level algorithm is presented for the
numerical solution of elliptic partial differential equations, specially
designed to run with high occupancy of streaming processors inside Graphics
Processing Units(GPUs). The algorithm consists of iterative, superposed
operations on a single grid, and it is composed of two simple full-grid
routines: a restriction and a coarsened interpolation-relaxation. The
restriction is used to collect sources using recursive coarsened averages, and
the interpolation-relaxation simultaneously applies coarsened finite-difference
operators and interpolations. The routines are scheduled in a saw-like refining
cycle. Convergence to machine precision is achieved repeating the full cycle
using accumulated residuals and successively collecting the solution. Its total
number of operations scale linearly with the number of nodes. It provides an
attractive fast solver for Boundary Value Problems (BVPs), specially for
simulations running entirely in the GPU. Applications shown in this work
include the deformation of two-dimensional grids, the computation of
three-dimensional streamlines for a singular trifoil-knot vortex and the
calculation of three-dimensional electric potentials in heterogeneous
dielectric media."
"Domain-specific languages (DSLs) are of increasing importance in scientific
high-performance computing to reduce development costs, raise the level of
abstraction and, thus, ease scientific programming. However, designing and
implementing DSLs is not an easy task, as it requires knowledge of the
application domain and experience in language engineering and compilers.
Consequently, many DSLs follow a weak approach using macros or text generators,
which lack many of the features that make a DSL a comfortable for programmers.
Some of these features---e.g., syntax highlighting, type inference, error
reporting, and code completion---are easily provided by language workbenches,
which combine language engineering techniques and tools in a common ecosystem.
In this paper, we present the Parallel Particle-Mesh Environment (PPME), a DSL
and development environment for numerical simulations based on particle methods
and hybrid particle-mesh methods. PPME uses the meta programming system (MPS),
a projectional language workbench. PPME is the successor of the Parallel
Particle-Mesh Language (PPML), a Fortran-based DSL that used conventional
implementation strategies. We analyze and compare both languages and
demonstrate how the programmer's experience can be improved using static
analyses and projectional editing. Furthermore, we present an explicit domain
model for particle abstractions and the first formal type system for particle
methods."
"Recently we presented TTC, a domain-specific compiler for tensor
transpositions. Despite the fact that the performance of the generated code is
nearly optimal, due to its offline nature, TTC cannot be utilized in all the
application codes in which the tensor sizes and the necessary tensor
permutations are determined at runtime. To overcome this limitation, we
introduce the open-source C++ library High-Performance Tensor Transposition
(HPTT). Similar to TTC, HPTT incorporates optimizations such as blocking,
multi-threading, and explicit vectorization; furthermore it decomposes any
transposition into multiple loops around a so called micro-kernel. This modular
design---inspired by BLIS---makes HPTT easy to port to different architectures,
by only replacing the hand-vectorized micro-kernel (e.g., a 4x4 transpose).
HPTT also offers an optional autotuning framework---guided by a performance
model---that explores a vast search space of implementations at runtime
(similar to FFTW). Across a wide range of different tensor transpositions and
architectures (e.g., Intel Ivy Bridge, Intel Knights Landing, ARMv7, IBM
Power7), HPTT attains a bandwidth comparable to that of SAXPY, and yields
remarkable speedups over Eigen's tensor transposition implementation. Most
importantly, the integration of HPTT into the Cyclops Tensor Framework (CTF)
improves the overall performance of tensor contractions by up to 3.1x."
"Aboria is a powerful and flexible C++ library for the implementation of
particle-based numerical methods. The particles in such methods can represent
actual particles (e.g. Molecular Dynamics) or abstract particles used to
discretise a continuous function over a domain (e.g. Radial Basis Functions).
Aboria provides a particle container, compatible with the Standard Template
Library, spatial search data structures, and a Domain Specific Language to
specify non-linear operators on the particle set. This paper gives an overview
of Aboria's design, an example of use, and a performance benchmark."
"This work demonstrates how to accelerate dense linear algebra computations
using CLBlast, an open-source OpenCL BLAS library providing optimized routines
for a wide variety of devices. It is targeted at machine learning and HPC
applications and thus provides a fast matrix-multiplication routine (GEMM) to
accelerate the core of many applications (e.g. deep learning, iterative
solvers, astrophysics, computational fluid dynamics, quantum chemistry).
CLBlast has four main advantages over other BLAS libraries: 1) it is optimized
for and tested on a large variety of OpenCL devices including less commonly
used devices such as embedded and low-power GPUs, 2) it can be explicitly tuned
for specific problem-sizes on specific hardware platforms, 3) it can perform
operations in half-precision floating-point FP16 saving precious bandwidth,
time and energy, 4) and it can combine multiple operations in a single batched
routine, accelerating smaller problems significantly. This paper describes the
library and demonstrates the advantages of CLBlast experimentally for different
use-cases on a wide variety of OpenCL hardware."
"Automatic differentiation is a technique which allows a programmer to define
a numerical computation via compositions of a broad range of numeric and
computational primitives and have the underlying system support the computation
of partial derivatives of the result with respect to any of its inputs, without
making any finite difference approximations, and without manipulating large
symbolic expressions representing the computation. This note describes a novel
approach to reverse mode automatic differentiation using constraint logic
programmming, specifically, the constraint handling rules (CHR) library of SWI
Prolog, resulting in a very small (50 lines of code) implementation. When
applied to a differentiation-based implementation of the inside-outside
algorithm for parameter learning in probabilistic grammars, the CHR based
implementations outperformed two well-known frameworks for optimising
differentiable functions, Theano and TensorFlow, by a large margin."
"The efficient solution of discretizations of coupled systems of partial
differential equations (PDEs) is at the core of much of numerical simulation.
Significant effort has been expended on scalable algorithms to precondition
Krylov iterations for the linear systems that arise. With few exceptions, the
reported numerical implementation of such solution strategies is specific to a
particular model setup, and intimately ties the solver strategy to the
discretization and PDE, especially when the preconditioner requires auxiliary
operators. In this paper, we present recent improvements in the Firedrake
finite element library that allow for straightforward development of the
building blocks of extensible, composable, preconditioners that decouple the
solver from the model formulation. Our implementation extends the algebraic
composability of linear solvers offered by the PETSc library by augmenting
operators, and hence preconditioners, with the ability to assemble any
necessary auxiliary operators. Rather than specifying up front the full solver
configuration, tied to the model, solvers can be developed independently of
model formulation and configured at runtime. We illustrate with examples from
incompressible fluids and temperature-driven convection."
"We present a full implementation of the parareal algorithm---an integration
technique to solve differential equations in parallel---in the Julia
programming language for a fully general, first-order, initial-value problem.
Our implementation accepts both coarse and fine integrators as functional
arguments. We use Euler's method and another Runge-Kutta integration technique
as the integrators in our experiments. We also present a simulation of the
algorithm for purposes of pedagogy."
"We present high performance implementations of the QR and the singular value
decomposition of a batch of small matrices hosted on the GPU with applications
in the compression of hierarchical matrices. The one-sided Jacobi algorithm is
used for its simplicity and inherent parallelism as a building block for the
SVD of low rank blocks using randomized methods. We implement multiple kernels
based on the level of the GPU memory hierarchy in which the matrices can reside
and show substantial speedups against streamed cuSOLVER SVDs. The resulting
batched routine is a key component of hierarchical matrix compression, opening
up opportunities to perform H-matrix arithmetic efficiently on GPUs."
"A pseudo-random number generator (RNG) might be used to generate w-bit random
samples in d dimensions if the number of state bits is at least dw. Some RNGs
perform better than others and the concept of equidistribution has been
introduced in the literature in order to rank different RNGs. We define what it
means for a RNG to be (d,w)-equidistributed, and then argue that
(d,w)-equidistribution is not necessarily a desirable property."
"Pseudorandom number generators are required for many computational tasks,
such as stochastic modelling and simulation. This paper investigates the serial
CPU and parallel GPU implementation of a Linear Congruential Generator based on
the binary representation of the normal number $\alpha_{2,3}$. We adapted two
methods of modular reduction which allowed us to perform most operations in
64-bit integer arithmetic, improving on the original implementation based on
106-bit double-double operations. We found that our implementation is faster
than existing methods in literature, and our generation rate is close to the
limiting rate imposed by the efficiency of writing to a GPU's global memory."
"In many scientific and engineering applications, one has to solve not one but
a sequence of instances of the same problem. Often times, the problems in the
sequence are linked in a way that allows intermediate results to be reused. A
characteristic example for this class of applications is given by the
Genome-Wide Association Studies (GWAS), a widely spread tool in computational
biology. GWAS entails the solution of up to trillions ($10^{12}$) of correlated
generalized least-squares problems, posing a daunting challenge: the
performance of petaflops ($10^{15}$ floating-point operations) over terabytes
of data.
  In this paper, we design an algorithm for performing GWAS on multi-core
architectures. This is accomplished in three steps. First, we show how to
exploit the relation among successive problems, thus reducing the overall
computational complexity. Then, through an analysis of the required data
transfers, we identify how to eliminate any overhead due to input/output
operations. Finally, we study how to decompose computation into tasks to be
distributed among the available cores, to attain high performance and
scalability. With our algorithm, a GWAS that currently requires the use of a
supercomputer may now be performed in matter of hours on a single multi-core
node.
  The discussion centers around the methodology to develop the algorithm rather
than the specific application. We believe the paper contributes valuable
guidelines of general applicability for computational scientists on how to
develop and optimize numerical algorithms."
"We introduce the MathGR package, written in Mathematica. The package can
manipulate tensor and GR calculations with either abstract or explicit indices,
simplify tensors with permutational symmetries, decompose tensors from abstract
indices to partially or completely explicit indices and convert partial
derivatives into total derivatives. Frequently used GR tensors and a model of
FRW universe with ADM type perturbations are predefined. The package is built
around the philosophy to ""keep it simple"", and makes use of latest tensor
technologies of Mathematica."
"Pseudo-spectral method is one of the most accurate techniques for simulating
turbulent flows. Fast Fourier transform (FFT) is an integral part of this
method. In this paper, we present a new procedure to compute FFT in which we
save operations during interprocess communications by avoiding transpose of the
array. As a result, our transpose-free FFT is 15\% to 20\% faster than FFTW."
"The paper demonstrates the optimization of the execution environment of a
hybrid OpenMP+MPI computational fluid dynamics code (shallow water equation
solver) on a cluster enabled with Intel Xeon Phi coprocessors. The discussion
includes: (1) Controlling the number and affinity of OpenMP threads to optimize
access to memory bandwidth; (2) Tuning the inter-operation of OpenMP and MPI to
partition the problem for better data locality; (3) Ordering the MPI ranks in a
way that directs some of the traffic into faster communication channels; (4)
Using efficient peer-to-peer communication between Xeon Phi coprocessors based
on the InfiniBand fabric.
  With tuning, the application has 90% percent efficiency of parallel scaling
up to 8 Intel Xeon Phi coprocessors in 2 compute nodes. For larger problems,
scalability is even better, because of the greater computation to communication
ratio. However, problems of that size do not fit in the memory of one
coprocessor. The performance of the solver on one Intel Xeon Phi coprocessor
7120P exceeds the performance on a dual-socket Intel Xeon E5-2697 v2 CPU by a
factor of 1.6x. In a 2-node cluster with 4 coprocessors per compute node, the
MIC architecture yields 5.8x more performance than the CPUs. Only one line of
legacy Fortran code had to be changed in order to achieve the reported
performance on the MIC architecture (not counting changes to the command-line
interface). The methodology discussed in this paper is directly applicable to
other bandwidth-bound stencil algorithms utilizing a hybrid OpenMP+MPI
approach."
"Numerical continuation methods track a solution path defined by a homotopy.
The systems we consider are defined by polynomials in several variables with
complex coefficients. For larger dimensions and degrees, the numerical
conditioning worsens and hardware double precision becomes often insufficient
to reach the end of the solution path. With double double and quad double
arithmetic, we can solve larger problems that we could not solve with hardware
double arithmetic, but at a higher computational cost. This cost overhead can
be compensated by acceleration on a Graphics Processing Unit (GPU). We describe
our implementation and report on computational results on benchmark polynomial
systems."
"Polynomial systems occur in many fields of science and engineering.
Polynomial homotopy continuation methods apply symbolic-numeric algorithms to
solve polynomial systems. We describe the design and implementation of our web
interface and reflect on the application of polynomial homotopy continuation
methods to solve polynomial systems in the cloud. Via the graph isomorphism
problem we organize and classify the polynomial systems we solved. The
classification with the canonical form of a graph identifies newly submitted
systems with systems that have already been solved."
"The computation of the tropical prevariety is the first step in the
application of polyhedral methods to compute positive dimensional solution sets
of polynomial systems. In particular, pretropisms are candidate leading
exponents for the power series developments of the solutions. The computation
of the power series may start as soon as one pretropism is available, so our
parallel computation of the tropical prevariety has an application in a
pipelined solver.
  We present a parallel implementation of dynamic enumeration. Our first
distributed memory implementation with forked processes achieved good speedups,
but quite often resulted in large variations in the execution times of the
processes. The shared memory multithreaded version applies work stealing to
reduce the variability of the run time. Our implementation applies the thread
safe Parma Polyhedral Library (PPL), in exact arithmetic with the GNU
Multiprecision Arithmetic Library (GMP), aided by the fast memory allocations
of TCMalloc.
  Our parallel implementation is capable of computing the tropical prevariety
of the cyclic 16-roots problem. We also report on computational experiments on
the $n$-body and $n$-vortex problems; our computational results compare
favorably with Gfan."
"We present a proof of concept for adapting the finite-difference time-domain
method (FDTD) for solving a 1+1D complex-valued, delay partial differential
equation (PDE) that emerges in the study of waveguide quantum electrodynamics
(QED). The delay term exists in both spatial and temporal directions, rendering
the conventional approaches such as the method of lines inapplicable. We show
that by properly designing the grid and by using the exact (partial) solution
as the boundary condition, the delay PDE can be numerically solved. Our code
provides a numerically exact solution to the time-dependent multi-photon
scattering problem in waveguide QED. The program is written in C and
open-sourced on GitHub."