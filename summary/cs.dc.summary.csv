summary
"This paper presents a synchronization-based, multi-process computational
model of anticipatory systems called the Phase Web. It describes a
self-organizing paradigm that explicitly recognizes and exploits the existence
of a boundary between inside and outside, accepts and exploits intentionality,
and uses explicit self-reference to describe eg. auto-poiesis. The model
explicitly connects computation to a discrete Clifford algebraic formalization
that is in turn extended into homology and co-homology, wherein the recursive
nature of objects and boundaries becomes apparent and itself subject to
hierarchical recursion. Topsy, a computer program embodying the Phase Web, is
available at www.cs.auc.dk/topsy."
"Gryphon is a distributed computing paradigm for message brokering, which is
the transferring of information in the form of streams of events from
information providers to information consumers. This extended abstract outlines
the major problems in message brokering and Gryphon's approach to solving them."
"We show that, contrary to common belief, Dijkstra's self-stabilizing mutual
exclusion algorithm on a ring [Dij74,Dij82] also stabilizes when the number of
states per node is one less than the number of nodes on the ring."
"We argue that the tools of decision theory need to be taken more seriously in
the specification and analysis of systems. We illustrate this by considering a
simple problem involving reliable communication, showing how considerations of
utility and probability can be used to decide when it is worth sending
heartbeat messages and, if they are sent, how often they should be sent."
"We present a theory of automata with boundary for designing, modelling and
analysing distributed systems. Notions of behaviour, design and simulation
appropriate to the theory are defined. The problem of model checking for
deadlock detection is discussed, and an algorithm for state space reduction in
exhaustive search, based on the theory presented here, is described. Three
examples of the application of the theory are given, one in the course of the
development of the ideas and two as illustrative examples of the use of the
theory."
"The idle computers on a local area, campus area, or even wide area network
represent a significant computational resource---one that is, however, also
unreliable, heterogeneous, and opportunistic. This type of resource has been
used effectively for embarrassingly parallel problems but not for more tightly
coupled problems. We describe an algorithm that allows branch-and-bound
problems to be solved in such environments. In designing this algorithm, we
faced two challenges: (1) scalability, to effectively exploit the variably
sized pools of resources available, and (2) fault tolerance, to ensure the
reliability of services. We achieve scalability through a fully decentralized
algorithm, by using a membership protocol for managing dynamically available
resources. However, this fully decentralized design makes achieving reliability
even more challenging. We guarantee fault tolerance in the sense that the loss
of up to all but one resource will not affect the quality of the solution. For
propagating information efficiently, we use epidemic communication for both the
membership protocol and the fault-tolerance mechanism. We have developed a
simulation framework that allows us to evaluate design alternatives. Results
obtained in this framework suggest that our techniques can execute scalably and
reliably."
"Sorting is one of the classic problems of computer science. Whilst well
understood on sequential machines, the diversity of architectures amongst
parallel systems means that algorithms do not perform uniformly on all
platforms. This document describes the implementation of a radix based
algorithm for sorting positive integers on a Fujitsu AP1000 Supercomputer,
which was constructed as an entry in the Joint Symposium on Parallel Processing
(JSPP) 1994 Parallel Software Contest (PSC94). Brief consideration is also
given to a full radix sort conducted in parallel across the machine."
"The problem of minimizing mean response time of generic jobs submitted to a
heterogenous distributed computer systems is considered in this paper. A static
load balancing strategy, in which decision of redistribution of loads does not
depend on the state of the system, is used for this purpose. The article is
closely related to a previous article on the same topic. The present article
points out number of inconsistencies in the previous article, provides a new
formulation, and discusses the impact of new findings, based on the improved
formulation, on the results of the previous article."
"We consider a system of t synchronous processes that communicate only by
sending messages to one another, and that together must perform $n$ independent
units of work. Processes may fail by crashing; we want to guarantee that in
every execution of the protocol in which at least one process survives, all n
units of work will be performed. We consider three parameters: the number of
messages sent, the total number of units of work performed (including
multiplicities), and time. We present three protocols for solving the problem.
All three are work-optimal, doing O(n+t) work. The first has moderate costs in
the remaining two parameters, sending O(t\sqrt{t}) messages, and taking O(n+t)
time. This protocol can be easily modified to run in any completely
asynchronous system equipped with a failure detection mechanism. The second
sends only O(t log{t}) messages, but its running time is large (exponential in
n and t). The third is essentially time-optimal in the (usual) case in which
there are no failures, and its time complexity degrades gracefully as the
number of failures increases."
"Phase clocks are synchronization tools that implement a form of logical time
in distributed systems. For systems tolerating transient faults by self-repair
of damaged data, phase clocks can enable reasoning about the progress of
distributed repair procedures. This paper presents a phase clock algorithm
suited to the model of transient memory faults in asynchronous systems with
read/write registers. The algorithm is self-stabilizing and guarantees accuracy
of phase clocks within O(k) time following an initial state that is k-faulty.
Composition theorems show how the algorithm can be used for the timing of
distributed procedures that repair system outputs."
"The availability of powerful microprocessors and high-speed networks as
commodity components has enabled high performance computing on distributed
systems (wide-area cluster computing). In this environment, as the resources
are usually distributed geographically at various levels (department,
enterprise, or worldwide) there is a great challenge in integrating,
coordinating and presenting them as a single resource to the user; thus forming
a computational grid. Another challenge comes from the distributed ownership of
resources with each resource having its own access policy, cost, and mechanism.
  The proposed Nimrod/G grid-enabled resource management and scheduling system
builds on our earlier work on Nimrod and follows a modular and component-based
architecture enabling extensibility, portability, ease of development, and
interoperability of independently developed components. It uses the Globus
toolkit services and can be easily extended to operate with any other emerging
grid middleware services. It focuses on the management and scheduling of
computations over dynamic resources scattered geographically across the
Internet at department, enterprise, or global level with particular emphasis on
developing scheduling schemes based on the concept of computational economy for
a real test bed, namely, the Globus testbed (GUSTO)."
"Byzantine Agreement introduced in [Pease, Shostak, Lamport, 80] is a widely
used building block of reliable distributed protocols. It simulates broadcast
despite the presence of faulty parties within the network, traditionally using
only private unicast links. Under such conditions, Byzantine Agreement requires
more than 2/3 of the parties to be compliant. [Fitzi, Maurer, 00], constructed
a Byzantine Agreement protocol for any compliant majority based on an
additional primitive allowing transmission to any two parties simultaneously.
They proposed a problem of generalizing these results to wider channels and
fewer compliant parties. We prove that 2f < kh condition is necessary and
sufficient for implementing broadcast with h compliant and f faulty parties
using k-cast channels."
"Many scientific applications are I/O intensive and generate or access large
data sets, spanning hundreds or thousands of ""files."" Management, storage,
efficient access, and analysis of this data present an extremely challenging
task. We have developed a software system, called Scientific Data Manager
(SDM), that uses a combination of parallel file I/O and database support for
high-performance scientific data management. SDM provides a high-level API to
the user and internally, uses a parallel file system to store real data and a
database to store application-related metadata. In this paper, we describe how
we designed and implemented SDM to support irregular applications. SDM can
efficiently handle the reading and writing of data in an irregular mesh as well
as the distribution of index values. We describe the SDM user interface and how
we implemented it to achieve high performance. SDM makes extensive use of
MPI-IO's noncontiguous collective I/O functions. SDM also uses the concept of a
history file to optimize the cost of the index distribution using the metadata
stored in the database. We present performance results with two irregular
applications, a CFD code called FUN3D and a Rayleigh-Taylor instability code,
on the SGI Origin2000 at Argonne National Laboratory."
"Parallel jobs are different from sequential jobs and require a different type
of process management. We present here a process management system for parallel
programs such as those written using MPI. A primary goal of the system, which
we call MPD (for multipurpose daemon), is to be scalable. By this we mean that
startup of interactive parallel jobs comprising thousands of processes is
quick, that signals can be quickly delivered to processes, and that stdin,
stdout, and stderr are managed intuitively. Our primary target is parallel
machines made up of clusters of SMPs, but the system is also useful in more
tightly integrated environments. We describe how MPD enables much faster
startup and better runtime management of parallel jobs. We show how close
control of stdio can support the easy implementation of a number of convenient
system utilities, even a parallel debugger. We describe a simple but general
interface that can be used to separate any process manager from a parallel
library, which we use to keep MPD separate from MPICH."
"The Globus Data Grid architecture provides a scalable infrastructure for the
management of storage resources and data that are distributed across Grid
environments. These services are designed to support a variety of scientific
applications, ranging from high-energy physics to computational genomics, that
require access to large amounts of data (terabytes or even petabytes) with
varied quality of service requirements. By layering on a set of core services,
such as data transport, security, and replica cataloging, one can construct
various higher-level services. In this paper, we discuss the design and
implementation of a high-level replica selection service that uses information
regarding replica location and user preferences to guide selection from among
storage replica alternatives. We first present a basic replica selection
service design, then show how dynamic information collected using Globus
information service capabilities concerning storage system properties can help
improve and optimize the selection process. We demonstrate the use of Condor's
ClassAds resource description and matchmaking mechanism as an efficient tool
for representing and matching storage resource capabilities and policies
against application requirements."
"The first self-stabilizing algorithm [Dij73] assumed the existence of a
central daemon, that activates one processor at time to change state as a
function of its own state and the state of a neighbor. Subsequent research has
reconsidered this algorithm without the assumption of a central daemon, and
under different forms of communication, such as the model of link registers. In
all of these investigations, one common feature is the atomicity of
communication, whether by shared variables or read/write registers. This paper
weakens the atomicity assumptions for the communication model, proposing
versions of [Dij73] that tolerate various weaker forms of atomicity. First, a
solution for the case of regular registers is presented. Then the case of safe
registers is considered, with both negative and positive results presented. The
paper also presents an implementation of [Dij73] based on registers that have
probabilistically correct behavior, which requires a notion of weak
stabilization."
"This paper precisely analyzes the wire density and required area in standard
layout styles for the hypercube. The most natural, regular layout of a
hypercube of N^2 nodes in the plane, in a N x N grid arrangement, uses
floor(2N/3)+1 horizontal wiring tracks for each row of nodes. (The number of
tracks per row can be reduced by 1 with a less regular design.) This paper also
gives a simple formula for the wire density at any cut position and a full
characterization of all places where the wire density is maximized (which does
not occur at the bisection)."
"The accelerated development in Grid and peer-to-peer computing has positioned
them as promising next generation computing platforms. They enable the creation
of Virtual Enterprises (VE) for sharing resources distributed across the world.
However, resource management, application development and usage models in these
environments is a complex undertaking. This is due to the geographic
distribution of resources that are owned by different organizations. The
resource owners of each of these resources have different usage or access
policies and cost models, and varying loads and availability. In order to
address complex resource management issues, we have proposed a computational
economy framework for resource allocation and for regulating supply and demand
in Grid computing environments. The framework provides mechanisms for
optimizing resource provider and consumer objective functions through trading
and brokering services. In a real world market, there exist various economic
models for setting the price for goods based on supply-and-demand and their
value to the user. They include commodity market, posted price, tenders and
auctions. In this paper, we discuss the use of these models for interaction
between Grid components in deciding resource value and the necessary
infrastructure to realize them. In addition to normal services offered by Grid
computing systems, we need an infrastructure to support interaction protocols,
allocation mechanisms, currency, secure banking, and enforcement services.
Furthermore, we demonstrate the usage of some of these economic models in
resource brokering through Nimrod/G deadline and cost-based scheduling for two
different optimization strategies on the World Wide Grid (WWG) testbed."
"High-throughput computing projects require the solution of large numbers of
problems. In many cases, these problems can be solved on desktop PCs, or can be
broken down into independent ""PC-solvable"" sub-problems. In such cases, the
projects are high-performance computing projects, but only because of the sheer
number of the needed calculations. We briefly describe our efforts to increase
the throughput of one such project. We then explain how to easily set up a
distributed computing facility composed of standard networked PCs running
Windows 95, 98, 2000, or NT. The facility requires no special software or
hardware, involves little or no re-coding of application software, and operates
almost invisibly to the owners of the PCs. Depending on the number and quality
of PCs recruited, performance can rival that of supercomputers."
"We present the first explicit, and currently simplest, randomized algorithm
for 2-process wait-free test-and-set. It is implemented with two 4-valued
single writer single reader atomic variables. A test-and-set takes at most 11
expected elementary steps, while a reset takes exactly 1 elementary step. Based
on a finite-state analysis, the proofs of correctness and expected length are
compressed into one table."
"The NEOS Server 4.0 provides a general Internet-based client/server as a link
between users and software applications. The administrative guide covers the
fundamental principals behind the operation of the NEOS Server, installation
and trouble-shooting of the Server software, and implementation details of
potential interest to a NEOS Server administrator. The guide also discusses
making new software applications available through the Server, including areas
of concern to remote solver administrators such as maintaining security,
providing usage instructions, and enforcing reasonable restrictions on jobs.
The administrative guide is intended both as an introduction to the NEOS Server
and as a reference for use when running the Server."
"The ability to harness heterogeneous, dynamically available ""Grid"" resources
is attractive to typically resource-starved computational scientists and
engineers, as in principle it can increase, by significant factors, the number
of cycles that can be delivered to applications. However, new adaptive
application structures and dynamic runtime system mechanisms are required if we
are to operate effectively in Grid environments. In order to explore some of
these issues in a practical setting, we are developing an experimental
framework, called Cactus, that incorporates both adaptive application
structures for dealing with changing resource characteristics and adaptive
resource selection mechanisms that allow applications to change their resource
allocations (e.g., via migration) when performance falls outside specified
limits. We describe here the adaptive resource selection mechanisms and
describe how they are used to achieve automatic application migration to
""better"" resources following performance degradation. Our results provide
insights into the architectural structures required to support adaptive
resource selection. In addition, we suggest that this ""Cactus Worm"" is an
interesting challenge problem for Grid computing."
"Shared registers are basic objects used as communication mediums in
asynchronous concurrent computation. A concurrent timestamp system is a higher
typed communication object, and has been shown to be a powerful tool to solve
many concurrency control problems. It has turned out to be possible to
construct such higher typed objects from primitive lower typed ones. The next
step is to find efficient constructions. We propose a very efficient wait-free
construction of bounded concurrent timestamp systems from 1-writer multireader
registers. This finalizes, corrects, and extends, a preliminary bounded
multiwriter construction proposed by the second author in 1986. That work
partially initiated the current interest in wait-free concurrent objects, and
introduced a notion of discrete vector clocks in distributed algorithms."
"We describe a family of MPI applications we call the Parallel Unix Commands.
These commands are natural parallel versions of common Unix user commands such
as ls, ps, and find, together with a few similar commands particular to the
parallel environment. We describe the design and implementation of these
programs and present some performance results on a 256-node Linux cluster. The
Parallel Unix Commands are open source and freely available."
"The Message Passing Interface (MPI) has been extremely successful as a
portable way to program high-performance parallel computers. This success has
occurred in spite of the view of many that message passing is difficult and
that other approaches, including automatic parallelization and directive-based
parallelism, are easier to use. This paper argues that MPI has succeeded
because it addresses all of the important issues in providing a parallel
programming model."
"We discuss the use of both MPI and OpenMP in the teaching of senior
undergraduate and junior graduate classes in parallel programming. We briefly
introduce the OpenMP standard and discuss why we have chosen to use it in
parallel programming classes. Advantages of using OpenMP over message passing
methods are discussed. We also include a brief enumeration of some of the
drawbacks of using OpenMP and how these drawbacks are being addressed by
supplementing OpenMP with additional MPI codes and projects. Several projects
given in my class are also described in this paper."
"TANGO is an object oriented control system toolkit based on CORBA presently
under development at the ESRF. IN this paper, the TANGO philosophy is briefly
presented. All the existing tools developed around TANGO will also be
presented. This include a code genrator, a WEB interface to TANGO objects, an
administration tool and an interface to LabView. Finally, an xample of a TANGO
device server for OPC device is given."
"The Integrated Computer Control System (ICCS) is based on a scalable software
framework that is distributed over some 325 computers throughout the NIF
facility. The framework provides templates and services at multiple levels of
abstraction for the construction of software applications that communicate via
CORBA (Common Object Request Broker Architecture). Various forms of
object-oriented software design patterns are implemented as templates to be
extended by application software. Developers extend the framework base classes
to model the numerous physical control points, thereby sharing the
functionality defined by the base classes. About 56,000 software objects each
individually addressed through CORBA are to be created in the complete ICCS.
Most objects have a persistent state that is initialized at system start-up and
stored in a database. Additional framework services are provided by centralized
server programs that implement events, alerts, reservations, message logging,
database/file persistence, name services, and process management. The ICCS
software framework approach allows for efficient construction of a software
system that supports a large number of distributed control points representing
a complex control application."
"he ESRF control system is in the process of being modernised. The present
contrsystem is based on VME, 10 MHz Ethernet, OS9, Solaris, HP-UX, NFS/RPC,
Motif and C. The new control system will be based on compact PCI, 100 MHz
Ethernet, Linux, Windows, Solaris, CORBA/IIOP, C++, Java and Python. The main
frontend operating system will be GNU/Linux running on Intel/x86 and
Motorola/68k. Linux will also be used on handheld devices for mobile control.
This poster describes how GNU/Linux is being used to modernise the control
system and what problems have been encountered so far"
"Computational Grids are emerging as a popular paradigm for solving
large-scale compute and data intensive problems in science, engineering, and
commerce. However, application composition, resource management and scheduling
in these environments is a complex undertaking. In this paper, we illustrate
the creation of a virtual laboratory environment by leveraging existing Grid
technologies to enable molecular modeling for drug design on distributed
resources. It involves screening millions of molecules of chemical compounds
against a protein target, chemical database (CDB) to identify those with
potential use for drug design. We have grid-enabled the molecular docking
process by composing it as a parameter sweep application using the Nimrod-G
tools. We then developed new tools for remote access to molecules in CDB small
molecule database. The Nimrod-G resource broker along with molecule CDB data
broker is used for scheduling and on-demand processing of jobs on distributed
grid resources. The results demonstrate the ease of use and suitability of the
Nimrod-G and virtual laboratory tools."
"Computational Grids, coupling geographically distributed resources such as
PCs, workstations, clusters, and scientific instruments, have emerged as a next
generation computing platform for solving large-scale problems in science,
engineering, and commerce. However, application development, resource
management, and scheduling in these environments continue to be a complex
undertaking. In this article, we discuss our efforts in developing a resource
management system for scheduling computations on resources distributed across
the world with varying quality of service. Our service-oriented grid computing
system called Nimrod-G manages all operations associated with remote execution
including resource discovery, trading, scheduling based on economic principles
and a user defined quality of service requirement. The Nimrod-G resource broker
is implemented by leveraging existing technologies such as Globus, and provides
new services that are essential for constructing industrial-strength Grids. We
discuss results of preliminary experiments on scheduling some parametric
computations using the Nimrod-G resource broker on a world-wide grid testbed
that spans five continents."
"Multireader shared registers are basic objects used as communication medium
in asynchronous concurrent computation. We propose a surprisingly simple and
natural scheme to obtain several wait-free constructions of bounded 1-writer
multireader registers from atomic 1-writer 1-reader registers, that is easier
to prove correct than any previous construction. Our main construction is the
first symmetric pure timestamp one that is optimal with respect to the
worst-case local use of control bits; the other one is optimal with respect to
global use of control bits; both are optimal in time."
"Clusters, grids, and peer-to-peer (P2P) networks have emerged as popular
paradigms for next generation parallel and distributed computing. The
management of resources and scheduling of applications in such large-scale
distributed systems is a complex undertaking. In order to prove the
effectiveness of resource brokers and associated scheduling algorithms, their
performance needs to be evaluated under different scenarios such as varying
number of resources and users with different requirements. In a grid
environment, it is hard and even impossible to perform scheduler performance
evaluation in a repeatable and controllable manner as resources and users are
distributed across multiple organizations with their own policies. To overcome
this limitation, we have developed a Java-based discrete-event grid simulation
toolkit called GridSim. The toolkit supports modeling and simulation of
heterogeneous grid resources (both time- and space-shared), users and
application models. It provides primitives for creation of application tasks,
mapping of tasks to resources, and their management. To demonstrate suitability
of the GridSim toolkit, we have simulated a Nimrod-G like grid resource broker
and evaluated the performance of deadline and budget constrained cost- and
time-minimization scheduling algorithms."
"Computational Grids and peer-to-peer (P2P) networks enable the sharing,
selection, and aggregation of geographically distributed resources for solving
large-scale problems in science, engineering, and commerce. The management and
composition of resources and services for scheduling applications, however,
becomes a complex undertaking. We have proposed a computational economy
framework for regulating the supply and demand for resources and allocating
them for applications based on the users quality of services requirements. The
framework requires economy driven deadline and budget constrained (DBC)
scheduling algorithms for allocating resources to application jobs in such a
way that the users requirements are met. In this paper, we propose a new
scheduling algorithm, called DBC cost-time optimisation, which extends the DBC
cost-optimisation algorithm to optimise for time, keeping the cost of
computation at the minimum. The superiority of this new scheduling algorithm,
in achieving lower job completion time, is demonstrated by simulating the
World-Wide Grid and scheduling task-farming applications for different deadline
and budget scenarios using both this new and the cost optimisation scheduling
algorithms."
"Computational Grids, emerging as an infrastructure for next generation
computing, enable the sharing, selection, and aggregation of geographically
distributed resources for solving large-scale problems in science, engineering,
and commerce. As the resources in the Grid are heterogeneous and geographically
distributed with varying availability and a variety of usage and cost policies
for diverse users at different times and, priorities as well as goals that vary
with time. The management of resources and application scheduling in such a
large and distributed environment is a complex task. This thesis proposes a
distributed computational economy as an effective metaphor for the management
of resources and application scheduling. It proposes an architectural framework
that supports resource trading and quality of services based scheduling. It
enables the regulation of supply and demand for resources and provides an
incentive for resource owners for participating in the Grid and motives the
users to trade-off between the deadline, budget, and the required level of
quality of service. The thesis demonstrates the capability of economic-based
systems for peer-to-peer distributed computing by developing users'
quality-of-service requirements driven scheduling strategies and algorithms. It
demonstrates their effectiveness by performing scheduling experiments on the
World-Wide Grid for solving parameter sweep applications."
"This document gives an overview of a Grid testbed architecture proposal for
the NorduGrid project. The aim of the project is to establish an inter-Nordic
testbed facility for implementation of wide area computing and data handling.
The architecture is supposed to define a Grid system suitable for solving data
intensive problems at the Large Hadron Collider at CERN. We present the various
architecture components needed for such a system. After that we go on to give a
description of the dynamics by showing the task flow."
"This report presents results of the tests measuring the performance of
multi-threaded file transfers, using the GridFTP implementation of the Globus
project over the NorduGrid network resources. Point to point WAN tests, carried
out between the sites of Copenhagen, Lund, Oslo and Uppsala, are described. It
was found that multiple threaded download via the high performance GridFTP
protocol can significantly improve file transfer performance, and can serve as
a reliable data"
"The efficient implementation of collective communiction operations has
received much attention. Initial efforts produced ""optimal"" trees based on
network communication models that assumed equal point-to-point latencies
between any two processes. This assumption is violated in most practical
settings, however, particularly in heterogeneous systems such as clusters of
SMPs and wide-area ""computational Grids,"" with the result that collective
operations perform suboptimally. In response, more recent work has focused on
creating topology-aware trees for collective operations that minimize
communication across slower channels (e.g., a wide-area network). While these
efforts have significant communication benefits, they all limit their view of
the network to only two layers. We present a strategy based upon a multilayer
view of the network. By creating multilevel topology-aware trees we take
advantage of communication cost differences at every level in the network. We
used this strategy to implement topology-aware versions of several MPI
collective operations in MPICH-G2, the Globus Toolkit[tm]-enabled version of
the popular MPICH implementation of the MPI standard. Using information about
topology provided by MPICH-G2, we construct these multilevel topology-aware
trees automatically during execution. We present results demonstrating the
advantages of our multilevel approach by comparing it to the default
(topology-unaware) implementation provided by MPICH and a topology-aware
two-layer implementation."
"Application development for distributed computing ""Grids"" can benefit from
tools that variously hide or enable application-level management of critical
aspects of the heterogeneous environment. As part of an investigation of these
issues, we have developed MPICH-G2, a Grid-enabled implementation of the
Message Passing Interface (MPI) that allows a user to run MPI programs across
multiple computers, at the same or different sites, using the same commands
that would be used on a parallel computer. This library extends the Argonne
MPICH implementation of MPI to use services provided by the Globus Toolkit for
authentication, authorization, resource allocation, executable staging, and
I/O, as well as for process creation, monitoring, and control. Various
performance-critical operations, including startup and collective operations,
are configured to exploit network topology information. The library also
exploits MPI constructs for performance management; for example, the MPI
communicator construct is used for application-level discovery of, and
adaptation to, both network topology and network quality-of-service mechanisms.
We describe the MPICH-G2 design and implementation, present performance
results, and review application experiences, including record-setting
distributed simulations."
"We describe an efficient and fault-tolerant algorithm for distributed cyclic
garbage collection. The algorithm imposes few requirements on the local
machines and allows for flexibility in the choice of local collector and
distributed acyclic garbage collector to use with it. We have emphasized
reducing the number and size of network messages without sacrificing the
promptness of collection throughout the algorithm. Our proposed collector is a
variant of back tracing to avoid extensive synchronization between machines. We
have added an explicit forward tracing stage to the standard back tracing stage
and designed a tuned heuristic to reduce the total amount of work done by the
collector. Of particular note is the development of fault-tolerant cooperation
between traces and a heuristic that aggressively reduces the set of suspect
objects."
"With the tremendous advances in processor and memory technology, I/O has
risen to become the bottleneck in high-performance computing for many
applications. The development of parallel file systems has helped to ease the
performance gap, but I/O still remains an area needing significant performance
improvement. Research has found that noncontiguous I/O access patterns in
scientific applications combined with current file system methods to perform
these accesses lead to unacceptable performance for large data sets. To enhance
performance of noncontiguous I/O we have created list I/O, a native version of
noncontiguous I/O. We have used the Parallel Virtual File System (PVFS) to
implement our ideas. Our research and experimentation shows that list I/O
outperforms current noncontiguous I/O access methods in most I/O situations and
can substantially enhance the performance of real-world scientific
applications."
"A novel algorithm for performing parallel, distributed computer simulations
on the Internet using IP control messages is introduced. The algorithm employs
carefully constructed ICMP packets which enable the required computations to be
completed as part of the standard IP communication protocol. After providing a
detailed description of the algorithm, experimental applications in the areas
of stochastic neural networks and deterministic cellular automata are
discussed. As an example of the algorithms potential power, a simulation of a
deterministic cellular automaton involving 10^5 Internet connected devices was
performed."
"Memory consistency models have been developed to specify what values may be
returned by a read given that, in a distributed system, memory operations may
only be partially ordered. Before this work, consistency models were defined
independently. Each model followed a set of rules which was separate from the
rules of every other model. In our work we have defined a set of four
consistency properties. Any subset of the four properties yields a set of rules
which constitute a consistency model. Every consistency model previously
described in the literature can be defined based on our four properties.
Therefore, we present these properties as a unfied theory of shared memory
consistency."
"Computational Grids are emerging as new infrastructure for Internet-based
parallel and distributed computing. They enable the sharing, exchange,
discovery, and aggregation of resources distributed across multiple
administrative domains, organizations and enterprises. To accomplish this,
Grids need infrastructure that supports various services: security, uniform
access, resource management, scheduling, application composition, computational
economy, and accountability. Many Grid projects have developed technologies
that provide many of these services with an exception of accountability. To
overcome this limitation, we propose a new infrastructure called Grid Bank that
provides services for accounting. This paper presents requirements of Grid
accountability and different models within which it can operate and proposes
Grid Bank Services Architecture that meets them. The paper highlights
implementation issues with detailed discussion on format for various
records/database that the GridBank need to maintain. It also presents protocols
for interaction between GridBank and various components within Grid computing
environments."
"The National Fusion Collaboratory (NFC) project was created to advance
scientific understanding and innovation in magnetic fusion research by enabling
more efficient use of existing experimental facilities through more effective
integration of experiment, theory, and modeling. To achieve this objective, NFC
introduced the concept of ""network services"", which build on top of
computational Grids, and provide Fusion codes, together with their maintenance
and hardware resources as a service to the community. This mode of operation
requires the development of new authorization and enforcement capabilities. In
addition, the nature of Fusion experiments places strident quality of service
requirements on codes run during the experimental cycle. In this paper, we
describe Grid computing requirements of the Fusion community, and present our
first experiments in meeting those requirements."
"Message passing programs commonly use buffers to avoid unnecessary
synchronizations and to improve performance by overlapping communication with
computation. Unfortunately, using buffers makes the program no longer portable,
potentially unable to complete on systems without a sufficient number of
buffers. Effective buffer use entails that the minimum number needed for a safe
execution be allocated.
  We explore a variety of problems related to buffer allocation for safe and
efficient execution of message passing programs. We show that determining the
minimum number of buffers or verifying a buffer assignment are intractable
problems. However, we give a polynomial time algorithm to determine the minimum
number of buffers needed to allow for asynchronous execution. We extend these
results to several different buffering schemes, which in some cases make the
problems tractable."
"As Grids are emerging as the next generation service-oriented computing
platforms, they need to support Grid economy that helps in the management of
supply and demand for resources and offers an economic incentive for Grid
resource providers. To enable this Grid economy, a market-like Grid environment
including an infrastructure that supports the publication of services and their
discovery is needed. As part of the Gridbus project, we proposed and have
developed a Grid Market Directory (GMD) that serves as a registry for
high-level service publication and discovery in Virtual Organisations."
"Grids are experiencing a rapid growth in their application and along with
this there is a requirement for a portal which is easy to use and scalable. We
have responded to this requirement by developing an easy to use, scalable,
web-based portal called G-Monitor. This paper proposes a generic architecture
for a web portal into a grid environment and discusses our implementation and
its application."
"Computational Grids are emerging as a platform for next-generation parallel
and distributed computing. Large-scale parametric studies and parameter sweep
applications find a natural place in the Grid?s distribution model. There is
little or no communication between jobs. The task of parallelizing and
distributing existing applications is conceptually trivial. These properties of
parametric studies make it an ideal place to start developing integrated
development environments (IDEs) for rapidly Grid-enabling applications.
However, the availability of IDEs for scientists to Grid-enable their
applications, without the need of developing them as parallel applications
explicitly, is still lacking. This paper presents a Java based IDE called
Visual Parametric Tool (VPT), developed as part of the Gridbus project, for
rapid creation of parameter sweep (data parallel/SPMD) applications. It
supports automatic creation of parameter script and parameterisation of the
input data files, which is compatible with the Nimrod-G parameter specification
language. The usefulness of VPT is demonstrated by a case study on composition
of molecular docking application as a parameter sweep application. Such
applications can be deployed on clusters using the Nimrod/enFuzion system and
on global Grids using the Nimrod-G grid resource broker."
"With the advent of the Internet, search engines have begun sprouting like
mushrooms after a rainfall. Only in recent years, have developers become more
innovative, and came up with guided searching facilities online. The goals of
these applications are to help ease and guide the searching efforts of a novice
web user toward their desired objectives. A number of implementations of such
services are emerging. This paper proposes a guided meta-search engine, called
""Guided Google"", as it serves as an interface to the actual Google.com search
engine, using the Google Web Services."
"The lack of computational power within an organization for analyzing
scientific data, and the distribution of knowledge (by scientists) and
technologies (advanced scientific devices) are two major problems commonly
observed in scientific disciplines. One such scientific discipline is brain
science. The analysis of brain activity data gathered from the MEG
(Magnetoencephalography) instrument is an important research topic in medical
science since it helps doctors in identifying symptoms of diseases. The data
needs to be analyzed exhaustively to efficiently diagnose and analyze brain
functions and requires access to large-scale computational resources. The
potential platform for solving such resource intensive applications is the
Grid. This paper describes a MEG data analysis system developed by us,
leveraging Grid technologies, primarily Nimrod-G, Gridbus, and Globus. This
paper explains the application of economy-based grid scheduling algorithms to
the problem domain for on-demand processing of analysis jobs."
"The reader-writer-problem is a standard problem in concurrent programming. A
resource is shared by several processes which need either inclusive reading or
exclusive writing access. The known solutions to this problem typically involve
a number of global counters and queues. Here a very simple algorithm is
presented which needs only two semaphores for synchronisation and no other
global objects. The approach yields a fair solution without starving."
"The recent proliferation of Data Grids and the increasingly common practice
of using resources as distributed data stores provide a convenient environment
for communities of researchers to share, replicate, and manage access to copies
of large datasets. This has led to the question of which replica can be
accessed most efficiently. In such environments, fetching data from one of the
several replica locations requires accurate predictions of end-to-end transfer
times. The answer to this question can depend on many factors, including
physical characteristics of the resources and the load behavior on the CPUs,
networks, and storage devices that are part of the end-to-end data path linking
possible sources and sinks. Our approach combines end-to-end application
throughput observations with network and disk load variations and captures
whole-system performance and variations in load patterns. Our predictions
characterize the effect of load variations of several shared devices (network
and disk) on file transfer times. We develop a suite of univariate and
multivariate predictors that can use multiple data sources to improve the
accuracy of the predictions as well as address Data Grid variations
(availability of data and sporadic nature of transfers). We ran a large set of
data transfer experiments using GridFTP and observed performance predictions
within 15% error for our testbed sites, which is quite promising for a
pragmatic system."
"The EU DataGrid project workpackage 4 has as an objective to provide the
necessary tools for automating the management of medium size to very large
computing fabrics. At the end of the second project year subsystems for
centralized configuration management (presented at LISA'02) and
performance/exception monitoring have been delivered. This will soon be
augmented with a subsystem for node installation and service configuration,
which is based on existing widely used standards where available (e.g. rpm,
kickstart, init.d scripts) and clean interfaces to OS dependent components
(e.g. base installation and service management). The three subsystems together
allow for centralized management of very large computer farms. Finally, a fault
tolerance system is being developed for tying together the above subsystems to
form a complete framework for automated enterprise computing management by
3Q03. All software developed is open source covered by the EU DataGrid project
license agreements. This article describes the architecture behind the designed
fabric management system and the status of the different developments. It also
covers the experience with an existing tool for automated configuration and
installation that have been adapted and used from the beginning to manage the
EU DataGrid testbed, which is now used for LHC data challenges."
"WorldGrid is an intercontinental testbed spanning Europe and the US
integrating architecturally different Grid implementations based on the Globus
toolkit. It has been developed in the context of the DataTAG and iVDGL
projects, and successfully demonstrated during the WorldGrid demos at IST2002
(Copenhagen) and SC2002 (Baltimore). Two HEP experiments, ATLAS and CMS,
successful exploited the WorldGrid testbed for executing jobs simulating the
response of their detectors to physics eve nts produced by real collisions
expected at the LHC accelerator starting from 2007. This data intensive
activity has been run since many years on local dedicated computing farms
consisting of hundreds of nodes and Terabytes of disk and tape storage. Within
the WorldGrid testbed, for the first time HEP simulation jobs were submitted
and run indifferently on US and European resources, despite of their underlying
different Grid implementations, and produced data which could be retrieved and
further analysed on the submitting machine, or simply stored on the remote
resources and registered on a Replica Catalogue which made them available to
the Grid for further processing. In this contribution we describe the job
submission from Europe for both ATLAS and CMS applications, performed through
the GENIUS portal operating on top of an EDG User Interface submitting to an
EDG Resource Broker, pointing out the chosen interoperability solutions which
made US and European resources equivalent from the applications point of view,
the data management in the WorldGrid environment, and the CMS specific
production tools which were interfaced to the GENIUS portal."
"In this paper we report on the first two years of running the CERN testbed
site for the EU DataGRID project. The site consists of about 120 dual-processor
PCs distributed over several testbeds used for different purposes: software
development, system integration, and application tests. Activities at the site
included test productions of MonteCarlo data for LHC experiments, tutorials and
demonstrations of GRID technologies, and support for individual users analysis.
This paper focuses on node installation and configuration techniques, service
management, user support in a gridified environment, and includes
considerations on scalability and security issues and comparisons with
""traditional"" production systems, as seen from the administrator point of view."
"During the last years large farms have been built using commodity hardware.
This hardware lacks components for remote and automated administration.
Products that can be retrofitted to these systems are either costly or
inherently insecure. We present a system based on serial ports and simple
machine controlled relays. We report on experience gained by setting up a
50-machine test environment as well as current work in progress in the area."
"Distributed Services Architecture with support for mobile agents between
services, offer significantly improved communication and computational
flexibility. The uses of agents allow execution of complex operations that
involve large amounts of data to be processed effectively using distributed
resources. The prototype system Distributed Agents for Mobile and Dynamic
Services (DIAMOnDS), allows a service to send agents on its behalf, to other
services, to perform data manipulation and processing. Agents have been
implemented as mobile services that are discovered using the Jini Lookup
mechanism and used by other services for task management and communication.
Agents provide proxies for interaction with other services as well as specific
GUI to monitor and control the agent activity. Thus agents acting on behalf of
one service cooperate with other services to carry out a job, providing
inter-operation of loosely coupled services in a semi-autonomous way. Remote
file system access functionality has been incorporated by the agent framework
and allows services to dynamically share and browse the file system resources
of hosts, running the services. Generic database access functionality has been
implemented in the mobile agent framework that allows performing complex data
mining and processing operations efficiently in distributed system. A basic
data searching agent is also implemented that performs a query based search in
a file system. The testing of the framework was carried out on WAN by moving
Connectivity Test agents between AgentStations in CERN, Switzerland and NUST,
Pakistan."
"McRunjob is a powerful grid workflow manager used to manage the generation of
large numbers of production processing jobs in High Energy Physics. In use at
both the DZero and CMS experiments, McRunjob has been used to manage large
Monte Carlo production processing since 1999 and is being extended to uses in
regular production processing for analysis and reconstruction. Described at
CHEP 2001, McRunjob converts core metadata into jobs submittable in a variety
of environments. The powerful core metadata description language includes
methods for converting the metadata into persistent forms, job descriptions,
multi-step workflows, and data provenance information. The language features
allow for structure in the metadata by including full expressions, namespaces,
functional dependencies, site specific parameters in a grid environment, and
ontological definitions. It also has simple control structures for
parallelization of large jobs. McRunjob features a modular design which allows
for easy expansion to new job description languages or new application level
tasks."
"The BaBar online data acquisition (DAQ) system includes approximately fifty
Unix systems that collectively implement the level-three trigger. These systems
all run the same code. Each of these systems has its own state, and this state
is expected to change in response to changes in the overall DAQ system. A
specialized subsystem has been developed to initiate processing on this
collection of systems, and to monitor them both for error conditions and to
ensure that they all follow the same state trajectory within a specifiable
period of time. This subsystem receives start commands from the main DAQ run
control system, and reports major coherent state changes, as well as error
conditions, back to the run control system. This state monitoring subsystem has
the novel feature that it does not know anything about the state machines that
it is monitoring, and hence does not introduce any fundamentally new state
machine into the overall system. This feature makes it trivially applicable to
other multi-node subsystems. Indeed it has already found a second application
beyond the level-three trigger, within the BaBar experiment."
"The CMS Integration Grid Testbed (IGT) comprises USCMS Tier-1 and Tier-2
hardware at the following sites: the California Institute of Technology, Fermi
National Accelerator Laboratory, the University of California at San Diego, and
the University of Florida at Gainesville. The IGT runs jobs using the Globus
Toolkit with a DAGMan and Condor-G front end. The virtual organization (VO) is
managed using VO management scripts from the European Data Grid (EDG). Gridwide
monitoring is accomplished using local tools such as Ganglia interfaced into
the Globus Metadata Directory Service (MDS) and the agent based Mona Lisa.
Domain specific software is packaged and installed using the Distrib ution
After Release (DAR) tool of CMS, while middleware under the auspices of the
Virtual Data Toolkit (VDT) is distributed using Pacman. During a continuo us
two month span in Fall of 2002, over 1 million official CMS GEANT based Monte
Carlo events were generated and returned to CERN for analysis while being
demonstrated at SC2002. In this paper, we describe the process that led to one
of the world's first continuously available, functioning grids."
"Several applications have been implemented with access via the Clarens web
service infrastructure, including virtual organization management, JetMET
physics data analysis using relational databases, and Storage Resource Broker
(SRB) access. This functionality is accessible transparently from Python
scripts, the Root analysis framework and from Java applications and browser
applets."
"Clarens is a uniquely flexible web services infrastructure providing a
unified access protocol to a diverse set of functions useful to the HEP
community. It uses the standard HTTP protocol combined with application layer,
certificate based authentication to provide single sign-on to individuals,
organizations and hosts, with fine-grained access control to services, files
and virtual organization (VO) management. This contribution describes the
server functionality, while client applications are described in a subsequent
talk."
"We describe R-GMA (Relational Grid Monitoring Architecture) which is being
developed within the European DataGrid Project as an Grid Information and
Monitoring System. Is is based on the GMA from GGF, which is a simple
Consumer-Producer model. The special strength of this implementation comes from
the power of the relational model. We offer a global view of the information as
if each VO had one large relational database. We provide a number of different
Producer types with different characteristics; for example some support
streaming of information. We also provide combined Consumer/Producers, which
are able to combine information and republish it. At the heart of the system is
the mediator, which for any query is able to find and connect to the best
Producers to do the job. We are able to invoke MDS info-provider scripts and
publish the resulting information via R-GMA in addition to having some of our
own sensors. APIs are available which allow the user to deploy monitoring and
information services for any application that may be needed in the future. We
have used it both for information about the grid (primarily to find what
services are available at any one time) and for application monitoring. R-GMA
has been deployed in Grid testbeds, we describe the results and experiences of
this deployment."
"One of the fundamental concepts in Grid computing is the creation of Virtual
Organizations (VO's): a set of resource consumers and providers that join
forces to solve a common problem. Typical examples of Virtual Organizations
include collaborations formed around the Large Hadron Collider (LHC)
experiments. To date, Grid computing has been applied on a relatively small
scale, linking dozens of users to a dozen resources, and management of these
VO's was a largely manual operation. With the advance of large collaboration,
linking more than 10000 users with a 1000 sites in 150 counties, a
comprehensive, automated management system is required. It should be simple
enough not to deter users, while at the same time ensuring local site autonomy.
The VO Management Service (VOMS), developed by the EU DataGrid and DataTAG
projects[1, 2], is a secured system for managing authorization for users and
resources in virtual organizations. It extends the existing Grid Security
Infrastructure[3] architecture with embedded VO affiliation assertions that can
be independently verified by all VO members and resource providers. Within the
EU DataGrid project, Grid services for job submission, file- and database
access are being equipped with fine- grained authorization systems that take VO
membership into account. These also give resource owners the ability to ensure
site security and enforce local access policies. This paper will describe the
EU DataGrid security architecture, the VO membership service and the local site
enforcement mechanisms Local Centre Authorization Service (LCAS), Local
Credential Mapping Service(LCMAPS) and the Java Trust and Authorization
Manager."
"Application users have now been experiencing for about a year with the
standardized resource brokering services provided by the 'workload management'
package of the EU DataGrid project (WP1). Understanding, shaping and pushing
the limits of the system has provided valuable feedback on both its design and
implementation. A digest of the lessons, and ""better practices"", that were
learned, and that were applied towards the second major release of the
software, is given."
"The BaBar experiment is characterized by extremely high luminosity, a complex
detector, and a huge data volume, with increasing requirements each year. To
fulfill these requirements a new control system has been designed and developed
for the offline data reconstruction system. The new control system described in
this paper provides the performance and flexibility needed to manage a large
number of small computing farms, and takes full benefit of OO design. The
infrastructure is well isolated from the processing layer, it is generic and
flexible, based on a light framework providing message passing and cooperative
multitasking. The system is actively distributed, enforces the separation
between different processing tiers by using different naming domains, and glues
them together by dedicated brokers. It provides a powerful Finite State Machine
framework to describe custom processing models in a simple regular language.
This paper describes this new control system, currently in use at SLAC and
Padova on ~450 CPUs organized in 12 farms."
"In the first phase of the EU DataGrid (EDG) project, a Data Management System
has been implemented and provided for deployment. The components of the current
EDG Testbed are: a prototype of a Replica Manager Service built around the
basic services provided by Globus, a centralised Replica Catalogue to store
information about physical locations of files, and the Grid Data Mirroring
Package (GDMP) that is widely used in various HEP collaborations in Europe and
the US for data mirroring. During this year these services have been refined
and made more robust so that they are fit to be used in a pre-production
environment. Application users have been using this first release of the Data
Management Services for more than a year. In the paper we present the
components and their interaction, our implementation and experience as well as
the feedback received from our user communities. We have resolved not only
issues regarding integration with other EDG service components but also many of
the interoperability issues with components of our partner projects in Europe
and the U.S. The paper concludes with the basic lessons learned during this
operation. These conclusions provide the motivation for the architecture of the
next generation of Data Management Services that will be deployed in EDG during
2003."
"WorldGRID is an intercontinental testbed spanning Europe and the US
integrating architecturally different Grid implementations based on the Globus
toolkit. The WorldGRID testbed has been successfully demonstrated during the
WorldGRID demos at SuperComputing 2002 (Baltimore) and IST2002 (Copenhagen)
where real HEP application jobs were transparently submitted from US and Europe
using ""native"" mechanisms and run where resources were available, independently
of their location. To monitor the behavior and performance of such testbed and
spot problems as soon as they arise, DataTAG has developed the EDT-Monitor tool
based on the Nagios package that allows for Virtual Organization centric views
of the Grid through dynamic geographical maps. The tool has been used to spot
several problems during the WorldGRID operations, such as malfunctioning
Resource Brokers or Information Servers, sites not correctly configured, job
dispatching problems, etc. In this paper we give an overview of the package,
its features and scalability solutions and we report on the experience acquired
and the benefit that a GRID operation center would gain from such a tool."
"Workpackage 8 of the European Datagrid project was formed in January 2001
with representatives from the four LHC experiments, and with experiment
independent people from five of the six main EDG partners. In September 2002
WP8 was strengthened by the addition of effort from BaBar and D0. The original
mandate of WP8 was, following the definition of short- and long-term
requirements, to port experiment software to the EDG middleware and testbed
environment. A major additional activity has been testing the basic
functionality and performance of this environment. This paper reviews
experiences and evaluations in the areas of job submission, data management,
mass storage handling, information systems and monitoring. It also comments on
the problems of remote debugging, the portability of code, and scaling problems
with increasing numbers of jobs, sites and nodes. Reference is made to the
pioneeering work of Atlas and CMS in integrating the use of the EDG Testbed
into their data challenges. A forward look is made to essential software
developments within EDG and to the necessary cooperation between EDG and LCG
for the LCG prototype due in mid 2003."
"In the future ALICE heavy ion experiment at CERN's Large Hadron Collider
input data rates of up to 25 GB/s have to be handled by the High Level Trigger
(HLT) system, which has to scale them down to at most 1.25 GB/s before being
written to permanent storage. The HLT system that is being designed to cope
with these data rates consists of a large PC cluster, up to the order of a 1000
nodes, connected by a fast network. For the software that will run on these
nodes a flexible data transport and distribution software framework has been
developed. This framework consists of a set of separate components, that can be
connected via a common interface, allowing to construct different
configurations for the HLT, that are even changeable at runtime. To ensure a
fault-tolerant operation of the HLT, the framework includes a basic fail-over
mechanism that will be further expanded in the future, utilizing the runtime
reconnection feature of the framework's component interface. First performance
tests show very promising results for the software, indicating that it can
achieve an event rate for the data transport sufficiently high to satisfy
ALICE's requirements."
"The EU DataGrid has deployed a grid testbed at approximately 20 sites across
Europe, with several hundred registered users. This paper describes
authorisation systems produced by GridPP and currently used on the EU DataGrid
Testbed, including local Unix pool accounts and fine-grained access control
with Access Control Lists and Grid-aware filesystems, fileservers and web
developement environments."
"The European DataTAG project has taken a major step towards making the
concept of a worldwide computing Grid a reality. In collaboration with the
companion U.S. project iVDGL, DataTAG has realized an intercontinental testbed
spanning Europe and the U.S. integrating architecturally different Grid
implementations based on the Globus toolkit. The WorldGrid testbed has been
successfully demonstrated at SuperComputing 2002 and IST2002 where real HEP
application jobs were transparently submitted from U.S. and Europe using native
mechanisms and run where resources were available, independently of their
location. In this paper we describe the architecture of the WorldGrid testbed,
the problems encountered and the solutions taken in realizing such a testbed.
With our work we present an important step towards interoperability of Grid
middleware developed and deployed in Europe and the U.S.. Some of the solutions
developed in WorldGrid will be adopted by the LHC Computing Grid first service.
To the best of our knowledge, this is the first large-scale testbed that
combines middleware components and makes them work together."
"Dataset storage, exchange, and access play a critical role in scientific
applications. For such purposes netCDF serves as a portable and efficient file
format and programming interface, which is popular in numerous scientific
application domains. However, the original interface does not provide an
efficient mechanism for parallel data storage and access. In this work, we
present a new parallel interface for writing and reading netCDF datasets. This
interface is derived with minimum changes from the serial netCDF interface but
defines semantics for parallel access and is tailored for high performance. The
underlying parallel I/O is achieved through MPI-IO, allowing for dramatic
performance gains through the use of collective I/O optimizations. We compare
the implementation strategies with HDF5 and analyze both. Our tests indicate
programming convenience and significant I/O performance improvement with this
parallel netCDF interface."
"For data analysis of large-scale experiments such as LHC Atlas and other
Japanese high energy and nuclear physics projects, we have constructed a Grid
test bed at ICEPP and KEK. These institutes are connected to national
scientific gigabit network backbone called SuperSINET. In our test bed, we have
installed NorduGrid middleware based on Globus, and connected 120TB HPSS at KEK
as a large scale data store. Atlas simulation data at ICEPP has been
transferred and accessed using SuperSINET. We have tested various performances
and characteristics of HPSS through this high speed WAN. The measurement
includes comparison between computing and storage resources are tightly coupled
with low latency LAN and long distant WAN."
"In 2002 the ATLAS experiment started a series of Data Challenges (DC) of
which the goals are the validation of the Computing Model, of the complete
software suite, of the data model, and to ensure the correctness of the
technical choices to be made. A major feature of the first Data Challenge (DC1)
was the preparation and the deployment of the software required for the
production of large event samples for the High Level Trigger (HLT) and physics
communities, and the production of those samples as a world-wide distributed
activity. The first phase of DC1 was run during summer 2002, and involved 39
institutes in 18 countries. More than 10 million physics events and 30 million
single particle events were fully simulated. Over a period of about 40 calendar
days 71000 CPU-days were used producing 30 Tbytes of data in about 35000
partitions. In the second phase the next processing step was performed with the
participation of 56 institutes in 21 countries (~ 4000 processors used in
parallel). The basic elements of the ATLAS Monte Carlo production system are
described. We also present how the software suite was validated and the
participating sites were certified. These productions were already partly
performed by using different flavours of Grid middleware at ~ 20 sites."
"High energy physics experiments including those at the Tevatron and the
upcoming LHC require analysis of large data sets which are best handled by
distributed computation. We present the design and development of a distributed
data analysis framework based on Java. Analysis jobs run through three phases:
discovery of data sets available, brokering/assignment of data sets to analysis
servers, and job execution. Each phase is represented by a set of abstract
interfaces. These interfaces allow different techniques to be used without
modification to the framework. For example, the communications interface has
been implemented by both a packet protocol and a SOAP-based scheme. User
authentication can be provided either through simple passwords or through a GSI
certificates system. Data from CMS HCAL Testbeams, the L3 LEP experiment, and a
hypothetical high-energy linear collider experiment have been interfaced with
the framework."
"Having built up Linux clusters to more than 1000 nodes over the past five
years, we already have practical experience confronting some of the LHC scale
computing challenges: scalability, automation, hardware diversity, security,
and rolling OS upgrades. This paper describes the tools and processes we have
implemented, working in close collaboration with the EDG project [1],
especially with the WP4 subtask, to improve the manageability of our clusters,
in particular in the areas of system installation, configuration, and
monitoring. In addition to the purely technical issues, providing shared
interactive and batch services which can adapt to meet the diverse and changing
requirements of our users is a significant challenge. We describe the
developments and tuning that we have introduced on our LSF based systems to
maximise both responsiveness to users and overall system utilisation. Finally,
this paper will describe the problems we are facing in enlarging our
heterogeneous Linux clusters, the progress we have made in dealing with the
current issues and the steps we are taking to gridify the clusters"
"This paper describes DIRAC, the LHCb Monte Carlo production system. DIRAC has
a client/server architecture based on: Compute elements distributed among the
collaborating institutes; Databases for production management, bookkeeping (the
metadata catalogue) and software configuration; Monitoring and cataloguing
services for updating and accessing the databases. Locally installed software
agents implemented in Python monitor the local batch queue, interrogate the
production database for any outstanding production requests using the XML-RPC
protocol and initiate the job submission. The agent checks and, if necessary,
installs any required software automatically. After the job has processed the
events, the agent transfers the output data and updates the metadata catalogue.
DIRAC has been successfully installed at 18 collaborating institutes, including
the DataGRID, and has been used in recent Physics Data Challenges. In the near
to medium term future we must use a mixed environment with different types of
grid middleware or no middleware. We describe how this flexibility has been
achieved and how ubiquitously available grid middleware would improve DIRAC."
"Registration and management of users in a large scale Grid computing
environment presents new challenges that are not well addressed by existing
protocols. Within a single Virtual Organization (VO), thousands of users will
potentially need access to hundreds of computing sites, and the traditional
model where users register for local accounts at each site will present
significant scaling problems. However, computing sites must maintain control
over access to the site and site policies generally require individual local
accounts for every user. We present here a model that allows users to register
once with a VO and yet still provides all of the computing sites the
information they require with the required level of trust. We have developed
tools to allow sites to automate the management of local accounts and the
mappings between Grid identities and local accounts."
"This paper presents a prototype for redundant, highly available and fault
tolerant peer to peer framework for data management. Peer to peer computing is
gaining importance due to its flexible organization, lack of central authority,
distribution of functionality to participating nodes and ability to utilize
unused computational resources. Emergence of GRID computing has provided much
needed infrastructure and administrative domain for peer to peer computing. The
components of this framework exploit peer group concept to scope service and
information search, arrange services and information in a coherent manner,
provide selective redundancy and ensure availability in face of failure and
high load conditions. A prototype system has been implemented using JXTA peer
to peer technology and XML is used for service description and interfaces,
allowing peers to communicate with services implemented in various platforms
including web services and JINI services. It utilizes code mobility to achieve
role interchange among services and ensure dynamic group membership. Security
is ensured by using Public Key Infrastructure (PKI) to implement group level
security policies for membership and service access."
"AliEn is a production environment that implements several components of the
Grid paradigm needed to simulate, reconstruct and analyse HEP data in a
distributed way. The system is built around Open Source components, uses the
Web Services model and standard network protocols to implement the computing
platform that is currently being used to produce and analyse Monte Carlo data
at over 30 sites on four continents. The aim of this paper is to present the
current AliEn architecture and outline its future developments in the light of
emerging standards."
"AliEn (ALICE Environment) is a lightweight GRID framework developed by the
Alice Collaboration. When the experiment starts running, it will collect data
at a rate of approximately 2 PB per year, producing O(109) files per year. All
these files, including all simulated events generated during the preparation
phase of the experiment, must be accounted and reliably tracked in the GRID
environment. The backbone of AliEn is a distributed file catalogue, which
associates universal logical file name to physical file names for each dataset
and provides transparent access to datasets independently of physical location.
The file replication and transport is carried out under the control of the File
Transport Broker. In addition, the file catalogue maintains information about
every job running in the system. The jobs are distributed by the Job Resource
Broker that is implemented using a simplified pull (as opposed to traditional
push) architecture. This paper describes the Job and File Transport Resource
Brokers and shows that a similar architecture can be applied to solve both
problems."
"The BaBar experiment at SLAC is in its fourth year of running. The data
processing system has been continuously evolving to meet the challenges of
higher luminosity running and the increasing bulk of data to re-process each
year. To meet these goals a two-pass processing architecture has been adopted,
where 'rolling calibrations' are quickly calculated on a small fraction of the
events in the first pass and the bulk data reconstruction done in the second.
This allows for quick detector feedback in the first pass and allows for the
parallelization of the second pass over two or more separate farms. This
two-pass system allows also for distribution of processing farms off-site. The
first such site has been setup at INFN Padova. The challenges met here were
many. The software was ported to a full Linux-based, commodity hardware system.
The raw dataset, 90 TB, was imported from SLAC utilizing a 155 Mbps network
link. A system for quality control and export of the processed data back to
SLAC was developed. Between SLAC and Padova we are currently running three
pass-one farms, with 32 CPUs each, and nine pass-two farms with 64 to 80 CPUs
each. The pass-two farms can process between 2 and 4 million events per day.
Details about the implementation and performance of the system will be
presented."
"Among the services offered by the AliEn (ALICE Environment
http://alien.cern.ch) Grid framework there is a virtual file catalogue to allow
transparent access to distributed data-sets using various file transfer
protocols. $alienfs$ (AliEn File System) integrates the AliEn file catalogue as
a new file system type into the Linux kernel using LUFS, a hybrid user space
file system framework (Open Source http://lufs.sourceforge.net). LUFS uses a
special kernel interface level called VFS (Virtual File System Switch) to
communicate via a generalised file system interface to the AliEn file system
daemon. The AliEn framework is used for authentication, catalogue browsing,
file registration and read/write transfer operations. A C++ API implements the
generic file system operations. The goal of AliEnFS is to allow users easy
interactive access to a worldwide distributed virtual file system using
familiar shell commands (f.e. cp,ls,rm ...) The paper discusses general aspects
of Grid File Systems, the AliEn implementation and present and future
developments for the AliEn Grid File System."
"In the first phase of the European DataGrid project, the 'workload
management' package (WP1) implemented a working prototype, providing users with
an environment allowing to define and submit jobs to the Grid, and able to find
and use the ``best'' resources for these jobs. Application users have now been
experiencing for about a year now with this first release of the workload
management system. The experiences acquired, the feedback received by the user
and the need to plug new components implementing new functionalities, triggered
an update of the existing architecture. A description of this revised and
complemented workload management system is given."
"When thousands of processors are involved in performing event filtering on a
trigger farm, there is likely to be a large number of failures within the
software and hardware systems. BTeV, a proton/antiproton collider experiment at
Fermi National Accelerator Laboratory, has designed a trigger, which includes
several thousand processors. If fault conditions are not given proper
treatment, it is conceivable that this trigger system will experience failures
at a high enough rate to have a negative impact on its effectiveness. The RTES
(Real Time Embedded Systems) collaboration is a group of physicists, engineers,
and computer scientists working to address the problem of reliability in
large-scale clusters with real-time constraints such as this. Resulting
infrastructure must be highly scalable, verifiable, extensible by users, and
dynamically changeable."
"Every year the PHENIX collaboration deals with increasing volume of data (now
about 1/4 PB/year). Apparently the more data the more questions how to process
all the data in most efficient way. In recent past many developments in HEP
computing were dedicated to the production environment. Now we need more tools
to help to obtain physics results from the analysis of distributed simulated
and experimental data. Developments in Grid architectures gave many examples
how distributed computing facilities can be organized to meet physics analysis
needs. We feel that our main task in this area is to try to use already
developed systems or system components in PHENIX environment.
  We are concentrating here on the followed problems: file/replica catalog
which keep names of our files, data moving over WAN, job submission in
multicluster environment.
  PHENIX is a running experiment and this fact narrowed our ability to test new
software on the collaboration computer facilities. We are experimenting with
system prototypes at State University of New York at Stony Brook (SUNYSB) where
we run midrange computing cluster for physics analysis. The talk is dedicated
to discuss some experience with Grid software and achieved results."
"We present two versions of a grid job submission system produced for the
BaBar experiment. Both use globus job submission to process data spread across
various sites, producing output which can be combined for analysis. The
problems encountered with authorisation and authentication, data location, job
submission, and the input and output sandboxes are described, as are the
solutions. The total system is still some way short of the aims of enterprises
such as the EDG, but represent a significant step along the way."
"Sheer amount of petabyte scale data foreseen in the LHC experiments require a
careful consideration of the persistency design and the system design in the
world-wide distributed computing. Event parallelism of the HENP data analysis
enables us to take maximum advantage of the high performance cluster computing
and networking when we keep the parallelism both in the data processing phase,
in the data management phase, and in the data transfer phase. A modular
architecture of FADS/ Goofy, a versatile detector simulation framework for
Geant4, enables an easy choice of plug-in facilities for persistency
technologies such as Objectivity/DB and ROOT I/O. The framework is designed to
work naturally with the parallel file system of Grid Datafarm (Gfarm).
FADS/Goofy is proven to generate 10^6 Geant4-simulated Atlas Mockup events
using a 512 CPU PC cluster. The data in ROOT I/O files is replicated using
Gfarm file system. The histogram information is collected from the distributed
ROOT files. During the data replication it has been demonstrated to achieve
more than 2.3 Gbps data transfer rate between the PC clusters over seven
participating PC clusters in the United States and in Japan."
"Experiments like ATLAS at LHC involve a scale of computing and data
management that greatly exceeds the capability of existing systems, making it
necessary to resort to Grid-based Parallel Event Processing Systems (GEPS).
Traditional Grid systems concentrate the data in central data servers which
have to be accessed by many nodes each time an analysis or processing job
starts. These systems require very powerful central data servers and make
little use of the distributed disk space that is available in commodity
computers. The Grid-Brick system, which is described in this paper, follows a
different approach. The data storage is split among all grid nodes having each
one a piece of the whole information. Users submit queries and the system will
distribute the tasks through all the nodes and retrieve the result, merging
them together in the Job Submit Server. The main advantage of using this system
is the huge scalability it provides, while its biggest disadvantage appears in
the case of failure of one of the nodes. A workaround for this problem involves
data replication or backup."
"The MonALISA (Monitoring Agents in A Large Integrated Services Architecture)
system provides a distributed monitoring service. MonALISA is based on a
scalable Dynamic Distributed Services Architecture which is designed to meet
the needs of physics collaborations for monitoring global Grid systems, and is
implemented using JINI/JAVA and WSDL/SOAP technologies. The scalability of the
system derives from the use of multithreaded Station Servers to host a variety
of loosely coupled self-describing dynamic services, the ability of each
service to register itself and then to be discovered and used by any other
services, or clients that require such information, and the ability of all
services and clients subscribing to a set of events (state changes) in the
system to be notified automatically. The framework integrates several existing
monitoring tools and procedures to collect parameters describing computational
nodes, applications and network performance. It has built-in SNMP support and
network-performance monitoring algorithms that enable it to monitor end-to-end
network performance as well as the performance and state of site facilities in
a Grid. MonALISA is currently running around the clock on the US CMS test Grid
as well as an increasing number of other sites. It is also being used to
monitor the performance and optimize the interconnections among the reflectors
in the VRVS system."
"In this paper we present a methodology to provide an additional level of
centralized control for the grid resources. This centralized control is applied
to site-wide distribution of various grids and thus providing an upper hand in
the maintenance."
"The Run Control and Monitor System (RCMS) of the CMS experiment is the set of
hardware and software components responsible for controlling and monitoring the
experiment during data-taking. It provides users with a ""virtual counting
room"", enabling them to operate the experiment and to monitor detector status
and data quality from any point in the world. This paper describes the
architecture of the RCMS with particular emphasis on its scalability through a
distributed collection of nodes arranged in a tree-based hierarchy. The current
implementation of the architecture in a prototype RCMS used in test beam
setups, detector validations and DAQ demonstrators is documented. A discussion
of the key technologies used, including Web Services, and the results of tests
performed with a 128-node system are presented."
"Grid technologies aim at enabling a coordinated resource-sharing and
problem-solving capabilities over local and wide area networks and span
locations, organizations, machine architectures and software boundaries. The
heterogeneity of involved resources and the need for interoperability among
different grid middlewares require the sharing of a common information model.
Abstractions of different flavors of resources and services and conceptual
schemas of domain specific entities require a collaboration effort in order to
enable a coherent information services cooperation.
  With this paper, we present the result of our experience in grid resources
and services modelling carried out within the Grid Laboratory Uniform
Environment (GLUE) effort, a joint US and EU High Energy Physics projects
collaboration towards grid interoperability. The first implementation-neutral
agreement on services such as batch computing and storage manager, resources
such as the hierarchy cluster, sub-cluster, host and the storage library are
presented. Design guidelines and operational results are depicted together with
open issues and future evolutions."
"The CDF and D0 experiments probe the high-energy frontier and as they do so
have accumulated hundreds of Terabytes of data on the way to petabytes of data
over the next two years. The experiments have made a commitment to use the
developing Grid based on the SAM system to handle these data. The D0 SAM has
been extended for use in CDF as common patterns of design emerged to meet the
similar requirements of these experiments. The process by which the merger was
achieved is explained with particular emphasis on lessons learned concerning
the database design patterns plus realization of the use cases."
"The D0 experiment is facing many exciting challenges providing a computing
environment for its worldwide collaboration. Transparent access to data for
processing and analysis has been enabled through deployment of its SAM system
to collaborating sites and additional functionality will be provided soon with
SAMGrid components. In order to maximize access to global storage,
computational and intellectual resources, and to enable the system to scale to
the large demands soon to be realized, several strategic sites have been
identified as Regional Analysis Centers (RAC's). These sites play an expanded
role within the system. The philosophy and function of these centers is
discussed and details of their composition and operation are outlined. The plan
for future additional centers is also addressed."
"Grappa is a Grid portal effort designed to provide physicists convenient
access to Grid tools and services. The ATLAS analysis and control framework,
Athena, was used as the target application. Grappa provides basic Grid
functionality such as resource configuration, credential testing, job
submission, job monitoring, results monitoring, and preliminary integration
with the ATLAS replica catalog system, MAGDA. Grappa uses Jython to combine the
ease of scripting with the power of java-based toolkits. This provides a
powerful framework for accessing diverse Grid resources with uniform
interfaces. The initial prototype system was based on the XCAT Science Portal
developed at the Indiana University Extreme Computing Lab and was demonstrated
by running Monte Carlo production on the U.S. ATLAS test-bed. The portal also
communicated with a European resource broker on WorldGrid as part of the joint
iVDGL-DataTAG interoperability project for the IST2002 and SC2002
demonstrations. The current prototype replaces the XCAT Science Portal with an
xbooks jetspeed portlet for managing user scripts."
"We describe some of the key aspects of the SAMGrid system, used by the D0 and
CDF experiments at Fermilab. Having sustained success of the data handling part
of SAMGrid, we have developed new services for job and information services.
Our job management is rooted in \CondorG and uses enhancements that are general
applicability for HEP grids. Our information system is based on a uniform
framework for configuration management based on XML data representation and
processing."
"We describe the construction and results to date of Fermilab's three
Myrinet-networked lattice QCD production clusters (an 80-node dual Pentium III
cluster, a 48-node dual Xeon cluster, and a 128-node dual Xeon cluster). We
examine a number of aspects of performance of the MILC lattice QCD code running
on these clusters."
"Fermilab operates several clusters for lattice gauge computing. Minimal
manpower is available to manage these clusters. We have written a number of
tools and developed techniques to cope with this task. We describe our tools
which use the IPMI facilities of our systems for hardware management tasks such
as remote power control, remote system resets, and health monitoring. We
discuss our techniques involving network booting for installation and upgrades
of the operating system on these computers, and for reloading BIOS and other
firmware. Finally, we discuss our tools for parallel command processing and
their use in monitoring and administrating the PBS batch queue system used on
our clusters."
"The notion of grid computing has gained an increasing popularity recently as
a realistic solution to many of our large-scale data storage and processing
needs. It enables the sharing, selection and aggregation of resources
geographically distributed across collaborative organisations. Now more and
more people are beginning to embrace grid computing and thus are seeing the
need to set up their own grids and grid testbeds. With this comes the need to
have some means to enable them to view and monitor the status of the resources
in these testbeds (eg. Web based Grid portal). Generally developers invest a
substantial amount of time and effort developing custom monitoring software. To
overcome this limitation, this paper proposes Gridscape ? a tool that enables
the rapid creation of interactive and dynamic testbed portals (without any
programming effort). Gridscape primarily aims to provide a solution for those
users who need to be able to create a grid testbed portal but don?t necessarily
have the time or resources to build a system of their own from scratch."
"In this paper, we present XtremWeb, a Global Computing platform used to
generate monte carlos showers in Auger, an HEP experiment to study the highest
energy cosmic rays at Mallargue-Mendoza, Argentina.
  XtremWeb main goal, as a Global Computing platform, is to compute distributed
applications using idle time of widely interconnected machines. It is
especially dedicated to -but not limited to- multi-parameters applications such
as monte carlos computations; its security mechanisms ensuring not only hosts
integrity but also results certification and its fault tolerant features,
encouraged us to test it and, finally, to deploy it as to support our CPU needs
to simulate showers.
  We first introduce Auger computing needs and how Global Computing could help.
We then detail XtremWeb architecture and goals. The fourth and last part
presents the profits we have gained to choose this platform. We conclude on
what could be done next."
"We describe R-GMA (Relational Grid Monitoring Architecture) which has been
developed within the European DataGrid Project as a Grid Information and
Monitoring System. Is is based on the GMA from GGF, which is a simple
Consumer-Producer model. The special strength of this implementation comes from
the power of the relational model. We offer a global view of the information as
if each Virtual Organisation had one large relational database. We provide a
number of different Producer types with different characteristics; for example
some support streaming of information. We also provide combined
Consumer/Producers, which are able to combine information and republish it. At
the heart of the system is the mediator, which for any query is able to find
and connect to the best Producers for the job. We have developed components to
allow a measure of inter-working between MDS and R-GMA. We have used it both
for information about the grid (primarily to find out about what services are
available at any one time) and for application monitoring. R-GMA has been
deployed in various testbeds; we describe some preliminary results and
experiences of this deployment."
"One of the biggest problems in current distributed systems is that presented
by one machine attempting to determine the liveness of another in a timely
manner. Unfortunately, the symptoms exhibited by a failed machine can also be
the result of other causes, e.g., an overloaded machine or network which drops
messages, making it impossible to detect a machine failure with cetainty until
that machine recovers. This is a well understood problem and one which has led
to a large body of research into failure suspectors: since it is not possible
to detect a failure, the best one can do is suspect a failure and program
accordingly. However, one machine's suspicions may not be the same as
another's; therefore, these algorithms spend a considerable effort in ensuring
a consistent view among all available machines of who is suspects of being
failed. This paper describes a thought experiment on how quantum mechanics may
be used to provide a failure detector that is guaranteed to give both accurate
and instantaneous information about the liveness of machines, no matter the
distances involved."
"We consider a connected undirected graph $G(n,m)$ with $n$ nodes and $m$
edges. A $k$-dominating set $D$ in $G$ is a set of nodes having the property
that every node in $G$ is at most $k$ edges away from at least one node in $D$.
Finding a $k$-dominating set of minimum size is NP-hard. We give a new
synchronous distributed algorithm to find a $k$-dominating set in $G$ of size
no greater than $\lfloor n/(k+1)\rfloor$. Our algorithm requires $O(k\log^*n)$
time and $O(m\log k+n\log k\log^*n)$ messages to run. It has the same time
complexity as the best currently known algorithm, but improves on that
algorithm's message complexity and is, in addition, conceptually simpler."
"Matrix clocks are a generalization of the notion of vector clocks that allows
the local representation of causal precedence to reach into an asynchronous
distributed computation's past with depth $x$, where $x\ge 1$ is an integer.
Maintaining matrix clocks correctly in a system of $n$ nodes requires that
everymessage be accompanied by $O(n^x)$ numbers, which reflects an exponential
dependency of the complexity of matrix clocks upon the desired depth $x$. We
introduce a novel type of matrix clock, one that requires only $nx$ numbers to
be attached to each message while maintaining what for many applications may be
the most significant portion of the information that the original matrix clock
carries. In order to illustrate the new clock's applicability, we demonstrate
its use in the monitoring of certain resource-sharing computations."
"The main goal of Fiddle, a distributed debugging engine, is to provide a
flexible platform for developing debugging tools. Fiddle provides a layered set
of interfaces with a minimal set of debugging functionalities, for the
inspection and control of distributed and multi-threaded applications.
  This paper illustrates how Fiddle is used to support integrated testing and
debugging. The approach described is based on a tool, called Deipa, that
interprets sequences of commands read from an input file, generated by an
independent testing tool. Deipa acts as a Fiddle client, in order to enforce
specific execution paths in a distributed PVM program. Other Fiddle clients may
be used along with Deipa for the fine debugging at process level. Fiddle and
Deipa functionalities and architectures are described, and a working example
shows a step-by-step application of these tools."
"The I/O access patterns of many parallel applications consist of accesses to
a large number of small, noncontiguous pieces of data. If an application's I/O
needs are met by making many small, distinct I/O requests, however, the I/O
performance degrades drastically. To avoid this problem, MPI-IO allows users to
access noncontiguous data with a single I/O function call, unlike in Unix I/O.
In this paper, we explain how critical this feature of MPI-IO is for high
performance and how it enables implementations to perform optimizations. We
first provide a classification of the different ways of expressing an
application's I/O needs in MPI-IO--we classify them into four levels, called
level~0 through level~3. We demonstrate that, for applications with
noncontiguous access patterns, the I/O performance improves dramatically if
users write their applications to make level-3 requests (noncontiguous,
collective) rather than level-0 requests (Unix style). We then describe how our
MPI-IO implementation, ROMIO, delivers high performance for noncontiguous
requests. We explain in detail the two key optimizations ROMIO performs: data
sieving for noncontiguous requests from one process and collective I/O for
noncontiguous requests from multiple processes. We describe how we have
implemented these optimizations portably on multiple machines and file systems,
controlled their memory requirements, and also achieved high performance. We
demonstrate the performance and portability with performance results for three
applications--an astrophysics-application template (DIST3D), the NAS BTIO
benchmark, and an unstructured code (UNSTRUC)--on five different parallel
machines: HP Exemplar, IBM SP, Intel Paragon, NEC SX-4, and SGI Origin2000."
"Execution-replay (ER) is well known in the literature but has been restricted
to special system architectures for many years. Improved hardware resources and
the maturity of virtual machine technology promise to make ER useful for a
broader range of development projects.
  This paper describes an approach to create a practical, generic ER
infrastructure for desktop PC systems using virtual machine technology. In the
created VM environment arbitrary application programs will run and be replayed
unmodified, neither instrumentation nor recompilation are required."
"We present an architecture of Globus Toolkit 3 based testbed intended for
evaluation of applicability of the Open Grid Service Architecture (OGSA) for
Data Intensive Applications."
"We present a new approach to monitoring of the execution process of an
application job in the GRID environment. The main point of the approach is use
of GRID ervices to access monitoring information with the security level
available in GRID."
"LCG-1 is the second release of the software framework for the LHC Computing
Grid project. In our work we describe the installation process, arising
problems and their solutions, and configuration tuning details of the complete
LCG-1 site, including all LCG elements required for the self-sufficient site."
"Email has emerged as a dominant form of electronic communication between
people. Spam is a major problem for email users, with estimates of up to 56% of
email falling into that category. Control of Spam is being attempted with
technical and legislative methods. In this paper we look at email and spam from
a supply-demand perspective. We propose Gridemail, an email system based on an
economy of communicating parties, where participants? motivations are
represented as pricing policies and profiles. This system is expected to help
people regulate their personal communications to suit their conditions, and
help in removing unwanted messages."
"In this paper I describe some results on the use of virtual processors
technology for parallelize some SPMD computational programs. The tested
technology is the INTEL Hyper Threading on real processors, and the programs
are MATLAB scripts for floating points computation. The conclusions of the work
concern on the utility and limits of the used approach. The main result is that
using virtual processors is a good technique for improving parallel programs
not only for memory-based computations, but in the case of massive disk-storage
operations too."
"ClassdescMP is a distributed memory parallel programming system for use with
C++ and MPI. It uses the Classdesc reflection system to ease the task of
building complicated messages to be sent between processes. It doesn't hide the
underlying MPI API, so it is an augmentation of MPI capabilities. Users can
still call standard MPI function calls if needed for performance reasons."
"It is shown that, in a precise sense, if there is no bound on the number of
faulty processes in a system with unreliable but fair communication, Uniform
Distributed Coordination (UDC) can be attained if and only if a system has
perfect failure detectors. This result is generalized to the case where there
is a bound t on the number of faulty processes. It is shown that a certain type
of generalized failure detector is necessary and sufficient for achieving UDC
in a context with at most t faulty processes. Reasoning about processes'
knowledge as to which other processes are faulty plays a key role in the
analysis."
"Computational grids that couple geographically distributed resources are
becoming the de-facto computing platform for solving large-scale problems in
science, engineering, and commerce. Software to enable grid computing has been
primarily written for Unix-class operating systems, thus severely limiting the
ability to effectively utilize the computing resources of the vast majority of
desktop computers i.e. those running variants of the Microsoft Windows
operating system. Addressing Windows-based grid computing is particularly
important from the software industry's viewpoint where interest in grids is
emerging rapidly. Microsoft's .NET Framework has become near-ubiquitous for
implementing commercial distributed systems for Windows-based platforms,
positioning it as the ideal platform for grid computing in this context. In
this paper we present Alchemi, a .NET-based grid computing framework that
provides the runtime machinery and programming environment required to
construct desktop grids and develop grid applications. It allows flexible
application composition by supporting an object-oriented grid application
programming model in addition to a grid job model. Cross-platform support is
provided via a web services interface and a flexible execution model supports
dedicated and non-dedicated (voluntary) execution by grid nodes."
"Peer-to-peer (P2P) technologies have been widely used for content sharing,
popularly called ""file-swapping"" networks. This chapter gives a broad overview
of content sharing P2P technologies. It starts with the fundamental concept of
P2P computing followed by the analysis of network topologies used in
peer-to-peer systems. Next, three milestone peer-to-peer technologies: Napster,
Gnutella, and Fasttrack are explored in details, and they are finally concluded
with the comparison table in the last section."
"We describe the present status of the computing system in the Belle
experiment at the KEKB $e^+e^-$ asymmetric-energy collider. So far, we have
logged more than 160 fb$^{-1}$ of data, corresponding to the world's largest
data sample of 170M $B\bar{B}$ pairs at the $\Upsilon(4S)$ energy region. A
large amount of event data has to be processed to produce an analysis event
sample in a timely fashion. In addition, Monte Carlo events have to be created
to control systematic errors accurately. This requires stable and efficient
usage of computing resources. Here we review our computing model and then
describe how we efficiently proceed DST/MC productions in our system."
"The High Level Trigger (HLT) of the future ALICE heavy-ion experiment has to
reduce its input data rate of up to 25 GB/s to at most 1.25 GB/s for output
before the data is written to permanent storage. To cope with these data rates
a large PC cluster system is being designed to scale to several 1000 nodes,
connected by a fast network. For the software that will run on these nodes a
flexible data transport and distribution software framework, described in this
thesis, has been developed. The framework consists of a set of separate
components, that can be connected via a common interface. This allows to
construct different configurations for the HLT, that are even changeable at
runtime. To ensure a fault-tolerant operation of the HLT, the framework
includes a basic fail-over mechanism that allows to replace whole nodes after a
failure. The mechanism will be further expanded in the future, utilizing the
runtime reconnection feature of the framework's component interface. To connect
cluster nodes a communication class library is used that abstracts from the
actual network technology and protocol used to retain flexibility in the
hardware choice. It contains already two working prototype versions for the TCP
protocol as well as SCI network adapters. Extensions can be added to the
library without modifications to other parts of the framework. Extensive tests
and measurements have been performed with the framework. Their results as well
as conclusions drawn from them are also presented in this thesis. Performance
tests show very promising results for the system, indicating that it can
fulfill ALICE's requirements concerning the data transport."
"The material in this note is used as an introduction to distributed
algorithms in a four year course on software and automatic control system in
the computer technology department of the Komsomolsk-on-Amur state technical
university. All our the program examples are written in Borland C/C++ 5.02 for
Windows 95/98/2000/NT/XP, and hence suit to compile and execute by Visual
C/C++. We consider the following approaches of the distributed computing: the
conversion of recursive algorithms to multithread applications, a realization
of the pairing algorithm, the building of wave systems by Petri nets and object
oriented programming."
"Grids aim at exploiting synergies that result from cooperation of autonomous
distributed entities. The synergies that result from grid cooperation include
the sharing, exchange, selection, and aggregation of geographically distributed
resources such as computers, data bases, software, and scientific instruments
for solving large-scale problems in science, engineering, and commerce. For
this cooperation to be sustainable, participants need to have economic
incentive. Therefore, ""incentive"" mechanisms should be considered as one of key
design parameters of Grid architectures. In this article, we present an
overview and status of an open source Grid toolkit, called Gridbus, whose
architecture is fundamentally driven by the requirements of Grid economy.
Gridbus technologies provide services for both computational and data grids
that power the emerging eScience and eBusiness applications."
"The next generation of scientific experiments and studies, popularly called
as e-Science, is carried out by large collaborations of researchers distributed
around the world engaged in analysis of huge collections of data generated by
scientific instruments. Grid computing has emerged as an enabler for e-Science
as it permits the creation of virtual organizations that bring together
communities with common objectives. Within a community, data collections are
stored or replicated on distributed resources to enhance storage capability or
efficiency of access. In such an environment, scientists need to have the
ability to carry out their studies by transparently accessing distributed data
and computational resources. In this paper, we propose and develop a Grid
broker that mediates access to distributed resources by (a) discovering
suitable data sources for a given analysis scenario, (b) suitable computational
resources, (c) optimally mapping analysis jobs to resources, (d) deploying and
monitoring job execution on selected resources, (e) accessing data from local
or remote data source during job execution and (f) collating and presenting
results. The broker supports a declarative and dynamic parametric programming
model for creating grid applications. We have used this model in grid-enabling
a high energy physics analysis application (Belle Analysis Software Framework).
The broker has been used in deploying Belle experiment data analysis jobs on a
grid testbed, called Belle Analysis Data Grid, having resources distributed
across Australia interconnected through GrangeNet."
"We develop a new Lagrangian material particle -- dynamical domain
decomposition method (MPD^3) for large scale parallel molecular dynamics (MD)
simulation of nonstationary heterogeneous systems on a heterogeneous computing
net. MPD^3 is based on Voronoi decomposition of simulated matter. The map of
Voronoi polygons is known as the Dirichlet tessellation and used for grid
generation in computational fluid dynamics. From the hydrodynamics point of
view the moving Voronoi polygon looks as a material particle (MP). MPs can
exchange particles and information. To balance heterogeneous computing
conditions the MP centers should be dependent on timing data. We propose a
simple and efficient iterative algorithm which based on definition of the
timing-dependent balancing displacement of MP center for next simulation step.
  The MPD^3 program was tested in various computing environments and physical
problems. We have demonstrated that MPD^3 is a high-adaptive decomposition
algorithm for MD simulation. It was shown that the well-balanced decomposition
can result from dynamical Voronoi polygon tessellation. One would expect the
similar approach can be successfully applied for other particle methods like
Monte Carlo, particle-in-cell, and smooth-particle-hydrodynamics."
"Grid is an infrastructure that involves the integrated and collaborative use
of computers, networks, databases and scientific instruments owned and managed
by multiple organizations. Grid applications often involve large amounts of
data and/or computing resources that require secure resource sharing across
organizational boundaries. This makes Grid application management and
deployment a complex undertaking. Grid middlewares provide users with seamless
computing ability and uniform access to resources in the heterogeneous Grid
environment. Several software toolkits and systems have been developed, most of
which are results of academic research projects, all over the world. This
chapter will focus on four of these middlewares--UNICORE, Globus, Legion and
Gridbus. It also presents our implementation of a resource broker for UNICORE
as this functionality was not supported in it. A comparison of these systems on
the basis of the architecture, implementation model and several other features
is included."
"The concept of coupling geographically distributed resources for solving
large scale problems is becoming increasingly popular forming what is popularly
called grid computing. Management of resources in the Grid environment becomes
complex as the resources are geographically distributed, heterogeneous in
nature and owned by different individuals and organizations each having their
own resource management policies and different access and cost models. There
have been many projects that have designed and implemented the resource
management systems with a variety of architectures and services. In this paper
we have presented the general requirements that a Resource Management system
should satisfy. The taxonomy has also been defined based on which survey of
resource management systems in different existing Grid projects has been
conducted to identify the key areas where these systems lack the desired
functionality."
"Handheld devices, while growing rapidly, are inherently constrained and lack
the capability of executing resource hungry applications. This paper presents
the design and implementation of distributed analysis and load-balancing system
for hand-held devices using multi-agents system. This system enables low
resource mobile handheld devices to act as potential clients for Grid enabled
applications and analysis environments. We propose a system, in which mobile
agents will transport, schedule, execute and return results for heavy
computational jobs submitted by handheld devices. Moreover, in this way, our
system provides high throughput computing environment for hand-held devices."
This paper was withdrawn by the authors.
"We describe a distributed processing cluster of inexpensive Linux machines
developed jointly by the Astronomy and Computer Science departments at
Haverford College which has been successfully used to search a large volume of
data from a recent radio pulsar survey. Analysis of radio pulsar surveys
requires significant computational resources to handle the demanding data
storage and processing needs. One goal of this project was to explore issues
encountered when processing a large amount of pulsar survey data with limited
computational resources. This cluster, which was developed and activated in
only a few weeks by supervised undergraduate summer research students, used
existing decommissioned computers, the campus network, and a script-based,
client-oriented, self-scheduled data distribution approach to process the data.
This setup provided simplicity, efficiency, and ""on-the-fly"" scalability at low
cost. The entire 570 GB data set from the pulsar survey was processed at
Haverford over the course of a ten-week summer period using this cluster. We
conclude that this cluster can serve as a useful computational model in cases
where data processing must be carried out on a limited budget. We have also
constructed a DVD archive of the raw survey data in order to investigate the
feasibility of using DVD as an inexpensive and easily accessible raw data
storage format for pulsar surveys. DVD-based storage has not been widely
explored in the pulsar community, but it has several advantages. The DVD
archive we have constructed is reliable, portable, inexpensive, and can be
easily read by any standard modern machine."
"Although recent works try to improve collective communication in grid systems
by separating intra and inter-cluster communication, the optimisation of
communications focus only on inter-cluster communications. We believe, instead,
that the overall performance of the application may be improved if
intra-cluster collective communications performance is known in advance. Hence,
it is important to have an accurate model of the intra-cluster collective
communications, which provides the necessary evidences to tune and to predict
their performance correctly. In this paper we present our experience on
modelling such communication strategies. We describe and compare different
implementation strategies with their communication models, evaluating the
models' accuracy and describing the practical challenges that can be found when
modelling collective communications."
"Recently, many works focus on the implementation of collective communication
operations adapted to wide area computational systems, like computational Grids
or global-computing. Due to the inherently heterogeneity of such environments,
most works separate ""clusters"" in different hierarchy levels. to better model
the communication. However, in our opinion, such works do not give enough
attention to the delimitation of such clusters, as they normally use the
locality or the IP subnet from the machines to delimit a cluster without
verifying the ""homogeneity"" of such clusters. In this paper, we describe a
strategy to gather network information from different local-area networks and
to construct ""logical homogeneous clusters"", better suited to the performance
modelling."
"Recent works try to optimise collective communication in grid systems
focusing mostly on the optimisation of communications among different clusters.
We believe that intra-cluster collective communications should also be
optimised, as a way to improve the overall efficiency and to allow the
construction of multi-level collective operations. Indeed, inside homogeneous
clusters, a simple optimisation approach rely on the comparison from different
implementation strategies, through their communication models. In this paper we
evaluate this approach, comparing different implementation strategies with
their predicted performances. As a result, we are able to choose the
communication strategy that better adapts to each network environment."
"The use of under-utilized Internet resources is widely recognized as a viable
form of high performance computing. Sustained processing power of roughly 40T
FLOPS using 4 million volunteered Internet hosts has been reported for
embarrassingly parallel problems. At the same time, peer-to-peer (P2P) file
sharing networks, with more than 50 million participants, have demonstrated the
capacity for scale in distributed systems. This paper contributes a study of
load balancing techniques for a general class of loosely-synchronous parallel
algorithms when executed over a P2P network. We show that decentralized,
diffusive load balancing can be effective at balancing load and is facilitated
by the dynamic properties of P2P. While a moderate degree of dynamicity can
benefit load balancing, significant dynamicity hinders the parallel program
performance due to the need for increased load migration. To the best of our
knowledge this study provides new insight into the performance of
loosely-synchronous parallel programs over the Internet."
"Project SETI@HOME has proven to be one of the biggest successes of
distributed computing during the last years. With a quite simple approach SETI
manages to process large volumes of data using a vast amount of distributed
computer power.
  To extend the generic usage of this kind of distributed computing tools,
BOINC is being developed. In this paper we propose HEP@HOME, a BOINC version
tailored to the specific requirements of the High Energy Physics (HEP)
community.
  The HEP@HOME will be able to process large amounts of data using virtually
unlimited computing power, as BOINC does, and it should be able to work
according to HEP specifications. In HEP the amounts of data to be analyzed or
reconstructed are of central importance. Therefore, one of the design
principles of this tool is to avoid data transfer. This will allow scientists
to run their analysis applications and taking advantage of a large number of
CPUs. This tool also satisfies other important requirements in HEP, namely,
security, fault-tolerance and monitoring."
"We propose a simple distributed hash table called ReCord, which is a
generalized version of Randomized-Chord and offers improved tradeoffs in
performance and topology maintenance over existing P2P systems. ReCord is
scalable and can be easily implemented as an overlay network, and offers a good
tradeoff between the node degree and query latency. For instance, an $n$-node
ReCord with $O(\log n)$ node degree has an expected latency of $\Theta(\log n)$
hops. Alternatively, it can also offer $\Theta(\frac{\log n}{\log \log n})$
hops latency at a higher cost of $O(\frac{\log^2 n}{\log
  \log n})$ node degree. Meanwhile, simulations of the dynamic behaviors of
ReCord are studied."
"Resource sharing within Grid collaborations usually implies specific sharing
mechanisms at participating sites. Challenging policy issues can arise within
virtual organizations (VOs) that integrate participants and resources spanning
multiple physical institutions. Resource owners may wish to grant to one or
more VOs the right to use certain resources subject to local policy and service
level agreements, and each VO may then wish to use those resources subject to
VO policy. Thus, we must address the question of what usage policies (UPs)
should be considered for resource sharing in VOs. As a first step in addressing
this question, we develop and evaluate different UP scenarios within a
specialized context that mimics scientific Grids within which the resources to
be shared are computers. We also present a UP architecture and define roles and
functions for scheduling resources in such grid environments while satisfying
resource owner policies."
"We present a novel framework, called balanced overlay networks (BON), that
provides scalable, decentralized load balancing for distributed computing using
large-scale pools of heterogeneous computers. Fundamentally, BON encodes the
information about each node's available computational resources in the
structure of the links connecting the nodes in the network. This distributed
encoding is self-organized, with each node managing its in-degree and local
connectivity via random-walk sampling. Assignment of incoming jobs to nodes
with the most free resources is also accomplished by sampling the nodes via
short random walks. Extensive simulations show that the resulting highly
dynamic and self-organized graph structure can efficiently balance
computational load throughout large-scale networks. These simulations cover a
wide spectrum of cases, including significant heterogeneity in available
computing resources and high burstiness in incoming load. We provide analytical
results that prove BON's scalability for truly large-scale networks: in
particular we show that under certain ideal conditions, the network structure
converges to Erdos-Renyi (ER) random graphs; our simulation results, however,
show that the algorithm does much better, and the structures seem to approach
the ideal case of d-regular random graphs. We also make a connection between
highly-loaded BONs and the well-known ball-bin randomized load balancing
framework."
"We introduce several notions of reduction in distributed computing, and
investigate reduction properties of two fundamental agreement tasks, namely
Consensus and Atomic Commitment.
  We first propose the notion of reduction ""a la Karp'', an analog for
distributed computing of the classical Karp reduction. We then define a weaker
reduction which is the analog of Cook reduction. These two reductions are
called K-reduction and C-reduction, respectively.
  We also introduce the notion of C*-reduction which has no counterpart in
classical (namely, non distributed) systems, and which naturally arises when
dealing with symmetric tasks.
  We establish various reducibility and irreducibility theorems with respect to
these three reductions. Our main result is an incomparability statement for
Consensus and Atomic Commitment tasks: we show that they are incomparable with
respect to the C-reduction, except when the resiliency degree is 1, in which
case Atomic Commitment is strictly harder than Consensus. A side consequence of
these results is that our notion of C-reduction is strictly weaker than the one
of K-reduction, even for unsolvable tasks."
"We extend the results of Part I by considering a new class of agreement
tasks, the so-called k-Threshold Agreement tasks (previously introduced by
Charron-Bost and Le Fessant). These tasks naturally interpolate between Atomic
Commitment and Consensus. Moreover, they constitute a valuable tool to derive
irreducibility results between Consensus tasks only. In particular, they allow
us to show that (A) for a fixed set of processes, the higher the resiliency
degree is, the harder the Consensus task is, and (B) for a fixed resiliency
degree, the smaller the set of processes is, the harder the Consensus task is.
  The proofs of these results lead us to consider new oracle-based reductions,
involving a weaker variant of the C-reduction introduced in Part I. We also
discuss the relationship between our results and previous ones relating
f-resiliency and wait-freedom."
"Existing attempts at utility computing revolve around two approaches. The
first consists of proprietary solutions involving renting time on dedicated
utility computing machines. The second requires the use of heavy, monolithic
applications that are difficult to deploy, maintain, and use.
  We propose a distributed, community-oriented approach to utility computing.
Our approach provides an infrastructure built on Web Services in which modular
components are combined to create a seemingly simple, yet powerful system. The
community-oriented nature generates an economic environment which results in
fair transactions between consumers and providers of computing cycles while
simultaneously encouraging improvements in the infrastructure of the
computational grid itself."
"Supercomputing systems today often come in the form of large numbers of
commodity systems linked together into a computing cluster. These systems, like
any distributed system, can have large numbers of independent hardware
components cooperating or collaborating on a computation. Unfortunately, any of
this vast number of components can fail at any time, resulting in potentially
erroneous output. In order to improve the robustness of supercomputing
applications in the presence of failures, many techniques have been developed
to provide resilience to these kinds of system faults. This survey provides an
overview of these various fault-tolerance techniques."
"We illustrate the benefits of combining database systems and Grid
technologies for data-intensive applications. Using a cluster of SQL servers,
we reimplemented an existing Grid application that finds galaxy clusters in a
large astronomical database. The SQL implementation runs an order of magnitude
faster than the earlier Tcl-C-file-based implementation. We discuss why and how
Grid applications can take advantage of database systems."
"E-learning can be loosely defined as a wide set of applications and
processes, which uses available electronic media (and tools) to deliver
vocational education and training. With its increasing recognition as an
ubiquitous mode of instruction and interaction in the academic as well as
corporate world, the need for a scaleable and realistic model is becoming
important. In this paper we introduce SELF; a Semantic grid-based E-Learning
Framework. SELF aims to identify the key-enablers in a practical grid-based
E-learning environment and to minimize technological reworking by proposing a
well-defined interaction plan among currently available tools and technologies.
We define a dichotomy with E-learning specific application layers on top and
semantic grid-based support layers underneath. We also map the latest open and
freeware technologies with various components in SELF."
"Localization is one of the fundamental issues in sensor networks. It is
almost always assumed that it must be solved by assigning coordinates to the
nodes. This article discusses positioning algorithms from a theoretical,
practical and simulative point of view, and identifies difficulties and
limitations. Ideas for more abstract means of location awareness are presented
and the resulting possible improvements for applications are shown. Nodes with
certain topological or environmental properties are clustered, and the
neighborhood structure of the clusters is modeled as a graph. Eines der
fundamentalen Probleme in Sensornetzwerken besteht darin, ein Bewusstsein fuer
die Position eines Knotens im Netz zu entwickeln. Dabei wird fast immer davon
ausgegangen, dass dies durch die Zuweisung von Koordinaten zu erfolgen hat. In
diesem Artikel wird auf theoretischer, praktischer und simulativer Ebene ein
kritischer Blick auf entsprechende Verfahren geworfen, und es werden Grenzen
aufgezeigt. Es wird ein Ansatz vorgestellt, mit dem in der Zukunft eine
abstrakte Form von Lokationsbewusstsein etabliert werden kann, und es wird
gezeigt, wie Anwendungen dadurch verbessert werden koennen. Er basiert auf
einer graphenbasierten Modellierung des Netzes: Knoten mit bestimmten
topologischen oder Umwelteigenschaften werden zu Clustern zusammengefasst, und
Clusternachbarschaften dann als Graphen modelliert."
"This paper establishes the state of the art in both deterministic and
randomized online permutation routing in the POPS network. Indeed, we show that
any permutation can be routed online on a POPS network either with
$O(\frac{d}{g}\log g)$ deterministic slots, or, with high probability, with
$5c\lceil d/g\rceil+o(d/g)+O(\log\log g)$ randomized slots, where constant
$c=\exp (1+e^{-1})\approx 3.927$. When $d=\Theta(g)$, that we claim to be the
""interesting"" case, the randomized algorithm is exponentially faster than any
other algorithm in the literature, both deterministic and randomized ones. This
is true in practice as well. Indeed, experiments show that it outperforms its
rivals even starting from as small a network as a POPS(2,2), and the gap grows
exponentially with the size of the network. We can also show that, under proper
hypothesis, no deterministic algorithm can asymptotically match its
performance."
"Des travaux r\'{e}cents visent l'optimisation des op\'{e}rations de
communication collective dans les environnements de type grille de calcul. La
solution la plus r\'{e}pandue est la s\'{e}paration des communications internes
et externes \`{a} chaque grappe, mais cela n'exclut pas le d\'{e}coupage des
communications en plusieurs couches, pratique efficace d\'{e}montr\'{e}e par
Karonis et al. [10]. Dans les deux cas, la pr\'{e}diction des performances est
un facteur essentiel, soit pour le r\'{e}glage fin des param\`{e}tres de
communication, soit pour le calcul de la distribution et de la hi\'{e}rarchie
des communications. Pour cela, il est tr\`{e}s important d'avoir des
mod\`{e}les pr\'{e}cis des communications collectives, lesquels seront
utilis\'{e}s pour pr\'{e}dire ces performances. Cet article d\'{e}crit notre
exp\'{e}rience sur la mod\'{e}lisation des op\'{e}rations de communication
collective. Nous pr\'{e}sentons des mod\`{e}les de communication pour
diff\'{e}rents patrons de communication collective comme un vers plusieurs, un
vers plusieurs personnalis\'{e} et plusieurs vers plusieurs. Pour \'{e}valuer
la pr\'{e}cision des mod\`{e}les, nous comparons les pr\'{e}dictions obtenues
avec les r\'{e}sultats des exp\'{e}rimentations effectu\'{e}es sur deux
environnements r\'{e}seaux diff\'{e}rents, Fast Ethernet et Myrinet."
"With the advent of Grid and application technologies, scientists and
engineers are building more and more complex applications to manage and process
large data sets, and execute scientific experiments on distributed resources.
Such application scenarios require means for composing and executing complex
workflows. Therefore, many efforts have been made towards the development of
workflow management systems for Grid computing. In this paper, we propose a
taxonomy that characterizes and classifies various approaches for building and
executing workflows on Grids. We also survey several representative Grid
workflow systems developed by various projects world-wide to demonstrate the
comprehensiveness of the taxonomy. The taxonomy not only highlights the design
and engineering similarities and differences of state-of-the-art in Grid
workflow systems, but also identifies the areas that need further research."
"This paper introduces a new mechanism for specifying constraints in
distributed workflows. By introducing constraints in a contextual form, it is
shown how different people and groups within collaborative communities can
cooperatively constrain workflows. A comparison with existing state-of-the-art
workflow systems is made. These ideas are explored in practice with an
illustrative example from High Energy Physics."
"Selecting optimal resources for submitting jobs on a computational Grid or
accessing data from a data grid is one of the most important tasks of any Grid
middleware. Most modern Grid software today satisfies this responsibility and
gives a best-effort performance to solve this problem. Almost all decisions
regarding scheduling and data access are made by the software automatically,
giving users little or no control over the entire process. To solve this
problem, a more interactive set of services and middleware is desired that
provides users more information about Grid weather, and gives them more control
over the decision making process. This paper presents a set of services that
have been developed to provide more interactive resource management
capabilities within the Grid Analysis Environment (GAE) being developed
collaboratively by Caltech, NUST and several other institutes. These include a
steering service, a job monitoring service and an estimator service that have
been designed and written using a common Grid-enabled Web Services framework
named Clarens. The paper also presents a performance analysis of the developed
services to show that they have indeed resulted in a more interactive and
powerful system for user-centric Grid-enabled physics analysis."
"Grid based systems require a database access mechanism that can provide
seamless homogeneous access to the requested data through a virtual data access
system, i.e. a system which can take care of tracking the data that is stored
in geographically distributed heterogeneous databases. This system should
provide an integrated view of the data that is stored in the different
repositories by using a virtual data access mechanism, i.e. a mechanism which
can hide the heterogeneity of the backend databases from the client
applications. This paper focuses on accessing data stored in disparate
relational databases through a web service interface, and exploits the features
of a Data Warehouse and Data Marts. We present a middleware that enables
applications to access data stored in geographically distributed relational
databases without being aware of their physical locations and underlying
schema. A web service interface is provided to enable applications to access
this middleware in a language and platform independent way. A prototype
implementation was created based on Clarens [4], Unity [7] and POOL [8]. This
ability to access the data stored in the distributed relational databases
transparently is likely to be a very powerful one for Grid users, especially
the scientific community wishing to collate and analyze data distributed over
the Grid."
"High Energy Physics (HEP) and other scientific communities have adopted
Service Oriented Architectures (SOA) as part of a larger Grid computing effort.
This effort involves the integration of many legacy applications and
programming libraries into a SOA framework. The Grid Analysis Environment (GAE)
is such a service oriented architecture based on the Clarens Grid Services
Framework and is being developed as part of the Compact Muon Solenoid (CMS)
experiment at the Large Hadron Collider (LHC) at European Laboratory for
Particle Physics (CERN). Clarens provides a set of authorization, access
control, and discovery services, as well as XMLRPC and SOAP access to all
deployed services. Two implementations of the Clarens Web Services Framework
(Python and Java) offer integration possibilities for a wide range of
programming languages. This paper describes the Java implementation of the
Clarens Web Services Framework called JClarens. and several web services of
interest to the scientific and Grid community that have been deployed using
JClarens."
"Modern high-performance computing relies heavily on the use of commodity
processors arranged together in clusters. These clusters consist of individual
nodes (typically off-the-shelf single or dual processor machines) connected
together with a high speed interconnect. Using cluster computation has many
benefits, but also carries the liability of being failure prone due to the
sheer number of components involved. Many effective solutions have been
proposed to aid failure recovery in clusters, their one significant downside
being the failure models they support. Most of the work in the area has focused
on detecting and correcting fail-stop errors. We propose a system that will
also detect more general error models, such as Byzantine errors, thus allowing
existing failure recovery methods to handle them correctly."
"In this article we present the design choices and the evaluation of a batch
scheduler for large clusters, named OAR. This batch scheduler is based upon an
original design that emphasizes on low software complexity by using high level
tools. The global architecture is built upon the scripting language Perl and
the relational database engine Mysql. The goal of the project OAR is to prove
that it is possible today to build a complex system for ressource management
using such tools without sacrificing efficiency and scalability. Currently, our
system offers most of the important features implemented by other batch
schedulers such as priority scheduling (by queues), reservations, backfilling
and some global computing support. Despite the use of high level tools, our
experiments show that our system has performances close to other systems.
Furthermore, OAR is currently exploited for the management of 700 nodes (a
metropolitan GRID) and has shown good efficiency and robustness."
"With the current trend of multiprocessor machines towards more and more
hierarchical architectures, exploiting the full computational power requires
careful distribution of execution threads and data so as to limit expensive
remote memory accesses. Existing multi-threaded libraries provide only limited
facilities to let applications express distribution indications, so that
programmers end up with explicitly distributing tasks according to the
underlying architecture, which is difficult and not portable. In this article,
we present: (1) a model for dynamically expressing the structure of the
computation; (2) a scheduler interpreting this model so as to make judicious
hierarchical distribution decisions; (3) an implementation within the Marcel
user-level thread library. We experimented our proposal on a scientific
application running on a ccNUMA Bull NovaScale with 16 Intel Itanium II
processors; results show a 30% gain compared to a classical scheduler, and are
similar to what a handmade scheduler achieves in a non-portable way."
"We propose an algorithm which produces a randomized strategy reaching optimal
data propagation in wireless sensor networks (WSN).In [6] and [8], an energy
balanced solution is sought using an approximation algorithm. Our algorithm
improves by (a) when an energy-balanced solution does not exist, it still finds
an optimal solution (whereas previous algorithms did not consider this case and
provide no useful solution) (b) instead of being an approximation algorithm, it
finds the exact solution in one pass. We also provide a rigorous proof of the
optimality of our solution."
"We advocate in this paper the use of grid-based infrastructures that are
designed for seamless approaches to the numerical expert users, i.e., the
multiphysics applications designers. It relies on sophisticated computing
environments based on computing grids, connecting heterogeneous computing
resources: mainframes, PC-clusters and workstations running multiphysics codes
and utility software, e.g., visualization tools. The approach is based on
concepts defined by the HEAVEN* consortium. HEAVEN is a European scientific
consortium including industrial partners from the aerospace, telecommunication
and software industries, as well as academic research institutes. Currently,
the HEAVEN consortium works on a project that aims to create advanced services
platforms. It is intended to enable ""virtual private grids"" supporting various
environments for users manipulating a suitable high-level interface. This will
become the basis for future generalized services allowing the integration of
various services without the need to deploy specific grid infrastructures."
"We show how recent theoretical advances for data-propagation in Wireless
Sensor Networks (WSNs) can be combined to improve gradient-based routing (GBR)
in Wireless Sensor Networks. We propose a mixed-strategy of direct transmission
and multi-hop propagation of data which improves the lifespan of WSNs by
reaching better energy-load-balancing amongst sensor nodes."
"Wasps, bees, ants and termites all make effective use of their environment
and resources by displaying collective swarm intelligence. Termite colonies -
for instance - build nests with a complexity far beyond the comprehension of
the individual termite, while ant colonies dynamically allocate labor to
various vital tasks such as foraging or defense without any central
decision-making ability. Recent research suggests that microbial life can be
even richer: highly social, intricately networked, and teeming with
interactions, as found in bacteria. What strikes from these observations is
that both ant colonies and bacteria have similar natural mechanisms based on
Stigmergy and Self-Organization in order to emerge coherent and sophisticated
patterns of global behaviour. Keeping in mind the above characteristics we will
present a simple model to tackle the collective adaptation of a social swarm
based on real ant colony behaviors (SSA algorithm) for tracking extrema in
dynamic environments and highly multimodal complex functions described in the
well-know De Jong test suite. Then, for the purpose of comparison, a recent
model of artificial bacterial foraging (BFOA algorithm) based on similar
stigmergic features is described and analyzed. Final results indicate that the
SSA collective intelligence is able to cope and quickly adapt to unforeseen
situations even when over the same cooperative foraging period, the community
is requested to deal with two different and contradictory purposes, while
outperforming BFOA in adaptive speed."
"We explore the feasibility of implementing a reliable, high performance,
distributed storage system on a commodity computing cluster. Files are
distributed across storage nodes using erasure coding with small Low-Density
Parity-Check (LDPC) codes which provide high reliability while keeping the
storage and performance overhead small. We present performance measurements
done on a prototype system comprising 50 nodes which are self organised using a
peer-to-peer overlay."
"This work reports experiences on using radio ranging to position sensors in a
grid topology. The implementation is simple, efficient, and could be
practically distributed. The paper describes an implementation and experimental
result based on RSSI distance estimation. Novel techniques such as fuzzy
membership functions and table lookup are used to obtain more accurate result
and simplify the computation. An 86% accuracy is achieved in the experiment in
spite of inaccurate RSSI distance estimates with errors up to 60%."
"We describe a synchronous distributed algorithm which identifies the
edge-biconnected components of a connected network. It requires a leader, and
uses messages of size O(log |V|). The main idea is to preorder a BFS spanning
tree, and then to efficiently compute least common ancestors so as to mark
cycle edges. This algorithm takes O(Diam) time and uses O(|E|) messages.
Furthermore, we show that no correct singly-initiated edge-biconnectivity
algorithm can beat either bound on any graph by more than a constant factor. We
also describe a near-optimal local algorithm for edge-biconnectivity."
"Results from and progress on the development of a Data Intensive and Network
Aware (DIANA) Scheduling engine, primarily for data intensive sciences such as
physics analysis, are described. Scientific analysis tasks can involve
thousands of computing, data handling, and network resources and the size of
the input and output files and the amount of overall storage space allocated to
a user necessarily can have significant bearing on the scheduling of data
intensive applications. If the input or output files must be retrieved from a
remote location, then the time required transferring the files must also be
taken into consideration when scheduling compute resources for the given
application. The central problem in this study is the coordinated management of
computation and data at multiple locations and not simply data movement.
However, this can be a very costly operation and efficient scheduling can be a
challenge if compute and data resources are mapped without network cost. We
have implemented an adaptive algorithm within the DIANA Scheduler which takes
into account data location and size, network performance and computation
capability to make efficient global scheduling decisions. DIANA is a
performance-aware as well as an economy-guided Meta Scheduler. It iteratively
allocates each job to the site that is likely to produce the best performance
as well as optimizing the global queue for any remaining pending jobs.
Therefore it is equally suitable whether a single job is being submitted or
bulk scheduling is being performed. Results suggest that considerable
performance improvements are to be gained by adopting the DIANA scheduling
approach."
"The MammoGrid project has delivered the first deployed instance of a
healthgrid for clinical mammography that spans national boundaries. During the
last year, the final MammoGrid prototype has undergone a series of rigorous
tests undertaken by radiologists in the UK and Italy and this paper draws
conclusions from those tests for the benefit of the Healthgrid community. In
addition, lessons learned during the lifetime of the project are detailed and
recommendations drawn for future health applications using grids. Following the
completion of the project, plans have been put in place for the
commercialisation of the MammoGrid system and this is also reported in this
article. Particular emphasis is placed on the issues surrounding the transition
from collaborative research project to a marketable product. This paper
concludes by highlighting some of the potential areas of future development and
research."
"There is a compelling demand for the integration and exploitation of
heterogeneous biomedical information for improved clinical practice, medical
research, and personalised healthcare across the EU. The Health-e-Child project
aims at developing an integrated healthcare platform for European Paediatrics,
providing seamless integration of traditional and emerging sources of
biomedical information. The long-term goal of the project is to provide
uninhibited access to universal biomedical knowledge repositories for
personalised and preventive healthcare, large-scale information-based
biomedical research and training, and informed policy making. The project focus
will be on individualised disease prevention, screening, early diagnosis,
therapy and follow-up of paediatric heart diseases, inflammatory diseases, and
brain tumours. The project will build a Grid-enabled European network of
leading clinical centres that will share and annotate biomedical data, validate
systems clinically, and diffuse clinical excellence across Europe by setting up
new technologies, clinical workflows, and standards. This paper outlines the
design approach being adopted in Health-e-Child to enable the delivery of an
integrated biomedical information platform."
"In recent years, many DHT-based P2P systems have been proposed, analyzed, and
certain deployments have reached a global scale with nearly one million nodes.
One is thus faced with the question of which particular DHT system to choose,
and whether some are inherently more robust and scalable.
  Toward developing such a comparative framework, we present the reachable
component method (RCM) for analyzing the performance of different DHT routing
systems subject to random failures. We apply RCM to five DHT systems and obtain
analytical expressions that characterize their routability as a continuous
function of system size and node failure probability. An important consequence
is that in the large-network limit, the routability of certain DHT systems go
to zero for any non-zero probability of node failure. These DHT routing
algorithms are therefore unscalable, while some others, including Kademlia,
which powers the popular eDonkey P2P system, are found to be scalable."
"The efficient exploitation of worldwide distributed storage and computing
resources available in the grids require a robust, transparent and fast
deployment of experiment specific software. The approach followed by the CMS
experiment at CERN in order to enable Monte-Carlo simulations, data analysis
and software development in an international collaboration is presented. The
current status and future improvement plans are described."
"Grid computing has emerged as an effective means of facilitating the sharing
of distributed heterogeneous resources, enabling collaboration in large scale
environments. However, the nature of Grid systems, coupled with the
overabundance and fragmentation of information, makes it difficult to monitor
resources, services, and computations in order to plan and make decisions. In
this paper we present Gridscape II, a customisable portal component that can be
used on its own or plugged in to compliment existing Grid portals. Gridscape II
manages the gathering of information from arbitrary, heterogeneous and
distributed sources and presents them together seamlessly within a single
interface. It also leverages the Google Maps API in order to provide a highly
interactive user interface. Gridscape II is simple and easy to use, providing a
solution to those users who do not wish to invest heavily in developing their
own monitoring portal from scratch, and also for those users who want something
that is easy to customise and extend for their specific needs."
"This chapter focuses on the use of Grid technologies to achieve utility
computing. An overview of how Grids can support utility computing is first
presented through the architecture of Utility Grids. Then, utility-based
resource allocation is described in detail at each level of the architecture.
Finally, some industrial solutions for utility computing are discussed."
"The Service Level Agreement~(SLA) based grid superscheduling approach
promotes coordinated resource sharing. Superscheduling is facilitated between
administratively and topologically distributed grid sites by grid schedulers
such as Resource brokers. In this work, we present a market-based SLA
coordination mechanism. We based our SLA model on a well known \emph{contract
net protocol}.
  The key advantages of our approach are that it allows:~(i) resource owners to
have finer degree of control over the resource allocation that was previously
not possible through traditional mechanism; and (ii) superschedulers to bid for
SLA contracts in the contract net with focus on completing the job within the
user specified deadline. In this work, we use simulation to show the
effectiveness of our proposed approach."
"Research interest in Grid computing has grown significantly over the past
five years. Management of distributed resources is one of the key issues in
Grid computing. Central to management of resources is the effectiveness of
resource allocation as it determines the overall utility of the system. The
current approaches to superscheduling in a grid environment are non-coordinated
since application level schedulers or brokers make scheduling decisions
independently of the others in the system. Clearly, this can exacerbate the
load sharing and utilization problems of distributed resources due to
suboptimal schedules that are likely to occur. To overcome these limitations,
we propose a mechanism for coordinated sharing of distributed clusters based on
computational economy. The resulting environment, called
\emph{Grid-Federation}, allows the transparent use of resources from the
federation when local resources are insufficient to meet its users'
requirements. The use of computational economy methodology in coordinating
resource allocation not only facilitates the QoS based scheduling, but also
enhances utility delivered by resources."
"Let $F$ be a function on pairs of vertices. An {\em $F$- labeling scheme} is
composed of a {\em marker} algorithm for labeling the vertices of a graph with
short labels, coupled with a {\em decoder} algorithm allowing one to compute
$F(u,v)$ of any two vertices $u$ and $v$ directly from their labels. As
applications for labeling schemes concern mainly large and dynamically changing
networks, it is of interest to study {\em distributed dynamic} labeling
schemes. This paper investigates labeling schemes for dynamic trees.
  This paper presents a general method for constructing labeling schemes for
dynamic trees. Our method is based on extending an existing {\em static} tree
labeling scheme to the dynamic setting. This approach fits many natural
functions on trees, such as ancestry relation, routing (in both the adversary
and the designer port models), nearest common ancestor etc.. Our resulting
dynamic schemes incur overheads (over the static scheme) on the label size and
on the communication complexity. Informally, for any function $k(n)$ and any
static $F$-labeling scheme on trees, we present an $F$-labeling scheme on
dynamic trees incurring multiplicative overhead factors
  (over the static scheme) of $O(\log_{k(n)} n)$ on the label size and
$O(k(n)\log_{k(n)} n)$ on the amortized message complexity. In particular, by
setting $k(n)=n^{\epsilon}$ for any $0<\epsilon<1$, we obtain dynamic labeling
schemes with asymptotically optimal label sizes and sublinear amortized message
complexity for all the above mentioned functions."
"The paper is devoted to the problem of mapping affine loop nests onto
distributed memory parallel computers. A method to find affine transformations
of loop nests for parallel execution and distribution of data over processors
is presented. The method tends to minimize the number of communications between
processors and to improve locality of data within one processor. A problem of
determination of data exchange sequence is investigated. Conditions to
determine the ability to arrange broadcast is presented."
"There are several ideas being used today for Web information retrieval, and
specifically in Web search engines. The PageRank algorithm is one of those that
introduce a content-neutral ranking function over Web pages. This ranking is
applied to the set of pages returned by the Google search engine in response to
posting a search query. PageRank is based in part on two simple common sense
concepts: (i)A page is important if many important pages include links to it.
(ii)A page containing many links has reduced impact on the importance of the
pages it links to. In this paper we focus on asynchronous iterative schemes to
compute PageRank over large sets of Web pages. The elimination of the
synchronizing phases is expected to be advantageous on heterogeneous platforms.
The motivation for a possible move to such large scale distributed platforms
lies in the size of matrices representing Web structure. In orders of
magnitude: $10^{10}$ pages with $10^{11}$ nonzero elements and $10^{12}$ bytes
just to store a small percentage of the Web (the already crawled); distributed
memory machines are necessary for such computations. The present research is
part of our general objective, to explore the potential of asynchronous
computational models as an underlying framework for very large scale
computations over the Grid. The area of ``internet algorithmics'' appears to
offer many occasions for computations of unprecedent dimensionality that would
be good candidates for this framework."
"A verification method for distributed systems based on decoupling forward and
backward behaviour is proposed. This method uses an event structure based
algorithm that, given a CCS process, constructs its causal compression relative
to a choice of observable actions. Verifying the original process equipped with
distributed backtracking on non-observable actions, is equivalent to verifying
its relative compression which in general is much smaller. We call this method
Declarative Concurrent Programming (DCP). DCP technique compares well with
direct bisimulation based methods. Benchmarks for the classic dining
philosophers problem show that causal compression is rather efficient both
time- and space-wise. State of the art verification tools can successfully
handle more than 15 agents, whereas they can handle no more than 5 following
the traditional direct method; an altogether spectacular improvement, since in
this example the specification size is exponential in the number of agents."
"Grid computing has made substantial advances during the last decade. Grid
middleware such as Globus has contributed greatly in making this possible.
There are, however, significant barriers to the adoption of Grid computing in
other fields, most notably day-to-day user computing environments. We will
demonstrate in this paper that this is primarily due to the limitations of the
existing Grid middleware which does not take into account the needs of everyday
scientific and business users. In this paper we will formally advocate a Grid
Operating System and propose an architecture to migrate Grid computing into a
Grid operating system which we believe would help remove most of the technical
barriers to the adoption of Grid computing and make it relevant to the
day-to-day user. We believe this proposed transition to a Grid operating system
will drive more pervasive Grid computing research and application development
and deployment in future."
"This paper presents an overview of the MammoGrid project and some of its
achievements. In terms of the global grid project, and European research in
particular, the project has successfully demonstrated the capacity of a
grid-based system to support effective collaboration between physicians,
including handling and querying image databases, as well as using grid
services, such as image standardization and Computer-Aided Detection (CADe) of
suspect or indicative features. In terms of scientific results, in radiology,
there have been significant epidemiological findings in the assessment of
breast density as a risk factor, but the results for CADe are less clear-cut.
Finally, the foundations of a technology transfer process to establish a
working MammoGrid plus system in Spain through the company Maat GKnowledge and
the collaboration of CIEMAT and hospitals in Extremadura."
"Results from the research and development of a Data Intensive and Network
Aware (DIANA) scheduling engine, to be used primarily for data intensive
sciences such as physics analysis, are described. In Grid analyses, tasks can
involve thousands of computing, data handling, and network resources. The
central problem in the scheduling of these resources is the coordinated
management of computation and data at multiple locations and not just data
replication or movement. However, this can prove to be a rather costly
operation and efficient sing can be a challenge if compute and data resources
are mapped without considering network costs. We have implemented an adaptive
algorithm within the so-called DIANA Scheduler which takes into account data
location and size, network performance and computation capability in order to
enable efficient global scheduling. DIANA is a performance-aware and
economy-guided Meta Scheduler. It iteratively allocates each job to the site
that is most likely to produce the best performance as well as optimizing the
global queue for any remaining jobs. Therefore it is equally suitable whether a
single job is being submitted or bulk scheduling is being performed. Results
indicate that considerable performance improvements can be gained by adopting
the DIANA scheduling approach."
"The ``Pulse Synchronization'' problem can be loosely described as targeting
to invoke a recurring distributed event as simultaneously as possible at the
different nodes and with a frequency that is as regular as possible. This
target becomes surprisingly subtle and difficult to achieve when facing both
transient and permanent failures. In this paper we present an algorithm for
pulse synchronization that self-stabilizes while at the same time tolerating a
permanent presence of Byzantine faults. The Byzantine nodes might incessantly
try to de-synchronize the correct nodes. Transient failures might throw the
system into an arbitrary state in which correct nodes have no common notion
what-so-ever, such as time or round numbers, and can thus not infer anything
from their own local states upon the state of other correct nodes. The
presented algorithm grants nodes the ability to infer that eventually all
correct nodes will invoke their pulses within a very short time interval of
each other and will do so regularly.
  Pulse synchronization has previously been shown to be a powerful tool for
designing general self-stabilizing Byzantine algorithms and is hitherto the
only method that provides for the general design of efficient practical
protocols in the confluence of these two fault models. The difficulty, in
general, to design any algorithm in this fault model may be indicated by the
remarkably few algorithms resilient to both fault models. The few published
self-stabilizing Byzantine algorithms are typically complicated and sometimes
converge from an arbitrary initial state only after exponential or super
exponential time."
"Clock synchronization is a very fundamental task in distributed system. It
thus makes sense to require an underlying clock synchronization mechanism to be
highly fault-tolerant. A self-stabilizing algorithm seeks to attain
synchronization once lost; a Byzantine algorithm assumes synchronization is
never lost and focuses on containing the influence of the permanent presence of
faulty nodes. There are efficient self-stabilizing solutions for clock
synchronization as well as efficient solutions that are resilient to Byzantine
faults. In contrast, to the best of our knowledge there is no practical
solution that is self-stabilizing while tolerating the permanent presence of
Byzantine nodes. We present the first linear-time self-stabilizing Byzantine
clock synchronization algorithm. Our deterministic clock synchronization
algorithm is based on the observation that all clock synchronization algorithms
require events for exchanging clock values and re-synchronizing the clocks to
within safe bounds. These events usually need to happen synchronously at the
different nodes. In classic Byzantine algorithms this is fulfilled or aided by
having the clocks initially close to each other and thus the actual clock
values can be used for synchronizing the events. This implies that clock values
cannot differ arbitrarily, which necessarily renders these solutions to be
non-stabilizing. Our scheme suggests using an underlying distributed pulse
synchronization module that is uncorrelated to the clock values."
"During the last decade there has been a huge interest in Grid technologies,
and numerous Grid projects have been initiated with various visions of the
Grid. While all these visions have the same goal of resource sharing, they
differ in the functionality that a Grid supports, the grid characterisation,
programming environments, etc. In this paper we present a new Grid system
dedicated to deal with data issues, called DGET (Data Grid Environment and
Tools). DGET is characterized by its peer-to-peer communication system and
entity-based architecture, therefore, taking advantage of the main
functionality of both systems; P2P and Grid. DGET is currently under
development and a prototype implementing the main components is in its first
phase of testing. In this paper we limit our description to the system
architectural features and to the main differences with other systems."
"During the last decade there has been a huge interest in Grid technologies,
and numerous Grid projects have been initiated with various visions of the
Grid. While all these visions have the same goal of resource sharing, they
differ in the functionality that a Grid supports, characterization, programming
environments, etc. We present a new Grid system dedicated to dealing with data
issues, called DGET (Data Grid Environment and Tools). DGET is characterized by
its peerto- peer communication system and entity-based architecture, therefore,
taking advantage of the main functionality of both systems; P2P and Grid. DGET
is currently under development and a prototype implementing the main components
is in its first phase of testing. In this paper we limit our description to the
system architectural features and to the main differences with other systems.
Keywords: Grid Computing, Peer to Peer, Peer to Peer Grid"
"Grid environments have recently been developed with low stretch and overheads
that increase with the logarithm of the number of nodes in the system. Getting
and sending data to/from a large numbers of nodes is gaining importance due to
an increasing number of independent data providers and the heterogeneity of the
network/Grid. One of the key challenges is to achieve a balance between low
bandwidth consumption and good reliability. In this paper we present an
implementation of a reliable multicast protocol over a fault tolerant MPI:
MPICHV2. It can provide one way to solve the problem of transferring large
chunks of data between applications running on a grid with limited network
links. We first show that we can achieve similar performance as the MPICH-P4
implementation by using multicast with data compression in a cluster. Next, we
provide a theoretical cluster organization and GRID network architecture to
harness the performance provided by using multicast. Finally, we present the
conclusion and future work."
"Grid computing has enabled pooling a very large number of heterogeneous
resource administered by different security domains. Applications are
dynamically deployed on the resources available at the time. Dynamic nature of
the resources and applications requirements makes needs the grid middleware to
support the ability of migrating a running application to a different resource.
Especially, Grid applications are typically long running and thus stoping them
and starting them from scratch is not a feasible option. This paper presents an
overview of migration support in a java based grid middleware called DGET.
Migration support in DGET includes multi-threaded migration and asynchronous
migration as well."
"In this paper we proposed a hierarchical P2P network based on a dynamic
partitioning on a 1-D space. This hierarchy is created and maintained
dynamically and provides a gridmiddleware (like DGET) a P2P basic functionality
for resource discovery and load-balancing.This network architecture is called
TreeP (Tree based P2P network architecture) and is based on atessellation of a
1-D space. We show that this topology exploits in an efficient way
theheterogeneity feature of the network while limiting the overhead introduced
by the overlaymaintenance. Experimental results show that this topology is
highly resilient to a large number ofnetwork failures."
"The proliferation of Content Delivery Networks (CDN) reveals that existing
content networks are owned and operated by individual companies. As a
consequence, closed delivery networks are evolved which do not cooperate with
other CDNs and in practice, islands of CDNs are formed. Moreover, the logical
separation between contents and services in this context results in two content
networking domains. But present trends in content networks and content
networking capabilities give rise to the interest in interconnecting content
networks. Finding ways for distinct content networks to coordinate and
cooperate with other content networks is necessary for better overall service.
In addition to that, meeting the QoS requirements of users according to the
negotiated Service Level Agreements between the user and the content network is
a burning issue in this perspective. In this article, we present an open,
scalable and Service-Oriented Architecture based system to assist the creation
of open Content and Service Delivery Networks (CSDN) that scale and support
sharing of resources with other CSDNs."
"We study the question of ``how robust are the known lower bounds of labeling
schemes when one increases the number of consulted labels''. Let $f$ be a
function on pairs of vertices. An $f$-labeling scheme for a family of graphs
$\cF$ labels the vertices of all graphs in $\cF$ such that for every graph
$G\in\cF$ and every two vertices $u,v\in G$, the value $f(u,v)$ can be inferred
by merely inspecting the labels of $u$ and $v$.
  This paper introduces a natural generalization: the notion of $f$-labeling
schemes with queries, in which the value $f(u,v)$ can be inferred by inspecting
not only the labels of $u$ and $v$ but possibly the labels of some additional
vertices. We show that inspecting the label of a single additional vertex (one
{\em query}) enables us to reduce the label size of many labeling schemes
significantly."
"In this work we are interested in the problem of scheduling and
redistributing data on master-slave platforms. We consider the case were the
workers possess initial loads, some of which having to be redistributed in
order to balance their completion times. We examine two different scenarios.
The first model assumes that the data consists of independent and identical
tasks. We prove the NP-completeness in the strong sense for the general case,
and we present two optimal algorithms for special platform types. Furthermore
we propose three heuristics for the general case. Simulations consolidate the
theoretical results. The second data model is based on Divisible Load Theory.
This problem can be solved in polynomial time by a combination of linear
programming and simple analytical manipulations."
"In this paper, we discuss and compare several policies to place replicas in
tree networks, subject to server capacity and QoS constraints. The client
requests are known beforehand, while the number and location of the servers are
to be determined. The standard approach in the literature is to enforce that
all requests of a client be served by the closest server in the tree. We
introduce and study two new policies. In the first policy, all requests from a
given client are still processed by the same server, but this server can be
located anywhere in the path from the client to the root. In the second policy,
the requests of a given client can be processed by multiple servers. One major
contribution of this paper is to assess the impact of these new policies on the
total replication cost. Another important goal is to assess the impact of
server heterogeneity, both from a theoretical and a practical perspective. In
this paper, we establish several new complexity results, and provide several
efficient polynomial heuristics for NP-complete instances of the problem. These
heuristics are compared to an absolute lower bound provided by the formulation
of the problem in terms of the solution of an integer linear program."
"The actor model eases the definition of concurrent programs with non uniform
behaviors. Static analysis of such a model was previously done in a data-flow
oriented way, with type systems. This approach was based on constraint set
resolution and was not able to deal with precise properties for communications
of behaviors. We present here a new approach, control-flow oriented, based on
the abstract interpretation framework, able to deal with communication of
behaviors. Within our new analyses, we are able to verify most of the previous
properties we observed as well as new ones, principally based on occurrence
counting."
"Asynchronous executions of a distributed algorithm differ from each other due
to the nondeterminism in the order in which the messages exchanged are handled.
In many situations of interest, the asynchronous executions induced by
restricting nondeterminism are more efficient, in an application-specific
sense, than the others. In this work, we define partially ordered executions of
a distributed algorithm as the executions satisfying some restricted orders of
their actions in two different frameworks, those of the so-called event- and
pulse-driven computations. The aim of these restrictions is to characterize
asynchronous executions that are likely to be more efficient for some important
classes of applications. Also, an asynchronous algorithm that ensures the
occurrence of partially ordered executions is given for each case. Two of the
applications that we believe may benefit from the restricted nondeterminism are
backtrack search, in the event-driven case, and iterative algorithms for
systems of linear equations, in the pulse-driven case."
"Existing Content Delivery Networks (CDNs) exhibit the nature of closed
delivery networks which do not cooperate with other CDNs and in practice,
islands of CDNs are formed. The logical separation between contents and
services in this context results in two content networking domains. In addition
to that, meeting the Quality of Service requirements of users according to
negotiated Service Level Agreement is crucial for a CDN. Present trends in
content networks and content networking capabilities give rise to the interest
in interconnecting content networks. Hence, in this paper, we present an open,
scalable, and Service-Oriented Architecture (SOA)-based system that assist the
creation of open Content and Service Delivery Networks (CSDNs), which scale and
supports sharing of resources through peering with other CSDNs. To encourage
resource sharing and peering arrangements between different CDN providers at
global level, we propose using market-based models by introducing an
economy-based strategy for content replication."
"Entry in: Encyclopedia of Algorithms, Ming-Yang Kao, Ed., Springer, To
appear.
  Synonyms: Wait-free registers, wait-free shared variables, asynchronous
communication hardware. Problem Definition: Consider a system of asynchronous
processes that communicate among themselves by only executing read and write
operations on a set of shared variables (also known as shared registers). The
system has no global clock or other synchronization primitives."
"Peer to peer (P2P) systems are moving from application specific architectures
to a generic service oriented design philosophy. This raises interesting
problems in connection with providing useful P2P middleware services that are
capable of dealing with resource assignment and management in a large-scale,
heterogeneous and unreliable environment. One such service, the slicing
service, has been proposed to allow for an automatic partitioning of P2P
networks into groups (slices) that represent a controllable amount of some
resource and that are also relatively homogeneous with respect to that
resource, in the face of churn and other failures. In this report we propose
two algorithms to solve the distributed slicing problem. The first algorithm
improves upon an existing algorithm that is based on gossip-based sorting of a
set of uniform random numbers. We speed up convergence via a heuristic for
gossip peer selection. The second algorithm is based on a different approach:
statistical approximation of the rank of nodes in the ordering. The
scalability, efficiency and resilience to dynamics of both algorithms relies on
their gossip-based models. We present theoretical and experimental results to
prove the viability of these algorithms."
"The continuous increase in performance requirements, for both scientific
computation and industry, motivates the need of a powerful computing
infrastructure. The Grid appeared as a solution for inexpensive execution of
heavy applications in a parallel and distributed manner. It allows combining
resources independently of their physical location and architecture to form a
global resource pool available to all grid users. However, grid environments
are highly unstable and unpredictable. Adaptability is a crucial issue in this
context, in order to guarantee an appropriate quality of service to users.
Migration is a technique frequently used for achieving adaptation. The
objective of this report is to survey the problem of strong migration in
heterogeneous environments like the grids', the related implementation issues
and the current solutions."
"We consider the problem of failure detection in dynamic networks such as
MANETs. Unreliable failure detectors are classical mechanisms which provide
information about process failures. However, most of current implementations
consider that the network is fully connected and that the initial number of
nodes of the system is known. This assumption is not applicable to dynamic
environments. Furthermore, such implementations are usually timer-based while
in dynamic networks there is no upper bound for communication delays since
nodes can move. This paper presents an asynchronous implementation of a failure
detector for unknown and mobile networks. Our approach does not rely on timers
and neither the composition nor the number of nodes in the system are known. We
prove that our algorithm can implement failure detectors of class <>S when
behavioral properties and connectivity conditions are satisfied by the
underlying system."
"A semantic framework for analyzing safe composition of distributed programs
is presented. Its applicability is illustrated by a study of program
composition when communication is reliable but not necessarily FIFO\@. In this
model, special care must be taken to ensure that messages do not accidentally
overtake one another in the composed program. We show that barriers do not
exist in this model. Indeed, no program that sends or receives messages can
automatically be composed with arbitrary programs without jeopardizing their
intended behavior. Safety of composition becomes context-sensitive and new
tools are needed for ensuring it. A notion of \emph{sealing} is defined, where
if a program $P$ is immediately followed by a program $Q$ that seals $P$ then
$P$ will be communication-closed--it will execute as if it runs in isolation.
The investigation of sealing in this model reveals a novel connection between
Lamport causality and safe composition. A characterization of sealable programs
is given, as well as efficient algorithms for testing if $Q$ seals $P$ and for
constructing a seal for a significant class of programs. It is shown that every
sealable program that is open to interference on $O(n^2)$ channels can be
sealed using O(n) messages."
"All practical applications contain some degree of nondeterminism. When such
applications are replicated to achieve Byzantine fault tolerance (BFT), their
nondeterministic operations must be controlled to ensure replica consistency.
To the best of our knowledge, only the most simplistic types of replica
nondeterminism have been dealt with. Furthermore, there lacks a systematic
approach to handling common types of nondeterminism. In this paper, we propose
a classification of common types of replica nondeterminism with respect to the
requirement of achieving Byzantine fault tolerance, and describe the design and
implementation of the core mechanisms necessary to handle such nondeterminism
within a Byzantine fault tolerance framework."
"In this paper, we first formalize the problem to be solved, i.e., the Scatter
Problem (SP). We then show that SP cannot be deterministically solved. Next, we
propose a randomized algorithm for this problem. The proposed solution is
trivially self-stabilizing. We then show how to design a self-stabilizing
version of any deterministic solution for the Pattern Formation and the
Gathering problems."
"Min, Veeravalli, and Barlas proposed strategies to minimize the overall
execution time of one or several divisible loads on a heterogeneous linear
network, using one or more installments. We show on a very simple example that
the proposed approach does not always produce a solution and that, when it
does, the solution is often suboptimal. We also show how to find an optimal
scheduling for any instance, once the number of installments per load is given.
Finally, we formally prove that under a linear cost model, as in the original
paper, an optimal schedule has an infinite number of installments. Such a cost
model can therefore not be sed to design practical multi-installment
strategies."
"To fully harness Grids, users or middlewares must have some knowledge on the
topology of the platform interconnection network. As such knowledge is usually
not available, one must uses tools which automatically build a topological
network model through some measurements. In this article, we define a
methodology to assess the quality of these network model building tools, and we
apply this methodology to representatives of the main classes of model builders
and to two new algorithms. We show that none of the main existing techniques
build models that enable to accurately predict the running time of simple
application kernels for actual platforms. However some of the new algorithms we
propose give excellent results in a wide range of situations."
"A mobile agent in a network wants to visit every node of an n-node network,
using a small number of steps. We investigate the performance of the following
``nearest neighbor'' heuristic: always go to the nearest unvisited node. If the
network graph never changes, then from (Rosenkrantz, Stearns and Lewis, 1977)
and (Hurkens and Woeginger, 2004) it follows that Theta(n log n) steps are
necessary and sufficient in the worst case. We give a simpler proof of the
upper bound and an example that improves the best known lower bound.
  We investigate how the performance of this heuristic changes when it is
distributively implemented in a network. Even if network edges are allow to
fail over time, we show that the nearest neighbor strategy never runs for more
than O(n^2) iterations. We also show that any strategy can be forced to take at
least n(n-1)/2 steps before all nodes are visited, if the edges of the network
are deleted in an adversarial way."
"Geographic routing is becoming the protocol of choice for many sensor network
applications. The current state of the art is unsatisfactory: some algorithms
are very efficient, however they require a preliminary planarization of the
communication graph. Planarization induces overhead and is not realistic in
many scenarios. On the otherhand, georouting algorithms which do not rely on
planarization have fairly low success rates and either fail to route messages
around all but the simplest obstacles or have a high topology control overhead
(e.g. contour detection algorithms). To overcome these limitations, we propose
GRIC, the first lightweight and efficient on demand (i.e. all-to-all)
geographic routing algorithm which does not require planarization and has
almost 100% delivery rates (when no obstacles are added). Furthermore, the
excellent behavior of our algorithm is maintained even in the presence of large
convex obstacles. The case of hard concave obstacles is also studied; such
obstacles are hard instances for which performance diminishes."
"In this paper, we introduce a new user-level DSM system which has the ability
to directly interact with underlying interconnection networks. The DSM system
provides the application programmer a flexible API to program parallel
applications either using shared memory semantics over physically distributed
memory or to use an efficient remote memory demand paging technique. We also
introduce a new time slice based memory consistency protocol which is used by
the DSM system. We present preliminary results from our implementation on a
small Opteron Linux cluster interconnected over Myrinet."
"Gossipping has demonstrate to be an efficient mechanism for spreading
information among P2P networks. Within the context of P2P computing, we propose
the so-called Evolvable Agent Model for distributed population-based algorithms
which uses gossipping as communication policy, and represents every individual
as a self-scheduled single thread. The model avoids obsolete nodes in the
population by defining a self-adaptive refresh rate which depends on the
latency and bandwidth of the network. Such a mechanism balances the migration
rate to the congestion of the links pursuing global population coherence. We
perform an experimental evaluation of this model on a real parallel system and
observe how solution quality and algorithm speed scale with the number of
processors with this seamless approach."
"This paper studies the problem of broadcasting in synchronous point-to-point
networks, where one initiator owns a piece of information that has to be
transmitted to all other vertices as fast as possible. The model of fractional
dynamic faults with threshold is considered: in every step either a fixed
number $T$, or a fraction $\alpha$, of sent messages can be lost depending on
which quantity is larger.
  As the main result we show that in complete graphs and hypercubes it is
possible to inform all but a constant number of vertices, exhibiting only a
logarithmic slowdown, i.e. in time $O(D\log n)$ where $D$ is the diameter of
the network and $n$ is the number of vertices.
  Moreover, for complete graphs under some additional conditions (sense of
direction, or $\alpha<0.55$) the remaining constant number of vertices can be
informed in the same time, i.e. $O(\log n)$."
"Applications in science and engineering often require huge computational
resources for solving problems within a reasonable time frame. Parallel
supercomputers provide the computational infrastructure for solving such
problems. A traditional application scheduler running on a parallel cluster
only supports static scheduling where the number of processors allocated to an
application remains fixed throughout the lifetime of execution of the job. Due
to the unpredictability in job arrival times and varying resource requirements,
static scheduling can result in idle system resources thereby decreasing the
overall system throughput. In this paper we present a prototype framework
called ReSHAPE, which supports dynamic resizing of parallel MPI applications
executed on distributed memory platforms. The framework includes a scheduler
that supports resizing of applications, an API to enable applications to
interact with the scheduler, and a library that makes resizing viable.
Applications executed using the ReSHAPE scheduler framework can expand to take
advantage of additional free processors or can shrink to accommodate a high
priority application, without getting suspended. In our research, we have
mainly focused on structured applications that have two-dimensional data arrays
distributed across a two-dimensional processor grid. The resize library
includes algorithms for processor selection and processor mapping. Experimental
results show that the ReSHAPE framework can improve individual job turn-around
time and overall system throughput."
"This paper analyses the possibilities of performing parallel
transaction-oriented simulations with a special focus on the space-parallel
approach and discrete event simulation synchronisation algorithms that are
suitable for transaction-oriented simulation and the target environment of Ad
Hoc Grids. To demonstrate the findings a Java-based parallel
transaction-oriented simulator for the simulation language GPSS/H is
implemented on the basis of the promising Shock Resistant Time Warp
synchronisation algorithm and using the Grid framework ProActive. The
validation of this parallel simulator shows that the Shock Resistant Time Warp
algorithm can successfully reduce the number of rolled back Transaction moves
but it also reveals circumstances in which the Shock Resistant Time Warp
algorithm can be outperformed by the normal Time Warp algorithm. The conclusion
of this paper suggests possible improvements to the Shock Resistant Time Warp
algorithm to avoid such problems."
"A finite element method is presented to compute time harmonic microwave
fields in three dimensional configurations. Nodal-based finite elements have
been coupled with an absorbing boundary condition to solve open boundary
problems. This paper describes how the modeling of large devices has been made
possible using parallel computation, New algorithms are then proposed to
implement this formulation on a cluster of workstations (10 DEC ALPHA 300X) and
on a CRAY C98. Analysis of the computation efficiency is performed using simple
problems. The electromagnetic scattering of a plane wave by a perfect electric
conducting airplane is finally given as example."
"We address the problem of &#64257;nding nice labellings for event structures
of degree 3. We develop a minimum theory by which we prove that the labelling
number of an event structure of degree 3 is bounded by a linear function of the
height. The main theorem we present in this paper states that event structures
of degree 3 whose causality order is a tree have a nice labelling with 3
colors. Finally, we exemplify how to use this theorem to construct upper bounds
for the labelling number of other event structures of degree 3."
"We introduce a distributed algorithm for clock synchronization in sensor
networks. Our algorithm assumes that nodes in the network only know their
immediate neighborhoods and an upper bound on the network's diameter.
Clock-synchronization messages are only sent as part of the communication,
assumed reasonably frequent, that already takes place among nodes. The
algorithm has the gradient property of [2], achieving an O(1) worst-case skew
between the logical clocks of neighbors. As in the case of [3,8], the
algorithm's actions are such that no constant lower bound exists on the rate at
which logical clocks progress in time, and for this reason the lower bound of
[2,5] that forbids constant skew between neighbors does not apply."
"Exploiting full computational power of current more and more hierarchical
multiprocessor machines requires a very careful distribution of threads and
data among the underlying non-uniform architecture. Unfortunately, most
operating systems only provide a poor scheduling API that does not allow
applications to transmit valuable scheduling hints to the system. In a previous
paper, we showed that using a bubble-based thread scheduler can significantly
improve applications' performance in a portable way. However, since
multithreaded applications have various scheduling requirements, there is no
universal scheduler that could meet all these needs. In this paper, we present
a framework that allows scheduling experts to implement and experiment with
customized thread schedulers. It provides a powerful API for dynamically
distributing bubbles among the machine in a high-level, portable, and efficient
way. Several examples show how experts can then develop, debug and tune their
own portable bubble schedulers."
"Traditional parallel schedulers running on cluster supercomputers support
only static scheduling, where the number of processors allocated to an
application remains fixed throughout the execution of the job. This results in
under-utilization of idle system resources thereby decreasing overall system
throughput. In our research, we have developed a prototype framework called
ReSHAPE, which supports dynamic resizing of parallel MPI applications executing
on distributed memory platforms. The resizing library in ReSHAPE includes
support for releasing and acquiring processors and efficiently redistributing
application state to a new set of processors. In this paper, we derive an
algorithm for redistributing two-dimensional block-cyclic arrays from $P$ to
$Q$ processors, organized as 2-D processor grids. The algorithm ensures a
contention-free communication schedule for data redistribution if $P_r \leq
Q_r$ and $P_c \leq Q_c$. In other cases, the algorithm implements circular row
and column shifts on the communication schedule to minimize node contention."
"Deployment of distributed applications on large systems, and especially on
grid infrastructures, becomes a more and more complex task. Grid users spend a
lot of time to prepare, install and configure middleware and application
binaries on nodes, and eventually start their applications. The problem is that
the deployment process is composed of many heterogeneous tasks that have to be
orchestrated in a specific correct order. As a consequence, the automatization
of the deployment process is currently very difficult to reach. To address this
problem, we propose in this paper a generic deployment framework allowing to
automatize the execution of heterogeneous tasks composing the whole deployment
process. Our approach is based on a reification as software components of all
required deployment mechanisms or existing tools. Grid users only have to
describe the configuration to deploy in a simple natural language instead of
programming or scripting how the deployment process is executed. As a toy
example, this framework is used to deploy CORBA component-based applications
and OpenCCM middleware on one thousand nodes of the French Grid5000
infrastructure."
"This paper deals with the replica placement problem on fully homogeneous tree
networks known as the Replica Placement optimization problem. The client
requests are known beforehand, while the number and location of the servers are
to be determined. We investigate the latter problem using the Closest access
policy when adding QoS and bandwidth constraints. We propose an optimal
algorithm in two passes using dynamic programming."
"Checkpointing is an indispensable technique to provide fault tolerance for
long-running high-throughput applications like those running on desktop grids.
This paper argues that a dedicated checkpoint storage system, optimized to
operate in these environments, can offer multiple benefits: reduce the load on
a traditional file system, offer high-performance through specialization, and,
finally, optimize data management by taking into account checkpoint application
semantics. Such a storage system can present a unifying abstraction to
checkpoint operations, while hiding the fact that there are no dedicated
resources to store the checkpoint data. We prototype stdchk, a checkpoint
storage system that uses scavenged disk space from participating desktops to
build a low-cost storage system, offering a traditional file system interface
for easy integration with applications. This paper presents the stdchk
architecture, key performance optimizations, support for incremental
checkpointing, and increased data availability. Our evaluation confirms that
the stdchk approach is viable in a desktop grid setting and offers a low cost
storage system with desirable performance characteristics: high write
throughput and reduced storage space and network effort to save checkpoint
images."
"Mapping workflow applications onto parallel platforms is a challenging
problem, even for simple application patterns such as pipeline graphs. Several
antagonist criteria should be optimized, such as throughput and latency (or a
combination). In this paper, we study the complexity of the bi-criteria mapping
problem for pipeline graphs on communication homogeneous platforms. In
particular, we assess the complexity of the well-known chains-to-chains problem
for different-speed processors, which turns out to be NP-hard. We provide
several efficient polynomial bi-criteria heuristics, and their relative
performance is evaluated through extensive simulations."
"We introduce a simple tool called the wavelet (or, r-wavelet) scheme.
Wavelets deals with coordination among processes which are at most r hops away
of each other. We present a selfstabilizing solution for this scheme. Our
solution requires no underlying structure and works in arbritrary anonymous
networks, i.e., no process identifier is required. Moreover, our solution works
under any (even unfair) daemon. Next, we use the wavelet scheme to design
self-stabilizing layer clocks. We show that they provide an efficient device in
the design of local coordination problems at distance r, i.e., r-barrier
synchronization and r-local resource allocation (LRA) such as r-local mutual
exclusion (LME), r-group mutual exclusion (GME), and r-Reader/Writers. Some
solutions to the r-LRA problem (e.g., r-LME) also provide transformers to
transform algorithms written assuming any r-central daemon into algorithms
working with any distributed daemon."
"Min, Veeravalli, and Barlas have recently proposed strategies to minimize the
overall execution time of one or several divisible loads on a heterogeneous
linear network, using one or more installments. We show on a very simple
example that their approach does not always produce a solution and that, when
it does, the solution is often suboptimal. We also show how to find an optimal
schedule for any instance, once the number of installments per load is given.
Then, we formally state that any optimal schedule has an infinite number of
installments under a linear cost model as the one assumed in the original
papers. Therefore, such a cost model cannot be used to design practical
multi-installment strategies. Finally, through extensive simulations we
confirmed that the best solution is always produced by the linear programming
approach, while solutions of the original papers can be far away from the
optimal."
"How to pass from local to global scales in anonymous networks? How to
organize a selfstabilizing propagation of information with feedback. From the
Angluin impossibility results, we cannot elect a leader in a general anonymous
network. Thus, it is impossible to build a rooted spanning tree. Many problems
can only be solved by probabilistic methods. In this paper we show how to use
Unison to design a self-stabilizing barrier synchronization in an anonymous
network. We show that the commuication structure of this barrier
synchronization designs a self-stabilizing wave-stream, or pipelining wave, in
anonymous networks. We introduce two variants of Wave: the strong waves and the
wavelets. A strong wave can be used to solve the idempotent r-operator
parametrized computation problem. A wavelet deals with k-distance computation.
We show how to use Unison to design a self-stabilizing wave stream, a
self-stabilizing strong wave stream and a self-stabilizing wavelet stream."
"The Desktop Grid offers solutions to overcome several challenges and to
answer increasingly needs of scientific computing. Its technology consists
mainly in exploiting resources, geographically dispersed, to treat complex
applications needing big power of calculation and/or important storage
capacity. However, as resources number increases, the need for scalability,
self-organisation, dynamic reconfigurations, decentralisation and performance
becomes more and more essential. Since such properties are exhibited by P2P
systems, the convergence of grid computing and P2P computing seems natural. In
this context, this paper evaluates the scalability and performance of P2P tools
for discovering and registering services. Three protocols are used for this
purpose: Bonjour, Avahi and Free-Pastry. We have studied the behaviour of
theses protocols related to two criteria: the elapsed time for registrations
services and the needed time to discover new services. Our aim is to analyse
these results in order to choose the best protocol we can use in order to
create a decentralised middleware for desktop grid."
"Discovery Systems (DS) can be considered as entry points for global loosely
coupled distributed systems. An efficient Discovery System in essence increases
the performance, reliability and decision making capability of distributed
systems. With the rapid increase in scale of distributed applications, existing
solutions for discovery systems are fast becoming either obsolete or incapable
of handling such complexity. They are particularly ineffective when handling
service lifetimes and providing up-to-date information, poor at enabling
dynamic service access and they can also impose unwanted restrictions on
interfaces to widely available information repositories. In this paper we
present essential the design characteristics, an implementation and a
performance analysis for a discovery system capable of overcoming these
deficiencies in large, globally distributed environments."
"This paper presents the design and implementation of a Grid-enabled physics
analysis environment for handheld and other resource-limited computing devices
as one example of the use of mobile devices in eScience. Handheld devices offer
great potential because they provide ubiquitous access to data and
round-the-clock connectivity over wireless links. Our solution aims to provide
users of handheld devices the capability to launch heavy computational tasks on
computational and data Grids, monitor the jobs status during execution, and
retrieve results after job completion. Users carry their jobs on their handheld
devices in the form of executables (and associated libraries). Users can
transparently view the status of their jobs and get back their outputs without
having to know where they are being executed. In this way, our system is able
to act as a high-throughput computing environment where devices ranging from
powerful desktop machines to small handhelds can employ the power of the Grid.
The results shown in this paper are readily applicable to the wider eScience
community."
"The use of meta-schedulers for resource management in large-scale distributed
systems often leads to a hierarchy of schedulers. In this paper, we discuss why
existing meta-scheduling hierarchies are sometimes not sufficient for Grid
systems due to their inability to re-organise jobs already scheduled locally.
Such a job re-organisation is required to adapt to evolving loads which are
common in heavily used Grid infrastructures. We propose a peer-to-peer
scheduling model and evaluate it using case studies and mathematical modelling.
We detail the DIANA (Data Intensive and Network Aware) scheduling algorithm and
its queue management system for coping with the load distribution and for
supporting bulk job scheduling. We demonstrate that such a system is beneficial
for dynamic, distributed and self-organizing resource management and can assist
in optimizing load or job distribution in complex Grid infrastructures."
"Objectives: Grid-based technologies are emerging as potential solutions for
managing and collaborating distributed resources in the biomedical domain. Few
examples exist, however, of successful implementations of Grid-enabled medical
systems and even fewer have been deployed for evaluation in practice. The
objective of this paper is to evaluate the use in clinical practice of a
Grid-based imaging prototype and to establish directions for engineering future
medical Grid developments and their subsequent deployment. Method: The
MammoGrid project has deployed a prototype system for clinicians using the Grid
as its information infrastructure. To assist in the specification of the system
requirements (and for the first time in healthgrid applications), use-case
modelling has been carried out in close collaboration with clinicians and
radiologists who had no prior experience of this modelling technique. A
critical qualitative and, where possible, quantitative analysis of the
MammoGrid prototype is presented leading to a set of recommendations from the
delivery of the first deployed Grid-based medical imaging application. Results:
We report critically on the application of software engineering techniques in
the specification and implementation of the MammoGrid project and show that
use-case modelling is a suitable vehicle for representing medical requirements
and for communicating effectively with the clinical community. This paper also
discusses the practical advantages and limitations of applying the Grid to
real-life clinical applications and presents the consequent lessons learned."
"Grid Computing has made substantial advances in the past decade; these are
primarily due to the adoption of standardized Grid middleware. However Grid
computing has not yet become pervasive because of some barriers that we believe
have been caused by the adoption of middleware centric approaches. These
barriers include: scant support for major types of applications such as
interactive applications; lack of flexible, autonomic and scalable Grid
architectures; lack of plug-and-play Grid computing and, most importantly, no
straightforward way to setup and administer Grids. PhantomOS is a project which
aims to address many of these barriers. Its goal is the creation of a user
friendly pervasive Grid computing platform that facilitates the rapid
deployment and easy maintenance of Grids whilst providing support for major
types of applications on Grids of almost any topology. In this paper we present
the detailed system architecture and an overview of its implementation."
"In Grids scheduling decisions are often made on the basis of jobs being
either data or computation intensive: in data intensive situations jobs may be
pushed to the data and in computation intensive situations data may be pulled
to the jobs. This kind of scheduling, in which there is no consideration of
network characteristics, can lead to performance degradation in a Grid
environment and may result in large processing queues and job execution delays
due to site overloads. In this paper we describe a Data Intensive and Network
Aware (DIANA) meta-scheduling approach, which takes into account data,
processing power and network characteristics when making scheduling decisions
across multiple sites. Through a practical implementation on a Grid testbed, we
demonstrate that queue and execution times of data-intensive jobs can be
significantly improved when we introduce our proposed DIANA scheduler. The
basic scheduling decisions are dictated by a weighting factor for each
potential target location which is a calculated function of network
characteristics, processing cycles and data location and size. The job
scheduler provides a global ranking of the computing resources and then selects
an optimal one on the basis of this overall access and execution cost. The
DIANA approach considers the Grid as a combination of active network elements
and takes network characteristics as a first class criterion in the scheduling
decision matrix along with computation and data. The scheduler can then make
informed decisions by taking into account the changing state of the network,
locality and size of the data and the pool of available processing cycles."
"Gamma Ray Bursts (GRBs) are intense narrowly-beamed flashes of gamma-rays of
cosmological origin. They are among the most scientifically interesting
astrophysical systems, and the riddle concerning their central engines and
emission mechanisms is one of the most complex and challenging problems of
astrophysics today. In this article we outline our petascale approach to the
GRB problem and discuss the computational toolkits and numerical codes that are
currently in use and that will be scaled up to run on emerging petaflop scale
computing platforms in the near future.
  Petascale computing will require additional ingredients over conventional
parallelism. We consider some of the challenges which will be caused by future
petascale architectures, and discuss our plans for the future development of
the Cactus framework and its applications to meet these challenges in order to
profit from these new architectures."
"We introduce an optimization algorithm for resource allocation in the LIPI
Public Cluster to optimize its usage according to incoming requests from users.
The tool is an extended and modified genetic algorithm developed to match
specific natures of public cluster. We present a detail analysis of
optimization, and compare the results with the exact calculation. We show that
it would be very useful and could realize an automatic decision making system
for public clusters."
"We present extended multi block approach in the LIPI Public Cluster. The
multi block approach enables a cluster to be divided into several independent
blocks which run jobs owned by different users simultaneously. Previously, we
have maintained the blocks using single master node for all blocks due to
efficiency and resource limitations. Following recent advancements and
expansion of node\'s number, we have modified the multi block approach with
multiple master nodes, each of them is responsible for a single block. We argue
that this approach improves the overall performance significantly, for
especially data intensive computational works."
"A Black Hole is an harmful host in a network that destroys incoming agents
without leaving any trace of such event. The problem of locating the black hole
in a network through a team of agent coordinated by a common protocol is
usually referred in literature as the Black Hole Search problem (or BHS for
brevity) and it is a consolidated research topic in the area of distributed
algorithms. The aim of this paper is to extend the results for BHS by
considering more general (and hence harder) classes of dangerous host. In
particular we introduce rB-hole as a probabilistic generalization of the Black
Hole, in which the destruction of an incoming agent is a purely random event
happening with some fixed probability (like flipping a biased coin). The main
result we present is that if we tolerate an arbitrarily small error probability
in the result then the rB-hole Search problem, or RBS, is not harder than the
usual BHS. We establish this result in two different communication model,
specifically both in presence or absence of whiteboards non-located at the
homebase. The core of our methods is a general reduction tool for transforming
algorithms for the black hole into algorithms for the rB-hole."
"A local algorithm is a distributed algorithm where each node must operate
solely based on the information that was available at system startup within a
constant-size neighbourhood of the node. We study the applicability of local
algorithms to max-min LPs where the objective is to maximise $\min_k \sum_v
c_{kv} x_v$ subject to $\sum_v a_{iv} x_v \le 1$ for each $i$ and $x_v \ge 0$
for each $v$. Here $c_{kv} \ge 0$, $a_{iv} \ge 0$, and the support sets $V_i =
\{v : a_{iv} > 0 \}$, $V_k = \{v : c_{kv}>0 \}$, $I_v = \{i : a_{iv} > 0 \}$
and $K_v = \{k : c_{kv} > 0 \}$ have bounded size. In the distributed setting,
each agent $v$ is responsible for choosing the value of $x_v$, and the
communication network is a hypergraph $\mathcal{H}$ where the sets $V_k$ and
$V_i$ constitute the hyperedges. We present inapproximability results for a
wide range of structural assumptions; for example, even if $|V_i|$ and $|V_k|$
are bounded by some constants larger than 2, there is no local approximation
scheme. To contrast the negative results, we present a local approximation
algorithm which achieves good approximation ratios if we can bound the relative
growth of the vertex neighbourhoods in $\mathcal{H}$."
"Commuting operations greatly simplify consistency in distributed systems.
This paper focuses on designing for commutativity, a topic neglected
previously. We show that the replicas of \emph{any} data type for which
concurrent operations commute converges to a correct value, under some simple
and standard assumptions. We also show that such a data type supports
transactions with very low cost. We identify a number of approaches and
techniques to ensure commutativity. We re-use some existing ideas
(non-destructive updates coupled with invariant identification), but propose a
much more efficient implementation. Furthermore, we propose a new technique,
background consensus. We illustrate these ideas with a shared edit buffer data
type."
"This document describes our current effort to gridify Jade, a java-based
environment for the autonomic management of clustered J2EE application servers,
developed in the INRIA SARDES research team. Towards this objective, we use the
java ProActive grid technology. We first present some of the challenges to turn
such an autonomic management system initially dedicated to distributed
applications running on clusters of machines, into one that can provide
self-management capabilities to large-scale systems, i.e. deployed on grid
infrastructures. This leads us to a brief state of the art on grid monitoring
systems. Then, we recall the architecture of Jade, and consequently propose to
reorganize it in a potentially more scalable way. Practical experiments pertain
to the use of the grid deployment feature offered by ProActive to easily
conduct the deployment of the Jade system or its revised version on any sort of
grid."
"As Grid computing is becoming an inevitable future, managing, scheduling and
monitoring dynamic, heterogeneous resources will present new challenges.
Solutions will have to be agile and adaptive, support self-organization and
autonomous management, while maintaining optimal resource utilisation.
Presented in this paper are basic principles and architectural concepts for
efficient resource allocation in heterogeneous Grid environment."
"Effective resource utilisation monitoring and highly granular yet adaptive
measurements are prerequisites for a more efficient Grid scheduler. We present
a suite of measurement applications able to monitor per-process resource
utilisation, and a customisable tool for emulating observed utilisation models."
"As the Grid evolves from a high performance cluster middleware to a
multipurpose utility computing framework, a good understanding of Grid
applications, their statistics and utilisation patterns is required. This study
looks at job execution times and resource utilisations in a Grid environment,
and their significance in cluster and network dimensioning, local level
scheduling and resource management."
"This paper presents basic concepts, architectural principles and algorithms
for efficient resource and security management in cluster computing
environments and the Grid. The work presented in this paper is funded by
BTExacT and the EPSRC project SO-GRM (GR/S21939)."
"Wider adoption of the Grid concept has led to an increasing amount of
federated computational, storage and visualisation resources being available to
scientists and researchers. Distributed and heterogeneous nature of these
resources renders most of the legacy cluster monitoring and management
approaches inappropriate, and poses new challenges in workflow scheduling on
such systems. Effective resource utilisation monitoring and highly granular yet
adaptive measurements are prerequisites for a more efficient Grid scheduler. We
present a suite of measurement applications able to monitor per-process
resource utilisation, and a customisable tool for emulating observed
utilisation models. We also outline our future work on a predictive and
probabilistic Grid scheduler. The research is undertaken as part of UK
e-Science EPSRC sponsored project SO-GRM (Self-Organising Grid Resource
Management) in cooperation with BT."
"The Grid technology is evolving into a global, service-orientated
architecture, a universal platform for delivering future high demand
computational services. Strong adoption of the Grid and the utility computing
concept is leading to an increasing number of Grid installations running a wide
range of applications of different size and complexity. In this paper we
address the problem of elivering deadline/economy based scheduling in a
heterogeneous application environment using statistical properties of job
historical executions and its associated meta-data. This approach is motivated
by a study of six-month computational load generated by Grid applications in a
multi-purpose Grid cluster serving a community of twenty e-Science projects.
The observed job statistics, resource utilisation and user behaviour is
discussed in the context of management approaches and models most suitable for
supporting a probabilistic and autonomous scheduling architecture."
"Mapping applications onto heterogeneous platforms is a difficult challenge,
even for simple application patterns such as pipeline graphs. The problem is
even more complex when processors are subject to failure during the execution
of the application. In this paper, we study the complexity of a bi-criteria
mapping which aims at optimizing the latency (i.e., the response time) and the
reliability (i.e., the probability that the computation will be successful) of
the application. Latency is minimized by using faster processors, while
reliability is increased by replicating computations on a set of processors.
However, replication increases latency (additional communications, slower
processors). The application fails to be executed only if all the processors
fail during execution. While simple polynomial algorithms can be found for
fully homogeneous platforms, the problem becomes NP-hard when tackling
heterogeneous platforms. This is yet another illustration of the additional
complexity added by heterogeneity."
"The domain of numerical simulation is a place where the parallelization of
numerical code is common. The definition of a numerical context means the
configuration of resources such as memory, processor load and communication
graph, with an evolving feature: the resources availability. A feature is often
missing: the adaptability. It is not predictable and the adaptable aspect is
essential. Without calling into question these implementations of these codes,
we create an adaptive use of these implementations. Because the execution has
to be driven by the availability of main resources, the components of a numeric
computation have to react when their context changes. This paper offers a new
architecture, a mobile computing architecture, based on mobile agents and
JavaSpace. At the end of this paper, we apply our architecture to several case
studies and obtain our first results."
"We study the predictive power of autoregressive moving average models when
forecasting demand in two shared computational networks, PlanetLab and Tycoon.
Demand in these networks is very volatile, and predictive techniques to plan
usage in advance can improve the performance obtained drastically.
  Our key finding is that a random walk predictor performs best for
one-step-ahead forecasts, whereas ARIMA(1,1,0) and adaptive exponential
smoothing models perform better for two and three-step-ahead forecasts. A Monte
Carlo bootstrap test is proposed to evaluate the continuous prediction
performance of different models with arbitrary confidence and statistical
significance levels. Although the prediction results differ between the Tycoon
and PlanetLab networks, we observe very similar overall statistical properties,
such as volatility dynamics."
"Volunteer Computing, sometimes called Public Resource Computing, is an
emerging computational model that is very suitable for work-pooled parallel
processing. As more complex grid applications make use of work flows in their
design and deployment it is reasonable to consider the impact of work flow
deployment over a Volunteer Computing infrastructure. In this case, the inter
work flow I/O can lead to a significant increase in I/O demands at the work
pool server. A possible solution is the use of a Peer-to- Peer based parallel
computing architecture to off-load this I/O demand to the workers; where the
workers can fulfill some aspects of work flow coordination and I/O checking,
etc. However, achieving robustness in such a large scale system is a
challenging hurdle towards the decentralized execution of work flows and
general parallel processes. To increase robustness, we propose and show the
merits of using an adaptive checkpoint scheme that efficiently checkpoints the
status of the parallel processes according to the estimation of relevant
network and peer parameters. Our scheme uses statistical data observed during
runtime to dynamically make checkpoint decisions in a completely de-
centralized manner. The results of simulation show support for our proposed
approach in terms of reduced required runtime."
"This paper describes how it is possible to increase GP Computing Power via
Volunteer Computing (VC) using the BOINC framework. Two experiments using
well-known GP tools -Lil-gp & ECJ- are performed in order to demonstrate the
benefit of using VC in terms of computing power and speed up. Finally we
present an extension of the model where any GP tool or framework can be used
inside BOINC regardless of its programming language, complexity or required
operating system."
"Distributed systems are now both very large and highly dynamic. Peer to peer
overlay networks have been proved efficient to cope with this new deal that
traditional approaches can no longer accommodate. While the challenge of
organizing peers in an overlay network has generated a lot of interest leading
to a large number of solutions, maintaining critical data in such a network
remains an open issue. In this paper, we are interested in defining the portion
of nodes and frequency one has to probe, given the churn observed in the
system, in order to achieve a given probability of maintaining the persistence
of some critical data. More specifically, we provide a clear result relating
the size and the frequency of the probing set along with its proof as well as
an analysis of the way of leveraging such an information in a large scale
dynamic distributed system."
"Mapping workflow applications onto parallel platforms is a challenging
problem, even for simple application patterns such as pipeline graphs. Several
antagonistic criteria should be optimized, such as throughput and latency (or a
combination). Typical applications include digital image processing, where
images are processed in steady-state mode. In this paper, we study the mapping
of a particular image processing application, the JPEG encoding. Mapping
pipelined JPEG encoding onto parallel platforms is useful for instance for
encoding Motion JPEG images. As the bi-criteria mapping problem is NP-complete,
we concentrate on the evaluation and performance of polynomial heuristics."
"We describe the e-Science strategy in Venezuela, in particular initiatives by
the Centro Nacional de Calculo Cientifico Universidad de Los Andes (CECALCULA),
Merida, the Universidad de Los Andes (ULA), Merida, and the Instituto
Venezolano de Investigaciones Cientificas (IVIC), Caracas. We present the plans
for the Venezuelan Academic Grid and the current status of Grid ULA supported
by Internet2. We show different web-based scientific applications that are
being developed in quantum chemistry, atomic physics, structural damage
analysis, biomedicine and bioclimate within the framework of the
E-Infrastructure shared between Europe and Latin America (EELA)"
"Energy consumption is the most important factor that determines sensor node
lifetime. The optimization of wireless sensor network lifetime targets not only
the reduction of energy consumption of a single sensor node but also the
extension of the entire network lifetime. We propose a simple and adaptive
energy-conserving topology management scheme, called SAND (Self-Organizing
Active Node Density). SAND is fully decentralized and relies on a distributed
probing approach and on the redundancy resolution of sensors for energy
optimizations, while preserving the data forwarding and sensing capabilities of
the network. We present the SAND's algorithm, its analysis of convergence, and
simulation results. Simulation results show that, though slightly increasing
path lengths from sensor to sink nodes, the proposed scheme improves
significantly the network lifetime for different neighborhood densities
degrees, while preserving both sensing and routing fidelity."
"ILU(k) is a commonly used preconditioner for iterative linear solvers for
sparse, non-symmetric systems. It is often preferred for the sake of its
stability. We present TPILU(k), the first efficiently parallelized ILU(k)
preconditioner that maintains this important stability property. Even better,
TPILU(k) preconditioning produces an answer that is bit-compatible with the
sequential ILU(k) preconditioning. In terms of performance, the TPILU(k)
preconditioning is shown to run faster whenever more cores are made available
to it --- while continuing to be as stable as sequential ILU(k). This is in
contrast to some competing methods that may become unstable if the degree of
thread parallelism is raised too far. Where Block Jacobi ILU(k) fails in an
application, it can be replaced by TPILU(k) in order to maintain good
performance, while also achieving full stability. As a further optimization,
TPILU(k) offers an optional level-based incomplete inverse method as a fast
approximation for the original ILU(k) preconditioned matrix. Although this
enhancement is not bit-compatible with classical ILU(k), it is bit-compatible
with the output from the single-threaded version of the same algorithm. In
experiments on a 16-core computer, the enhanced TPILU(k)-based iterative linear
solver performed up to 9 times faster. As we approach an era of many-core
computing, the ability to efficiently take advantage of many cores will become
ever more important. TPILU(k) also demonstrates good performance on cluster or
Grid. For example, the new algorithm achieves 50 times speedup with 80 nodes
for general sparse matrices of dimension 160,000 that are diagonally dominant."
"We define the ``Pulse Synchronization'' problem that requires nodes to
achieve tight synchronization of regular pulse events, in the settings of
distributed computing systems. Pulse-coupled synchronization is a phenomenon
displayed by a large variety of biological systems, typically overcoming a high
level of noise. Inspired by such biological models, a robust and
self-stabilizing Byzantine pulse synchronization algorithm for distributed
computer systems is presented. The algorithm attains near optimal
synchronization tightness while tolerating up to a third of the nodes
exhibiting Byzantine behavior concurrently. Pulse synchronization has been
previously shown to be a powerful building block for designing algorithms in
this severe fault model. We have previously shown how to stabilize general
Byzantine algorithms, using pulse synchronization. To the best of our knowledge
there is no other scheme to do this without the use of synchronized pulses."
"Strong replica consistency is often achieved by writing deterministic
applications, or by using a variety of mechanisms to render replicas
deterministic. There exists a large body of work on how to render replicas
deterministic under the benign fault model. However, when replicas can be
subject to malicious faults, most of the previous work is no longer effective.
Furthermore, the determinism of the replicas is often considered harmful from
the security perspective and for many applications, their integrity strongly
depends on the randomness of some of their internal operations. This calls for
new approaches towards achieving replica consistency while preserving the
replica randomness. In this paper, we present two such approaches. One is based
on Byzantine agreement and the other on threshold coin-tossing. Each approach
has its strength and weaknesses. We compare the performance of the two
approaches and outline their respective best use scenarios."
"In this paper, we describe a novel proactive recovery scheme based on service
migration for long-running Byzantine fault tolerant systems. Proactive recovery
is an essential method for ensuring long term reliability of fault tolerant
systems that are under continuous threats from malicious adversaries. The
primary benefit of our proactive recovery scheme is a reduced vulnerability
window. This is achieved by removing the time-consuming reboot step from the
critical path of proactive recovery. Our migration-based proactive recovery is
coordinated among the replicas, therefore, it can automatically adjust to
different system loads and avoid the problem of excessive concurrent proactive
recoveries that may occur in previous work with fixed watchdog timeouts.
Moreover, the fast proactive recovery also significantly improves the system
availability in the presence of faults."
"We study the important problem of tracking moving targets in wireless sensor
networks. We try to overcome the limitations of standard state of the art
tracking methods based on continuous location tracking, i.e. the high energy
dissipation and communication overhead imposed by the active participation of
sensors in the tracking process and the low scalability, especially in sparse
networks. Instead, our approach uses sensors in a passive way: they just record
and judiciously spread information about observed target presence in their
vicinity; this information is then used by the (powerful) tracking agent to
locate the target by just following the traces left at sensors. Our protocol is
greedy, local, distributed, energy efficient and very successful, in the sense
that (as shown by extensive simulations) the tracking agent manages to quickly
locate and follow the target; also, we achieve good trade-offs between the
energy dissipation and latency."
"We consider the question of averaging on a graph that has one sparse cut
separating two subgraphs that are internally well connected.
  While there has been a large body of work devoted to algorithms for
distributed averaging, nearly all algorithms involve only {\it convex} updates.
In this paper, we suggest that {\it non-convex} updates can lead to significant
improvements. We do so by exhibiting a decentralized algorithm for graphs with
one sparse cut that uses non-convex averages and has an averaging time that can
be significantly smaller than the averaging time of known distributed
algorithms, such as those of \cite{tsitsiklis, Boyd}. We use stochastic
dominance to prove this result in a way that may be of independent interest."
"In this paper we consider the operator mapping problem for in-network stream
processing applications. In-network stream processing consists in applying a
tree of operators in steady-state to multiple data objects that are continually
updated at various locations on a network. Examples of in-network stream
processing include the processing of data in a sensor network, or of continuous
queries on distributed relational databases. We study the operator mapping
problem in a ``constructive'' scenario, i.e., a scenario in which one builds a
platform dedicated to the application buy purchasing processing servers with
various costs and capabilities. The objective is to minimize the cost of the
platform while ensuring that the application achieves a minimum steady-state
throughput. The first contribution of this paper is the formalization of a set
of relevant operator-placement problems as linear programs, and a proof that
even simple versions of the problem are NP-complete. Our second contribution is
the design of several polynomial time heuristics, which are evaluated via
extensive simulations and compared to theoretical bounds for optimal solutions."
"Tingkat kompleksitas dari program simulasi dinamika molekular membutuhkan
mesin pemroses dengan kemampuan yang sangat besar. Mesin-mesin paralel terbukti
memiliki potensi untuk menjawab tantangan komputasi ini. Untuk memanfaatkan
potensi ini secara maksimal, diperlukan suatu program paralel dengan tingkat
efisiensi, efektifitas, skalabilitas, dan ekstensibilitas yang maksimal pula.
Program NAMD yang dibahas pada penulisan ini dianggap mampu untuk memenuhi
semua kriteria yang diinginkan. Program ini dirancang dengan
mengimplementasikan pustaka Charm++ untuk pembagian tugas perhitungan secara
paralel. NAMD memiliki sistem automatic load balancing secara periodik yang
cerdas, sehingga dapat memaksimalkan penggunaan kemampuan mesin yang tersedia.
Program ini juga dirancang secara modular, sehingga dapat dimodifikasi dan
ditambah dengan sangat mudah. NAMD menggunakan banyak kombinasi algoritma
perhitungan dan tehnik-tehnik numerik lainnya dalam melakukan tugasnya. NAMD
2.5 mengimplementasikan semua tehnik dan persamaan perhitungan yang digunakan
dalam dunia simulasi dinamika molekular saat ini. NAMD dapat berjalan diatas
berbagai mesin paralel termasuk arsitektur cluster, dengan hasil speedup yang
mengejutkan. Tulisan ini akan menjelaskan dan membuktikan kemampuan NAMD secara
paralel diatas lima buah mesin cluster. Penulisan ini juga akan memaparkan
kinerja NAMD pada beberapa."
"Cloud computing has demonstrated that processing very large datasets over
commodity clusters can be done simply given the right programming model and
infrastructure. In this paper, we describe the design and implementation of the
Sector storage cloud and the Sphere compute cloud. In contrast to existing
storage and compute clouds, Sector can manage data not only within a data
center, but also across geographically distributed data centers. Similarly, the
Sphere compute cloud supports User Defined Functions (UDF) over data both
within a data center and across data centers. As a special case, MapReduce
style programming can be implemented in Sphere by using a Map UDF followed by a
Reduce UDF. We describe some experimental studies comparing Sector/Sphere and
Hadoop using the Terasort Benchmark. In these studies, Sector is about twice as
fast as Hadoop. Sector/Sphere is open source."
"We present a local algorithm (constant-time distributed algorithm) for
approximating max-min LPs. The objective is to maximise $\omega$ subject to $Ax
\le 1$, $Cx \ge \omega 1$, and $x \ge 0$ for nonnegative matrices $A$ and $C$.
The approximation ratio of our algorithm is the best possible for any local
algorithm; there is a matching unconditional lower bound."
"The aim of this paper is to provide qualitative models characterizing
interdependencies related failures of two critical infrastructures: the
electricity infrastructure and the associated information infrastructure. The
interdependencies of these two infrastructures are increasing due to a growing
connection of the power grid networks to the global information infrastructure,
as a consequence of market deregulation and opening. These interdependencies
increase the risk of failures. We focus on cascading, escalating and
common-cause failures, which correspond to the main causes of failures due to
interdependencies. We address failures in the electricity infrastructure, in
combination with accidental failures in the information infrastructure, then we
show briefly how malicious attacks in the information infrastructure can be
addressed."
"We present a local algorithm (constant-time distributed algorithm) for
finding a 3-approximate vertex cover in bounded-degree graphs. The algorithm is
deterministic, and no auxiliary information besides port numbering is required."
"We consider the problem of efficiently managing massive data in a large-scale
distributed environment. We consider data strings of size in the order of
Terabytes, shared and accessed by concurrent clients. On each individual
access, a segment of a string, of the order of Megabytes, is read or modified.
Our goal is to provide the clients with efficient fine-grain access the data
string as concurrently as possible, without locking the string itself. This
issue is crucial in the context of applications in the field of astronomy,
databases, data mining and multimedia. We illustrate these requiremens with the
case of an application for searching supernovae. Our solution relies on
distributed, RAM-based data storage, while leveraging a DHT-based, parallel
metadata management scheme. The proposed architecture and algorithms have been
validated through a software prototype and evaluated in a cluster environment."
"This paper addresses the problem of efficiently storing and accessing massive
data blocks in a large-scale distributed environment, while providing efficient
fine-grain access to data subsets. This issue is crucial in the context of
applications in the field of databases, data mining and multimedia. We propose
a data sharing service based on distributed, RAM-based storage of data, while
leveraging a DHT-based, natively parallel metadata management scheme. As
opposed to the most commonly used grid storage infrastructures that provide
mechanisms for explicit data localization and transfer, we provide a
transparent access model, where data are accessed through global identifiers.
Our proposal has been validated through a prototype implementation whose
preliminary evaluation provides promising results."
"A distributed adaptive algorithm to estimate a time-varying signal, measured
by a wireless sensor network, is designed and analyzed. One of the major
features of the algorithm is that no central coordination among the nodes needs
to be assumed. The measurements taken by the nodes of the network are affected
by noise, and the communication among the nodes is subject to packet losses.
Nodes exchange local estimates and measurements with neighboring nodes. Each
node of the network locally computes adaptive weights that minimize the
estimation error variance. Decentralized conditions on the weights, needed for
the convergence of the estimation error throughout the overall network, are
presented. A Lipschitz optimization problem is posed to guarantee stability and
the minimization of the variance. An efficient strategy to distribute the
computation of the optimal solution is investigated. A theoretical performance
analysis of the distributed algorithm is carried out both in the presence of
perfect and lossy links. Numerical simulations illustrate performance for
various network topologies and packet loss probabilities."
"We propose a group membership service for dynamic ad hoc networks. It
maintains as long as possible the existing groups and ensures that each group
diameter is always smaller than a constant, fixed according to the application
using the groups. The proposed protocol is self-stabilizing and works in
dynamic distributed systems. Moreover, it ensures a kind of continuity in the
service offer to the application while the system is converging, except if too
strong topology changes happen. Such a best effort behavior allows applications
to rely on the groups while the stabilization has not been reached, which is
very useful in dynamic ad hoc networks."
"We present a scheme to convert self-stabilizing algorithms that use
randomization during and following convergence to self-stabilizing algorithms
that use randomization only during convergence. We thus reduce the number of
random bits from an infinite number to a bounded number. The scheme is
applicable to the cases in which there exits a local predicate for each node,
such that global consistency is implied by the union of the local predicates.
We demonstrate our scheme over the token circulation algorithm of Herman and
the recent constant time Byzantine self-stabilizing clock synchronization
algorithm by Ben-Or, Dolev and Hoch. The application of our scheme results in
the first constant time Byzantine self-stabilizing clock synchronization
algorithm that uses a bounded number of random bits."
"Since the very beginning of hardware development, computer processors were
invented with ever-increasing clock frequencies and sophisticated in-build
optimization strategies. Due to physical limitations, this 'free lunch' of
speedup has come to an end.
  The following article gives a summary and bibliography for recent trends and
challenges in CMP architectures. It discusses how 40 years of parallel
computing research need to be considered in the upcoming multi-core era. We
argue that future research must be driven from two sides - a better expression
of hardware structures, and a domain-specific understanding of software
parallelism."
"The study consists of two parts. Objective of the first part is modern
language constructions responsible for algorithmically insolvability of
parallelizing problem. Second part contains several ways to modify the
constructions to make the problem algorithmically solvable"
"The article suggests a description of a system of tables with a set of
special lists absorbing a semantics of data and reflects a fullness of data. It
shows how their parallel processing can be constructed based on the
descriptions. The approach also might be used for definition intermediate
targets for data mining and unstructured data processing."
"Probably building non procedural languages is the most prospective way for
parallel programming just because non procedural means no fixed way for
execution. The article consists of 3 parts. In first part we consider formal
systems for definition a named datasets and studying an expression power of
different subclasses. In the second part we consider a complexity of algorithms
of building sets by the definitions. In third part we consider a fullness and
flexibility of the class of program based data set definitions."
"Analysis of asset liability management (ALM) strategies especially for long
term horizon is a crucial issue for banks, funds and insurance companies.
  Modern economic models, investment strategies and optimization criteria make
ALM studies computationally very intensive task. It attracts attention to
multiprocessor system and especially to the cheapest one: multi core PCs and PC
clusters.
  In this article we are analyzing problem of parallel organization of
portfolio optimization, results of using clusters for optimization and the most
efficient cluster architecture for these kinds of tasks."
"Many challenging tasks in sensor networks, including sensor calibration,
ranking of nodes, monitoring, event region detection, collaborative filtering,
collaborative signal processing, {\em etc.}, can be formulated as a problem of
solving a linear system of equations. Several recent works propose different
distributed algorithms for solving these problems, usually by using linear
iterative numerical methods.
  In this work, we extend the settings of the above approaches, by adding
another dimension to the problem. Specifically, we are interested in {\em
self-stabilizing} algorithms, that continuously run and converge to a solution
from any initial state. This aspect of the problem is highly important due to
the dynamic nature of the network and the frequent changes in the measured
environment.
  In this paper, we link together algorithms from two different domains. On the
one hand, we use the rich linear algebra literature of linear iterative methods
for solving systems of linear equations, which are naturally distributed with
rapid convergence properties. On the other hand, we are interested in
self-stabilizing algorithms, where the input to the computation is constantly
changing, and we would like the algorithms to converge from any initial state.
We propose a simple novel method called \syncAlg as a self-stabilizing variant
of the linear iterative methods. We prove that under mild conditions the
self-stabilizing algorithm converges to a desired result. We further extend
these results to handle the asynchronous case.
  As a case study, we discuss the sensor calibration problem and provide
simulation results to support the applicability of our approach."
"Cloud Computing has become another buzzword after Web 2.0. However, there are
dozens of different definitions for Cloud Computing and there seems to be no
consensus on what a Cloud is. On the other hand, Cloud Computing is not a
completely new concept; it has intricate connection to the relatively new but
thirteen-year established Grid Computing paradigm, and other relevant
technologies such as utility computing, cluster computing, and distributed
systems in general. This paper strives to compare and contrast Cloud Computing
with Grid Computing from various angles and give insights into the essential
characteristics of both."
"Loosely coupled programming is a powerful paradigm for rapidly creating
higher-level applications from scientific programs on petascale systems,
typically using scripting languages. This paradigm is a form of many-task
computing (MTC) which focuses on the passing of data between programs as
ordinary files rather than messages. While it has the significant benefits of
decoupling producer and consumer and allowing existing application programs to
be executed in parallel with no recoding, its typical implementation using
shared file systems places a high performance burden on the overall system and
on the user who will analyze and consume the downstream data. Previous efforts
have achieved great speedups with loosely coupled programs, but have done so
with careful manual tuning of all shared file system access. In this work, we
evaluate a prototype collective IO model for file-based MTC. The model enables
efficient and easy distribution of input data files to computing nodes and
gathering of output results from them. It eliminates the need for such manual
tuning and makes the programming of large-scale clusters using a loosely
coupled model easier. Our approach, inspired by in-memory approaches to
collective operations for parallel programming, builds on fast local file
systems to provide high-speed local file caches for parallel scripts, uses a
broadcast approach to handle distribution of common input data, and uses
efficient scatter/gather and caching techniques for input and output. We
describe the design of the prototype model, its implementation on the Blue
Gene/P supercomputer, and present preliminary measurements of its performance
on synthetic benchmarks and on a large-scale molecular dynamics application."
"The ability to detect fragments of deleted image files and to reconstruct
these image files from all available fragments on disk is a key activity in the
field of digital forensics. Although reconstruction of image files from the
file fragments on disk can be accomplished by simply comparing the content of
sectors on disk with the content of known files, this brute-force approach can
be time consuming. This paper presents results from research into the use of
Graphics Processing Units (GPUs) in detecting specific image file byte patterns
in disk clusters. Unique identifying pattern for each disk sector is compared
against patterns in known images. A pattern match indicates the potential
presence of an image and flags the disk sector for further in-depth examination
to confirm the match. The GPU-based implementation outperforms the software
implementation by a significant margin."
"We present an algorithm for boundary approximation in locally-linked sensor
networks that communicate with a remote monitoring station. Delaunay
triangulations and Voronoi diagrams are used to generate a sensor communication
network and define boundary segments between sensors, respectively. The
proposed algorithm reduces remote station communication by approximating
boundaries via a decentralized computation executed within the sensor network.
Moreover, the algorithm identifies boundaries based on differences between
neighboring sensor readings, and not absolute sensor values. An analysis of the
bandwidth consumption of the algorithm is presented and compared to two naive
approaches. The proposed algorithm reduces the amount of remote communication
(compared to the naive approaches) and becomes increasingly useful in networks
with more nodes."
"In this paper, we present the computational task-management tool Ganga, which
allows for the specification, submission, bookkeeping and post-processing of
computational tasks on a wide set of distributed resources. Ganga has been
developed to solve a problem increasingly common in scientific projects, which
is that researchers must regularly switch between different processing systems,
each with its own command set, to complete their computational tasks. Ganga
provides a homogeneous environment for processing data on heterogeneous
resources. We give examples from High Energy Physics, demonstrating how an
analysis can be developed on a local system and then transparently moved to a
Grid system for processing of all available data. Ganga has an API that can be
used via an interactive interface, in scripts, or through a GUI. Specific
knowledge about types of tasks or computational resources is provided at
run-time through a plugin system, making new developments easy to integrate. We
give an overview of the Ganga architecture, give examples of current use, and
demonstrate how Ganga can be used in many different areas of science."
"In an ideal distributed computing infrastructure, users would be able to use
diverse distributed computing resources in a simple coherent way, with
guaranteed security and efficient use of shared resources in accordance with
the wishes of the owners of the resources. Our strategy for approaching this
ideal is to first find the simplest structure within which these goals can
plausibly be achieved. This structure, we find, is given by a particular
recursive distributive lattice freely constructed from a presumed partially
ordered set of all data in the infrastructure. Minor syntactic adjustments to
the resulting algebra yields a simple language resembling a UNIX shell, a
concept of execution and an interprocess protocol. Persons, organizations and
servers within the system express their interests explicitly via a hierarchical
currency. The currency provides a common framework for treating authentication,
access control and resource sharing as economic problems while also introducing
a new dimension for improving the infrastructure over time by designing system
components which compete with each other to earn the currency. We explain these
results, discuss experience with an implementation called egg and point out
areas where more research is needed."
"The use of High Performance Computing (HPC) in commercial and consumer IT
applications is becoming popular. They need the ability to gain rapid and
scalable access to high-end computing capabilities. Cloud computing promises to
deliver such a computing infrastructure using data centers so that HPC users
can access applications and data from a Cloud anywhere in the world on demand
and pay based on what they use. However, the growing demand drastically
increases the energy consumption of data centers, which has become a critical
issue. High energy consumption not only translates to high energy cost, which
will reduce the profit margin of Cloud providers, but also high carbon
emissions which is not environmentally sustainable. Hence, energy-efficient
solutions are required that can address the high increase in the energy
consumption from the perspective of not only Cloud provider but also from the
environment. To address this issue we propose near-optimal scheduling policies
that exploits heterogeneity across multiple data centers for a Cloud provider.
We consider a number of energy efficiency factors such as energy cost, carbon
emission rate, workload, and CPU power efficiency which changes across
different data center depending on their location, architectural design, and
management system. Our carbon/energy based scheduling policies are able to
achieve on average up to 30% of energy savings in comparison to profit based
scheduling policies leading to higher profit and less carbon emissions."
"We introduce and address the problem of concurrent autonomic management of
different non-functional concerns in parallel applications build as a
hierarchical composition of behavioural skeletons. We first define the problems
arising when multiple concerns are dealt with by independent managers, then we
propose a methodology supporting coordinated management, and finally we discuss
how autonomic management of multiple concerns may be implemented in a typical
use case. The paper concludes with an outline of the challenges involved in
realizing the proposed methodology on distributed target architectures such as
clusters and grids. Being based on the behavioural skeleton concept proposed in
the CoreGRID GCM, it is anticipated that the methodology will be readily
integrated into the current reference implementation of GCM based on Java
ProActive and running on top of major grid middleware systems."
"Reliable systems have always been built out of unreliable components. Early
on, the reliable components were small such as mirrored disks or ECC (Error
Correcting Codes) in core memory. These systems were designed such that
failures of these small components were transparent to the application. Later,
the size of the unreliable components grew larger and semantic challenges crept
into the application when failures occurred.
  As the granularity of the unreliable component grows, the latency to
communicate with a backup becomes unpalatable. This leads to a more relaxed
model for fault tolerance. The primary system will acknowledge the work request
and its actions without waiting to ensure that the backup is notified of the
work. This improves the responsiveness of the system.
  There are two implications of asynchronous state capture: 1) Everything
promised by the primary is probabilistic. There is always a chance that an
untimely failure shortly after the promise results in a backup proceeding
without knowledge of the commitment. Hence, nothing is guaranteed! 2)
Applications must ensure eventual consistency. Since work may be stuck in the
primary after a failure and reappear later, the processing order for work
cannot be guaranteed.
  Platform designers are struggling to make this easier for their applications.
Emerging patterns of eventual consistency and probabilistic execution may soon
yield a way for applications to express requirements for a ""looser"" form of
consistency while providing availability in the face of ever larger failures.
  This paper recounts portions of the evolution of these trends, attempts to
show the patterns that span these changes, and talks about future directions as
we continue to ""build on quicksand""."
"A general class of unidirectional transforms is presented that can be
computed in a distributed manner along an arbitrary routing tree. Additionally,
we provide a set of conditions under which these transforms are invertible.
These transforms can be computed as data is routed towards the collection (or
sink) node in the tree and exploit data correlation between nodes in the tree.
Moreover, when used in wireless sensor networks, these transforms can also
leverage data received at nodes via broadcast wireless communications. Various
constructions of unidirectional transforms are also provided for use in data
gathering in wireless sensor networks. New wavelet transforms are also proposed
which provide significant improvements over existing unidirectional transforms."
"The study deals with the parallelization of finite element based
Navier-Stokes codes using domain decomposition and state-ofart sparse direct
solvers. There has been significant improvement in the performance of sparse
direct solvers. Parallel sparse direct solvers are not found to exhibit good
scalability. Hence, the parallelization of sparse direct solvers is done using
domain decomposition techniques. A highly efficient sparse direct solver
PARDISO is used in this study. The scalability of both Newton and modified
Newton algorithms are tested."
"With increasing complexity of tourism business models and tasks, there is a
clear need of the next generation e-Tourism infrastructure to support flexible
automation, integration, computation, storage, and collaboration. Currently
several enabling technologies such as semantic Web, Web service, agent and grid
computing have been applied in the different e-Tourism applications, however
there is no a unified framework to be able to integrate all of them. So this
paper presents a promising e-Tourism framework based on emerging semantic grid,
in which a number of key design issues are discussed including architecture,
ontologies structure, semantic reconciliation, service and resource discovery,
role based authorization and intelligent agent. The paper finally provides the
implementation of the framework."
"This tutorial presents a recipe for the construction of a compute cluster for
processing large volumes of data, using cheap, easily available personal
computer hardware (Intel/AMD based PCs) and freely available open source
software (Ubuntu Linux, Apache Hadoop)."
"We craft a few scenarios for the execution of sequential and parallel jobs on
future generation machines. Checkpointing or migration, which technique to
choose?"
"The need for high availability (HA) and disaster recovery (DR) in IT
environment is more stringent than most of the other sectors of enterprises.
Many businesses require the availability of business-critical applications 24
hours a day, seven days a week, and can afford no data loss in the event of a
disaster. It is vital that the IT infrastructure is resilient with regard to
disruption, even site failures, and that business operations can continue
without significant impact. As a result, DR has gained great importance in IT.
Clustering of multiple industries standard servers together to allow workload
sharing and fail-over capabilities is a low cost approach. In this paper, we
present the availability model through Semi-Markov Process (SMP) and also
analyze the difference in downtime of the SMP model and the approximate
Continuous Time Markov Chain (CTMC) model. To acquire system availability, we
perform numerical analysis and SHARPE tool evaluation."
"A local algorithm is a distributed algorithm that completes after a constant
number of synchronous communication rounds. We present local approximation
algorithms for the minimum dominating set problem and the maximum matching
problem in 2-coloured and weakly 2-coloured graphs. In a weakly 2-coloured
graph, both problems admit a local algorithm with the approximation factor
$(\Delta+1)/2$, where $\Delta$ is the maximum degree of the graph. We also give
a matching lower bound proving that there is no local algorithm with a better
approximation factor for either of these problems. Furthermore, we show that
the stronger assumption of a 2-colouring does not help in the case of the
dominating set problem, but there is a local approximation scheme for the
maximum matching problem in 2-coloured graphs."
"This case study illustrates the potential benefits and risks associated with
the migration of an IT system in the oil & gas industry from an in-house data
center to Amazon EC2 from a broad variety of stakeholder perspectives across
the enterprise, thus transcending the typical, yet narrow, financial and
technical analysis offered by providers. Our results show that the system
infrastructure in the case study would have cost 37% less over 5 years on EC2,
and using cloud computing could have potentially eliminated 21% of the support
calls for this system. These findings seem significant enough to call for a
migration of the system to the cloud but our stakeholder impact analysis
revealed that there are significant risks associated with this. Whilst the
benefits of using the cloud are attractive, we argue that it is important that
enterprise decision-makers consider the overall organizational implications of
the changes brought about with cloud computing to avoid implementing local
optimizations at the cost of organization-wide performance."
"This paper considers N mobile nodes that move together in the vicinity of
each other, whose initial poses as well as subsequent movements must be
accurately tracked in real time with the assist of M(>=3) reference nodes. By
engaging the neighboring mobile nodes in a simple but effective cooperation,
and by exploiting both the time-of-arrival (TOA) information (between mobile
nodes and reference nodes) and the received-signal-strength (RSS) information
(between mobile nodes), an effective new localization strategy, termed
cooperative TOA and RSS (COTAR), is developed. An optimal maximum likelihood
detector is first formulated, followed by the derivation of a low-complexity
iterative approach that can practically achieve the Cramer-Rao lower bound.
Instead of using simplified channel models as in many previous studies, a
sophisticated and realistic channel model is used, which can effectively
account for the critical fact that the direct path is not necessarily the
strongest path. Extensive simulations are conducted in static and mobile
settings, and various practical issues and system parameters are evaluated. It
is shown that COTAR significantly outperforms the existing strategies,
achieving a localization accuracy of only a few tenths of a meter in clear
environments and a couple of meters in heavily obstructed environments."
"This paper considers distributed coding for multi-source single-sink data
collection wireless networks. A unified framework for network coding and
channel coding, termed ""generalized adaptive network coded cooperation""
(GANCC), is proposed. Key ingredients of GANCC include: matching code graphs
with the dynamic network graphs on-the-fly, and integrating channel coding with
network coding through circulant low-density parity-check codes. Several code
constructing methods and several families of sparse-graph codes are proposed,
and information theoretical analysis is performed. It is shown that GANCC is
simple to operate, adaptive in real time, distributed in nature, and capable of
providing remarkable coding gains even with a very limited number of
cooperating users."
"We consider a Mobile Ad-hoc NETwork (MANET) formed by n agents that move at
speed V according to the Manhattan Random-Way Point model over a square region
of side length L. The resulting stationary (agent) spatial probability
distribution is far to be uniform: the average density over the ""central zone""
is asymptotically higher than that over the ""suburb"". Agents exchange data iff
they are at distance at most R within each other.
  We study the flooding time of this MANET: the number of time steps required
to broadcast a message from one source agent to all agents of the network in
the stationary phase. We prove the first asymptotical upper bound on the
flooding time. This bound holds with high probability, it is a decreasing
function of R and V, and it is tight for a wide and relevant range of the
network parameters (i.e. L, R and V).
  A consequence of our result is that flooding over the sparse and
highly-disconnected suburb can be as fast as flooding over the dense and
connected central zone. Rather surprisingly, this property holds even when R is
exponentially below the connectivity threshold of the MANET and the speed V is
very low."
"Outlier detection in data streams has gained wide importance presently due to
the increasing cases of fraud in various applications of data streams. The
techniques for outlier detection have been divided into either statistics
based, distance based, density based or deviation based. Till now, most of the
work in the field of fraud detection was distance based but it is incompetent
from computational point of view. In this paper we introduced a new clustering
based approach, which divides the stream in chunks and clusters each chunk
using kmedian into variable number of clusters. Instead of storing complete
data stream chunk in memory, we replace it with the weighted medians found
after mining a data stream chunk and pass that information along with the newly
arrived data chunk to the next phase. The weighted medians found in each phase
are tested for outlierness and after a given number of phases, it is either
declared as a real outlier or an inlier. Our technique is theoretically better
than the k-means as it does not fix the number of clusters to k rather gives a
range to it and provides a more stable and better solution which runs in
poly-logarithmic space."
"We describe an algorithm for Byzantine agreement that is scalable in the
sense that each processor sends only $\tilde{O}(\sqrt{n})$ bits, where $n$ is
the total number of processors. Our algorithm succeeds with high probability
against an \emph{adaptive adversary}, which can take over processors at any
time during the protocol, up to the point of taking over arbitrarily close to a
1/3 fraction. We assume synchronous communication but a \emph{rushing}
adversary. Moreover, our algorithm works in the presence of flooding:
processors controlled by the adversary can send out any number of messages. We
assume the existence of private channels between all pairs of processors but
make no other cryptographic assumptions. Finally, our algorithm has latency
that is polylogarithmic in $n$. To the best of our knowledge, ours is the first
algorithm to solve Byzantine agreement against an adaptive adversary, while
requiring $o(n^{2})$ total bits of communication."
"We consider how underused computing resources within an enterprise may be
harnessed to improve utilization and create an elastic computing
infrastructure. Most current cloud provision involves a data center model, in
which clusters of machines are dedicated to running cloud infrastructure
software. We propose an additional model, the ad hoc cloud, in which
infrastructure software is distributed over resources harvested from machines
already in existence within an enterprise. In contrast to the data center cloud
model, resource levels are not established a priori, nor are resources
dedicated exclusively to the cloud while in use. A participating machine is not
dedicated to the cloud, but has some other primary purpose such as running
interactive processes for a particular user. We outline the major
implementation challenges and one approach to tackling them."
"This paper presents a methodology and a system, named LogMaster, for mining
correlations of events that have multiple attributions, i.e., node ID,
application ID, event type, and event severity, in logs of large-scale cluster
systems. Different from traditional transactional data, e.g., supermarket
purchases, system logs have their unique characteristic, and hence we propose
several innovative approaches to mine their correlations. We present a simple
metrics to measure correlations of events that may happen interleavedly. On the
basis of the measurement of correlations, we propose two approaches to mine
event correlations; meanwhile, we propose an innovative abstraction: event
correlation graphs (ECGs) to represent event correlations, and present an ECGs
based algorithm for predicting events. For two system logs of a production
Hadoop-based cloud computing system at Research Institution of China Mobile and
a production HPC cluster system at Los Alamos National Lab (LANL), we evaluate
our approaches in three scenarios: (a) predicting all events on the basis of
both failure and non-failure events; (b) predicting only failure events on the
basis of both failure and non-failure events; (c) predicting failure events
after removing non-failure events."
"We consider the problem of developing an efficient multi-threaded
implementation of the matrix-vector multiplication algorithm for sparse
matrices with structural symmetry. Matrices are stored using the compressed
sparse row-column format (CSRC), designed for profiting from the symmetric
non-zero pattern observed in global finite element matrices. Unlike classical
compressed storage formats, performing the sparse matrix-vector product using
the CSRC requires thread-safe access to the destination vector. To avoid race
conditions, we have implemented two partitioning strategies. In the first one,
each thread allocates an array for storing its contributions, which are later
combined in an accumulation step. We analyze how to perform this accumulation
in four different ways. The second strategy employs a coloring algorithm for
grouping rows that can be concurrently processed by threads. Our results
indicate that, although incurring an increase in the working set size, the
former approach leads to the best performance improvements for most matrices."
"We consider asynchronous message-passing systems in which some links are
timely and processes may crash. Each run defines a timeliness graph among
correct processes: (p; q) is an edge of the timeliness graph if the link from p
to q is timely (that is, there is bound on communication delays from p to q).
The main goal of this paper is to approximate this timeliness graph by graphs
having some properties (such as being trees, rings, ...). Given a family S of
graphs, for runs such that the timeliness graph contains at least one graph in
S then using an extraction algorithm, each correct process has to converge to
the same graph in S that is, in a precise sense, an approximation of the
timeliness graph of the run. For example, if the timeliness graph contains a
ring, then using an extraction algorithm, all correct processes eventually
converge to the same ring and in this ring all nodes will be correct processes
and all links will be timely. We first present a general extraction algorithm
and then a more specific extraction algorithm that is communication efficient
(i.e., eventually all the messages of the extraction algorithm use only links
of the extracted graph)."
"Parameter sweeping is a widely used algorithmic technique in computational
science. It is specially suited for high-throughput computing since the jobs
evaluating the parameter space are loosely coupled or independent.
  A tool that integrates the modeling of a parameter study with the control of
jobs in a distributed architecture is presented. The main task is to facilitate
the creation and deletion of job templates, which are the elements describing
the jobs to be run. Extra functionality relies upon the GridWay Metascheduler,
acting as the middleware layer for job submission and control. It supports
interesting features like multi-dimensional sweeping space, wildcarding of
parameters, functional evaluation of ranges, value-skipping and job template
automatic indexation.
  The use of this tool increases the reliability of the parameter sweep study
thanks to the systematic bookkeping of job templates and respective job
statuses. Furthermore, it simplifies the porting of the target application to
the grid reducing the required amount of time and effort."
"This paper presents a realization for the reliable and fast startup of
distributed systems written in Erlang. The traditional startup provided by the
Erlang/OTP library is sequential, parallelization usually requires unsafe and
ad-hoc solutions. The proposed method calls only for slight modifications in
the Erlang/OTP stdlib by applying a system dependency graph. It makes the
startup safe, quick, and it is equally easy to use in newly developed and
legacy systems."
"This paper deals with the parallel raytracing part of virtual-reality system
PROLAND, developed at the home institution of authors. It describes an actual
implementation of the raytracing part and introduces a Coloured Petri Nets
model of the implementation. The model is used for an evaluation of the
implementation by means of simulation-based performance analysis and also forms
the basis for future improvements of its parallelization strategy."
"Consider an n-vertex graph G = (V,E) of maximum degree Delta, and suppose
that each vertex v \in V hosts a processor. The processors are allowed to
communicate only with their neighbors in G. The communication is synchronous,
i.e., it proceeds in discrete rounds. In the distributed vertex coloring
problem the objective is to color G with Delta + 1, or slightly more than Delta
+ 1, colors using as few rounds of communication as possible. (The number of
rounds of communication will be henceforth referred to as running time.)
Efficient randomized algorithms for this problem are known for more than twenty
years \cite{L86, ABI86}. Specifically, these algorithms produce a (Delta +
1)-coloring within O(log n) time, with high probability. On the other hand, the
best known deterministic algorithm that requires polylogarithmic time employs
O(Delta^2) colors. This algorithm was devised in a seminal FOCS'87 paper by
Linial \cite{L87}. Its running time is O(log^* n). In the same paper Linial
asked whether one can color with significantly less than Delta^2 colors in
deterministic polylogarithmic time. By now this question of Linial became one
of the most central long-standing open questions in this area. In this paper we
answer this question in the affirmative, and devise a deterministic algorithm
that employs \Delta^{1 +o(1)} colors, and runs in polylogarithmic time.
Specifically, the running time of our algorithm is O(f(Delta) log Delta log n),
for an arbitrarily slow-growing function f(Delta) = \omega(1). We can also
produce O(Delta^{1 + \eta})-coloring in O(log Delta log n)-time, for an
arbitrarily small constant \eta > 0, and O(Delta)-coloring in
O(Delta^{\epsilon} log n) time, for an arbitrarily small constant \epsilon > 0."
"Intensive experiences show and confirm that grid environments can be
considered as the most promising way to solve several kinds of problems
relating either to cooperative work especially where involved collaborators are
dispersed geographically or to some very greedy applications which require
enough power of computing or/and storage. Such environments can be classified
into two categories; first, dedicated grids where the federated computers are
solely devoted to a specific work through its end. Second, Volunteer grids
where federated computers are not completely devoted to a specific work but
instead they can be randomly and intermittently used, at the same time, for any
other purpose or they can be connected or disconnected at will by their owners
without any prior notification. Each category of grids includes surely several
advantages and disadvantages; nevertheless, we think that volunteer grids are
very promising and more convenient especially to build a general multipurpose
distributed scalable environment. Unfortunately, the big challenge of such
environments is, however, security and trust. Indeed, owing to the fact that
every federated computer in such an environment can randomly be used at the
same time by several users or can be disconnected suddenly, several security
problems will automatically arise. In this paper, we propose a novel solution
based on identity federation, agent technology and the dynamic enforcement of
access control policies that lead to the design and implementation of trusted
volunteer grid environments."
"One of the biggest huddles faced by researchers studying algorithms for
massive graphs is the lack of large input graphs that are essential for the
development and test of the graph algorithms. This paper proposes two efficient
and highly scalable parallel graph generation algorithms that can produce
massive realistic graphs to address this issue. The algorithms, designed to
achieve high degree of parallelism by minimizing inter-processor
communications, are two of the fastest graph generators which are capable of
generating scale-free graphs with billions of vertices and edges. The synthetic
graphs generated by the proposed methods possess the most common properties of
real complex networks such as power-law degree distribution, small-worldness,
and communities-within-communities. Scalability was tested on a large cluster
at Lawrence Livermore National Laboratory. In the experiment, we were able to
generate a graph with 1 billion vertices and 5 billion edges in less than 13
seconds. To the best of our knowledge, this is the largest synthetic scale-free
graph reported in the literature."
"Cloud computing promises a radical shift in the provisioning of computing
resource within the enterprise. This paper: i) describes the challenges that
decision makers face when attempting to determine the feasibility of the
adoption of cloud computing in their organisations; ii) illustrates a lack of
existing work to address the feasibility challenges of cloud adoption in the
enterprise; iii) introduces the Cloud Adoption Toolkit that provides a
framework to support decision makers in identifying their concerns, and
matching these concerns to appropriate tools/techniques that can be used to
address them. The paper adopts a position paper methodology such that case
study evidence is provided, where available, to support claims. We conclude
that the Cloud Adoption Toolkit, whilst still under development, shows signs
that it is a useful tool for decision makers as it helps address the
feasibility challenges of cloud adoption in the enterprise."
"Cloud computing providers have setup several data centers at different
geographical locations over the Internet in order to optimally serve needs of
their customers around the world. However, existing systems do not support
mechanisms and policies for dynamically coordinating load distribution among
different Cloud-based data centers in order to determine optimal location for
hosting application services to achieve reasonable QoS levels. Further, the
Cloud computing providers are unable to predict geographic distribution of
users consuming their services, hence the load coordination must happen
automatically, and distribution of services must change in response to changes
in the load. To counter this problem, we advocate creation of federated Cloud
computing environment (InterCloud) that facilitates just-in-time,
opportunistic, and scalable provisioning of application services, consistently
achieving QoS targets under variable workload, resource and network conditions.
The overall goal is to create a computing environment that supports dynamic
expansion or contraction of capabilities (VMs, services, storage, and database)
for handling sudden variations in service demands.
  This paper presents vision, challenges, and architectural elements of
InterCloud for utility-oriented federation of Cloud computing environments. The
proposed InterCloud environment supports scaling of applications across
multiple vendor clouds. We have validated our approach by conducting a set of
rigorous performance evaluation study using the CloudSim toolkit. The results
demonstrate that federated Cloud computing model has immense potential as it
offers significant performance gains as regards to response time and cost
saving under dynamic workload scenarios."
"Minimizing waiting time for tasks waiting in the queue for execution is one
of the important scheduling cri-teria which took a wide area in scheduling
preemptive tasks. In this paper we present Changeable Time Quan-tum (CTQ)
approach combined with the round-robin algorithm, we try to adjust the time
quantum according to the burst times of the tasks in the ready queue. There are
two important benefits of using (CTQ) approach: minimizing the average waiting
time of the tasks, consequently minimizing the average turnaround time, and
keeping the number of context switches as low as possible, consequently
minimizing the scheduling overhead. In this paper, we consider the scheduling
problem for preemptive tasks, where the time costs of these tasks are known a
priori. Our experimental results demonstrate that CTQ can provide much lower
scheduling overhead and better scheduling criteria."
"To save cost, recently more and more users choose to provision virtual
machine resources in cluster systems, especially in data centres. Maintaining a
consistent member view is the foundation of reliable cluster managements, and
it also raises several challenge issues for large scale cluster systems
deployed with virtual machines (which we call virtualized clusters). In this
paper, we introduce our experiences in design and implementation of scalable
member view management on large-scale virtual clusters. Our research
contributions are three-fold: 1) we propose a scalable and reliable management
infrastructure that combines a peer-to-peer structure and a hierarchy structure
to maintain a consistent member view in virtual clusters; 2) we present a
light-weighted group membership algorithm that can reach the consistent member
view within a single round of message exchange; and 3) we design and implement
a scalable membership service that can provision virtual machines and maintain
a consistent member view in virtual clusters. Our work is verified on Dawning
5000A, which ranked No.10 of Top 500 super computers in November, 2008."
"Computational Grid is enormous environments with heterogeneous resources and
stable infrastructures among other Internet-based computing systems. However,
the managing of resources in such systems has its special problems. Scheduler
systems need to get last information about participant nodes from information
centers for the purpose of firmly job scheduling. In this paper, we focus on
online updating resource information centers with processed and provided data
based on the assumed hierarchical model. A hybrid knowledge extraction method
has been used to classifying grid nodes based on prediction of jobs' features.
An affirmative point of this research is that scheduler systems don't waste
extra time for getting up-to-date information of grid nodes. The experimental
result shows the advantages of our approach compared to other conservative
methods, especially due to its ability to predict the behavior of nodes based
on comprehensive data tables on each node."
"Self-stabilization is an versatile approach to fault-tolerance since it
permits a distributed system to recover from any transient fault that
arbitrarily corrupts the contents of all memories in the system. Byzantine
tolerance is an attractive feature of distributed system that permits to cope
with arbitrary malicious behaviors. We consider the well known problem of
constructing a maximum metric tree in this context. Combining these two
properties prove difficult: we demonstrate that it is impossible to contain the
impact of Byzantine nodes in a self-stabilizing context for maximum metric tree
construction (strict stabilization). We propose a weaker containment scheme
called topology-aware strict stabilization, and present a protocol for
computing maximum metric trees that is optimal for this scheme with respect to
impossibility result."
"In mobile database environments, multiple users may access similar data items
irrespective of their physical location leading to concurrent access anomalies.
As disconnections and mobility are the common characteristics in mobile
environment, performing concurrent access to a particular data item leads to
inconsistency. Most of the approaches use locking mechanisms to achieve
concurrency control. However this leads to increase in blocking and abort rate.
In this paper an optimistic concurrency control strategy using on-demand
multicasting is proposed for mobile database environments which guarantees
consistency and introduces application-specific conflict detection and
resolution strategies. The simulation results specify increase in system
throughput by reducing the transaction abort rates as compared to the other
optimistic strategies proposed in literature."
"Efficiency and simplicity of random algorithms have made them a lucrative
alternative for solving complex problems in the domain of communication
networks. This paper presents a random algorithm for handling the routing
problem in Mobile Ad hoc Networks [MANETS].The performance of most existing
routing protocols for MANETS degrades in terms of packet delay and congestion
caused as the number of mobile nodes increases beyond a certain level or their
speed passes a certain level. As the network becomes more and more dynamic,
congestion in network increases due to control packets generated by the routing
protocols in the process of route discovery and route maintenance. Most of this
congestion is due to flooding mechanism used in protocols like AODV and DSDV
for the purpose of route discovery and route maintenance or for route discovery
as in the case of DSR protocol. This paper introduces the concept of random
routing algorithm that neither maintains a routing table nor floods the entire
network as done by various known protocols thereby reducing the load on network
in terms of number of control packets in a highly dynamic scenario. This paper
calculates the expected run time of the designed random algorithm."
"Cloud computing refers to a paradigm shift to overall IT solutions while
raising the accessibility, scalability and effectiveness through its enabling
technologies. However, migrated cloud platforms and services cost benefits as
well as performances are neither clear nor summarized. Globalization and the
recessionary economic times have not only raised the bar of a better IT
delivery models but also have given access to technology enabled services via
internet. Cloud computing has vast potential in terms of lean Retail
methodologies that can minimize the operational cost by using the third party
based IT capabilities, as a service. It will not only increase the ROI but will
also help in lowering the total cost of ownership. In this paper we have tried
to compare the cloud computing cost benefits with the actual premise cost which
an organization incurs normally. However, in spite of the cost benefits, many
IT professional believe that the latest model i.e. ""cloud computing"" has risks
and security concerns. This report demonstrates how to answer the following
questions: (1) Idea behind cloud computing. (2) Monetary cost benefits of using
cloud with respect to traditional premise computing. (3) What are the various
security issues? We have tried to find out the cost benefit by comparing the
Microsoft Azure cloud cost with the prevalent premise cost."
"This paper presents the overall design of a multi-agent framework for tuning
the performance of an application executing in a distributed environment. The
multi-agent framework provides services like resource brokering, analyzing
performance monitoring data, local tuning and also rescheduling in case of any
performance problem on a specific resource provider. The paper also briefly
describes the implementation of some part of the framework. In particular, job
migration on the basis of performance monitoring data is particularly
highlighted in this paper."
"In a heterogeneous, dynamic environment, like Grid, post-mortem analysis is
of no use and data needs to be collected and analysed in real time. Novel
techniques are also required for dynamically tuning the application's
performance and resource brokering in order to maintain the desired QoS. The
objective of this paper is to propose an integrated framework for performance
analysis and tuning of the application, and rescheduling the application, if
necessary, to some other resources in order to adapt to the changing resource
usage scenario in a dynamic environment."
"We present the \emph{discrete beeping} communication model, which assumes
nodes have minimal knowledge about their environment and severely limited
communication capabilities. Specifically, nodes have no information regarding
the local or global structure of the network, don't have access to synchronized
clocks and are woken up by an adversary. Moreover, instead on communicating
through messages they rely solely on carrier sensing to exchange information.
We study the problem of \emph{interval coloring}, a variant of vertex coloring
specially suited for the studied beeping model. Given a set of resources, the
goal of interval coloring is to assign every node a large contiguous fraction
of the resources, such that neighboring nodes share no resources. To highlight
the importance of the discreteness of the model, we contrast it against a
continuous variant described in [17]. We present an O(1$ time algorithm that
terminates with probability 1 and assigns an interval of size
$\Omega(T/\Delta)$ that repeats every $T$ time units to every node of the
network. This improves an $O(\log n)$ time algorithm with the same guarantees
presented in \cite{infocom09}, and accentuates the unrealistic assumptions of
the continuous model. Under the more realistic discrete model, we present a Las
Vegas algorithm that solves $\Omega(T/\Delta)$-interval coloring in $O(\log n)$
time with high probability and describe how to adapt the algorithm for dynamic
networks where nodes may join or leave. For constant degree graphs we prove a
lower bound of $\Omega(\log n)$ on the time required to solve interval coloring
for this model against randomized algorithms. This lower bound implies that our
algorithm is asymptotically optimal for constant degree graphs."
"A simple method for improving cache efficiency of serial and parallel
explicit finite procedure with application to casting solidification simulation
over three-dimensional complex geometries is presented. The method is based on
division of the global data to smaller blocks and treating each block
independently from others at each time step. A novel parallel finite element
algorithm for non-overlapped element-base decomposed domain is presented for
implementation of serial and parallel version of the presented method. Effect
of mesh reordering on the efficiency is also investigated. A simple algorithm
is presented for high quality decomposition of decoupled global mesh. Our
result shows 10-20 \% performance improvement by mesh reordering and 1.2-2.2
speedup with application of the presented cache efficient algorithm (for serial
and parallel versions). Also the presented parallel solver (without
cache-efficient feature) shows nearly linear speedup on the traditional
Ethernet networked Linux cluster."
"Self-stabilization is a versatile approach to fault-tolerance since it
permits a distributed system to recover from any transient fault that
arbitrarily corrupts the contents of all memories in the system. Byzantine
tolerance is an attractive feature of distributed systems that permits to cope
with arbitrary malicious behaviors. Combining these two properties proved
difficult: it is impossible to contain the spatial impact of Byzantine nodes in
a self-stabilizing context for global tasks such as tree orientation and tree
construction. We present and illustrate a new concept of Byzantine containment
in stabilization. Our property, called Strong Stabilization enables to contain
the impact of Byzantine nodes if they actually perform too many Byzantine
actions. We derive impossibility results for strong stabilization and present
strongly stabilizing protocols for tree orientation and tree construction that
are optimal with respect to the number of Byzantine nodes that can be tolerated
in a self-stabilizing context."
"Self-stabilization is a versatile approach to fault-tolerance since it
permits a distributed system to recover from any transient fault that
arbitrarily corrupts the contents of all memories in the system. Byzantine
tolerance is an attractive feature of distributed systems that permits to cope
with arbitrary malicious behaviors. We consider the well known problem of
constructing a breadth-first spanning tree in this context. Combining these two
properties proves difficult: we demonstrate that it is impossible to contain
the impact of Byzantine nodes in a strictly or strongly stabilizing manner. We
then adopt the weaker scheme of topology-aware strict stabilization and we
present a similar weakening of strong stabilization. We prove that the
classical $min+1$ protocol has optimal Byzantine containment properties with
respect to these criteria."
"Managing the transactions in real time distributed computing system is not
easy, as it has heterogeneously networked computers to solve a single problem.
If a transaction runs across some different sites, it may commit at some sites
and may failure at another site, leading to an inconsistent transaction. The
complexity is increase in real time applications by placing deadlines on the
response time of the database system and transactions processing. Such a system
needs to process Transactions before these deadlines expired. A series of
simulation study have been performed to analyze the performance under different
transaction management under conditions such as different workloads,
distribution methods, execution mode-distribution and parallel etc. The
scheduling of data accesses are done in order to meet their deadlines and to
minimize the number of transactions that missed deadlines. A new concept is
introduced to manage the transactions in dynamic ways rather than setting
computing parameters in static ways. With this approach, the system gives a
significant improvement in performance."
"Coordinated checkpointing is an effective fault tolerant technique in
distributed system as it avoids the domino effect and require minimum storage
requirement. Most of the earlier coordinated checkpoint algorithms block their
computation during checkpointing and forces minimum-process or non-blocking but
forces all nodes to takes checkpoint even though many of them may not be
necessary or non-blocking minimum-process but takes useless checkpoints or
reduced useless checkpoint but has higher synchronization message overhead or
has high checkpoint request propagation time. Hence in mobile distributed
systems there is a great need of minimizing the number of communication message
and checkpointing overhead as it raise new issues such as mobility, low
bandwidth of wireless channels, frequently disconnections, limited battery
power and lack of reliable stable storage on mobile nodes. In this paper, we
propose a minimum-process coordinated checkpointing algorithm for mobile
distributed system where no useless checkpoints are taken, no blocking of
processes takes place and enforces a minimum-number of processes to take
checkpoints. Our algorithm imposes low memory and computation overheads on MH's
and low communication overheads on wireless channels. It avoids awakening of an
MH if it is not required to take its checkpoint and has reduced latency time as
each process involved in a global checkpoint can forward its own decision
directly to the checkpoint initiator."
"Cloud Data Servers is the novel approach for providing secure service to
e-business .Millions of users are surfing the Cloud for various purposes,
therefore they need highly safe and persistent services. Usually hackers target
particular Operating Systems or a Particular Controller. Inspiteof several
ongoing researches Conventional Web Servers and its Intrusion Detection System
might not be able to detect such attacks. So we implement a Cloud Data Server
with Session Controller Architecture using Redundancy and Disconnected Data
Access Mechanism. In this paper, we generate the hash code using MD5 algorithm.
With the help of which we can circumvent even the attacks, which are undefined
by traditional Systems .we implement Cloud Data Sever using Java and Hash Code
backup Management using My SQL. Here we Implement AES Algorithm for providing
more Security for the hash Code. The CDS using the Virtual Controller controls
and monitors the Connections and modifications of the page so as to prevent
malicious users from hacking the website. In the proposed approach an activity
analyzer takes care of intimating the administrator about possible intrusions
and the counter measures required to tackle them. The efficiency ratio of our
approach is 98.21% compared with similar approaches."
"The paper presents three self-stabilizing protocols for basic fair and
reliable link communication primitives. We assume a link-register communication
model under read/write atomicity, where every process can read from but cannot
write into its neighbours' registers. The first primitive guarantees that any
process writes a new value in its register(s) only after all its neighbours
have read the previous value, whatever the initial scheduling of processes'
actions. The second primitive implements a ""weak rendezvous"" communication
mechanism by using an alternating bit protocol: whenever a process
consecutively writes n values (possibly the same ones) in a register, each
neighbour is guaranteed to read each value from the register at least once. On
the basis of the previous protocol, the third primitive implements a ""quasi
rendezvous"": in words, this primitive ensures furthermore that there exists
exactly one reading between two writing operations All protocols are
self-stabilizing and run in asynchronous arbitrary networks. The goal of the
paper is in handling each primitive by a separate procedure, which can be used
as a ""black box"" in more involved self-stabilizing protocols."
"Cloud computing is offering utility-oriented IT services to users worldwide.
Based on a pay-as-you-go model, it enables hosting of pervasive applications
from consumer, scientific, and business domains. However, data centers hosting
Cloud applications consume huge amounts of energy, contributing to high
operational costs and carbon footprints to the environment. Therefore, we need
Green Cloud computing solutions that can not only save energy for the
environment but also reduce operational costs. This paper presents vision,
challenges, and architectural elements for energy-efficient management of Cloud
computing environments. We focus on the development of dynamic resource
provisioning and allocation algorithms that consider the synergy between
various data center infrastructures (i.e., the hardware, power units, cooling
and software), and holistically work to boost data center energy efficiency and
performance. In particular, this paper proposes (a) architectural principles
for energy-efficient management of Clouds; (b) energy-efficient resource
allocation policies and scheduling algorithms considering quality-of-service
expectations, and devices power usage characteristics; and (c) a novel software
technology for energy-efficient management of Clouds. We have validated our
approach by conducting a set of rigorous performance evaluation study using the
CloudSim toolkit. The results demonstrate that Cloud computing model has
immense potential as it offers significant performance gains as regards to
response time and cost saving under dynamic workload scenarios."
"Youpi stands for ""YOUpi is your processing PIpeline"". It is a portable, easy
to use web application providing high level functionalities to perform data
reduction on scientific FITS images. It is built on top of open source
processing tools that are released to the community by Terapix, in order to
organize your data on a computer cluster, to manage your processing jobs in
real time and to facilitate teamwork by allowing fine-grain sharing of results
and data. On the server side, Youpi is written in the Python programming
language and uses the Django web framework. On the client side, Ajax techniques
are used along with the Prototype and script.aculo.us Javascript librairies."
"In this paper, a method for efficient scheduling to obtain optimum job
throughput in a distributed campus grid environment is presented; Traditional
job schedulers determine job scheduling using user and job resource attributes.
User attributes are related to current usage, historical usage, user priority
and project access. Job resource attributes mainly comprise of soft
requirements (compilers, libraries) and hard requirements like memory, storage
and interconnect. A job scheduler dispatches jobs to a resource if a job's hard
and soft requirements are met by a resource. In current scenario during
execution of a job, if a resource becomes unavailable, schedulers are presented
with limited options, namely re-queuing job or migrating job to a different
resource. Both options are expensive in terms of data and compute time. These
situations can be avoided, if the often ignored factor, availability time of a
resource in a grid environment is considered. We propose resource rank
approach, in which jobs are dispatched to a resource which has the highest rank
among all resources that match the job's requirement. The results show that our
approach can increase throughput of many serial / monolithic jobs."
"Event ordering in distributed system (DS) is disputable and proactive subject
in DS particularly with the emergence of multimedia synchronization. According
to the literature, different type of event ordering is used for different DS
mode such as asynchronous or synchronous. Recently, there are several novel
implementation of these types introduced to fulfill the demand for establishing
a certain order according to a specific criterion in DS with lighter
complexity."
"As more and more service providers choose Cloud platforms, which is provided
by third party resource providers, resource providers needs to provision
resources for heterogeneous workloads in different Cloud scenarios. Taking into
account the dramatic differences of heterogeneous workloads, can we
coordinately provision resources for heterogeneous workloads in Cloud
computing? In this paper we focus on this important issue, which is
investigated by few previous work. Our contributions are threefold: (1) we
respectively propose a coordinated resource provisioning solution for
heterogeneous workloads in two typical Cloud scenarios: first, a large
organization operates a private Cloud for two heterogeneous workloads; second,
a large organization or two service providers running heterogeneous workloads
revert to a public Cloud; (2) we build an agile system PhoenixCloud that
enables a resource provider to create coordinated runtime environments on
demand for heterogeneous workloads when they are consolidated on a Cloud site;
and (3) A comprehensive evaluation has been performed in experiments. For two
typical heterogeneous workload traces: parallel batch jobs and Web services,
our experiments show that: a) in a private Cloud scenario, when the throughput
is almost same like that of a dedicated cluster system, our solution decreases
the configuration size of a cluster by about 40%; b) in a public Cloud
scenario, our solution decreases not only the total resource consumption, but
also the peak resource consumption maximally to 31% with respect to that of EC2
+RightScale solution."
"There are numerous examples of problems in symbolic algebra in which the
required storage grows far beyond the limitations even of the distributed RAM
of a cluster. Often this limitation determines how large a problem one can
solve in practice. Roomy provides a minimally invasive system to modify the
code for such a computation, in order to use the local disks of a cluster or a
SAN as a transparent extension of RAM.
  Roomy is implemented as a C/C++ library. It provides some simple data
structures (arrays, unordered lists, and hash tables). Some typical programming
constructs that one might employ in Roomy are: map, reduce, duplicate
elimination, chain reduction, pair reduction, and breadth-first search. All
aspects of parallelism and remote I/O are hidden within the Roomy library."
"The evolution of distributed architectures and programming paradigms for
performance-oriented program development, challenge the state-of-the-art
technology for performance tools. The area of high performance computing is
rapidly expanding from single parallel systems to clusters and grids of
heterogeneous sequential and parallel systems. Performance analysis and tuning
applications is becoming crucial because it is hardly possible to otherwise
achieve the optimum performance of any application. The objective of this paper
is to study the state-of-the-art technology of the existing performance tools
for distributed systems. The paper surveys some representative tools from
different aspects in order to highlight the approaches and technologies used by
them."
"In this paper, we present the first snap-stabilizing message forwarding
protocol that uses a number of buffers per node being inde- pendent of any
global parameter, that is 4 buffers per link. The protocol works on a linear
chain of nodes, that is possibly an overlay on a large- scale and dynamic
system, e.g., Peer-to-Peer systems, Grids. . . Provided that the topology
remains a linear chain and that nodes join and leave ""neatly"", the protocol
tolerates topology changes. We expect that this protocol will be the base to
get similar results on more general topologies."
"We describe an approach to modelling a Byzantine tolerant distributed
algorithm as a family of related finite state machines, generated from a single
meta-model. Various artefacts are generated from each state machine, including
diagrams and source-level protocol implementations. The approach allows a state
machine formulation to be applied to problems for which it would not otherwise
be suitable, increasing confidence in correctness."
"In this paper we demonstrate how stateful Byzantine Fault Tolerant services
may be hosted on a Chord ring. The strategy presented is fourfold: firstly a
replication scheme that dissociates the maintenance of replicated service state
from ring recovery is developed. Secondly, clients of the ring based services
are made replication aware. Thirdly, a consensus protocol is introduced that
supports the serialization of updates. Finally Byzantine fault tolerant
replication protocols are developed that ensure the integrity of service data
hosted on the ring."
"The persistent programming systems of the 1980s offered a programming model
that integrated computation and long-term storage. In these systems, reliable
applications could be engineered without requiring the programmer to write
translation code to manage the transfer of data to and from non-volatile
storage. More importantly, it simplified the programmer's conceptual model of
an application, and avoided the many coherency problems that result from
multiple cached copies of the same information. Although technically
innovative, persistent languages were not widely adopted, perhaps due in part
to their closed-world model. Each persistent store was located on a single
host, and there were no flexible mechanisms for communication or transfer of
data between separate stores. Here we re-open the work on persistence and
combine it with modern peer-to-peer techniques in order to provide support for
orthogonal persistence in resilient and potentially long-running distributed
applications. Our vision is of an infrastructure within which an application
can be developed and distributed with minimal modification, whereupon the
application becomes resilient to certain failure modes. If a node, or the
connection to it, fails during execution of the application, the objects are
re-instantiated from distributed replicas, without their reference holders
being aware of the failure. Furthermore, we believe that this can be achieved
within a spectrum of application programmer intervention, ranging from minimal
to totally prescriptive, as desired. The same mechanisms encompass an
orthogonally persistent programming model. We outline our approach to
implementing this vision, and describe current progress."
"Middleware technologies often limit the way in which object classes may be
used in distributed applications due to the fixed distribution policies that
they impose. These policies permeate applications developed using existing
middleware systems and force an unnatural encoding of application level
semantics. For example, the application programmer has no direct control over
inter-address-space parameter passing semantics. Semantics are fixed by the
distribution topology of the application, which is dictated early in the design
cycle. This creates applications that are brittle with respect to changes in
distribution. This paper explores technology that provides control over the
extent to which inter-address-space communication is exposed to programmers, in
order to aid the creation, maintenance and evolution of distributed
applications. The described system permits arbitrary objects in an application
to be dynamically exposed for remote access, allowing applications to be
written without concern for distribution. Programmers can conceal or expose the
distributed nature of applications as required, permitting object placement and
distribution boundaries to be decided late in the design cycle and even
dynamically. Inter-address-space parameter passing semantics may also be
decided independently of object implementation and at varying times in the
design cycle, again possibly as late as run-time. Furthermore, transmission
policy may be defined on a per-class, per-method or per-parameter basis,
maximizing plasticity. This flexibility is of utility in the development of new
distributed applications, and the creation of management and monitoring
infrastructures for existing applications."
"We believe that to fully support adaptive distributed applications,
middleware must itself be adaptable, adaptive and policy-free. In this paper we
present a new language-independent adaptable and adaptive policy framework
suitable for integration in a wide variety of middleware systems. This
framework facilitates the construction of adaptive distributed applications.
The framework addresses adaptability through its ability to represent a wide
range of specific middleware policies. Adaptiveness is supported by a rich
contextual model, through which an application programmer may control precisely
how policies should be selected for any particular interaction with the
middleware. A contextual pattern mechanism facilitates the succinct expression
of both coarse- and fine-grain policy contexts. Policies may be specified and
altered dynamically, and may themselves take account of dynamic conditions. The
framework contains no hard-wired policies; instead, all policies can be
configured."
"In this paper we present a methodology and set of tools which assist the
construction of applications from components, by separating the issues of
transmission policy from component definition and implementation. This promotes
a greater degree of software reuse than is possible using traditional
middleware environments. Whilst component technologies are usually presented as
a mechanism for promoting reuse, reuse is often limited due to design choices
that permeate component implementation. The programmer has no direct control
over inter-address-space parameter passing semantics: it is fixed by the
distributed application's structure, based on the remote accessibility of the
components. Using traditional middleware tools and environments, the
application designer may be forced to use an unnatural encoding of application
level semantics since application parameter passing semantics are tightly
coupled with the component deployment topology. This paper describes how
inter-address-space parameter passing semantics may be decided independently of
component implementation. Transmission policy may be dynamically defined on a
per-class, per-method or per-parameter basis."
"Middleware technologies often limit the way in which object classes may be
used in distributed applications due to the fixed distribution policies imposed
by the Middleware system. These policies permeate the applications developed
using them and force an unnatural encoding of application level semantics. For
example, the application programmer has no direct control over
inter-address-space parameter passing semantics since it is fixed by the
application's distribution topology which is dictated early in the design cycle
by the Middleware. This creates applications that are brittle with respect to
changes in the way in which the applications are distributed. This paper
explores technology permitting arbitrary objects in an application to be
dynamically exposed for remote access. Using this, the application can be
written without concern for its distribution with object placement and
distribution boundaries decided late in the design cycle and even dynamically.
Inter-address-space parameter passing semantics may also be decided
independently of object implementation and at varying times in the design
cycle, again, possibly as late as run-time. Furthermore, transmission policy
may be defined on a per-class, per-method or per-parameter basis maximizing
plasticity. This flexibility is of utility in the development of new
distributed applications and the creation of management and monitoring
infrastructures for existing applications."
"The hypercube is one of the most popular interconnection networks since it
has simple structure and is easy to implement. The $n$-dimensional twisted
cube, denoted by $TQ_n$, an important variation of the hypercube, possesses
some properties superior to the hypercube. Recently, some interesting
properties of $TQ_n$ were investigated. In this paper, we construct two
edge-disjoint Hamiltonian cycles in $TQ_n$ for any odd integer $n\geqslant 5$.
The presence of two edge-disjoint Hamiltonian cycles provides an advantage when
implementing two algorithms that require a ring structure by allowing message
traffic to be spread evenly across the twisted cube. Furthermore, we construct
two equal node-disjoint cycles in $TQ_n$ for any odd integer $n\geqslant 3$, in
which these two cycles contain the same number of nodes and every node appears
in one cycle exactly once. In other words, we decompose a twisted cube into two
components with the same size such that each component contains a Hamiltonian
cycle."
"In this paper, we study the convergence behavior of distributed iterative
algorithms with quantized message passing. We first introduce general iterative
function evaluation algorithms for solving fixed point problems distributively.
We then analyze the convergence of the distributed algorithms, e.g. Jacobi
scheme and Gauss-Seidel scheme, under the quantized message passing. Based on
the closed-form convergence performance derived, we propose two quantizer
designs, namely the time invariant convergence-optimal quantizer (TICOQ) and
the time varying convergence-optimal quantizer (TVCOQ), to minimize the effect
of the quantization error on the convergence. We also study the tradeoff
between the convergence error and message passing overhead for both TICOQ and
TVCOQ. As an example, we apply the TICOQ and TVCOQ designs to the iterative
waterfilling algorithm of MIMO interference game."
"This paper explores technology permitting arbitrary application components to
be exposed for remote access from other software. Using this, the application
and its constituent components can be written without concern for its
distribution. Software running in different address spaces, on different
machines, can perform operations on the remotely accessible components. This is
of utility in the creation of distributed applications and in permitting tools
such as debuggers, component browsers, observers or remote probes access to
application components. Current middleware systems do not allow arbitrary
exposure of application components: instead, the programmer is forced to decide
statically which classes of component will support remote accessibility. In the
work described here, arbitrary components of any class can be dynamically
exposed via Web Services. Traditional Web Services are extended with a remote
reference scheme. This extension permits application components to be invoked
using either the traditional pass-by-value semantics supported by Web Services
or pass-by-reference semantics. The latter permits the preservation of local
call semantics across address space boundaries."
"This paper describes an implemented system which is designed to support the
deployment of applications offering distributed services, comprising a number
of distributed components. This is achieved by creating high level placement
and topology descriptions which drive tools that deploy applications consisting
of components running on multiple hosts. The system addresses issues of
heterogeneity by providing abstractions over host-specific attributes yielding
a homogeneous run-time environment into which components may be deployed. The
run-time environments provide secure binding mechanisms that permit deployed
components to bind to stored data and services on the hosts on which they are
running."
"We propose a framework for deployment and subsequent autonomic management of
component-based distributed applications. An initial deployment goal is
specified using a declarative constraint language, expressing constraints over
aspects such as component-host mappings and component interconnection topology.
A constraint solver is used to find a configuration that satisfies the goal,
and the configuration is deployed automatically. The deployed application is
instrumented to allow subsequent autonomic management. If, during execution,
the manager detects that the original goal is no longer being met, the
satisfy/deploy process can be repeated automatically in order to generate a
revised deployment that does meet the goal."
"Distributed systems with different levels of dependence to central services
have been designed and used during recent years. Pure peer-to-peer systems
among distributed systems have no dependence on a central resource. DHT is one
of the main techniques behind these systems resulting into failure tolerant
systems which are also able to isolate continuous changes to the network to a
small section of it and therefore making it possible to scale up such networks
to millions of nodes. This survey takes a look at P2P in general and DHT
algorithms and implementations in more detail."
"We propose a framework for the deployment and subsequent autonomic management
of component-based distributed applications. An initial deployment goal is
specified using a declarative constraint language, expressing constraints over
aspects such as component-host mappings and component interconnection topology.
A constraint solver is used to find a configuration that satisfies the goal,
and the configuration is deployed automatically. The deployed application is
instrumented to allow subsequent autonomic management. If, during execution,
the manager detects that the original goal is no longer being met, the
satisfy/deploy process can be repeated automatically in order to generate a
revised deployment that does meet the goal."
"We propose a middleware framework for deployment and subsequent autonomic
management of component-based distributed applications. An initial deployment
goal is specified using a declarative constraint language, expressing
constraints over aspects such as component-host mappings and component
interconnection topology. A constraint solver is used to find a configuration
that satisfies the goal, and the configuration is deployed automatically. The
deployed application is instrumented to allow subsequent autonomic management.
If, during execution, the manager detects that the original goal is no longer
being met, the satisfy/deploy process can be repeated automatically in order to
generate a revised deployment that does meet the goal."
"Pervasive services may be defined as services that are available ""to any
client (anytime, anywhere)"". Here we focus on the software and network
infrastructure required to support pervasive contextual services operating over
a wide area. One of the key requirements is a matching service capable of
as-similating and filtering information from various sources and determining
matches relevant to those services. We consider some of the challenges in
engineering a globally distributed matching service that is scalable,
manageable, and able to evolve incrementally as usage patterns, data formats,
services, network topologies and deployment technologies change. We outline an
approach based on the use of a peer-to-peer architecture to distribute user
events and data, and to support the deployment and evolution of the
infrastructure itself."
"A GLObal Smart Space (GLOSS) provides support for interaction amongst people,
artefacts and places while taking account of both context and movement on a
global scale. Crucial to the definition of a GLOSS is the provision of a set of
location-aware services that detect, convey, store and exploit location
information. We use one of these services, hearsay, to illustrate the
implementation dimensions of a GLOSS. The focus of the paper is on both local
and global software architecture to support the implementation of such
services. The local architecture is based on XML pipe-lines and is used to
construct location-aware components. The global architecture is based on a
hybrid peer-to-peer routing scheme and provides the local architectures with
the means to communicate in the global context."
"Motivated by Kleinberg's (2000) and subsequent work, we consider the
performance of greedy routing on a directed ring of $n$ nodes augmented with
long-range contacts. In this model, each node $u$ is given an additional $D_u$
edges, a degree chosen from a specified probability distribution. Each such
edge from $u$ is linked to a random node at distance $r$ ahead in the ring with
probability proportional to $1/r$, a ""harmonic"" distance distribution of
contacts. Aspnes et al. (2002) have shown an $O(\log^2 n / \ell)$ bound on the
expected length of greedy routes in the case when each node is assigned exactly
$\ell$ contacts and, as a consequence of recent work by Dietzfelbinger and
Woelfel (2009), this bound is known to be tight. In this paper, we generalize
Aspnes' upper bound to show that any degree distribution with mean $\ell$ and
maximum value $O(\log n)$ has greedy routes of expected length $O(\log^2n /
\ell)$, implying that any harmonic ring in this family is asymptotically
optimal. Furthermore, for a more general family of rings, we show that a fixed
degree distribution is optimal. More precisely, if each random contact is
chosen at distance $r$ with a probability that decreases with $r$, then among
degree distributions with mean $\ell$, greedy routing time is smallest when
every node is assigned $\floor{\ell}$ or $\ceiling{\ell}$ contacts."
"Entity matching is an important and difficult step for integrating web data.
To reduce the typically high execution time for matching we investigate how we
can perform entity matching in parallel on a distributed infrastructure. We
propose different strategies to partition the input data and generate multiple
match tasks that can be independently executed. One of our strategies supports
both, blocking to reduce the search space for matching and parallel matching to
improve efficiency. Special attention is given to the number and size of data
partitions as they impact the overall communication overhead and memory
requirements of individual match tasks. We have developed a service-based
distributed infrastructure for the parallel execution of match workflows. We
evaluate our approach in detail for different match strategies for matching
real-world product data of different web shops. We also consider caching of
in-put entities and affinity-based scheduling of match tasks."
"In this report we demonstrate the potential utility of resource allocation
management systems that use virtual machine technology for sharing parallel
computing resources among competing jobs. We formalize the resource allocation
problem with a number of underlying assumptions, determine its complexity,
propose several heuristic algorithms to find near-optimal solutions, and
evaluate these algorithms in simulation. We find that among our algorithms one
is very efficient and also leads to the best resource allocations. We then
describe how our approach can be made more general by removing several of the
underlying assumptions."
"Recent proliferation of embedded systems has generated a bold new paradigm,
known as open embedded systems. While traditional embedded systems provide only
closed base applications (natively-installed software) to users, open embedded
systems allow the users to freely execute open applications
(additionally-installed software) in order to meet various user requirements,
such as user personalization and device coordination. Key to the success of
platforms required for open embedded systems is the achievement of both the
scalable extension of base applications and the secure execution of open
applications. Most existing platforms, however, have focused on either scalable
or secure execution, limiting their applicability. This dissertation presents a
new secure platform using multi-core processors, which achieves both
scalability and security. Four techniques feature the new platform: (1)
seamless communication, by which legacy applications designed for a single
processor make it possible to be executed on multiple processors without any
software modifications; (2) secure processor partitioning with hardware
support, by which Operating Systems (OSs) required for base and open
applications are securely executed on separate processors; (3) asymmetric
virtualization, by which many OSs over the number of processors are securely
executed under secure processor partitioning; and (4) secure dynamic
partitioning, by which the number of processors allocated to individual OSs
makes it possible to be dynamically changed under secure processor
partitioning."
"Current middleware systems suffer from drawbacks. Often one is forced to make
decisions early in the design process about which classes may participate in
inter-machine communication. Further, application level and middleware specific
semantics cannot be separated forcing an unnatural design. The RAFDA project
proposes to adress these deficiencies by creating an adaptive, reflective
framework that enables the transformation of non-distributed applications into
isomorphic applications whose distribution architecture is flexible. This paper
describes the code transformation techniques that have been developed as part
of the project. The system enables the distribution of a program according to a
flexible configuration without user intervention. Proxy objects can then be
substituted, permitting cross-address space communication. The distributed
program can adapt to its environment by dynamically altering its distribution
boundaries."
"This document describes the Gloss Ontology. The ontology and associated class
model are organised into several packages. Section 2 describes each package in
detail, while Section 3 contains a summary of the whole ontology."
"In this paper we describe an architecture which: Permits the deployment and
execution of components in appropriate geographical locations. Provides
security mechanisms that prevent misuse of the architecture. Supports a
programming model that is familiar to application programmers. Permits
installed components to share data. Permits the deployed components to
communicate via communication channels. Provides evolution mechanisms
permitting the dynamic rearrangement of inter-connection topologies the
components that they connect. Supports the specification and deployment of
distributed component deployments."
"This document describes the Gloss infrastructure supporting implementation of
location-aware services. The document is in two parts. The first part describes
software architecture for the smart space. As described in D8, a local
architecture provides a framework for constructing Gloss applications, termed
assemblies, that run on individual physical nodes, whereas a global
architecture defines an overlay network for linking individual assemblies. The
second part outlines the hardware installation for local sensing. This
describes the first phase of the installation in Strathclyde University."
"We consider transactional memory contention management in the context of
balanced workloads, where if a transaction is writing, the number of write
operations it performs is a constant fraction of its total reads and writes. We
explore the theoretical performance boundaries of contention management in
balanced workloads from the worst-case perspective by presenting and analyzing
two new contention management algorithms. The first algorithm Clairvoyant is
O(\surd s)-competitive, where s is the number of shared resources. This
algorithm depends on explicitly knowing the conflict graph. The second
algorithm Non-Clairvoyant is O(\surd s \cdot log n)-competitive, with high
probability, which is only a O(log n) factor worse, but does not require
knowledge of the conflict graph, where n is the number of transactions. Both of
these algorithms are greedy. We also prove that the performance of Clairvoyant
is tight since there is no contention management algorithm that is better than
O((\surd s)^(1-\epsilon))-competitive for any constant \epsilon > 0, unless
NP\subseteq ZPP. To our knowledge, these results are significant improvements
over the best previously known O(s) competitive ratio bound."
"Most of the services viewed in context to grid and cloud computing are mostly
confined to services that are available for intellectual purposes. The grid or
cloud computing are large scale distributed systems. The essence of large scale
distribution can only be realized if the services are rendered to common man.
The only organization which has exposure to almost every single resident is the
respective governments in every country. As the size of population increases so
the need for a larger purview arises. The problem of having a large purview can
be solved by means of large scale grid for online services. The government
services can be rendered through fully customized Service-oriented Clouds. In
this paper we are presenting tight similarities between generic government
functioning and the service oriented grid/cloud approach. Also, we will discuss
the major issues in establishing services oriented grids for governmental
organization."
"Middleware technologies is a very big field, containing a strong already done
research as well as the currently running research to confirm already done
research's results and the to have some new solution by theoretical as well as
the experimental (practical) way. This document has been produced by Zeeshan
Ahmed (Student: Connectivity Software Technologies Blekinge Institute of
Technologies). This describes the research already done in the field of
middleware technologies including Web Services, Grid Computing, Grid Services
and Open Grid Service Infrastructure & Architecture. This document concludes
with the overview of Web (Grid) Service, Chain of Web (Grid) Services and the
necessary security issue."
"We present a sensor network testbed that monitors a hallway. It consists of
120 load sensors and 29 passive infrared sensors (PIRs), connected to 30
wireless sensor nodes. There are also 29 LEDs and speakers installed, operating
as actuators, and enabling a direct interaction between the testbed and
passers-by. Beyond that, the network is heterogeneous, consisting of three
different circuit boards---each with its specific responsibility. The design of
the load sensors is of extremely low cost compared to industrial solutions and
easily transferred to other settings. The network is used for in-network data
processing algorithms, offering possibilities to develop, for instance,
distributed target-tracking algorithms. Special features of our installation
are highly correlated sensor data and the availability of miscellaneous sensor
types."
"In data-intensive applications data transfer is a primary cause of job
execution delay. Data access time depends on bandwidth. The major bottleneck to
supporting fast data access in Grids is the high latencies of Wide Area
Networks and Internet. Effective scheduling can reduce the amount of data
transferred across the internet by dispatching a job to where the needed data
are present. Another solution is to use a data replication mechanism. Objective
of dynamic replica strategies is reducing file access time which leads to
reducing job runtime. In this paper we develop a job scheduling policy and a
dynamic data replication strategy, called HRS (Hierarchical Replication
Strategy), to improve the data access efficiencies. We study our approach and
evaluate it through simulation. The results show that our algorithm has
improved 12% over the current strategies."
"Recent advances in wireless sensor networks (WSNs) have led to many new
promissing applications. However data communication between nodes consumes a
large portion of the total energy of WSNs. Consequently efficient data
aggregation technique can help greatly to reduce power consumption. Data
aggregation has emerged as a basic approach in WSNs in order to reduce the
number of transmissions of sensor nodes over {\it aggregation tree} and hence
minimizing the overall power consumption in the network. If a sensor node fails
during data aggregation then the aggregation tree is disconnected. Hence the
WSNs rely on in-network aggregation for efficiency but a single faulty node can
severely influence the outcome by contributing an arbitrary partial aggregate
value.
  In this paper we have presented a distributed algorithm that reconstruct the
aggregation tree from the initial aggregation tree excluding the faulty sensor
node. This is a synchronous model that is completed in several rounds. Our
proposed scheme can handle multiple number of faulty nodes as well."
"In the coming decade, astronomical surveys of the sky will generate tens of
terabytes of images and detect hundreds of millions of sources every night. The
study of these sources will involve computation challenges such as anomaly
detection and classification, and moving object tracking. Since such studies
benefit from the highest quality data, methods such as image coaddition
(stacking) will be a critical preprocessing step prior to scientific
investigation. With a requirement that these images be analyzed on a nightly
basis to identify moving sources or transient objects, these data streams
present many computational challenges. Given the quantity of data involved, the
computational load of these problems can only be addressed by distributing the
workload over a large number of nodes. However, the high data throughput
demanded by these applications may present scalability challenges for certain
storage architectures. One scalable data-processing method that has emerged in
recent years is MapReduce, and in this paper we focus on its popular
open-source implementation called Hadoop. In the Hadoop framework, the data is
partitioned among storage attached directly to worker nodes, and the processing
workload is scheduled in parallel on the nodes that contain the required input
data. A further motivation for using Hadoop is that it allows us to exploit
cloud computing resources, e.g., Amazon's EC2. We report on our experience
implementing a scalable image-processing pipeline for the SDSS imaging database
using Hadoop. This multi-terabyte imaging dataset provides a good testbed for
algorithm development since its scope and structure approximate future surveys.
First, we describe MapReduce and how we adapted image coaddition to the
MapReduce framework. Then we describe a number of optimizations to our basic
approach and report experimental results comparing their performance."
"We consider the problem of clock synchronization in a wireless setting where
processors must power-down their radios in order to save energy. Energy
efficiency is a central goal in wireless networks, especially if energy
resources are severely limited. In the current setting, the problem is to
synchronize clocks of $m$ processors that wake up in arbitrary time points,
such that the maximum difference between wake up times is bounded by a positive
integer $n$, where time intervals are appropriately discretized. Currently, the
best-known results for synchronization for single-hop networks of $m$
processors is a randomized algorithm due to \cite{BKO09} of O(\sqrt {n /m}
\cdot poly-log(n)) awake times per processor and a lower bound of
Omega(\sqrt{n/m}) of the number of awake times needed per processor
\cite{BKO09}. The main open question left in their work is to close the
poly-log gap between the upper and the lower bound and to de-randomize their
probabilistic construction and eliminate error probability. This is exactly
what we do in this paper.
  That is, we show a {deterministic} algorithm with radio use of Theta(\sqrt {n
/m}) that never fails. We stress that our upper bound exactly matches the lower
bound proven in \cite{BKO09}, up to a small multiplicative constant. Therefore,
our algorithm is {optimal} in terms of energy efficiency and completely
resolves a long sequence of works in this area. In order to achieve these
results we devise a novel {adaptive} technique that determines the times when
devices power their radios on and off. In addition, we prove several lower
bounds on the energy efficiency of algorithms for {multi-hop networks}.
Specifically, we show that any algorithm for multi-hop networks must have radio
use of Omega(\sqrt n) per processor."
"Electing leader is a vital issue not only in distributed computing but also
in communication network [1, 2, 3, 4, 5], centralized mutual exclusion
algorithm [6, 7], centralized control IPC, etc. A leader is required to make
synchronization between different processes. And different election algorithms
are used to elect a coordinator among the available processes in the system
such a way that there will be only one coordinator at any time. Bully election
algorithm is one of the classical and well-known approaches in coordinator
election process. This paper will present a modified version of bully election
algorithm using a new concept called election commission. This approach will
not only reduce redundant elections but also minimize total number of elections
and hence it will minimize message passing, network traffic, and complexity of
the existing system."
"Algorithms come with multiple variants which are obtained by changing the
mathematical approach from which the algorithm is derived. These variants offer
a wide spectrum of performance when implemented on a multicore platform and we
seek to understand these differences in performances from a theoretical point
of view. To that aim, we derive and present the critical path lengths of each
algorithmic variant for our application problem which enables us to determine a
lower bound on the time to solution. This metric provides an intuitive grasp of
the performance of a variant and we present numerical experiments to validate
the tightness of our lower bounds on practical applications. Our case study is
the Cholesky inversion and its use in computing the inverse of a symmetric
positive definite matrix."
"We study the {edge-coloring} problem in the message-passing model of
distributed computing. This is one of the most fundamental and well-studied
problems in this area. Currently, the best-known deterministic algorithms for
(2Delta -1)-edge-coloring requires O(Delta) + log-star n time \cite{PR01},
where Delta is the maximum degree of the input graph. Also, recent results of
\cite{BE10} for vertex-coloring imply that one can get an
O(Delta)-edge-coloring in O(Delta^{epsilon} \cdot \log n) time, and an
O(Delta^{1 + epsilon})-edge-coloring in O(log Delta log n) time, for an
arbitrarily small constant epsilon > 0.
  In this paper we devise a drastically faster deterministic edge-coloring
algorithm. Specifically, our algorithm computes an O(Delta)-edge-coloring in
O(Delta^{epsilon}) + log-star n time, and an O(Delta^{1 +
epsilon})-edge-coloring in O(log Delta) + log-star n time. This result improves
the previous state-of-the-art {exponentially} in a wide range of Delta,
specifically, for 2^{Omega(\log-star n)} \leq Delta \leq polylog(n). In
addition, for small values of Delta our deterministic algorithm outperforms all
the existing {randomized} algorithms for this problem.
  On our way to these results we study the {vertex-coloring} problem on the
family of graphs with bounded {neighborhood independence}. This is a large
family, which strictly includes line graphs of r-hypergraphs for any r = O(1),
and graphs of bounded growth. We devise a very fast deterministic algorithm for
vertex-coloring graphs with bounded neighborhood independence. This algorithm
directly gives rise to our edge-coloring algorithms, which apply to {general}
graphs.
  Our main technical contribution is a subroutine that computes an
O(Delta/p)-defective p-vertex coloring of graphs with bounded neighborhood
independence in O(p^2) + \log-star n time, for a parameter p, 1 \leq p \leq
Delta."
"Group communication is becoming a more and more popular infrastructure for
efficient distributed applications. It consists in representing locally a group
of remote objects as a single object accessed in a single step; communications
are then broadcasted to all members. This paper provides models for automatic
verification of group-based applications, typically for detecting deadlocks or
checking message ordering. We show how to encode group communication, together
with different forms of synchronisation for group results. The proposed models
are parametric such that, for example, different group sizes or group members
could be experimented with the minimum modification of the original model."
"In Distributed Interactive Applications (DIA) such as multiplayer games,
where many participants are involved in a same game session and communicate
through a network, they may have an inconsistent view of the virtual world
because of the communication delays across the network. This issue becomes even
more challenging when communicating through a cellular network while executing
the DIA client on a mobile terminal. Consistency maintenance algorithms may be
used to obtain a uniform view of the virtual world. These algorithms are very
complex and hard to program and therefore, the implementation and the future
evolution of the application logic code become difficult. To solve this
problem, we propose an approach where the consistency concerns are handled
separately by a distributed component called a Synchronization Medium, which is
responsible for the communication management as well as the consistency
maintenance. We present the detailed architecture of the Synchronization Medium
and the generic interfaces it offers to DIAs. We evaluate our approach both
qualitatively and quantitatively. We first demonstrate that the Synchronization
Medium is a reusable component through the development of two game
applications, a car racing game and a space war game. A performance evaluation
then shows that the overhead introduced by the Synchronization Medium remains
acceptable."
"In recent years, extensive research has been conducted in the area of Service
Level Agreement (SLA) for utility computing systems. An SLA is a formal
contract used to guarantee that consumers' service quality expectation can be
achieved. In utility computing systems, the level of customer satisfaction is
crucial, making SLAs significantly important in these environments. Fundamental
issue is the management of SLAs, including SLA autonomy management or trade off
among multiple Quality of Service (QoS) parameters. Many SLA languages and
frameworks have been developed as solutions; however, there is no overall
classification for these extensive works. Therefore, the aim of this chapter is
to present a comprehensive survey of how SLAs are created, managed and used in
utility computing environment. We discuss existing use cases from Grid and
Cloud computing systems to identify the level of SLA realization in
state-of-art systems and emerging challenges for future research."
"Cloud infrastructures enable the efficient parallel execution of
data-intensive tasks such as entity resolution on large datasets. We
investigate challenges and possible solutions of using the MapReduce
programming model for parallel entity resolution. In particular, we propose and
evaluate two MapReduce-based implementations for Sorted Neighborhood blocking
that either use multiple MapReduce jobs or apply a tailored data replication."
"Virtualization has rapidly become a go-to technology for increasing
efficiency in the data center. With virtualization technologies providing
tremendous flexibility, even disparate architectures may be deployed on a
single machine without interference. Awareness of limitations and requirements
of physical hosts to be used for virtualization is important. This paper
reviews the present virtualization methods, virtual computing software, and
provides a brief analysis of the performance issues inherent to each. In the
end we present testing results of KVM-QEMU on two current Multi-Core CPU
Architectures and System Configurations."
"In this manuscript, we consider the problems of channel assignment in
wireless networks and data migration in heterogeneous storage systems. We show
that a soft edge coloring approach to both problems gives rigorous
approximation guarantees. In the channel assignment problem arising in wireless
networks a pair of edges incident to a vertex are said to be conflicting if the
channels assigned to them are the same. Our goal is to assign channels (color
edges) so that the number of conflicts is minimized. The problem is NP-hard by
a reduction from Edge coloring and we present two combinatorial algorithms for
this case. The first algorithm is based on a distributed greedy method and
gives a solution with at most $2(1-\frac{1}{k})|E|$ more conflicts than the
optimal solution.The approximation ratio if the second algorithm is $1 +
\frac{|V|}{|E|}$, which gives a ($1 + o(1)$)-factor for dense graphs and is the
best possible unless P = NP. We also consider the data migration problem in
heterogeneous storage systems. In such systems, data layouts may need to be
reconfigured over time for load balancing or in the event of system
failure/upgrades. It is critical to migrate data to their target locations as
quickly as possible to obtain the best performance of the system. Most of the
previous results on data migration assume that each storage node can perform
only one data transfer at a time. However, storage devices tend to have
heterogeneous capabilities as devices may be added over time due to storage
demand increase. We develop algorithms to minimize the data migration time. We
show that it is possible to find an optimal migration schedule when all $c_v$'s
are even. Furthermore, though the problem is NP-hard in general, we give an
efficient soft edge coloring algorithm that offers a rigorous $(1 +
o(1))$-approximation guarantee."
"Nowadays, several industrial applications are being ported to parallel
architectures. In fact, these platforms allow acquire more performance for
system modelling and simulation. In the electric machines area, there are many
problems which need speed-up on their solution. This paper examines the
parallelism of sparse matrix solver on the graphics processors. More
specifically, we implement the conjugate gradient technique with input matrix
stored in CSR, and Symmetric CSR and CSC formats. This method is one of the
most efficient iterative methods available for solving the finite-element basis
functions of Maxwell's equations. The GPU (Graphics Processing Unit), which is
used for its implementation, provides mechanisms to parallel the algorithm.
Thus, it increases significantly the computation speed in relation to serial
code on CPU based systems."
"Cloud computing is penetrating into various domains and environments, from
theoretical computer science to economy, from marketing hype to educational
curriculum and from R&D lab to enterprise IT infrastructure. Yet, the currently
developing state of cloud computing leaves several issues to address and also
affects cloud computing adoption by organizations. In this paper, we explain
how the transition into the cloud can occur in an organization and describe the
mechanism for transforming legacy infrastructure into a virtual
infrastructure-based cloud. We describe the state of the art of infrastructural
cloud, which is essential in the decision making on cloud adoption, and
highlight the challenges that can limit the scale and speed of the adoption. We
then suggest a strategic framework for designing a high performance cloud
system. This framework is applicable when transformation cloudbased deployment
model collides with some constraints. We give an example of the implementation
of the framework in a design of a budget-constrained high availability cloud
system."
"This article presents new properties of the mesh array for matrix
multiplication. In contrast to the standard array that requires 3n-2 steps to
complete its computation, the mesh array requires only 2n-1 steps. Symmetries
of the mesh array computed values are presented which enhance the efficiency of
the array for specific applications. In multiplying symmetric matrices, the
results are obtained in 3n/2+1 steps. The mesh array is examined for its
application as a scrambling system."
"Task parallelism as employed by the OpenMP task construct or some Intel
Threading Building Blocks (TBB) components, although ideal for tackling
irregular problems or typical producer/consumer schemes, bears some potential
for performance bottlenecks if locality of data access is important, which is
typically the case for memory-bound code on ccNUMA systems. We present a thin
software layer ameliorates adverse effects of dynamic task distribution by
sorting tasks into locality queues, each of which is preferably processed by
threads that belong to the same locality domain. Dynamic scheduling is fully
preserved inside each domain, and is preferred over possible load imbalance
even if nonlocal access is required, making this strategy well-suited for
typical multicore-mutisocket systems. The effectiveness of the approach is
demonstrated by using a blocked six-point stencil solver as a toy model."
"We show that distributed Infrastructure-as-a-Service (IaaS) compute clouds
can be effectively used for the analysis of high energy physics data. We have
designed a distributed cloud system that works with any application using large
input data sets requiring a high throughput computing environment. The system
uses IaaS-enabled science and commercial clusters in Canada and the United
States. We describe the process in which a user prepares an analysis virtual
machine (VM) and submits batch jobs to a central scheduler. The system boots
the user-specific VM on one of the IaaS clouds, runs the jobs and returns the
output to the user. The user application accesses a central database for
calibration data during the execution of the application. Similarly, the data
is located in a central location and streamed by the running application. The
system can easily run one hundred simultaneous jobs in an efficient manner and
should scale to many hundreds and possibly thousands of user jobs."
"The general description of infrastructure and content of SciShop.ru computer
simulation center is given. This resource is a new form of knowledge generation
and remote education using modern Cloud Computing technologies."
"A token ring is an arrangement of N processors that take turns engaging in an
activity which must be controlled. A token confers the right to engage in the
controlled activity. Processors communicate with neighbors in the ring to
obtain and release a token. The communication mechanism investigated in this
paper is the safe register abstraction, which may arbitrarily corrupt a value
that a processor reads when the operation reading a register is concurrent with
an write operation on that register by a neighboring processor. The main
results are simple protocols for quasi-atomic communication, constructed from
safe registers. A quasi-atomic register behaves atomically except that a
special undefined value may be returned in the case of concurrent read and
write operations. Under certain conditions that constrain the number of writes
and registers, quasi-atomic protocols are adequate substitutes for atomic
protocols. The paper demonstrates how quasi-atomic protocols can be used to
implement a self-stabilizing token ring, either by using two safe registers
between neighboring processors or by using O(lg N) safe registers between
neighbors, which lowers read complexity."
"The future of high-performance computing is aligning itself towards the
efficient use of highly parallel computing environments. One application where
the use of massive parallelism comes instinctively is Monte Carlo simulations,
where a large number of independent events have to be simulated. At the core of
the Monte Carlo simulation lies the Random Number Generator (RNG). In this
paper, the massively parallel implementation of a collection of pseudo-random
number generators on a graphics processing unit (GPU) is presented. The results
of the GPU implementation, in terms of samples/s, effective bandwidth and
operations per second, are presented. A comparison with other implementations
on different hardware platforms, in terms of samples/s, power efficiency and
cost-benefit, is also presented. Random numbers generation throughput of up to
~18MSamples/s have been achieved on the graphics hardware used. Efficient
hardware utilization, in terms of operations per second, has reached ~98% of
the possible integer operation throughput."
"In this paper, we study the MapReduce framework from an algorithmic
standpoint and demonstrate the usefulness of our approach by designing and
analyzing efficient MapReduce algorithms for fundamental sorting, searching,
and simulation problems. This study is motivated by a goal of ultimately
putting the MapReduce framework on an equal theoretical footing with the
well-known PRAM and BSP parallel models, which would benefit both the theory
and practice of MapReduce algorithms. We describe efficient MapReduce
algorithms for sorting, multi-searching, and simulations of parallel algorithms
specified in the BSP and CRCW PRAM models. We also provide some applications of
these results to problems in parallel computational geometry for the MapReduce
framework, which result in efficient MapReduce algorithms for sorting, 2- and
3-dimensional convex hulls, and fixed-dimensional linear programming. For the
case when mappers and reducers have a memory/message-I/O size of
$M=\Theta(N^\epsilon)$, for a small constant $\epsilon>0$, all of our MapReduce
algorithms for these applications run in a constant number of rounds."
"Kautz and de Bruijn graphs have a high degree of connectivity which makes
them ideal candidates for massively parallel computer network topologies. In
order to realize a practical computer architecture based on these graphs, it is
useful to have a means of constructing a large-scale system from smaller,
simpler modules. In this paper we consider the mathematical problem of
uniformly tiling a de Bruijn or Kautz graph. This can be viewed as a
generalization of the graph bisection problem. We focus on the problem of graph
tilings by a set of identical subgraphs. Tiles should contain a maximal number
of internal edges so as to minimize the number of edges connecting distinct
tiles. We find necessary and sufficient conditions for the construction of
tilings. We derive a simple lower bound on the number of edges which must leave
each tile, and construct a class of tilings whose number of edges leaving each
tile agrees asymptotically in form with the lower bound to within a constant
factor. These tilings make possible the construction of large-scale computing
systems based on de Bruijn and Kautz graph topologies."
"In this paper, we reviewed of several portable parallel programming paradigms
for use in a distributed programming environment. The Techniques reviewed here
are portable. These are mainly distributing computing using MPI pure java
based, MPI native java based (JNI) and PVM. We will discuss architecture and
utilities of each technique based on our literature review. We explored these
portable distributed techniques in four important characteristics scalability,
fault tolerance, load balancing and performance. We have identified the various
factors and issues for improving these four important characteristics."
"This paper describes the design and implementation of GridCertLib, a Java
library leveraging a Shibboleth-based authentication infrastructure and the
SLCS online certificate signing service, to provide short-lived X.509
certificates and Grid proxies. The main use case envisioned for GridCertLib, is
to provide seamless and secure access to Grid/X.509 certificates and proxies in
web applications and portals: when a user logs in to the portal using
Shibboleth authentication, GridCertLib can automatically obtain a Grid/X.509
certificate from the SLCS service and generate a VOMS proxy from it. We give an
overview of the architecture of GridCertLib and briefly describe its
programming model. Its application to some deployment scenarios is outlined, as
well as a report on practical experience integrating GridCertLib into portals
for Bioinformatics and Computational Chemistry applications, based on the
popular P-GRADE and Django softwares."
"We present a new model for distributed shared memory systems, based on remote
data accesses. Such features are offered by network interface cards that allow
one-sided operations, remote direct memory access and OS bypass. This model
leads to new interpretations of distributed algorithms allowing us to propose
an innovative detection technique of race conditions only based on logical
clocks. Indeed, the presence of (data) races in a parallel program makes it
hard to reason about and is usually considered as a bug."
"The analysis of climate regions is very important for designers and
architects, because the increase in density and built up spaces and reduction
in open spaces and green lands induce the increase of heat, especially in an
urban area, deteriorating the environment and causing health problems. This
study analyzes the Land Surface Temperature (LST) differences in the region of
Dobrogea, Romania, and compares with the land use and land cover types using TM
and ETM+ data of 1989 and 2000. As the analysis is performed on large data
sets, we used Grid Computing to implement a service for using on Computational
Grids with a Web-based client interface, which will be greatly useful and
convenient for those who are studying the ground thermal environment and heat
island effects by using Landsat TM/ETM+ bands, and have typical workstations,
with no special computing and storing resources for computationally intensive
satellite image processing and no license for a commercial image processing
tool. Based on the satellite imagery, the paper also addresses a Supervised
Classification algorithm and the computation of two indices of great value in
water resources management, Normalized Difference Vegetation Index (NDVI),
respectively Land Surface Emissivity (LSE)."
"Parallel Monte Carlo simulations often expose faults in random number
generators"
"Distributing spatially located heterogeneous workloads is an important
problem in parallel scientific computing. We investigate the problem of
partitioning such workloads (represented as a matrix of non-negative integers)
into rectangles, such that the load of the most loaded rectangle (processor) is
minimized. Since finding the optimal arbitrary rectangle-based partition is an
NP-hard problem, we investigate particular classes of solutions: rectilinear,
jagged and hierarchical. We present a new class of solutions called m-way
jagged partitions, propose new optimal algorithms for m-way jagged partitions
and hierarchical partitions, propose new heuristic algorithms, and provide
worst case performance analyses for some existing and new heuristics. Moreover,
the algorithms are tested in simulation on a wide set of instances. Results
show that two of the algorithms we introduce lead to a much better load balance
than the state-of-the-art algorithms. We also show how to design a two-phase
algorithm that reaches different time/quality tradeoff."
"Many-core architectures of the future are likely to have distributed memory
organizations and need fine grained concurrency management to be used
effectively. The Self-adaptive Virtual Processor (SVP) is an abstract
concurrent programming model which can provide this, but the model and its
current implementations assume a single address space shared memory. We
investigate and extend SVP to handle distributed environments, and discuss a
prototype SVP implementation which transparently supports execution on
heterogeneous distributed memory clusters over TCP/IP connections, while
retaining the original SVP programming model."
"A self-stabilizing protocol has the capacity to recover a legitimate behavior
whatever is its initial state. The majority of works in self-stabilization
assume a shared memory model or a communication using reliable and FIFO
channels. In this article, we interest in self-stabilizing systems using
bounded but non reliable and non FIFO channels. We propose a stabilizing
communication protocol with optimal fault resilience. In more details, this
protocol simulates a reliable and FIFO channel and ensures a minimal number of
looses, duplications, creations, and re-ordering of messages."
"A self-stabilizing is naturally resilient to transients faults (that is,
faults of finite duration). Recently, a new class of protocol appears. These
protocols are self-stabilizing and are moreover resilient to a limited number
of permanent faults. In this article, we interest in self-stabilizing protocols
that tolerate very hard permanent faults: Byzantine faults. We introduce two
new scheme of Byzantine containment in self-stabilizing systems. We show that,
for the problem of BFS spanning tree construction, the well known
self-stabilizing protocol min+1 provides without significant modification the
best Byzantine containment with respect to these new schemes."
"Cloud computing is rapidly emerging as a new paradigm for delivering IT
services as utlity-oriented services on subscription-basis. The rapid
development of applications and their deployment in Cloud computing
environments in efficient manner is a complex task. In this article, we give a
brief introduction to Cloud computing technology and Platform as a Service, we
examine the offerings in this category, and provide the basis for helping
readers to understand basic application platform opportunities in Cloud by
technologies such as Microsoft Azure, Sales Force, Google App, and Aneka for
Cloud computing. We demonstrate that Manjrasoft Aneka is a Cloud Application
Platform (CAP) leveraging these concepts and allowing an easy development of
Cloud ready applications on a Private/Public/Hybrid Cloud. Aneka CAP offers
facilities for quickly developing Cloud applications and a modular platform
where additional services can be easily integrated to extend the system
capabilities, thus being at pace with the rapidly evolution of Cloud computing."
"This work revisits existing algorithms for the QR factorization of
rectangular matrices composed of p-by-q tiles, where p >= q. Within this
framework, we study the critical paths and performance of algorithms such as
Sameh and Kuck, Modi and Clarke, Greedy, and those found within PLASMA.
Although neither Modi and Clarke nor Greedy is optimal, both are shown to be
asymptotically optimal for all matrices of size p = q^2 f(q), where f is any
function such that \lim_{+\infty} f= 0. This novel and important complexity
result applies to all matrices where p and q are proportional, p = \lambda q,
with \lambda >= 1, thereby encompassing many important situations in practice
(least squares). We provide an extensive set of experiments that show the
superiority of the new algorithms for tall matrices."
"Self-stabilization is a versatile approach to fault-tolerance since it
permits a distributed system to recover from any transient fault that
arbitrarily corrupts the contents of all memories in the system. Byzantine
tolerance is an attractive feature of distributed systems that permits to cope
with arbitrary malicious behaviors. This paper focus on systems that are both
self-stabilizing and Byzantine tolerant. We consider the well known problem of
constructing a maximum metric tree in this context. Combining these two
properties is known to induce many impossibility results. In this paper, we
provide first two impossibility results about the construction of maximum
metric tree in presence of transients and (permanent) Byzantine faults. Then,
we provide a new self-stabilizing protocol that provides optimal containment of
an arbitrary number of Byzantine faults."
"This article deals with some stochastic population protocols, motivated by
theoretical aspects of distributed computing. We modelize the problem by a
large urn of black and white balls from which at every time unit a fixed number
of balls are drawn and their colors are changed according to the number of
black balls among them. When the time and the number of balls both tend to
infinity the proportion of black balls converges to an algebraic number. We
prove that, surprisingly enough, not every algebraic number can be ""computed""
this way."
"We consider a set of k autonomous robots that are endowed with visibility
sensors (but that are otherwise unable to communicate) and motion actuators.
Those robots must collaborate to reach a sin- gle vertex that is unknown
beforehand, and to remain there hereafter. Previous works on gathering in
ring-shaped networks suggest that there exists a tradeoff between the size of
the set of potential initial configurations, and the power of the sensing
capabilities of the robots (i.e. the larger the initial configuration set, the
most powerful the sensor needs to be). We prove that there is no such trade
off. We propose a gathering protocol for an odd number of robots in a
ring-shaped network that allows symmetric but not periodic configurations as
initial configurations, yet uses only local weak multiplicity detection. Robots
are assumed to be anonymous and oblivious, and the execution model is the
non-atomic CORDA model with asynchronous fair scheduling. Our protocol allows
the largest set of initial configurations (with respect to impossibility
results) yet uses the weakest multiplicity detector to date. The time
complexity of our protocol is O(n2), where n denotes the size of the ring.
Compared to previous work that also uses local weak multiplicity detection, we
do not have the constraint that k < n/2 (here, we simply have 2 < k < n - 3)."
"Utility-based power allocation in wireless ad-hoc networks is inherently
nonconvex because of the global coupling induced by the co-channel
interference. To tackle this challenge, we first show that the globally optimal
point lies on the boundary of the feasible region, which is utilized as a basis
to transform the utility maximization problem into an equivalent max-min
problem with more structure. By using extended duality theory, penalty
multipliers are introduced for penalizing the constraint violations, and the
minimum weighted utility maximization problem is then decomposed into
subproblems for individual users to devise a distributed stochastic power
control algorithm, where each user stochastically adjusts its target utility to
improve the total utility by simulated annealing. The proposed distributed
power control algorithm can guarantee global optimality at the cost of slow
convergence due to simulated annealing involved in the global optimization. The
geometric cooling scheme and suitable penalty parameters are used to improve
the convergence rate. Next, by integrating the stochastic power control
approach with the back-pressure algorithm, we develop a joint scheduling and
power allocation policy to stabilize the queueing systems. Finally, we
generalize the above distributed power control algorithms to multicast
communications, and show their global optimality for multicast traffic."
"Hadoop MapReduce is now a popular choice for performing large-scale data
analytics. This technical report describes a detailed set of mathematical
performance models for describing the execution of a MapReduce job on Hadoop.
The models describe dataflow and cost information at the fine granularity of
phases within the map and reduce tasks of a job execution. The models can be
used to estimate the performance of MapReduce jobs as well as to find the
optimal configuration settings to use when running the jobs."
"The primary objective of this research work is to study and investigate the
performance measures of Gossip Routing protocol and Energy Efficient and
Reliable Adaptive Gossip routing protocols. We use TCP and CBR based traffic
models to analyze the performance of above mentioned protocols based on the
parameters of Packet Delivery Ratio, Average End-to-End Delay and Throughput.
We will investigate the effect of change in the simulation time and Number of
nodes for the MANET routing protocols. For Simulation, we have used ns-2
simulator."
"The goal of Byzantine Broadcast (BB) is to allow a set of fault-free nodes to
agree on information that a source node wants to broadcast to them, in the
presence of Byzantine faulty nodes. We consider design of efficient algorithms
for BB in {\em synchronous} point-to-point networks, where the rate of
transmission over each communication link is limited by its ""link capacity"".
The throughput of a particular BB algorithm is defined as the average number of
bits that can be reliably broadcast to all fault-free nodes per unit time using
the algorithm without violating the link capacity constraints. The {\em
capacity} of BB in a given network is then defined as the supremum of all
achievable BB throughputs in the given network, over all possible BB
algorithms.
  We develop NAB -- a Network-Aware Byzantine broadcast algorithm -- for
arbitrary point-to-point networks consisting of $n$ nodes, wherein the number
of faulty nodes is at most $f$, $f<n/3$, and the network connectivity is at
least $2f+1$. We also prove an upper bound on the capacity of Byzantine
broadcast, and conclude that NAB can achieve throughput at least 1/3 of the
capacity. When the network satisfies an additional condition, NAB can achieve
throughput at least 1/2 of the capacity.
  To the best of our knowledge, NAB is the first algorithm that can achieve a
constant fraction of capacity of Byzantine Broadcast (BB) in arbitrary
point-to-point networks."
"In this report, we investigate the multi-valued Byzantine consensus problem.
We introduce two algorithms: the first one achieves traditional validity
requirement for consensus, and the second one achieves a stronger ""q-validity""
requirement. Both algorithms are more efficient than the ones introduces in our
recent PODC 2011 paper titled ""Error-Free Multi-Valued Consensus with Byzantine
Failures""."
"Communication is a crucial ingredient in every kind of collaborative work.
But what is the least possible amount of communication required for a given
task? We formalize this question by introducing a new framework for distributed
computation, called {\em oblivious protocols}.
  We investigate the power of this model by considering two concrete examples,
the {\em musical chairs} task $MC(n,m)$ and the well-known {\em Renaming}
problem. The $MC(n,m)$ game is played by $n$ players (processors) with $m$
chairs. Players can {\em occupy} chairs, and the game terminates as soon as
each player occupies a unique chair. Thus we say that player $P$ is {\em in
conflict} if some other player $Q$ is occupying the same chair, i.e.,
termination means there are no conflicts. By known results from distributed
computing, if $m \le 2n-2$, no strategy of the players can guarantee
termination. However, there is a protocol with $m = 2n-1$ chairs that always
terminates. Here we consider an oblivious protocol where in every time step the
only communication is this: an adversarial {\em scheduler} chooses an arbitrary
nonempty set of players, and for each of them provides only one bit of
information, specifying whether the player is currently in conflict or not. A
player notified not to be in conflict halts and never changes its chair,
whereas a player notified to be in conflict changes its chair according to its
deterministic program. Remarkably, even with this minimal communication
termination can be guaranteed with only $m=2n-1$ chairs. Likewise, we obtain an
oblivious protocol for the Renaming problem whose name-space is small as that
of the optimal nonoblivious distributed protocol.
  Other aspects suggest themselves, such as the efficiency (program length) of
our protocols. We make substantial progress here as well, though many
interesting questions remain open."
"Humans are very good at optimizing solutions for specific problems.
Biological processes, on the other hand, have evolved to handle multiple
constrained distributed environments and so they are robust and adaptable.
Inspired by observations made in a biological system we have recently presented
a simple new randomized distributed MIS algorithm \cite{ZScience}. Here we
extend these results by removing a number of strong assumptions that we made,
making the algorithms more practical. Specifically we present an $O(\log^2 n)$
rounds synchronous randomized MIS algorithm which uses only 1 bit unary
messages (a beeping signal with collision detection), allows for asynchronous
wake up, does not assume any knowledge of the network topology, and assumes
only a loose bound on the network size. We also present an extension with no
collision detection in which the round complexity increases to $(\log^3 n)$.
Finally, we show that our algorithm is optimal under some restriction, by
presenting a tight lower bound of $\Omega(\log^2 n)$ on the number of rounds
required to construct a MIS for a restricted model."
"We compare the solvability of the Consensus and Broadcast problems in
synchronous communication networks in which the delivery of messages is not
reliable. The failure model is the mobile omission faults model. During each
round, some messages can be lost and the set of possible simultaneous losses is
the same for each round. We investigate these problems for the first time for
arbitrary sets of possible failures. Previously, these sets were defined by
bounding the numbers of failures.
  In this setting, we present a new necessary condition for the solvability of
Consensus that unifies previous impossibility results in this area. This
condition is expressed using Broadcastability properties. As a very important
application, we show that when the sets of omissions that can occur are defined
by bounding the numbers of failures, counted in any way (locally, globally,
etc.), then the Consensus problem is actually equivalent to the Broadcast
problem."
"Fault tolerance overhead of high performance computing (HPC) applications is
becoming critical to the efficient utilization of HPC systems at large scale.
HPC applications typically tolerate fail-stop failures by checkpointing.
Another promising method is in the algorithm level, called algorithmic
recovery. These two methods can achieve high efficiency when the system scale
is not very large, but will both lose their effectiveness when systems approach
the scale of Exaflops, where the number of processors including in system is
expected to achieve one million. This paper develops a new and efficient
algorithm-based fault tolerance scheme for HPC applications. When failure
occurs during the execution, we do not stop to wait for the recovery of
corrupted data, but replace them with the corresponding redundant data and
continue the execution. A background accelerated recovery method is also
proposed to rebuild redundancy to tolerate multiple times of failures during
the execution. To demonstrate the feasibility of our new scheme, we have
incorporated it to the High Performance Linpack. Theoretical analysis
demonstrates that our new fault tolerance scheme can still be effective even
when the system scale achieves the Exaflops. Experiment using SiCortex SC5832
verifies the feasibility of the scheme, and indicates that the advantage of our
scheme can be observable even in a small scale."
"We propose a novel job scheduling approach for homogeneous cluster computing
platforms. Its key feature is the use of virtual machine technology to share
fractional node resources in a precise and controlled manner. Other VM-based
scheduling approaches have focused primarily on technical issues or on
extensions to existing batch scheduling systems, while we take a more
aggressive approach and seek to find heuristics that maximize an objective
metric correlated with job performance. We derive absolute performance bounds
and develop algorithms for the online, non-clairvoyant version of our
scheduling problem. We further evaluate these algorithms in simulation against
both synthetic and real-world HPC workloads and compare our algorithms to
standard batch scheduling approaches. We find that our approach improves over
batch scheduling by orders of magnitude in terms of job stretch, while leading
to comparable or better resource utilization. Our results demonstrate that
virtualization technology coupled with lightweight online scheduling strategies
can afford dramatic improvements in performance for executing HPC workloads."
"This paper discusses the latest generation of the MONARC (MOdels of Networked
Analysis at Regional Centers) simulation framework, as a design and modelling
tool for large scale distributed systems applied to HEP experiments. A
process-oriented approach for discrete event simulation is well-suited for
describing concurrent running programs, as well as the stochastic arrival
patterns that characterize how such systems are used. The simulation engine is
based on Threaded Objects (or Active Objects), which offer great flexibility in
simulating the complex behavior of distributed data processing programs. The
engine provides an appropriate scheduling mechanism for the Active objects with
support for interrupts. This approach offers a natural way of describing
complex running programs that are data dependent and which concurrently compete
for shared resources as well as large numbers of concurrent data transfers on
shared resources. The framework provides a complete set of basic components
(processing nodes, data servers, network components) together with dynamically
loadable decision units (scheduling or data replication modules) for easily
building complex Computing Model simulations. Examples of simulating complex
data processing systems are presented, and the way the framework is used to
compare different decision making algorithms or to optimize the overall Grid
architecture and/or the policies that govern the Grid's use."
"Grid computing has gained an increasing importance in the last years,
especially in the academic environments, offering the possibility to rapidly
solve complex scientific problems. The monitoring of the Grid jobs has a vital
importance for analyzing the system's performance, for providing the users an
appropriate feed-back, and for obtaining historical data which may be used for
performance prediction. Several monitoring systems have been developed, with
different strategies to collect and store the information. We shall present
here a solution based on MonALISA, a distributed service for monitoring,
control and global optimization of complex systems, and LISA, a component
application of MonALISA which can help in optimizing other applications by
means of monitoring services. The advantages of this system are, among others,
flexibility, dynamic configuration, high communication performance."
"In the wake of the decisive impossibility result of Fischer, Lynch, and
Paterson for deterministic consensus protocols in the aynchronous model with
just one failure, Ben-Or and Bracha demonstrated that the problem could be
solved with randomness, even for Byzantine failures. Both protocols are natural
and intuitive to verify, and Bracha's achieves optimal resilience. However, the
expected running time of these protocols is exponential in general. Recently,
Kapron, Kempe, King, Saia, and Sanwalani presented the first efficient
Byzantine agreement algorithm in the asynchronous, full information model,
running in polylogarithmic time. Their algorithm is Monte Carlo and drastically
departs from the simple structure of Ben-Or and Bracha's Las Vegas algorithms.
  In this paper, we begin an investigation of the question: to what extent is
this departure necessary? Might there be a much simpler and intuitive Las Vegas
protocol that runs in expected polynomial time? We will show that the
exponential running time of Ben-Or and Bracha's algorithms is no mere accident
of their specific details, but rather an unavoidable consequence of their
general symmetry and round structure. We define a natural class of ""fully
symmetric round protocols"" for solving Byzantine agreement in an asynchronous
setting and show that any such protocol can be forced to run in expected
exponential time by an adversary in the full information model. We assume the
adversary controls $t$ Byzantine processors for $t = cn$, where $c$ is an
arbitrary positive constant $< 1/3$. We view our result as a step toward
identifying the level of complexity required for a polynomial-time algorithm in
this setting, and also as a guide in the search for new efficient algorithms."
"We present a distributed agent based system used to monitor, configure and
control complex, large scale data transfers in the Wide Area Network. The
Localhost Information Service Agent (LISA) is a lightweight dynamic service
that provides complete system and applications monitoring, is capable to
dynamically configure system parameters and can help in optimizing distributed
applications.
  As part of the MonALISA (Monitoring Agents in A Large Integrated Services
Architecture) system, LISA is an end host agent capable to collect any type of
monitoring information, to distribute them, and to take actions based on local
or global decision units. The system has been used for the Bandwidth Challenge
at Supercomputing 2006 to coordinate global large scale data transfers using
Fast Data Transfer (FDT) application between hundreds of servers distributed on
major Grid sites involved in processing High Energy Physics data for the future
Large Hadron Collider experiments."
"Over the Internet today, computing and communications environments are
significantly more complex and chaotic than classical distributed systems,
lacking any centralized organization or hierarchical control. There has been
much interest in emerging Peer-to-Peer (P2P) network overlays because they
provide a good substrate for creating large-scale data sharing, content
distribution and application-level multicast applications. In this paper we
present DistHash, a P2P overlay network designed to share large sets of
replicated distributed objects in the context of large-scale highly dynamic
infrastructures. We present original solutions to achieve optimal message
routing in hop-count and throughput, provide an adequate consistency approach
among replicas, as well as provide a fault-tolerant substrate."
"Obtaining high performance in IO intensive applications requires systems that
support reliable fast transfer, data replication, and caching. In this paper we
present an architecture designed for supporting IO intensive applications in
MedioGRID, a system for real-time processing of satellite images, operating in
a Grid environment. The solution ensures that applications which are processing
geographical data have uniform access to data and is based on continuous
monitoring of the data transfers using MonALISA and its extensions. The
MedioGRID architecture is also built on Globus, Condor and PBS and based on
this middleware we aim to extract information about the running systems. The
results obtained in testing MedioGRID system for large data transfers show that
monitoring system provides a very good view of system evolution."
"The paper presents a solution to the dynamic DAG scheduling problem in Grid
environments. It presents a distributed, scalable, efficient and fault-tolerant
algorithm for optimizing tasks assignment. The scheduler algorithm for tasks
with dependencies uses a heuristic model to optimize the total cost of tasks
execution. Also, a method based on genetic algorithms is proposed to optimize
the procedure of resources assignment. The experiments used the MonALISA
monitoring environment and its extensions. The results demonstrate very good
behavior in comparison with other scheduling approaches for this kind of DAG
scheduling algorithms."
"Scheduling applications on wide-area distributed systems is useful for
obtaining quick and reliable results in an efficient manner. Optimized
scheduling algorithms are fundamentally important in order to achieve optimized
resources utilization. The existing and potential applications include many
fields of activity like satellite image processing and medicine. The paper
proposes a scheduling algorithm for tasks with dependencies in Grid
environments. CoAllocation represents a strategy that provides a schedule for
task with dependencies, having as main purpose the efficiency of the schedule,
in terms of load balancing and minimum time for the execution of the tasks."
"The paper proposes a solution for the Grid scheduling problem, addressing in
particular the requirement of high performance an efficient algorithm must
fulfill. Advance Reservation engages a distributed, dynamic, fault-tolerant and
efficient strategy which reserves resources for future task execution. The
paper presents the main features of the strategy, the functioning mechanism the
strategy is based on and the methods used for evaluating the algorithm."
"We report on experiments exploring the interplay between the topology of the
complex network of dependent components in a large-scale data-centre, and the
robustness and scaling properties of that data-centre. In a previous paper [1]
we used the SPECI large-scale data-centre simulator [2] to compare the
robustness and scaling characteristics of data-centres whose dependent
components are connected via Strogatz-Watts small-world (SW) networks [3],
versus those organized as Barabasi-Albert scale-free (SF) networks [4], and
found significant differences. In this paper, we present results from using the
Klemm-Eguiliz (KE) construction method [5] to generate complex network
topologies for data-centre component dependencies. The KE model has a control
parameter {\mu}\in[0,1]\inR that determines whether the networks generated are
SW (0<{\mu}<<1) or SF ({\mu}=1) or a ""hybrid"" network topology part-way between
SW and SF (0<{\mu}<1). We find that the best scores for system-level
performance metrics of the simulated data-centres are given by ""hybrid"" values
of {\mu} significantly different from pure-SW or pure-SF."
"The trend for cloud computing has initiated a race towards data centres (DC)
of an ever-increasing size. The largest DCs now contain many hundreds of
thousands of virtual machine (VM) services. Given the finite lifespan of
hardware, such large DCs are subject to frequent hardware failure events that
can lead to disruption of service. To counter this, multiple redundant copies
of task threads may be distributed around a DC to ensure that individual
hardware failures do not cause entire jobs to fail. Here, we present results
demonstrating the resilience of different job scheduling algorithms in a
simulated DC with hardware failure. We use a simple model of jobs distributed
across a hardware network to demonstrate the relationship between resilience
and additional communication costs of different scheduling methods."
"We introduce Version 2 of SPECI, a system for predictive simulation modeling
of large-scale data-centres, i.e. warehouse-sized facilities containing
hundreds of thousands of servers, as used to provide cloud services."
"In this paper we present a system for monitoring and controlling dynamic
network circuits inside the USLHCNet network. This distributed service system
provides in near real-time complete topological information for all the
circuits, resource allocation and usage, accounting, detects automatically
failures in the links and network equipment, generate alarms and has the
functionality to take automatic actions. The system is developed based on the
MonALISA framework, which provides a robust monitoring and controlling service
oriented architecture, with no single points of failure."
"17th International Conference on Control Systems and Computer Science (CSCS
17), Bucharest, Romania, May 26-29, 2009. Vol. 1, pp. 401-406, ISSN: 2066-4451."
"With recent increasing computational and data requirements of scientific
applications, the use of large clustered systems as well as distributed
resources is inevitable. Although executing large applications in these
environments brings increased performance, the automation of the process
becomes more and more challenging. While the use of complex workflow management
systems has been a viable solution for this automation process in business
oriented environments, the open source engines available for scientific
applications lack some functionalities or are too difficult to use for
non-specialists. In this work we propose an architectural model for a grid
based workflow management platform providing features like an intuitive way to
describe workflows, efficient data handling mechanisms and flexible fault
tolerance support. Our integrated solution introduces a workflow engine
component based on ActiveBPEL extended with additional functionalities and a
scheduling component providing efficient mapping between tasks and available
resources."
"We evaluate optimized parallel sparse matrix-vector operations for several
representative application areas on widespread multicore-based cluster
configurations. First the single-socket baseline performance is analyzed and
modeled with respect to basic architectural properties of standard multicore
chips. Beyond the single node, the performance of parallel sparse matrix-vector
operations is often limited by communication overhead. Starting from the
observation that nonblocking MPI is not able to hide communication cost using
standard MPI implementations, we demonstrate that explicit overlap of
communication and computation can be achieved by using a dedicated
communication thread, which may run on a virtual core. Moreover we identify
performance benefits of hybrid MPI/OpenMP programming due to improved load
balancing even without explicit communication overlap. We compare performance
results for pure MPI, the widely used ""vector-like"" hybrid programming
strategies, and explicit overlap on a modern multicore-based cluster and a Cray
XE6 system."
"Simulation has become the evaluation method of choice for many areas of
distributing computing research. However, most existing simulation packages
have several limitations on the size and complexity of the system being
modeled. Fine grained simulation of complex systems such as Grids requires high
computational effort which can only be obtained by using an underlying
distributed architecture. We are proposing a new distributed simulation system
that has the advantage of being able to model very complex distributed systems
while hiding the computational effort from the end-user."
"Two key synchronization paradigms for the construction of scalable concurrent
data-structures are software combining and elimination. Elimination-based
concurrent data-structures allow operations with reverse semantics (such as
push and pop stack operations) to ""collide"" and exchange values without having
to access a central location. Software combining, on the other hand, is
effective when colliding operations have identical semantics: when a pair of
threads performing operations with identical semantics collide, the task of
performing the combined set of operations is delegated to one of the threads
and the other thread waits for its operation(s) to be performed. Applying this
mechanism iteratively can reduce memory contention and increase throughput. The
most highly scalable prior concurrent stack algorithm is the
elimination-backoff stack. The elimination-backoff stack provides high
parallelism for symmetric workloads in which the numbers of push and pop
operations are roughly equal, but its performance deteriorates when workloads
are asymmetric. We present DECS, a novel Dynamic Elimination-Combining Stack
algorithm, that scales well for all workload types. While maintaining the
simplicity and low-overhead of the elimination-bakcoff stack, DECS manages to
benefit from collisions of both identical- and reverse-semantics operations.
Our empirical evaluation shows that DECS scales significantly better than both
blocking and non-blocking best prior stack algorithms."
"The effective usages of computational resources are a primary concern of
up-to-date distributed applications. In this paper, we present a methodology to
reason about resource usages (acquisition, release, revision, ...), and
therefore the proposed approach enables to predict bad usages of resources.
Keeping in mind the interplay between local and global information occurring in
the application-resource interactions, we model resources as entities with
local policies and global properties governing the overall interactions.
Formally, our model takes the shape of an extension of pi-calculus with
primitives to manage resources. We develop a Control Flow Analysis computing a
static approximation of process behaviour and therefore of the resource usages."
"Virtualization technology allows currently any application run any
application complex and expensive computational (the scientific applications
are a good example) on heterogeneous distributed systems, which make regular
use of Grid and Cloud technologies, enabling significant savings in computing
time. This model is particularly interesting for the mass execution of
scientific simulations and calculations, allowing parallel execution of
applications using the same execution environment (unchanged) used by the
scientist as usual. However, the use and distribution of large virtual images
can be a problem (up to tens of GBytes), which is aggravated when attempting a
mass mailing on a large number of distributed computers. This work has as main
objective to present an analysis of how implementation and a proposal for the
improvement (reduction in size) of the virtual images pretending reduce
distribution time in distributed systems. This analysis is done very specific
requirements that need an operating system (guest OS) on some aspects of its
execution."
"We study the problem of cooperative localization of a large network of nodes
in integer-coordinated unit disk graphs, a simplified but useful version of
general random graph. Exploiting the property that the radius $r$ sets clear
cut on the connectivity of two nodes, we propose an essential philosophy that
""no connectivity is also useful information just like the information being
connected"" in unit disk graphs. Exercising this philosophy, we show that the
conventional network localization problem can be re-formulated to significantly
reduce the search space, and that global rigidity, a necessary and sufficient
condition for the existence of unique solution in general graphs, is no longer
necessary. While the problem is still NP-hard, we show that a (depth-first)
tree-search algorithm with memory O(N) ($N$ is the network size) can be
developed, and for practical setups, the search complexity and speed is very
manageable, and is magnitudes less than the conventional problem, especially
when the graph is sparse or when only very limited anchor nodes are available."
"In research paper ""Accurate estimation of the target location of object with
energy constraint & Adaptive Update Algorithms to Save Data"" one of the central
issues in sensor networks is track the location, of moving object which have
overhead of saving data, an accurate estimation of the target location of
object with energy constraint .We do not have any mechanism which control and
maintain data .The wireless communication bandwidth is also very limited. Some
field which is using this technique are flood and typhoon detection, forest
fire detection, temperature and humidity and ones we have these information use
these information back to a central air conditioning and ventilation system. In
this research paper, we propose protocol based on the prediction and adaptive
based algorithm which is using less sensor node reduced by an accurate
estimation of the target location. we are using minimum three sensor node to
get the accurate position .We can extend it upto four or five to find more
accurate location but we have energy constraint so we are using three with
accurate estimation of location help us to reduce sensor node..We show that our
tracking method performs well in terms of energy saving regardless of mobility
pattern of the mobile target .We extends the life time of network with less
sensor node. Once a new object is detected, a mobile agent will be initiated to
track the roaming path of the object. The agent is mobile since it will choose
the sensor closest to the object to stay. The agent may invite some nearby
slave sensors to cooperatively position the object and inhibit other irrelevant
(i.e., farther) sensors from tracking the object. As a result, the
communication and sensing overheads are greatly reduced."
"This paper introduces a new interconnection network topology called Balanced
Varietal Hypercube (BVH), suitable for massively parallel systems. The proposed
topology being a hybrid structure retains almost all the attractive properties
of Balanced Hypercube and Varietal Hypercube. The topology, various parameters,
routing and broadcasting of Balanced Varietal Hypercube are presented. The
performance of the Balanced Varietal Hypercube is compared with other networks.
In terms of diameter, cost and average distance and reliability the proposed
network is found to be better than the Hypercube, Balanced Hypercube and
Varietal Hypercube. Also it is more reliable and cost-effective than Hypercube
and Balanced Hypercube."
"The effectiveness and scalability of MapReduce-based implementations of
complex data-intensive tasks depend on an even redistribution of data between
map and reduce tasks. In the presence of skewed data, sophisticated
redistribution approaches thus become necessary to achieve load balancing among
all reduce tasks to be executed in parallel. For the complex problem of entity
resolution, we propose and evaluate two approaches for such skew handling and
load balancing. The approaches support blocking techniques to reduce the search
space of entity resolution, utilize a preprocessing MapReduce job to analyze
the data distribution, and distribute the entities of large blocks among
multiple reduce tasks. The evaluation on a real cloud infrastructure shows the
value and effectiveness of the proposed load balancing approaches."
"Distributed Nearest Neighbor Search (DNNS) locates service nodes that have
shortest interactive delay towards requesting hosts. DNNS provides an important
service for large-scale latency sensitive networked applications, such as VoIP,
online network games, or interactive network services on the cloud. Existing
work assumes the delay to be symmetric, which does not generalize to
applications that are sensitive to one-way delays, such as the multimedia video
delivery from the servers to the hosts. We propose a relaxed inframetric model
for the network delay space that does not assume the triangle inequality and
delay symmetry to hold. We prove that the DNNS requests can be completed
efficiently if the delay space exhibits modest inframetric dimensions, which we
can observe empirically. Finally, we propose a DNNS method named HybridNN
(\textit{Hybrid} \textit{N}earest \textit{N}eighbor search) based on the
inframetric model for fast and accurate DNNS. For DNNS requests, HybridNN
chooses closest neighbors accurately via the inframetric modelling, and
scalably by combining delay predictions with direct probes to a pruned set of
neighbors. Simulation results show that HybridNN locates nearly optimally the
nearest neighbor. Experiments on PlanetLab show that HybridNN can provide
accurate nearest neighbors that are close to optimal with modest query overhead
and maintenance traffic."
"With the increasing number of Quad-Core-based clusters and the introduction
of compute nodes designed with large memory capacity shared by multiple cores,
new problems related to scalability arise. In this paper, we analyze the
overall performance of a cluster built with nodes having a dual Quad-Core
Processor on each node. Some benchmark results are presented and some
observations are mentioned when handling such processors on a benchmark test. A
Quad-Core-based cluster's complexity arises from the fact that both local
communication and network communications between the running processes need to
be addressed. The potentials of an MPI-OpenMP approach are pinpointed because
of its reduced communication overhead. At the end, we come to a conclusion that
an MPI-OpenMP solution should be considered in such clusters since optimizing
network communications between nodes is as important as optimizing local
communications between processors in a multi-core cluster."
"Given a synchronous system, we study the question whether the behaviour of
that system can be exhibited by a (non-trivially) distributed and hence
asynchronous implementation. In this paper we show, by counterexample, that
synchronous systems cannot in general be implemented in an asynchronous fashion
without either introducing an infinite implementation or changing the causal
structure of the system behaviour."
"The proliferation of portable devices (PDAs, smartphones, digital multimedia
players, and so forth) allows mobile users to carry around a pool of computing,
storage and communication resources. Sharing these resources with other users
(""Digital Organisms"" -- DOs) opens the door to novel interesting scenarios,
where people trade resources to allow the execution, anytime and anywhere, of
applications that require a mix of capabilities. In this paper we present a
fully distributed approach for resource sharing among multiple devices owned by
different mobile users. Our scheme enables DOs to trade computing/networking
facilities through an auction-based mechanism, without the need of a central
control. We use a set of numerical experiments to compare our approach with an
optimal (centralized) allocation strategy that, given the set of resource
demands and offers, maximizes the number of matches. Results confirm the
effectiveness of our approach since it produces a fair allocation of resources
with low computational cost, providing DOs with the means to form an altruistic
digital ecosystem."
"In the past couple of decades, the computational abilities of supercomput-
ers have increased tremendously. Leadership scale supercomputers now are
capable of petaflops. Likewise, the problem size targeted by applications
running on such computers has also scaled. These large applications have I/O
throughput requirements on the order of tens of gigabytes per second. For a
variety of reasons, the I/O subsystems of such computers have not kept pace
with the computational increases, and the time required for I/O in an
application has become one of the dominant bottlenecks. Also troublesome is the
fact that scientific applications do not attain near the peak theoretical
bandwidth of the I/O subsystems. In addressing the two prior issues, one must
also question the nature of the data itself; one can ask whether contem- porary
practices of data dumping and analysis are optimal and whether they will
continue to be applicable as computers continue to scale. These three topics,
the I/O subsystem, the nature of scientific data output, and future possible
optimizations are discussed in this report."
"A parallel computer system is a collection of processing elements that
communicate and cooperate to solve large computational problems efficiently. To
achieve this, at first the large computational problem is partitioned into
several tasks with different work-loads and then are assigned to the different
processing elements for computation. Distribution of the work load is known as
Load Balancing. An appropriate distribution of work-loads across the various
processing elements is very important as disproportional workloads can
eliminate the performance benefit of parallelizing the job. Hence, load
balancing on parallel systems is a critical and challenging activity. Load
balancing algorithms can be broadly categorized as static or dynamic. Static
load balancing algorithms distribute the tasks to processing elements at
compile time, while dynamic algorithms bind tasks to processing elements at run
time. This paper explains only the different dynamic load balancing techniques
in brief used in parallel systems and concluding with the comparative
performance analysis result of these algorithms."
"Hamiltonicity is an important property in parallel and distributed
computation. Existence of Hamiltonian cycle allows efficient emulation of
distributed algorithms on a network wherever such algorithm exists for
linear-array and ring, and can ensure deadlock freedom in some routing
algorithms in hierarchical interconnection networks. Hamiltonicity can also be
used for construction of independent spanning tree and leads to designing fault
tolerant protocols. Optical Transpose Interconnection Systems or OTIS (also
referred to as two-level swapped network) is a widely studied interconnection
network topology which is popular due to high degree of scalability,
regularity, modularity and package ability. Surprisingly, to our knowledge,
only one strong result is known regarding Hamiltonicity of OTIS - showing that
OTIS graph built of Hamiltonian base graphs are Hamiltonian. In this work we
consider Hamiltonicity of OTIS networks, built on Non-Hamiltonian base and
answer some important questions. First, we prove that Hamiltonicity of base
graph is not a necessary condition for the OTIS to be Hamiltonian. We present
an infinite family of Hamiltonian OTIS graphs composed on Non-Hamiltonian base
graphs. We further show that, it is not sufficient for the base graph to have
Hamiltonian path for the OTIS constructed on it to be Hamiltonian. We give
constructive proof of Hamiltonicity for a large family of Butterfly-OTIS. This
proof leads to an alternate efficient algorithm for independent spanning trees
construction on this class of OTIS graphs. Our algorithm is linear in the
number of vertices as opposed to the generalized algorithm, which is linear in
the number of edges of the graph."
"Traditional heterogeneous parallel algorithms, designed for heterogeneous
clusters of workstations, are based on the assumption that the absolute speed
of the processors does not depend on the size of the computational task. This
assumption proved inaccurate for modern and perspective highly heterogeneous
HPC platforms. New class of algorithms based on the functional performance
model (FPM), representing the speed of the processor by a function of problem
size, has been recently proposed. These algorithms cannot be however employed
in self-adaptable applications because of very high cost of construction of the
functional performance model. The paper presents a new class of parallel
algorithms for highly heterogeneous HPC platforms. Like traditional FPM-based
algorithms, these algorithms assume that the speed of the processors is
characterized by speed functions rather than speed constants. Unlike the
traditional algorithms, they do not assume the speed functions to be given.
Instead, they estimate the speed functions of the processors for different
problem sizes during their execution. These algorithms do not construct the
full speed function for each processor but rather build and use their partial
estimates sufficient for optimal distribution of computations with a given
accuracy. The low execution cost of distribution of computations between
heterogeneous processors in these algorithms make them suitable for employment
in self-adaptable applications. Experiments with parallel matrix multiplication
applications based on this approach are performed on local and global
heterogeneous computational clusters. The results show that the execution time
of optimal matrix distribution between processors is significantly less, by
orders of magnitude, than the total execution time of the optimized
application."
"In this paper, we investigate random walk based token circulation in dynamic
environments subject to failures. We describe hypotheses on the dynamic
environment that allow random walks to meet the important property that the
token visits any node infinitely often. The randomness of this scheme allows it
to work on any topology, and require no adaptation after a topological change,
which is a desirable property for applications to dynamic systems. For random
walks to be a traversal scheme and to answer the concurrence problem, one needs
to guarantee that exactly one token circulates in the system. In the presence
of transient failures, configurations with multiple tokens or with no token can
occur. The meeting property of random walks solves the cases with multiple
tokens. The reloading wave mechanism we propose, together with timeouts, allows
to detect and solve cases with no token. This traversal scheme is
self-stabilizing, and universal, meaning that it needs no assumption on the
system topology. We describe conditions on the dynamicity (with a local
detection criterion) under which the algorithm is tolerant to dynamic
reconfigurations. We conclude by a study on the time between two visits of the
token to a node, which we use to tune the parameters of the reloading wave
mechanism according to some system characteristics."
"Clustering is a promising approach for building hierarchies and simplifying
the routing process in mobile ad-hoc network environments. The main objective
of clustering is to identify suitable node representatives, i.e. cluster heads
(CHs), to store routing and topology information and maximize clusters
stability. Traditional clustering algorithms suggest CH election exclusively
based on node IDs or location information and involve frequent broadcasting of
control packets, even when network topology remains unchanged. More recent
works take into account additional metrics (such as energy and mobility) and
optimize initial clustering. However, in many situations (e.g. in relatively
static topologies) re-clustering procedure is hardly ever invoked; hence
initially elected CHs soon reach battery exhaustion. Herein, we introduce an
efficient distributed clustering algorithm that uses both mobility and energy
metrics to provide stable cluster formations. CHs are initially elected based
on the time and cost-efficient lowest-ID method. During clustering maintenance
phase though, node IDs are re-assigned according to nodes mobility and energy
status, ensuring that nodes with low-mobility and sufficient energy supply are
assigned low IDs and, hence, are elected as CHs. Our algorithm also reduces
control traffic volume since broadcast period is adjusted according to nodes
mobility pattern: we employ infrequent broadcasting for relative static network
topologies, and increase broadcast frequency for highly mobile network
configurations. Simulation results verify that energy consumption is uniformly
distributed among network nodes and that signaling overhead is significantly
decreased."
"Data-flow is a natural approach to parallelism. However, describing
dependencies and control between fine-grained data-flow tasks can be complex
and present unwanted overheads. TALM (TALM is an Architecture and Language for
Multi-threading) introduces a user-defined coarse-grained parallel data-flow
model, where programmers identify code blocks, called super-instructions, to be
run in parallel and connect them in a data-flow graph. TALM has been
implemented as a hybrid Von Neumann/data-flow execution system: the
\emph{Trebuchet}. We have observed that TALM's usefulness largely depends on
how programmers specify and connect super-instructions. Thus, we present
\emph{Couillard}, a full compiler that creates, based on an annotated
C-program, a data-flow graph and C-code corresponding to each
super-instruction. We show that our toolchain allows one to benefit from
data-flow execution and explore sophisticated parallel programming techniques,
with small effort. To evaluate our system we have executed a set of real
applications on a large multi-core machine. Comparison with popular parallel
programming methods shows competitive speedups, while providing an easier
parallel programing approach."
"Coordination in a distributed system is facilitated if there is a unique
process, the leader, to manage the other processes. The leader creates edicts
and sends them to other processes for execution or forwarding to other
processes. The leader may fail, and when this occurs a leader election protocol
selects a replacement. This paper describes Nerio, a class of such leader
election protocols."
"We consider asynchronous multiprocessor systems where processes communicate
by accessing shared memory. Exchange of information among processes in such a
multiprocessor necessitates costly memory accesses called \emph{remote memory
references} (RMRs), which generate communication on the interconnect joining
processors and main memory. In this paper we compare two popular shared memory
architecture models, namely the \emph{cache-coherent} (CC) and
\emph{distributed shared memory} (DSM) models, in terms of their power for
solving synchronization problems efficiently with respect to RMRs. The
particular problem we consider entails one process sending a ""signal"" to a
subset of other processes. We show that a variant of this problem can be solved
very efficiently with respect to RMRs in the CC model, but not so in the DSM
model, even when we consider amortized RMR complexity.
  To our knowledge, this is the first separation in terms of amortized RMR
complexity between the CC and DSM models. It is also the first separation in
terms of RMR complexity (for asynchronous systems) that does not rely in any
way on wait-freedom---the requirement that a process makes progress in a
bounded number of its own steps."
"The scalability and efficiency of graph applications are significantly
constrained by conventional systems and their supporting programming models.
Technology trends like multicore, manycore, and heterogeneous system
architectures are introducing further challenges and possibilities for emerging
application domains such as graph applications. This paper explores the space
of effective parallel execution of ephemeral graphs that are dynamically
generated using the Barnes-Hut algorithm to exemplify dynamic workloads. The
workloads are expressed using the semantics of an Exascale computing execution
model called ParalleX. For comparison, results using conventional execution
model semantics are also presented. We find improved load balancing during
runtime and automatic parallelism discovery improving efficiency using the
advanced semantics for Exascale computing."
"Exascale systems, expected to emerge by the end of the next decade, will
require the exploitation of billion-way parallelism at multiple hierarchical
levels in order to achieve the desired sustained performance. The task of
assessing future machine performance is approached by identifying the factors
which currently challenge the scalability of parallel applications. It is
suggested that the root cause of these challenges is the incoherent coupling
between the current enabling technologies, such as Non-Uniform Memory Access of
present multicore nodes equipped with optional hardware accelerators and the
decades older execution model, i.e., the Communicating Sequential Processes
(CSP) model best exemplified by the message passing interface (MPI) application
programming interface. A new execution model, ParalleX, is introduced as an
alternative to the CSP model. In this paper, an overview of the ParalleX
execution model is presented along with details about a ParalleX-compliant
runtime system implementation called High Performance ParalleX (HPX). Scaling
and performance results for an adaptive mesh refinement numerical relativity
application developed using HPX are discussed. The performance results of this
HPX-based application are compared with a counterpart MPI-based mesh refinement
code. The overheads associated with HPX are explored and hardware solutions are
introduced for accelerating the runtime system."
"We consider the problem of sensor localization in a wireless network in a
multipath environment, where time and angle of arrival information are
available at each sensor. We propose a distributed algorithm based on belief
propagation, which allows sensors to cooperatively self-localize with respect
to one single anchor in a multihop network. The algorithm has low overhead and
is scalable. Simulations show that although the network is loopy, the proposed
algorithm converges, and achieves good localization accuracy."
"Several applications in astrophysics require adequately resolving many
physical and temporal scales which vary over several orders of magnitude.
Adaptive mesh refinement techniques address this problem effectively but often
result in constrained strong scaling performance. The ParalleX execution model
is an experimental execution model that aims to expose new forms of program
parallelism and eliminate any global barriers present in a scaling-impaired
application such as adaptive mesh refinement. We present two astrophysics
applications using the ParalleX execution model: a tabulated equation of state
component for neutron star evolutions and a cosmology model evolution.
Performance and strong scaling results from both simulations are presented. The
tabulated equation of state data are distributed with transparent access over
the nodes of the cluster. This allows seamless overlapping of computation with
the latencies introduced by the remote access to the table. Because of the
expected size increases to the equation of state table, this type of table
partitioning for neutron star simulations is essential while the implementation
is greatly simplified by ParalleX semantics."
"This paper describes a new QR factorization algorithm which is especially
designed for massively parallel platforms combining parallel distributed
multi-core nodes. These platforms make the present and the foreseeable future
of high-performance computing. Our new QR factorization algorithm falls in the
category of the tile algorithms which naturally enables good data locality for
the sequential kernels executed by the cores (high sequential performance), low
number of messages in a parallel distributed setting (small latency term), and
fine granularity (high parallelism)."
"E-science applications may require huge amounts of data and high processing
power where grid infrastructures are very suitable for meeting these
requirements. The load distribution in a grid may vary leading to the
bottlenecks and overloaded sites. We describe a hierarchical dynamic load
balancing protocol for Grids. The Grid consists of clusters and each cluster is
represented by a coordinator. Each coordinator first attempts to balance the
load in its cluster and if this fails, communicates with the other coordinators
to perform transfer or reception of load. This process is repeated
periodically. We analyze the correctness, performance and scalability of the
proposed protocol and show from the simulation results that our algorithm
balances the load by decreasing the number of high loaded nodes in a grid
environment."
"The high-performance scalable parallel algorithm for rigorous calculation of
partition function of lattice systems with finite number Ising spins was
developed. The parallel calculations run by C++ code with using of Message
Passing Interface and massive parallel instructions. The algorithm can be used
for the research of the interacting spin systems in the Ising models of 2D and
3D. The processing power and scalability is analyzed for different parallel and
distributed systems. Different methods of the speed up measuring allow obtain
the super-linear speeding up for the small number of processes. Program code
could be useful also for research by exact method of different Ising spin
systems, e.g. system with competition interactions."
"We present the use of a hybrid static/dynamic scheduling strategy of the task
dependency graph for direct methods used in dense numerical linear algebra.
This strategy provides a balance of data locality, load balance, and low
dequeue overhead. We show that the usage of this scheduling in communication
avoiding dense factorization leads to significant performance gains. On a 48
core AMD Opteron NUMA machine, our experiments show that we can achieve up to
64% improvement over a version of CALU that uses fully dynamic scheduling, and
up to 30% improvement over the version of CALU that uses fully static
scheduling. On a 16-core Intel Xeon machine, our hybrid static/dynamic
scheduling approach is up to 8% faster than the version of CALU that uses a
fully static scheduling or fully dynamic scheduling. Our algorithm leads to
speedups over the corresponding routines for computing LU factorization in well
known libraries. On the 48 core AMD NUMA machine, our best implementation is up
to 110% faster than MKL, while on the 16 core Intel Xeon machine, it is up to
82% faster than MKL. Our approach also shows significant speedups compared with
PLASMA on both of these systems."
"Byzantine Fault Tolerant (BFT) systems are considered by the systems research
community to be state of the art with regards to providing reliability in
distributed systems. BFT systems provide safety and liveness guarantees with
reasonable assumptions, amongst a set of nodes where at most f nodes display
arbitrarily incorrect behaviors, known as Byzantine faults. Despite this, BFT
systems are still rarely used in practice. In this paper we describe our
experience, from an application developer's perspective, trying to leverage the
publicly available and highly-tuned PBFT middleware (by Castro and Liskov), to
provide provable reliability guarantees for an electronic voting application
with high security and robustness needs. We describe several obstacles we
encountered and drawbacks we identified in the PBFT approach. These include
some that we tackled, such as lack of support for dynamic client management and
leaving state management completely up to the application. Others still
remaining include the lack of robust handling of non-determinism, lack of
support for web-based applications, lack of support for stronger cryptographic
primitives, and others. We find that, while many of the obstacles could be
overcome with a revised BFT middleware implementation that is tuned
specifically for the needs of the particular application, they require
significant engineering effort and time and their performance implications for
the end-application are unclear. An application developer is thus unlikely to
be willing to invest the time and effort to do so to leverage the BFT approach.
We conclude that the research community needs to focus on the usability of BFT
algorithms for real world applications, from the end-developer perspective, in
addition to continuing to improve the BFT middleware performance, robustness
and deployment layouts."
"Cloud computing providers are now offering their unused resources for leasing
in the spot market, which has been considered the first step towards a
full-fledged market economy for computational resources. Spot instances are
virtual machines (VMs) available at lower prices than their standard on-demand
counterparts. These VMs will run for as long as the current price is lower than
the maximum bid price users are willing to pay per hour. Spot instances have
been increasingly used for executing compute-intensive applications. In spite
of an apparent economical advantage, due to an intermittent nature of biddable
resources, application execution times may be prolonged or they may not finish
at all. This paper proposes a resource allocation strategy that addresses the
problem of running compute-intensive jobs on a pool of intermittent virtual
machines, while also aiming to run applications in a fast and economical way.
To mitigate potential unavailability periods, a multifaceted fault-aware
resource provisioning policy is proposed. Our solution employs price and
runtime estimation mechanisms, as well as three fault tolerance techniques,
namely checkpointing, task duplication and migration. We evaluate our
strategies using trace-driven simulations, which take as input real price
variation traces, as well as an application trace from the Parallel Workload
Archive. Our results demonstrate the effectiveness of executing applications on
spot instances, respecting QoS constraints, despite occasional failures."
"Infrastructure-as-a-Service providers are offering their unused resources in
the form of variable-priced virtual machines (VMs), known as ""spot instances"",
at prices significantly lower than their standard fixed-priced resources. To
lease spot instances, users specify a maximum price they are willing to pay per
hour and VMs will run only when the current price is lower than the user's bid.
This paper proposes a resource allocation policy that addresses the problem of
running deadline-constrained compute-intensive jobs on a pool of composed
solely of spot instances, while exploiting variations in price and performance
to run applications in a fast and economical way. Our policy relies on job
runtime estimations to decide what are the best types of VMs to run each job
and when jobs should run. Several estimation methods are evaluated and
compared, using trace-based simulations, which take real price variation traces
obtained from Amazon Web Services as input, as well as an application trace
from the Parallel Workload Archive. Results demonstrate the effectiveness of
running computational jobs on spot instances, at a fraction (up to 60% lower)
of the price that would normally cost on fixed priced resources."
"In our work we present two parallel algorithms and their lock-free
implementations using a popular GPU environment Nvidia CUDA. The first
algorithm is the push-relabel method for the flow problem in grid graphs. The
second is the cost scaling algorithm for the assignment problem in complete
bipartite graphs."
"We present preliminary results of an investigation into the suitability of
virtualised hardware -- in particular clouds -- for running computational
experiments. Our main concern was that the reported CPU time would not be
reliable and reproducible. The results demonstrate that while this is true in
cases where many virtual machines are running on the same physical hardware,
there is no inherent variation introduced by using virtualised hardware
compared to non-virtualised hardware."
"We study the fundamental problem of information spreading (also known as
gossip) in dynamic networks. In gossip, or more generally, $k$-gossip, there
are $k$ pieces of information (or tokens) that are initially present in some
nodes and the problem is to disseminate the $k$ tokens to all nodes. The goal
is to accomplish the task in as few rounds of distributed computation as
possible. The problem is especially challenging in dynamic networks where the
network topology can change from round to round and can be controlled by an
on-line adversary.
  The focus of this paper is on the power of token-forwarding algorithms, which
do not manipulate tokens in any way other than storing and forwarding them. We
first consider a worst-case adversarial model first studied by Kuhn, Lynch, and
Oshman~\cite{kuhn+lo:dynamic} in which the communication links for each round
are chosen by an adversary, and nodes do not know who their neighbors for the
current round are before they broadcast their messages. Our main result is an
$\Omega(nk/\log n)$ lower bound on the number of rounds needed for any
deterministic token-forwarding algorithm to solve $k$-gossip. This resolves an
open problem raised in~\cite{kuhn+lo:dynamic}, improving their lower bound of
$\Omega(n \log k)$, and matching their upper bound of $O(nk)$ to within a
logarithmic factor.
  We next show that token-forwarding algorithms can achieve subquadratic time
in the offline version of the problem where the adversary has to commit all the
topology changes in advance at the beginning of the computation, and present
two polynomial-time offline token-forwarding algorithms. Our results are a step
towards understanding the power and limitation of token-forwarding algorithms
in dynamic networks."
"Distributed consensus computation over random graph processes is considered.
The random graph process is defined as a sequence of random variables which
take values from the set of all possible digraphs over the node set. At each
time step, every node updates its state based on a Bernoulli trial, independent
in time and among different nodes: either averaging among the neighbor set
generated by the random graph, or sticking with its current state.
Connectivity-independence and arc-independence are introduced to capture the
fundamental influence of the random graphs on the consensus convergence.
Necessary and/or sufficient conditions are presented on the success
probabilities of the Bernoulli trials for the network to reach a global almost
sure consensus, with some sharp threshold established revealing a consensus
zero-one law. Convergence rates are established by lower and upper bounds of
the $\epsilon$-computation time. We also generalize the concepts of
connectivity/arc independence to their analogues from the $*$-mixing point of
view, so that our results apply to a very wide class of graphical models,
including the majority of random graph models in the literature, e.g.,
Erd\H{o}s-R\'{e}nyi, gossiping, and Markovian random graphs. We show that under
$*$-mixing, our convergence analysis continues to hold and the corresponding
almost sure consensus conditions are established. Finally, we further
investigate almost sure finite-time convergence of random gossiping algorithms,
and prove that the Bernoulli trials play a key role in ensuring finite-time
convergence. These results add to the understanding of the interplay between
random graphs, random computations, and convergence probability for distributed
information processing."
"Cloud computing is a disruptive technology, representing a new model for
information technology (IT) solution engineering and management that promises
to introduce significant cost savings and other benefits. The adoption of Cloud
computing requires a detailed comparison of infrastructure alternatives, taking
a number of aspects into careful consideration. Existing methods of evaluation,
however, limit decision making to the relative costs of cloud computing, but do
not take a broader range of criteria into account. In this paper, we introduce
a generic, multi-criteria-based decision framework and an application for Cloud
Computing, the Multi-Criteria Comparison Method for Cloud Computing ((MC2)2).
The framework and method allow organizations to determine what infrastructure
best suits their needs by evaluating and ranking infrastructure alternatives
using multiple criteria. Therefore, (MC2)2 offers a way to differentiate
infrastructures not only by costs, but also in terms of benefits, opportunities
and risks. (MC2)2 can be adapted to facilitate a wide array of decision-making
scenarios within the domain of information technology infrastructures,
depending on the criteria selected to support the framework."
"Design and architecture of cloud storage system plays a vital role in cloud
computing infrastructure in order to improve the storage capacity as well as
cost effectiveness. Usually cloud storage system provides users to efficient
storage space with elasticity feature. One of the challenges of cloud storage
system is difficult to balance the providing huge elastic capacity of storage
and investment of expensive cost for it. In order to solve this issue in the
cloud storage infrastructure, low cost PC cluster based storage server is
configured to be activated for large amount of data to provide cloud users.
Moreover, one of the contributions of this system is proposed an analytical
model using M/M/1 queuing network model, which is modeled on intended
architecture to provide better response time, utilization of storage as well as
pending time when the system is running. According to the analytical result on
experimental testing, the storage can be utilized more than 90% of storage
space. In this paper, two parts have been described such as (i) design and
architecture of PC cluster based cloud storage system. On this system, related
to cloud applications, services configurations are explained in detailed. (ii)
Analytical model has been enhanced to be increased the storage utilization on
the target architecture."
"Motivated by non-linear, non-Gaussian, distributed multi-sensor/agent
navigation and tracking applications, we propose a multi-rate consensus/fusion
based framework for distributed implementation of the particle filter (CF/DPF).
The CF/DPF framework is based on running localized particle filters to estimate
the overall state vector at each observation node. Separate fusion filters are
designed to consistently assimilate the local filtering distributions into the
global posterior by compensating for the common past information between
neighbouring nodes. The CF/DPF offers two distinct advantages over its
counterparts. First, the CF/DPF framework is suitable for scenarios where
network connectivity is intermittent and consensus can not be reached between
two consecutive observations. Second, the CF/DPF is not limited to the Gaussian
approximation for the global posterior density. A third contribution of the
paper is the derivation of the exact expression for computing the posterior
Cramer-Rao lower bound (PCRLB) for the distributed architecture based on a
recursive procedure involving the local Fisher information matrices (FIM) of
the distributed estimators. The performance of the CF/DPF algorithm closely
follows the centralized particle filter approaching the PCRLB at the signal to
noise ratios that we tested."
"Recently, the use and deployment of web services has dramatically increased.
This is due to the easiness, interoperability, and flexibility that web
services offer to the software systems, which other software structures don't
support or support poorly. Web services discovery became more important and
research conducted in this area became more critical. With the increasing
number of published and publicly available web services, speed in web service
discovery process is becoming an issue which cannot be neglected. This paper
proposes a generic non-functional based web services classification algorithm.
Classification algorithm depends on information supplied by web service
provider at the registration time. Authors have proved mathematically and
experimentally the usefulness and efficiency of proposed algorithm."
"One of the key problems in migrating multi-component enterprise applications
to Clouds is selecting the best mix of VM images and Cloud infrastructure
services. A migration process has to ensure that Quality of Service (QoS)
requirements are met, while satisfying conflicting selection criteria, e.g.
throughput and cost. When selecting Cloud services, application engineers must
consider heterogeneous sets of criteria and complex dependencies across
multiple layers impossible to resolve manually. To overcome this challenge, we
present the generic recommender framework CloudGenius and an implementation
that leverage well known multi-criteria decision making technique Analytic
Hierarchy Process to automate the selection process based on a model, factors,
and QoS requirements related to enterprise applications. In particular, we
introduce a structured migration process for multi-component enterprise
applications, clearly identify the most important criteria relevant to the
selection problem and present a multi-criteria-based selection algorithm.
Experiments with the software prototype CumulusGenius show time complexities."
"In this paper we describe the various scoring systems used to calculate
rewards of participants in Bitcoin pooled mining, explain the problems each
were designed to solve and analyze their respective advantages and
disadvantages."
"We consider the problem of scheduling communication on optical WDM
(wavelength division multiplexing) networks using the light-trails technology.
We seek to design scheduling algorithms such that the given transmission
requests can be scheduled using minimum number of wavelengths (optical
channels). We provide algorithms and close lower bounds for two versions of the
problem on an $n$ processor linear array/ring network. In the {\em stationary}
version, the pattern of transmissions (given) is assumed to not change over
time. For this, a simple lower bound is $c$, the congestion or the maximum
total traffic required to pass through any link. We give an algorithm that
schedules the transmissions using $O(c+\log{n})$ wavelengths. We also show a
pattern for which $\Omega(c+\log{n}/\log\log{n})$ wavelengths are needed. In
the {\em on-line} version, the transmissions arrive and depart dynamically, and
must be scheduled without upsetting the previously scheduled transmissions. For
this case we give an on-line algorithm which has competitive ratio
$\Theta(\log{n})$. We show that this is optimal in the sense that every on-line
algorithm must have competitive ratio $\Omega(\log{n})$. We also give an
algorithm that appears to do well in simulation (for the classes of traffic we
consider), but which has competitive ratio between $\Omega(\log^2n/\log
\log{n})$ and $O(\log^2n)$. We present detailed simulations of both our
algorithms."
"Despite the occurrence of elegant algorithms for solving complex problem,
exhaustive search has retained its significance since many real-life problems
exhibit no regular structure and exhaustive search is the only possible
solution. The advent of high-performance computing either via multicore
processors or distributed processors emphasizes the possibility for exhaustive
search by multiple search agents. Here we analyse the performance of exhaustive
search when it is conducted by multiple search agents. Several strategies for
cooperation between the search agents are evaluated. We discover that the
performance of the search improves with the increase in the level of
cooperation. Same search performance can be achieved with homogeneous and
heterogeneous search agents provided that the length of subregions allocated to
individual search regions follow the differences in the speeds of heterogeneous
search agents."
"Heterogeneous systems are becoming more common on High Performance Computing
(HPC) systems. Even using tools like CUDA and OpenCL it is a non-trivial task
to obtain optimal performance on the GPU. Approaches to simplifying this task
include Merge (a library based framework for heterogeneous multi-core systems),
Zippy (a framework for parallel execution of codes on multiple GPUs), BSGP (a
new programming language for general purpose computation on the GPU) and
CUDA-lite (an enhancement to CUDA that transforms code based on annotations).
In addition, efforts are underway to improve compiler tools for automatic
parallelization and optimization of affine loop nests for GPUs and for
automatic translation of OpenMP parallelized codes to CUDA.
  In this paper we present an alternative approach: a new computational
framework for the development of massively data parallel scientific codes
applications suitable for use on such petascale/exascale hybrid systems built
upon the highly scalable Cactus framework. As the first non-trivial
demonstration of its usefulness, we successfully developed a new 3D CFD code
that achieves improved performance."
"In grid computing, trust has massive significance. There is lot of research
to propose various models in providing trusted resource sharing mechanisms. The
trust is a belief or perception that various researchers have tried to
correlate with some computational model. Trust on any entity can be direct or
indirect. Direct trust is the impact of either first impression over the entity
or acquired during some direct interaction. Indirect trust is the trust may be
due to either reputation gained or recommendations received from various
recommenders of a particular domain in a grid or any other domain outside that
grid or outside that grid itself. Unfortunately, malicious indirect trust leads
to the misuse of valuable resources of the grid. This paper proposes the
mechanism of identifying and purging the untrustworthy recommendations in the
grid environment. Through the obtained results, we show the way of purging of
untrustworthy entities."
"We design and analyze the performance of a redundancy management mechanism
for Peer-to-Peer backup applications. Armed with the realization that a backup
system has peculiar requirements -- namely, data is read over the network only
during restore processes caused by data loss -- redundancy management targets
data durability rather than attempting to make each piece of information
availabile at any time.
  In our approach each peer determines, in an on-line manner, an amount of
redundancy sufficient to counter the effects of peer deaths, while preserving
acceptable data restore times. Our experiments, based on trace-driven
simulations, indicate that our mechanism can reduce the redundancy by a factor
between two and three with respect to redundancy policies aiming for data
availability. These results imply an according increase in storage capacity and
decrease in time to complete backups, at the expense of longer times required
to restore data. We believe this is a very reasonable price to pay, given the
nature of the application.
  We complete our work with a discussion on practical issues, and their
solutions, related to which encoding technique is more suitable to support our
scheme."
"This work introduces a runtime model for managing communication with support
for latency-hiding. The model enables non-computer science researchers to
exploit communication latency-hiding techniques seamlessly. For compiled
languages, it is often possible to create efficient schedules for
communication, but this is not the case for interpreted languages. By
maintaining data dependencies between scheduled operations, it is possible to
aggressively initiate communication and lazily evaluate tasks to allow maximal
time for the communication to finish before entering a wait state. We implement
a heuristic of this model in DistNumPy, an auto-parallelizing version of
numerical Python that allows sequential NumPy programs to run on distributed
memory architectures. Furthermore, we present performance comparisons for eight
benchmarks with and without automatic latency-hiding. The results shows that
our model reduces the time spent on waiting for communication as much as 27
times, from a maximum of 54% to only 2% of the total execution time, in a
stencil application."
"In this paper, we explore the problem of iterative approximate Byzantine
consensus in arbitrary directed graphs. In particular, we prove a necessary and
sufficient condition for the existence of iterative byzantine consensus
algorithms. Additionally, we use our sufficient condition to examine whether
such algorithms exist for some specific graphs."
"Let G = (V,E) be an n-vertex graph and M_d a d-vertex graph, for some
constant d. Is M_d a subgraph of G? We consider this problem in a model where
all n processes are connected to all other processes, and each message contains
up to O(log n) bits. A simple deterministic algorithm that requires
O(n^((d-2)/d) / log n) communication rounds is presented. For the special case
that M_d is a triangle, we present a probabilistic algorithm that requires an
expected O(ceil(n^(1/3) / (t^(2/3) + 1))) rounds of communication, where t is
the number of triangles in the graph, and O(min{n^(1/3) log^(2/3) n / (t^(2/3)
+ 1), n^(1/3)}) with high probability.
  We also present deterministic algorithms specially suited for sparse graphs.
In any graph of maximum degree Delta, we can test for arbitrary subgraphs of
diameter D in O(ceil(Delta^(D+1) / n)) rounds. For triangles, we devise an
algorithm featuring a round complexity of O(A^2 / n + log_(2+n/A^2) n), where A
denotes the arboricity of G."
"Service-oriented infrastructures pose new challenges in a number of areas,
notably with regard to security and dependability. BT has developed a
combination of innovative security solutions and governance frameworks that can
address these challenges. They include advances in identity federation;
distributed usage and access management; context-aware secure messaging,
routing and transformation; and (security) policy governance for
service-oriented architectures. This paper discusses these developments and the
steps being taken to validate their functionality and performance."
"In this article, the authors introduce the main ideas around the governance
of cross-Cloud application deployment and their related concepts. It is argued
that, due to the increasing complexity and nature of the Cloud market, an
intermediary specialized in brokering the deployment of different components of
a same application onto different Cloud products could both facilitate said
deployment and in some cases improve its quality in terms of cost, security &
reliability and QoS. In order to fulfill these objectives, the authors propose
a high level architecture that relies on their previous work on governance of
policy & rule driven distributed systems. This architecture aims at supplying
five main functions of 1) translation of Service Level Agreements (SLAs) and
pricing into a common shared DSL, 2) correlation of analytical data (e.g.
monitoring, metering), 3) combination of Cloud products, 4) information from
third parties regarding different aspects of Quality of Service (QoS) and 5)
cross-Cloud application deployment specification and governance."
"The rule technological landscape is becoming ever more complex, with an
extended number of specifications and products. It is therefore becoming
increasingly difficult to integrate rule-driven components and manage
interoperability in multi-rule engine environments. The described work presents
the possibility to provide a common interface for rule-driven components in a
distributed system. The authors' approach leverages on a set of discovery
protocol, rule interchange and user interface to alleviate the environment's
complexity."
"A fundamental ambition of grid and distributed systems is to be capable of
sustaining evolution and allowing for adaptability ((F. Losavio et al., 2002),
(S. Radhakrishnan, 2005)). Furthermore, as the complexity and sophistication of
theses structures increases, so does the need for adaptability of each
component. One of the primary benefits of service oriented architecture (SOA)
is the ability to compose applications, processes or more complex services from
other services which increases the capacity for adaptation. This document
proposes a novel infrastructure composition model that aims at increasing the
adaptability of the capabilities exposed through it by dynamically managing
their non functional requirements."
"In this paper, we propose an analytical method to model the dependency
between configuration parameters and total execution time of Map-Reduce
applications. Our approach has three key phases: profiling, modeling, and
prediction. In profiling, an application is run several times with different
sets of MapReduce configuration parameters to profile the execution time of the
application on a given platform. Then in modeling, the relation between these
parameters and total execution time is modeled by multivariate linear
regression. Among the possible configuration parameters, two main parameters
have been used in this study: the number of Mappers, and the number of
Reducers. For evaluation, two standard applications (WordCount, and Exim
Mainlog parsing) are utilized to evaluate our technique on a 4-node MapReduce
platform."
"Advance reservation is important to guarantee the quality of services of jobs
by allowing exclusive access to resources over a defined time interval on
resources. It is a challenge for the scheduler to organize available resources
efficiently and to allocate them for parallel AR jobs with deadline constraint
appropriately. This paper provides a slot-based data structure to organize
available resources of multiprocessor systems in a way that enables efficient
search and update operations, and formulates a suite of scheduling policies to
allocate resources for dynamically arriving AR requests. The performance of the
scheduling algorithms were investigated by simulations with different job sizes
and durations, system loads and scheduling flexibilities. Simulation results
show that job sizes and durations, system load and the flexibility of
scheduling will impact the performance metrics of all the scheduling
algorithms, and the PE-Worst-Fit algorithm becomes the best algorithm for the
scheduler with the highest acceptance rate of AR requests, and the jobs with
the First-Fit algorithm experience the lowest average slowdown. The data
structure and scheduling policies can be used to organize and allocate
resources for parallel AR jobs with deadline constraint in large-scale
computing systems."
"This paper presents AppPot, a system for creating Linux software appliances.
AppPot can be run as a regular batch or grid job and executed in user space,
and requires no special virtualization support in the infrastructure.
  The main design goal of AppPot is to bring the benefits of a
virtualization-based IaaS cloud to existing batch-oriented computing
infrastructures.
  In particular, AppPot addresses the application deployment and configuration
on large heterogeneous computing infrastructures: users are enabled to prepare
their own customized virtual appliance for providing a safe execution
environment for their applications. These appliances can then be executed on
virtually any computing infrastructure being in a private or public cloud as
well as any batch-controlled computing clusters the user may have access to.
  We give an overview of AppPot and its features, the technology that makes it
possible, and report on experiences running it in production use within the
Swiss National Grid infrastructure SMSCG."
"This paper presents a proof of correctness of an iterative approximate
Byzantine consensus (IABC) algorithm for directed graphs. The iterative
algorithm allows fault- free nodes to reach approximate conensus despite the
presence of up to f Byzantine faults. Necessary conditions on the underlying
network graph for the existence of a correct IABC algorithm were shown in our
recent work [15, 16]. [15] also analyzed a specific IABC algorithm and showed
that it performs correctly in any network graph that satisfies the necessary
condition, proving that the necessary condition is also sufficient. In this
paper, we present an alternate proof of correctness of the IABC algorithm,
using a familiar technique based on transition matrices [9, 3, 17, 19].
  The key contribution of this paper is to exploit the following observation:
for a given evolution of the state vector corresponding to the state of the
fault-free nodes, many alternate state transition matrices may be chosen to
model that evolution cor- rectly. For a given state evolution, we identify one
approach to suitably ""design"" the transition matrices so that the standard
tools for proving convergence can be applied to the Byzantine fault-tolerant
algorithm as well. In particular, the transition matrix for each iteration is
designed such that each row of the matrix contains a large enough number of
elements that are bounded away from 0."
"The MapReduce framework has been generating a lot of interest in a wide range
of areas. It has been widely adopted in industry and has been used to solve a
number of non-trivial problems in academia. Putting MapReduce on strong
theoretical foundations is crucial in understanding its capabilities. This work
links MapReduce to the BSP model of computation, underlining the relevance of
BSP to modern parallel algorithm design and defining a subclass of BSP
algorithms that can be efficiently implemented in MapReduce."
"Production operation of large distributed computing infrastructures (DCI)
still requires a lot of human intervention to reach acceptable quality of
service. This may be achievable for scientific communities with solid IT
support, but it remains a show-stopper for others. Some application execution
environments are used to hide runtime technical issues from end users. But they
mostly aim at fault-tolerance rather than incident resolution, and their
operation still requires substantial manpower. A longer-term support activity
is thus needed to ensure sustained quality of service for Virtual Organisations
(VO). This paper describes how the biomed VO has addressed this challenge by
setting up a technical support team. Its organisation, tooling, daily tasks,
and procedures are described. Results are shown in terms of resource usage by
end users, amount of reported incidents, and developed software tools. Based on
our experience, we suggest ways to measure the impact of the technical support,
perspectives to decrease its human cost and make it more community-specific."
"With the rise of service-oriented computing, applications are more and more
based on coordination of autonomous services. Envisioned over largely
distributed and highly dynamic platforms, expressing this coordination calls
for alternative programming models. The chemical programming paradigm, which
models applications as chemical solutions where molecules representing digital
entities involved in the computation, react together to produce a result, has
been recently shown to provide the needed abstractions for autonomic
coordination of services. However, the execution of such programs over large
scale platforms raises several problems hindering this paradigm to be actually
leveraged. Among them, the atomic capture of molecules participating in concur-
rent reactions is one of the most significant. In this paper, we propose a
protocol for the atomic capture of these molecules distributed and evolving
over a large scale platform. As the density of possible reactions is crucial
for the liveness and efficiency of such a capture, the protocol proposed is
made up of two sub-protocols, each of them aimed at addressing different levels
of densities of potential reactions in the solution. While the decision to
choose one or the other is local to each node participating in a program's
execution, a global coherent behaviour is obtained. Proof of liveness, as well
as intensive simulation results showing the efficiency and limited overhead of
the protocol are given."
"The paper is devoted to a mathematical model of concurrency the special case
of which is asynchronous system. Distributed asynchronous automata are
introduced here. It is proved that the Petri nets and transition systems with
independence can be considered like the distributed asynchronous automata. Time
distributed asynchronous automata are defined in standard way by the map which
assigns time intervals to events. It is proved that the time distributed
asynchronous automata are generalized the time Petri nets and asynchronous
systems."
"We investigate the hardness of establishing as many stable marriages (that
is, marriages that last forever) in a population whose memory is placed in some
arbitrary state with respect to the considered problem, and where traitors try
to jeopardize the whole process by behaving in a harmful manner. On the
negative side, we demonstrate that no solution that is completely insensitive
to traitors can exist, and we propose a protocol for the problem that is
optimal with respect to the traitor containment radius."
"The DEPAS (Decentralized Probabilistic Auto-Scaling) algorithm assumes an
overlay network of computing nodes where each node probabilistically decides to
shut down, allocate one or more other nodes or do nothing. DEPAS was
formulated, tested, and theoretically analyzed for the simplified case of
homogenous systems. In this paper, we extend DEPAS to heterogeneous systems."
"This work deals with Workflow Mining (WM) a very active and promising
research area. First, in this paper we give a critical and comparative study of
three representative WM systems of this area: the ProM, InWolve and
WorkflowMiner systems. The comparison is made according to quality criteria
that we have defined such as the capacity to filter and convert a Workflow log,
the capacity to discover workflow perspectives and the capacity to support
Multi-Analysis of processes. The major drawback of these systems is the non
possibility to deal with organizational perspective discovering issue. We mean
by organizational perspective, the organizational structures (federation,
coalition, market or hierarchy) and interaction protocols (contract net,
auction or vote). This paper defends the idea that organizational dimension in
Multi-Agent System is an appropriate approach to support the discovering of
this organizational perspective. Second, the paper proposes a Workflow log
meta-model which extends the classical one by considering the interactions
among actors thanks to the FIPA-ACL Performatives. Third, it describes in
details our DiscopFlow tool which validates our contribution."
"In this thesis report, we have a survey on state-of-the-art methods for
modelling resource utilization of MapReduce applications regard to its
configuration parameters. After implementation of one of the algorithms in
literature, we tried to find that if CPU usage modelling of a MapReduce
application can be used to predict CPU usage of another MapReduce application."
"Modern concurrent programming benefits from a large variety of
synchronization techniques. These include conventional pessimistic locking, as
well as optimistic techniques based on conditional synchronization primitives
or transactional memory. Yet, it is unclear which of these approaches better
leverage the concurrency inherent to multi-cores.
  In this paper, we compare the level of concurrency one can obtain by
converting a sequential program into a concurrent one using optimistic or
pessimistic techniques. To establish fair comparison of such implementations,
we introduce a new correctness criterion for concurrent programs, defined
independently of the synchronization techniques they use.
  We treat a program's concurrency as its ability to accept a concurrent
schedule, a metric inspired by the theories of both databases and transactional
memory. We show that pessimistic locking can provide strictly higher
concurrency than transactions for some applications whereas transactions can
provide strictly higher concurrency than pessimistic locks for others. Finally,
we show that combining the benefits of the two synchronization techniques can
provide strictly more concurrency than any of them individually. We propose a
list-based set algorithm that is optimal in the sense that it accepts all
correct concurrent schedules. As we show via experimentation, the optimality in
terms of concurrency is reflected by scalability gains."
"Graphics processing units (GPU) had evolved from a specialized hardware
capable to render high quality graphics in games to a commodity hardware for
effective processing blocks of data in a parallel schema. This evolution is
particularly interesting for scientific groups, which traditionally use mainly
CPU as a work horse, and now can profit of the arrival of GPU hardware to HPC
clusters. This new GPU hardware promises a boost in peak performance, but it is
not trivial to use. In this article a programming platform designed to promote
a direct use of this specialized hardware is presented. This platform includes
a visual editor of parallel data flows and it is oriented to the execution in
distributed clusters with GPUs. Examples of application in two characteristic
problems, Fast Fourier Transform and Image Compression, are also shown."
"This paper describes a CUDA implementation of Wagener's PRAM convex hull
algorithm in two dimensions. It is presented in Knuth's literate programming
style."
"In this chapter we focus on slack reclamation and propose a new slack
reclamation technique, Multiple Frequency Selection DVFS (MFS-DVFS). The key
idea is to execute each task with a linear combination of more than one
frequency such that this combination results in using the lowest energy by
covering the whole slack time of the task. We have tested our algorithm with
both random and real-world application task graphs and compared with the
results in previous researches in [9] and [12-13]. The experimental results
show that our approach can achieve energy almost identical to the optimum
energy saving."
"Cloud computing has penetrated the Information Technology industry deep
enough to influence major companies to adopt it into their mainstream business.
A strong thrust on the use of virtualization technology to realize
Infrastructure-as-a-Service (IaaS) has led enterprises to leverage
subscription-oriented computing capabilities of public Clouds for hosting their
application services. In parallel, research in academia has been investigating
transversal aspects such as security, software frameworks, quality of service,
and standardization. We believe that the complete realization of the Cloud
computing vision will lead to the introduction of a virtual market where Cloud
brokers, on behalf of end users, are in charge of selecting and composing the
services advertised by different Cloud vendors. In order to make this happen,
existing solutions and technologies have to be redesigned and extended from a
market-oriented perspective and integrated together, giving rise to what we
term Market-Oriented Cloud Computing.
  In this paper, we will assess the current status of Cloud computing by
providing a reference model, discuss the challenges that researchers and IT
practitioners are facing and will encounter in the near future, and present the
approach for solving them from the perspective of the Cloudbus toolkit, which
comprises of a set of technologies geared towards the realization of Market
Oriented Cloud Computing vision. We provide experimental results demonstrating
market-oriented resource provisioning and brokering within a Cloud and across
multiple distributed resources. We also include an application illustrating the
hosting of ECG analysis as SaaS on Amazon IaaS (EC2 and S3) services."
"We consider synchronous dynamic networks which like radio networks may have
asymmetric communication links, and are affected by communication rather than
processor failures. In this paper we investigate the minimal message
survivability in a per round basis that allows for the minimal global
cooperation, i.e., allows to solve any task that is wait-free read-write
solvable. The paper completely characterizes this survivability requirement.
Message survivability is formalized by considering adversaries that have a
limited power to remove messages in a round. Removal of a message on a link in
one direction does not necessarily imply the removal of the message on that
link in the other direction. Surprisingly there exist a single strongest
adversary which solves any wait-free read/write task. Any different adversary
that solves any wait-free read/write task is weaker, and any stronger adversary
will not solve any wait-free read/write task. ABD \cite{ABD} who considered
processor failure, arrived at an adversary that is $n/2$ resilient,
consequently can solve tasks, such as $n/2$-set-consensus, which are not
read/write wait-free solvable. With message adversaries, we arrive at an
adversary which has exactly the read-write wait-free power. Furthermore, this
adversary allows for a considerably simpler (simplest that we know of) proof
that the protocol complex of any read/write wait-free task is a subdivided
simplex, finally making this proof accessible for students with no
algebraic-topology prerequisites, and alternatively dispensing with the
assumption that the Immediate Snapshot complex is a subdivided simplex."
"State-space reduction techniques, used primarily in model-checkers, all rely
on the idea that some actions are independent, hence could be taken in any
(respective) order while put in parallel, without changing the semantics. It is
thus not necessary to consider all execution paths in the interleaving
semantics of a concurrent program, but rather some equivalence classes. The
purpose of this paper is to describe a new algorithm to compute such
equivalence classes, and a representative per class, which is based on ideas
originating in algebraic topology. We introduce a geometric semantics of
concurrent languages, where programs are interpreted as directed topological
spaces, and study its properties in order to devise an algorithm for computing
dihomotopy classes of execution paths. In particular, our algorithm is able to
compute a control-flow graph for concurrent programs, possibly containing
loops, which is ""as reduced as possible"" in the sense that it generates traces
modulo equivalence. A preliminary implementation was achieved, showing
promising results towards efficient methods to analyze concurrent programs,
with very promising results compared to partial-order reduction techniques."
"We study distributed computation in synchronous dynamic networks where an
omniscient adversary controls the unidirectional communication links. Its
behavior is modeled as a sequence of directed graphs representing the active
(i.e. timely) communication links per round. We prove that consensus is
impossible under some natural weak connectivity assumptions, and introduce
vertex-stable root components as a means for circumventing this impossibility.
Essentially, we assume that there is a short period of time during which an
arbitrary part of the network remains strongly connected, while its
interconnect topology may keep changing continuously. We present a consensus
algorithm that works under this assumption, and prove its correctness. Our
algorithm maintains a local estimate of the communication graphs, and applies
techniques for detecting stable network properties and univalent system
configurations. Our possibility results are complemented by several
impossibility results and lower bounds for consensus and other distributed
computing problems like leader election, revealing that our algorithm is
asymptotically optimal."
"The primary concern in area of computational grid is security and resources.
Most of the existing grids address this problem by authenticating the users,
hosts and their interactions in an appropriate manner. A secured system is
compulsory for the efficient utilization of grid services. The high degree of
strangeness has been identified as the problem factors in the secured selection
of grid. Without the assurance of a higher degree of trust relationship,
competent resource selection and utilization cannot be achieved. In this paper
we proposed an approach which is providing reliability and reputation aware
security for resource selection in grid environment. In this approach, the
self-protection capability and reputation weightage is utilized to obtain the
Reliability Factor (RF) value. Therefore jobs are allocated to the resources
that posses higher RF values. Extensive experimental evaluation shows that as
higher trust and reliable nodes are selected the chances of failure decreased
drastically."
"The emergence of cloud computing over the past five years is potentially one
of the breakthrough advances in the history of computing. It delivers hardware
and software resources as virtualization-enabled services and in which
administrators are free from the burden of worrying about the low level
implementation or system administration details. Although cloud computing
offers considerable opportunities for the users (e.g. application developers,
governments, new startups, administrators, consultants, scientists, business
analyst, etc.) such as no up-front investment, lowering operating cost, and
infinite scalability, it has many unique research challenges that need to be
carefully addressed in the future. In this paper, we present a survey on key
cloud computing concepts, resource abstractions, and programming operations for
orchestrating resources and associated research challenges, wherever
applicable."
"Delay-tolerant networks (DTNs) are characterized by a possible absence of
end-to-end communication routes at any instant. Still, connectivity can
generally be established over time and space. The optimality of a temporal path
(journey) in this context can be defined in several terms, including
topological (e.g. {\em shortest} in hops) and temporal (e.g. {\em fastest,
foremost}). The combinatorial problem of computing shortest, foremost, and
fastest journeys {\em given full knowledge} of the network schedule was
addressed a decade ago (Bui-Xuan {\it et al.}, 2003). A recent line of research
has focused on the distributed version of this problem, where foremost,
shortest or fastest {\em broadcast} are performed without knowing the schedule
beforehand. In this paper we show how to build {\em fastest} broadcast trees
(i.e., trees that minimize the global duration of the broadcast, however late
the departure is) in Time-Varying Graphs where intermittent edges are available
periodically (it is known that the problem is infeasible in the general case
even if various parameters of the graph are know). We address the general case
where contacts between nodes can have arbitrary durations and thus fastest
routes may consist of a mixture of {\em continuous} and {\em discontinuous}
segments (a more complex scenario than when contacts are {\em punctual} and
thus routes are only discontinuous). Using the abstraction of \tclocks to
compute the temporal distances, we solve the fastest broadcast problem by first
learning, at the emitter, what is its time of {\em minimum temporal
eccentricity} (i.e. the fastest time to reach all the other nodes), and second
by building a {\em foremost} broadcast tree relative to this particular
emission date."
"The problem of reliably transferring data from a set of $N_P$ producers to a
set of $N_C$ consumers in the BAR model, named N-party BAR Transfer (NBART), is
an important building block for volunteer computing systems. An algorithm to
solve this problem in synchronous systems, which provides a Nash equilibrium,
has been presented in previous work. In this paper, we propose an NBART
algorithm for asynchronous systems. Furthermore, we also address the
possibility of collusion among the Rational processes. Our game theoretic
analysis shows that the proposed algorithm tolerates certain degree of
arbitrary collusion, while still fulfilling the NBART properties."
"Hybrid parallel programming models combining distributed and shared memory
paradigms are well established in high-performance computing. The classical
prototype of hybrid programming in HPC is MPI/OpenMP, but many other
combinations are being investigated. Recently, the data-dependency driven, task
parallel model for shared memory parallelisation named StarSs has been
suggested for usage in combination with MPI. In this paper we apply hybrid
MPI/StarSs to a Lattice-Boltzmann code. In particular, we present the hybrid
programming model, the benefits we expect, the challenges in porting, and
finally a comparison of the performance of MPI/StarSs hybrid, MPI/OpenMP hybrid
and the original MPI-only versions of the same code."
"A self-stabilizing protocol tolerates by definition transient faults (faults
of finite duration). Recently, a new class of self-stabilizing protocols that
are able to tolerate a given number of permanent faults. In this paper, we
focus on self-stabilizing protocols able to tolerate Byzantine faults, that is
faults that introduce an arbitrary behaviour. We focus on strict-stabilization
in which the system have to contain the effects of Byzantine faults.
Specificaly, we study the possibility to construct in a self-stabilizing way a
maximal matching in a network where an arbitrary number of process may become
Byzantine."
"FastFlow is a structured parallel programming framework targeting shared
memory multicores. Its layered design and the optimized implementation of the
communication mechanisms used to implement the FastFlow streaming networks
provided to the application programmer as algorithmic skeletons support the
development of efficient fine grain parallel applications. FastFlow is
available (open source) at SourceForge
(http://sourceforge.net/projects/mc-fastflow/). This work introduces FastFlow
programming techniques and points out the different ways used to parallelize
existing C/C++ code using FastFlow as a software accelerator. In short: this is
a kind of tutorial on FastFlow."
"Resource allocation is the problem that a process may enter a critical
section CS of its code only when its resource requirements are not in conflict
with those of other processes in their critical sections. For each execution of
CS, these requirements are given anew. In the resource requirements, levels can
be distinguished, such as e.g. read access or write access. We allow infinitely
many processes that communicate by reliable asynchronous messages and have
finite memory. A simple starvation-free solution is presented. Processes only
wait for one another when they have conflicting resource requirements. The
correctness of the solution is argued with invariants and temporal logic. It
has been verified with the proof assistant PVS."
"In this paper we introduce a new way to deal with Grid portals referring to
our implementation. L-GRID is a light portal to access the EGEE/EGI Grid
infrastructure via Web, allowing users to submit their jobs from a common Web
browser in a few minutes, without any knowledge about the Grid infrastructure.
It provides the control over the complete lifecycle of a Grid Job, from its
submission and status monitoring, to the output retrieval. The system,
implemented as client-server architecture, is based on the Globus Grid
middleware. The client side application is based on a java applet; the server
relies on a Globus User Interface. There is no need of user registration on the
server side, and the user needs only his own X.509 personal certificate. The
system is user-friendly, secure (it uses SSL protocol, mechanism for dynamic
delegation and identity creation in public key infrastructures), highly
customizable, open source, and easy to install. The X.509 personal certificate
does not get out from the local machine. It allows to reduce the time spent for
the job submission, granting at the same time a higher efficiency and a better
security level in proxy delegation and management."
"The under exploitation of the available resources risks to be one of the main
problems for a computing center. The growing demand of computational power
necessarily entails more complex approaches in the management of the computing
resources, with particular attention to the batch queue system scheduler. In a
heterogeneous batch queue system, available for both serial single core
processes and parallel multi core jobs, it may happen that one or more
computational nodes composing the cluster are not fully occupied, running a
number of jobs lower than their actual capability. A typical case is
represented by more single core jobs running each one over a different multi
core server, while more parallel jobs - requiring all the available cores of a
host - are queued. A job rearrangement executed at runtime is able to free
extra resources, in order to host new processes. We present an efficient method
to improve the computing resources exploitation."
"Cloud computing is revolutionizing the ICT landscape by providing scalable
and efficient computing resources on demand. The ICT industry - especially data
centers, are responsible for considerable amounts of CO2 emissions and will
very soon be faced with legislative restrictions, such as the Kyoto protocol,
defining caps at different organizational levels (country, industry branch
etc.) A lot has been done around energy efficient data centers, yet there is
very little work done in defining flexible models considering CO2. In this
paper we present a first attempt of modeling data centers in compliance with
the Kyoto protocol. We discuss a novel approach for trading credits for
emission reductions across data centers to comply with their constraints. CO2
caps can be integrated with Service Level Agreements and juxtaposed to other
computing commodities (e.g. computational power, storage), setting a foundation
for implementing next-generation schedulers and pricing models that support
Kyoto-compliant CO2 trading schemes."
"We consider the problem of approximate consensus in mobile networks
containing Byzantine nodes. We assume that each correct node can communicate
only with its neighbors and has no knowledge of the global topology. As all
nodes have moving ability, the topology is dynamic. The number of Byzantine
nodes is bounded by f and known by all correct nodes. We first introduce an
approximate Byzantine consensus protocol which is based on the linear iteration
method. As nodes are allowed to collect information during several consecutive
rounds, moving gives them the opportunity to gather more values. We propose a
novel sufficient and necessary condition to guarantee the final convergence of
the consensus protocol. The requirement expressed by our condition is not
""universal"": in each phase it affects only a single correct node. More
precisely, at least one correct node among those that propose either the
minimum or the maximum value which is present in the network, has to receive
enough messages (quantity constraint) with either higher or lower values
(quality constraint). Of course, nodes' motion should not prevent this
requirement to be fulfilled. Our conclusion shows that the proposed condition
can be satisfied if the total number of nodes is greater than 3f+1."
"Fast Multipole Methods (FMM) are a fundamental operation for the simulation
of many physical problems. The high performance design of such methods usually
requires to carefully tune the algorithm for both the targeted physics and the
hardware. In this paper, we propose a new approach that achieves high
performance across architectures. Our method consists of expressing the FMM
algorithm as a task flow and employing a state-of-the-art runtime system,
StarPU, in order to process the tasks on the different processing units. We
carefully design the task flow, the mathematical operators, their Central
Processing Unit (CPU) and Graphics Processing Unit (GPU) implementations, as
well as scheduling schemes. We compute potentials and forces of 200 million
particles in 48.7 seconds on a homogeneous 160 cores SGI Altix UV 100 and of 38
million particles in 13.34 seconds on a heterogeneous 12 cores Intel Nehalem
processor enhanced with 3 Nvidia M2090 Fermi GPUs."
"One of the major challenges of cloud computing is the management of
request-response coupling and optimal allocation strategies of computational
resources for the various types of service requests. In the normal situations
the intelligence required to classify the nature and order of the request using
standard methods is insufficient because the arrival of request is at a random
fashion and it is meant for multiple resources with different priority order
and variety. Hence, it becomes absolutely essential that we identify the trends
of different request streams in every category by auto classifications and
organize preallocation strategies in a predictive way. It calls for designs of
intelligent modes of interaction between the client request and cloud computing
resource manager. This paper discusses about the corresponding scheme using
Adaptive Resonance Theory-2."
"Data centers form a key part of the infrastructure upon which a variety of
information technology services are built. They provide the capabilities of
centralized repository for storage, management, networking and dissemination of
data. With the rapid increase in the capacity and size of data centers, there
is a continuous increase in the demand for energy consumption. These data
centers not only consume a tremendous amount of energy but are riddled with IT
inefficiencies. Data center are plagued with thousands of servers as major
components. These servers consume huge energy without performing useful work.
In an average server environment, 30% of the servers are ""dead"" only consuming
energy, without being properly utilized. This paper proposes a five step model
using an emerging technology called virtualization to achieve energy efficient
data centers. The proposed model helps Data Center managers to properly
implement virtualization technology in their data centers to make them green
and energy efficient so as to ensure that IT infrastructure contributes as
little as possible to the emission of greenhouse gases, and helps to regain
power and cooling capacity, recapture resilience and dramatically reducing
energy costs and total cost of ownership."
"Gossip algorithms are widely used in modern distributed systems, with
applications ranging from sensor networks and peer-to-peer networks to mobile
vehicle networks and social networks. A tremendous research effort has been
devoted to analyzing and improving the asymptotic rate of convergence for
gossip algorithms. In this work we study finite-time convergence of
deterministic gossiping. We show that there exists a symmetric gossip algorithm
that converges in finite time if and only if the number of network nodes is a
power of two, while there always exists an asymmetric gossip algorithm with
finite-time convergence, independent of the number of nodes. For $n=2^m$ nodes,
we prove that a fastest convergence can be reached in $nm=n\log_2 n$ node
updates via symmetric gossiping. On the other hand, under asymmetric gossip
among $n=2^m+r$ nodes with $0\leq r<2^m$, it takes at least $mn+2r$ node
updates for achieving finite-time convergence. It is also shown that the
existence of finite-time convergent gossiping often imposes strong structural
requirements on the underlying interaction graph. Finally, we apply our results
to gossip algorithms in quantum networks, where the goal is to control the
state of a quantum system via pairwise interactions. We show that finite-time
convergence is never possible for such systems."
"Mobile Cloud Computing (MCC) which combines mobile computing and cloud
computing, has become one of the industry buzz words and a major discussion
thread in the IT world since 2009. As MCC is still at the early stage of
development, it is necessary to grasp a thorough understanding of the
technology in order to point out the direction of future research. With the
latter aim, this paper presents a review on the background and principle of
MCC, characteristics, recent research work, and future research trends. A brief
account on the background of MCC: from mobile computing to cloud computing is
presented and then followed with a discussion on characteristics and recent
research work. It then analyses the features and infrastructure of mobile cloud
computing. The rest of the paper analyses the challenges of mobile cloud
computing, summary of some research projects related to this area, and points
out promising future research directions."
"In this work, we study the propagation of influence and computation in
dynamic distributed systems. We focus on broadcasting models under a worst-case
dynamicity assumption which have received much attention recently. We drop for
the first time in worst-case dynamic networks the common instantaneous
connectivity assumption and require a minimal temporal connectivity. Our
temporal connectivity constraint only requires that another causal influence
occurs within every time-window of some given length. We establish that there
are dynamic graphs with always disconnected instances with equivalent temporal
connectivity to those with always connected instances. We present a termination
criterion and also establish the computational equivalence with instantaneous
connectivity networks. We then consider another model of dynamic networks in
which each node has an underlying communication neighborhood and the
requirement is that each node covers its local neighborhood within any
time-window of some given length. We discuss several properties and provide a
protocol for counting, that is for determining the number of nodes in the
network."
"In this work we describe the PriSM framework for decentralized deployment of
a federation of autonomous social networks (ASN). The individual ASNs are
centrally managed by organizations according to their institutional needs,
while cross-ASN interactions are facilitated subject to security and
confidentiality requirements specified by administrators and users of the ASNs.
Such decentralized deployment, possibly either on private or public clouds,
provides control and ownership of information/flow to individual organizations.
Lack of such complete control (if third party online social networking services
were to be used) has so far been a great barrier in taking full advantage of
the novel communication mechanisms at workplace that have however become
commonplace for personal usage with the advent of Web 2.0 platforms and online
social networks. PriSM provides a practical solution for organizations to
harness the advantages of online social networking both in
intra/inter-organizational settings without sacrificing autonomy, security and
confidentiality needs."
"This paper has been withdrawn by arXiv. arXiv admin note: author list
truncated due to disputed authorship and content. This submission repeats large
portions of text from this http URL by other authors. Duty cycle mode in WSN
improves energy-efficiency, but also introduces packet delivery latency.
Several duty-cycle based MAC schemes have been proposed to reduce latency, but
throughput is limited by duty-cycled scheduling performance. In this paper, a
Traffic-adaptive Time-division Multiple Access (TTMA), a distributed TDMA-based
MAC protocol is introduced to improves the throughput by traffic-adaptive
time-slot scheduling that increases the channel utilisation efficiency. The
proposed time-slot scheduling method first avoids time-slots assigned to nodes
with no traffic through fast traffic notification. It then achieves better
channel utilisation among nodes having traffic through an ordered schedule
negotiation scheme. By decomposing traffic notification and data transmission
scheduling into two phases leads each phase to be simple and efficient. The
performance evaluation shows that the two-phase design significantly improves
the throughput and outperforms the time division multiple access (TDMA) control
with slot stealing."
"The energy consumption issue in distributed computing systems has become
quite critical due to environmental concerns. In response to this, many
energy-aware scheduling algorithms have been developed primarily by using the
dynamic voltage-frequency scaling (DVFS) capability incorporated in recent
commodity processors. The majority of these algorithms involve two passes:
schedule generation and slack reclamation. The latter is typically achieved by
lowering processor frequency for tasks with slacks. In this article, we study
the latest papers in this area and develop them. This study has been evaluated
based on results obtained from experiments with 1,500 randomly generated task
graphs."
"Erasure coding techniques are getting integrated in networked distributed
storage systems as a way to provide fault-tolerance at the cost of less storage
overhead than traditional replication. Redundancy is maintained over time
through repair mechanisms, which may entail large network resource overheads.
In recent years, several novel codes tailor-made for distributed storage have
been proposed to optimize storage overhead and repair, such as Regenerating
Codes that minimize the per repair traffic, or Self-Repairing Codes which
minimize the number of nodes contacted per repair. Existing studies of these
coding techniques are however predominantly theoretical, under the simplifying
assumption that only one object is stored. They ignore many practical issues
that real systems must address, such as data placement, de/correlation of
multiple stored objects, or the competition for limited network resources when
multiple objects are repaired simultaneously. This paper empirically studies
the repair performance of these novel storage centric codes with respect to
classical erasure codes by simulating realistic scenarios and exploring the
interplay of code parameters, failure characteristics and data placement with
respect to the trade-offs of bandwidth usage and speed of repairs."
"In this paper we deal with the impact of multi and many-core processor
architectures on simulation. Despite the fact that modern CPUs have an
increasingly large number of cores, most softwares are still unable to take
advantage of them. In the last years, many tools, programming languages and
general methodologies have been proposed to help building scalable applications
for multi-core architectures, but those solutions are somewhat limited.
Parallel and distributed simulation is an interesting application area in which
efficient and scalable multi-core implementations would be desirable. In this
paper we investigate the use of the Go Programming Language to implement
optimistic parallel simulations based on the Time Warp mechanism. Specifically,
we describe the design, implementation and evaluation of a new parallel
simulator. The scalability of the simulator is studied when in presence of a
modern multi-core CPU and the effects of the Hyper-Threading technology on
optimistic simulation are analyzed."
"Discrete Event Simulation (DES) is a widely used technique in which the state
of the simulator is updated by events happening at discrete points in time
(hence the name). DES is used to model and analyze many kinds of systems,
including computer architectures, communication networks, street traffic, and
others. Parallel and Distributed Simulation (PADS) aims at improving the
efficiency of DES by partitioning the simulation model across multiple
processing elements, in order to enabling larger and/or more detailed studies
to be carried out. The interest on PADS is increasing since the widespread
availability of multicore processors and affordable high performance computing
clusters. However, designing parallel simulation models requires considerable
expertise, the result being that PADS techniques are not as widespread as they
could be. In this paper we describe ErlangTW, a parallel simulation middleware
based on the Time Warp synchronization protocol. ErlangTW is entirely written
in Erlang, a concurrent, functional programming language specifically targeted
at building distributed systems. We argue that writing parallel simulation
models in Erlang is considerably easier than using conventional programming
languages. Moreover, ErlangTW allows simulation models to be executed either on
single-core, multicore and distributed computing architectures. We describe the
design and prototype implementation of ErlangTW, and report some preliminary
performance results on multicore and distributed architectures using the well
known PHOLD benchmark."
"Classical erasure codes, e.g. Reed-Solomon codes, have been acknowledged as
an efficient alternative to plain replication to reduce the storage overhead in
reliable distributed storage systems. Yet, such codes experience high overhead
during the maintenance process. In this paper we propose a novel erasure-coded
framework especially tailored for networked storage systems. Our approach
relies on the use of random codes coupled with a clustered placement strategy,
enabling the maintenance of a failed machine at the granularity of multiple
files. Our repair protocol leverages network coding techniques to reduce by
half the amount of data transferred during maintenance, as several files can be
repaired simultaneously. This approach, as formally proven and demonstrated by
our evaluation on a public experimental testbed, enables to dramatically
decrease the bandwidth overhead during the maintenance process, as well as the
time to repair a failure. In addition, the implementation is made as simple as
possible, aiming at a deployment into practical systems."
"High efficient routing is an important issue in the design of limited energy
resource Wireless Sensor Networks (WSNs). Due to the characteristic of the
environment at which the sensor node is to operate, coupled with severe
resources; on-board energy, transmission power, processing capability, and
storage limitations, prompt for careful resource management and new routing
protocol so as to counteract the differences and challenges. To this end, we
present an Improved Energy-Efficient Ant-Based Routing (IEEABR) Algorithm in
wireless sensor networks. Compared to the state-of-the-art Ant-Based routing
protocols; Basic Ant-Based Routing (BABR) Algorithm, Sensor-driven and
Cost-aware ant routing (SC), Flooded Forward ant routing (FF), Flooded
Piggybacked ant routing (FP), and Energy-Efficient Ant-Based Routing (EEABR),
the proposed IEEABR approach has advantages in terms of reduced energy usage
which can effectively balance the WSN node's power consumption, and high energy
efficiency. The performance evaluations for the algorithms on a real
application are conducted in a well known WSN MATLAB-based simulator (RMASE)
using both static and dynamic scenario."
"The new era of computing called Cloud Computing allows the user to access the
cloud services dynamically over the Internet wherever and whenever needed.
Cloud consists of data and resources; and the cloud services include the
delivery of software, infrastructure, applications, and storage over the
Internet based on user demand through Internet. In short, cloud computing is a
business and economic model allowing the users to utilize high-end computing
and storage virtually with minimal infrastructure on their end. Cloud has three
service models namely, Cloud Software-as-a-Service (SaaS), Cloud
Platform-as-a-Service (PaaS), and Cloud Infrastructure-as-a-Service (IaaS).
This paper talks in depth of cloud infrastructure service management."
"According to the pay-per-use model adopted in clouds, the more the resources
consumed by an application running in a cloud computing environment, the
greater the amount of money the owner of the corresponding application will be
charged. Therefore, applying intelligent solutions to minimize the resource
consumption is of great importance. Because centralized solutions are deemed
unsuitable for large-distributed systems or large-scale applications, we
propose a fully distributed algorithm (called DRA) to overcome the scalability
issues. Specifically, DRA migrates the inter-communicating components of an
application, such as processes or virtual machines, close to each other to
minimize the total resource consumption. The migration decisions are made in a
dynamic way and based only on local information. We prove that DRA achieves
convergence and results always in the optimal solution."
"In Mobile Cloud Computing (MCC), Virtual Machine (VM) migration based process
offloading is a dominant approach to enhance Smart Mobile Devices (SMDs). A
challenging aspect of VM deployment is the additional computing resources usage
in the deployment and management of VM which obliges computing resources for VM
creation and configuration. The management of VM comprises computing resources
exploitation in the monitoring of VM in entire lifecycle and physical resources
management for VM on SMDs. Therefore, VM migration based application offloading
requires additional computing resource. Consequently computing resources demand
and execution time of the application increases respectively. In this paper, we
empirically review the impact of VM deployment and management on the execution
time of application in diverse scenarios. We investigate VM deployment and
management for application processing in simulation environment by employing
CloudSim: a simulation toolkit that provides an extensible simulation framework
to model VM deployment and management for application processing in cloud
infrastructure. The significance of this work is to ensure that VM deployment
and management necessitates additional computing resources on SMD for
application offloading. We evaluate VM deployment and management in application
processing by analyzing Key Performance Parameters (KPPs) in different
scenarios; such as VM deployment, the execution time of applications, and total
execution time of the simulation. We use KPPs to assess deviations in the
results of diverse experimental scenarios. The empirical analysis concludes
that VM deployment and management oblige additional resources on computing host
which make it a heavyweight approach for process offloading on smart mobile
device."
"In this work, we study the fundamental naming and counting problems (and some
variations) in networks that are anonymous, unknown, and possibly dynamic. In
counting, nodes must determine the size of the network n and in naming they
must end up with unique identities. By anonymous we mean that all nodes begin
from identical states apart possibly from a unique leader node and by unknown
that nodes have no a priori knowledge of the network (apart from some minimal
knowledge when necessary) including ignorance of n. Network dynamicity is
modeled by the 1-interval connectivity model, in which communication is
synchronous and a worst-case adversary chooses the edges of every round subject
to the condition that each instance is connected. We first focus on static
networks with broadcast where we prove that, without a leader, counting is
impossible to solve and that naming is impossible to solve even with a leader
and even if nodes know n. These impossibilities carry over to dynamic networks
as well. We also show that a unique leader suffices in order to solve counting
in linear time. Then we focus on dynamic networks with broadcast. We conjecture
that dynamicity renders nontrivial computation impossible. In view of this, we
let the nodes know an upper bound on the maximum degree that will ever appear
and show that in this case the nodes can obtain an upper bound on n. Finally,
we replace broadcast with one-to-each, in which a node may send a different
message to each of its neighbors. Interestingly, this natural variation is
proved to be computationally equivalent to a full-knowledge model, in which
unique names exist and the size of the network is known."
"The theme of this paper is how to find all instances of a given ""sample""
graph in a larger ""data graph,"" using a single round of map-reduce. For the
simplest sample graph, the triangle, we improve upon the best known such
algorithm. We then examine the general case, considering both the communication
cost between mappers and reducers and the total computation cost at the
reducers. To minimize communication cost, we exploit the techniques of (Afrati
and Ullman, TKDE 2011)for computing multiway joins (evaluating conjunctive
queries) in a single map-reduce round. Several methods are shown for
translating sample graphs into a union of conjunctive queries with as few
queries as possible. We also address the matter of optimizing computation cost.
Many serial algorithms are shown to be ""convertible,"" in the sense that it is
possible to partition the data graph, explore each partition in a separate
reducer, and have the total computation cost at the reducers be of the same
order as the computation cost of the serial algorithm."
"This paper describes the overlay protocol Chord using the formalism of
Abstract State Machines. The formalization concerns Chord actions that maintain
ring topology and manipulate distributed keys. We define a class of runs and
prove the correctness of our formalization with respect to it."
"We study real time periodic query scheduling for data collection in multihop
Wireless Sensor Networks (WSNs). Given a set of heterogenous data collection
queries in WSNs, each query requires the data from the source sensor nodes to
be collected to the control center within a certain end-to-end delay. We first
propose almost-tight necessary conditions for a set of different queries to be
schedulable by a WSN. We then develop a family of efficient and effective data
collection algorithms that can meet the real-time requirement under resource
constraints by addressing three tightly coupled tasks: (1) routing tree
construction for data collection, (2) link activity scheduling, and (3)
packet-level scheduling. Our theoretical analysis for the schedulability of
these algorithms show that they can achieve a constant fraction of the maximum
schedulable load. For the case of overloaded networks where not all queries can
be possibly satisfied, we propose an efficient approximation algorithm to
select queries to maximize the total weight of selected schedulable queries.
The simulations corroborate our theoretical analysis."
"In multiprocessor systems, one of the main factors of systems' performance is
task scheduling. The well the task be distributed among the processors the well
be the performance. Again finding the optimal solution of scheduling the tasks
into the processors is NP-complete, that is, it will take a lot of time to find
the optimal solution. Many evolutionary algorithms (e.g. Genetic Algorithm,
Simulated annealing) are used to reach the near optimal solution in linear
time. In this paper we propose a heuristic for genetic algorithm based task
scheduling in multiprocessor systems by choosing the eligible processor on
educated guess. From comparison it is found that this new heuristic based GA
takes less computation time to reach the suboptimal solution."
"MapReduce has become a popular programming model for running data intensive
applications on the cloud. Completion time goals or deadlines of MapReduce jobs
set by users are becoming crucial in existing cloud-based data processing
environments like Hadoop. There is a conflict between the scheduling MR jobs to
meet deadlines and ""data locality"" (assigning tasks to nodes that contain their
input data). To meet the deadline a task may be scheduled on a node without
local input data for that task causing expensive data transfer from a remote
node. In this paper, a novel scheduler is proposed to address the above problem
which is primarily based on the dynamic resource reconfiguration approach. It
has two components: 1) Resource Predictor: which dynamically determines the
required number of Map/Reduce slots for every job to meet completion time
guarantee; 2) Resource Reconfigurator: that adjusts the CPU resources while not
violating completion time goals of the users by dynamically increasing or
decreasing individual VMs to maximize data locality and also to maximize the
use of resources within the system among the active jobs. The proposed
scheduler has been evaluated against Fair Scheduler on virtual cluster built on
a physical cluster of 20 machines. The results demonstrate a gain of about 12%
increase in throughput of Jobs"
"Block iterative methods are extremely important as smoothers for multigrid
methods, as preconditioners for Krylov methods, and as solvers for diagonally
dominant linear systems. Developing robust and efficient algorithms suitable
for current and evolving GPU and multicore CPU systems is a significant
challenge. We address this issue in the case of constant-coefficient stencils
arising in the solution of elliptic partial differential equations on
structured 3D uniform and adaptively refined grids. Robust, highly parallel
implementations of block Jacobi and chaotic block Gauss-Seidel algorithms with
exact inversion of the blocks are developed using different parallelization
techniques. Experimental results for NVIDIA Fermi GPUs and AMD multicore
systems are presented."
"This report has two objectives. First, we describe a set of the production
distributed infrastructures currently available, so that the reader has a basic
understanding of them. This includes explaining why each infrastructure was
created and made available and how it has succeeded and failed. The set is not
complete, but we believe it is representative.
  Second, we describe the infrastructures in terms of their use, which is a
combination of how they were designed to be used and how users have found ways
to use them. Applications are often designed and created with specific
infrastructures in mind, with both an appreciation of the existing capabilities
provided by those infrastructures and an anticipation of their future
capabilities. Here, the infrastructures we discuss were often designed and
created with specific applications in mind, or at least specific types of
applications. The reader should understand how the interplay between the
infrastructure providers and the users leads to such usages, which we call
usage modalities. These usage modalities are really abstractions that exist
between the infrastructures and the applications; they influence the
infrastructures by representing the applications, and they influence the ap-
plications by representing the infrastructures."
"The quadratic assignment problem (QAP) is one of the most difficult
combinatorial optimization problems. An effective heuristic for obtaining
approximate solutions to the QAP is simulated annealing (SA). Here we describe
an SA implementation for the QAP which runs on a graphics processing unit
(GPU). GPUs are composed of low cost commodity graphics chips which in
combination provide a powerful platform for general purpose parallel computing.
For SA runs with large numbers of iterations, we find performance 50-100 times
better than that of a recent non-parallel but very efficient implementation of
SA for the QAP"
"The PERCS system was designed by IBM in response to a DARPA challenge that
called for a high-productivity high-performance computing system. The IBM PERCS
architecture is a two level direct network having low diameter and high
bisection bandwidth. Mapping and routing strategies play an important role in
the performance of applications on such a topology. In this paper, we study
mapping strategies for PERCS architecture, that examine how to map tasks of a
given job on to the physical processing nodes. We develop and present
fundamental principles for designing good mapping strategies that minimize
congestion. This is achieved via a theoretical study of some common
communication patterns under both direct and indirect routing mechanisms
supported by the architecture."
"Branch-and-Bound (B&B) algorithms are time intensive tree-based exploration
methods for solving to optimality combinatorial optimization problems. In this
paper, we investigate the use of GPU computing as a major complementary way to
speed up those methods. The focus is put on the bounding mechanism of B&B
algorithms, which is the most time consuming part of their exploration process.
We propose a parallel B&B algorithm based on a GPU-accelerated bounding model.
The proposed approach concentrate on optimizing data access management to
further improve the performance of the bounding mechanism which uses large and
intermediate data sets that do not completely fit in GPU memory. Extensive
experiments of the contribution have been carried out on well known FSP
benchmarks using an Nvidia Tesla C2050 GPU card. We compared the obtained
performances to a single and a multithreaded CPU-based execution. Accelerations
up to x100 are achieved for large problem instances."
"This paper proposes a distributed algorithm which deterministically gathers n
(n > 4) asynchronous, fat robots. The robots are assumed to be transparent and
they have full visibility. The robots are initially considered to be
stationary. A robot is visible in its motion. The robots do not store past
actions. They are anonymous and can not be distinguished by their appearances
and do not have common coordinate system or chirality. The robots do not
communicate through message passing. In the proposed gathering algorithm one
robot moves at a time towards its destination. The robot which moves, is
selected in such a way that, it will be the only robot eligible to move, until
it reaches its destination. In case of a tie, this paper proposes a leader
election algorithm which produces an ordering of the robots and the first robot
in the ordering becomes the leader. The ordering is unique in the sense that,
each robot, characterized by its location, agrees on the same ordering. We show
that if a set of robots can be ordered then they can gather deterministically.
The paper also characterizes the cases, where ordering is not possible. This
paper also presents an important fact that, if leader election is possible then
gathering pattern formation is possible even with no chirality."
"In this work, we explore iterative approximate Byzantine consensus algorithms
that do not make explicit use of the global parameter of the graph, i.e., the
upper-bound on the number of faults, f."
"Consider a synchronous point-to-point network of n nodes connected by
directed links, wherein each node has a binary input. This paper proves a tight
necessary and sufficient condition on the underlying communication topology for
achieving Byzantine consensus among these nodes in the presence of up to f
Byzantine faults. We derive a necessary condition, and then we provide a
constructive proof of sufficiency by presenting a Byzantine consensus algorithm
for directed graphs that satisfy the necessary condition.
  Prior work has developed analogous necessary and sufficient conditions for
undirected graphs. It is known that, for undirected graphs, the following two
conditions are together necessary and sufficient [8, 2, 6]: (i) n ? 3f + 1, and
(ii) network connectivity greater than 2f. However, these conditions are not
adequate to completely characterize Byzantine consensus in directed graphs."
"Traditional Byzantine resilient algorithms use 2f+1 vertex disjoint paths to
ensure message delivery in the presence of up to f Byzantine nodes. The
question of how these paths are identified is related to the fundamental
problem of topology discovery. Distributed algorithms for topology discovery
cope with a never ending task, dealing with frequent changes in the network
topology and unpredictable transient faults. Therefore, algorithms for topology
discovery should be self-stabilizing to ensure convergence of the topology
information following any such unpredictable sequence of events. We present the
first such algorithm that can cope with Byzantine nodes. Starting in an
arbitrary global state, and in the presence of f Byzantine nodes, each node is
eventually aware of all the other non-Byzantine nodes and their connecting
communication links. Using the topology information, nodes can, for example,
route messages across the network and deliver messages from one end user to
another. We present the first deterministic, cryptographicassumptions- free,
self-stabilizing, Byzantine-resilient algorithms for network topology discovery
and end-to-end message delivery. We also consider the task of r-neighborhood
discovery for the case in which r and the degree of nodes are bounded by
constants. The use of r-neighborhood discovery facilitates polynomial time,
communication and space solutions for the above tasks. The obtained algorithms
can be used to authenticate parties, in particular during the establishment of
private secrets, thus forming public key schemes that are resistant to
man-in-the-middle attacks of the compromised Byzantine nodes. A polynomial and
efficient end-to-end algorithm that is based on the established private secrets
can be employed in between periodical re-establishments of the secrets."
"Maximal Independent Set selection is a fundamental problem in distributed
computing. A novel probabilistic algorithm for this problem has recently been
proposed by Afek et al, inspired by the study of the way that developing cells
in the fly become specialised. The algorithm they propose is simple and robust,
but not as efficient as previous approaches: the expected time complexity is
O(log^2 n). Here we first show that the approach of Afek et al cannot achieve
better efficiency than this across all networks, no matter how the probability
values are chosen. However, we then propose a new algorithm that incorporates
another important feature of the biological system: adapting the probabilities
used at each node based on local feedback from neighbouring nodes. Our new
algorithm retains all the advantages of simplicity and robustness, but also
achieves the optimal efficiency of O(log n) expected time."
"In late 2009, Amazon introduced spot instances to offer their unused
resources at lower cost with reduced reliability. Amazon's spot instances allow
customers to bid on unused Amazon EC2 capacity and run those instances for as
long as their bid exceeds the current spot price. The spot price changes
periodically based on supply and demand, and customers whose bids exceed it
gain access to the available spot instances. Customers may expect their
services at lower cost with spot instances compared to on-demand or reserved.
However the reliability is compromised since the instances(IaaS) providing the
service(SaaS) may become unavailable at any time without any notice to the
customer. Checkpointing and migration schemes are of great use to cope with
such situation. In this paper we study various checkpointing schemes that can
be used with spot instances. Also we device some algorithms for checkpointing
scheme on top of application-centric resource provisioning framework that
increase the reliability while reducing the cost significantly."
"In the last decade, scheduling of Directed Acyclic Graph (DAG) application in
the context of Grid environment has attracted attention of many researchers.
However, deployment of Grid environment requires skills, efforts, budget, and
time. Although various simulation toolkits or frameworks are available for
simulating Grid environment, either they support different possible studies in
Grid computing area or takes lot of efforts in molding them to make them
suitable for scheduling of DAG application. In this paper, we describe design
and implementation of GridSim based ready to use application scheduler for
scheduling of DAG application in Grid environment. The proposed application
scheduler supports supplying DAG application and configuration of Grid
resources through GUI. We also describe implementation of Min-Min static
scheduling algorithm for scheduling of DAG application to validate the proposed
scheduler. Our proposed DAG application scheduling simulator is useful, easy,
and time-saver."
"Algorithms for frequent pattern mining, a popular informatics application,
have unique requirements that are not met by any of the existing parallel
tools. In particular, such applications operate on extremely large data sets
and have irregular memory access patterns. For efficient parallelization of
such applications, it is necessary to support dynamic load balancing along with
scheduling mechanisms that allow users to exploit data locality. Given these
requirements, task parallelism is the most promising of the available parallel
programming models. However, existing solutions for task parallelism schedule
tasks implicitly and hence, custom scheduling policies that can exploit data
locality cannot be easily employed. In this paper we demonstrate and
characterize the speedup obtained in a frequent pattern mining application
using a custom clustered scheduling policy in place of the popular Cilk-style
policy. We present PFunc, a novel task parallel library whose customizable task
scheduling and task priorities facilitated the implementation of our clustered
scheduling policy."
"This paper presents a comparative study of distributed systems and the
security issues associated with those systems. Four commonly used distributed
systems were considered for detailed analysis in terms of technologies
involved, security issues faced by them and solution proposed to circumvent
those issues. Finally the security issues and the solutions were summarized and
compared with each other."
"This paper presents a comparison of OpenMP and OpenCL based on the parallel
implementation of algorithms from various fields of computer applications. The
focus of our study is on the performance of benchmark comparing OpenMP and
OpenCL. We observed that OpenCL programming model is a good option for mapping
threads on different processing cores. Balancing all available cores and
allocating sufficient amount of work among all computing units, can lead to
improved performance. In our simulation, we used Fedora operating system; a
system with Intel Xeon Dual core processor having thread count 24 coupled with
NVIDIA Quadro FX 3800 as graphical processing unit."
"Large-scale key-value storage systems sacrifice consistency in the interest
of dependability (i.e., partition tolerance and availability), as well as
performance (i.e., latency). Such systems provide eventual
consistency,which---to this point---has been difficult to quantify in real
systems. Given the many implementations and deployments of
eventually-consistent systems (e.g., NoSQL systems), attempts have been made to
measure this consistency empirically, but they suffer from important drawbacks.
For example, state-of-the art consistency benchmarks exercise the system only
in restricted ways and disrupt the workload, which limits their accuracy.
  In this paper, we take the position that a consistency benchmark should paint
a comprehensive picture of the relationship between the storage system under
consideration, the workload, the pattern of failures, and the consistency
observed by clients. To illustrate our point, we first survey prior efforts to
quantify eventual consistency. We then present a benchmarking technique that
overcomes the shortcomings of existing techniques to measure the consistency
observed by clients as they execute the workload under consideration. This
method is versatile and minimally disruptive to the system under test. As a
proof of concept, we demonstrate this tool on Cassandra."
"In this article we describe the problems and solutions related to the
integration of desktop grid middleware in a cloud, in this case the open source
SlapOS cloud. We focus on the issues about recipes that describe the
integration and the problem of the confinement of execution. They constitute
two aspects of service-oriented architecture and Cloud Computing. These two
issues solved with SlapOS are not in relation to what is traditionally done in
the clouds because we do not rely on virtual machines and, there is no data
center (as defined in cloud). Moreover, we show that from the initial
deployment model we take into account not only Web applications, B2B
applications... but also applications from the field of grids; here desktop
grid middleware which is a case study."
"The programming paradigm Map-Reduce and its main open-source implementation,
Hadoop, have had an enormous impact on large scale data processing. Our goal in
this expository writeup is two-fold: first, we want to present some complexity
measures that allow us to talk about Map-Reduce algorithms formally, and
second, we want to point out why this model is actually different from other
models of parallel programming, most notably the PRAM (Parallel Random Access
Memory) model. We are looking for complexity measures that are detailed enough
to make fine-grained distinction between different algorithms, but which also
abstract away many of the implementation details."
"Much of the past work on asynchronous approximate Byzantine consensus has
assumed scalar inputs at the nodes [3, 7]. Recent work has yielded approximate
Byzantine consensus algorithms for the case when the input at each node is a
d-dimensional vector, and the nodes must reach consensus on a vector in the
convex hull of the input vectors at the fault-free nodes [8, 12]. The
d-dimensional vectors can be equivalently viewed as points in the d-dimensional
Euclidean space. Thus, the algorithms in [8, 12] require the fault-free nodes
to decide on a point in the d-dimensional space.
  In this paper, we generalize the problem to allow the decision to be a convex
polytope in the d-dimensional space, such that the decided polytope is within
the convex hull of the input vectors at the fault-free nodes. We name this
problem as Byzantine convex consensus (BCC), and present an asynchronous
approximate BCC algorithm with optimal fault tolerance. Ideally, the goal here
is to agree on a convex polytope that is as large as possible. While we do not
claim that our algorithm satisfies this goal, we show a bound on the output
convex polytope chosen by our algorithm."
"This is the second of a planned collection of four yearly volumes describing
the deployment of a heterogeneous many-core platform for experiments on
scalable custom interconnects and management of fault and critical events,
applied to many-process applications. This volume covers several topics, among
which: 1- a system for awareness of faults and critical events (named LO|FA|MO)
on experimental heterogeneous many-core hardware platforms; 2- the integration
and test of the experimental hardware heterogeneous many-core platform QUoNG,
based on the APEnet+ custom interconnect; 3- the design of a
Software-Programmable Distributed Network Processor architecture (DNP) using
ASIP technology; 4- the initial stages of design of a new DNP generation onto a
28nm FPGA. These developments were performed in the framework of the EURETILE
European Project under the Grant Agreement no. 247846."
"Much of the past work on asynchronous approximate Byzantine consensus has
assumed scalar inputs at the nodes [4, 8]. Recent work has yielded approximate
Byzantine consensus algorithms for the case when the input at each node is a
d-dimensional vector, and the nodes must reach consensus on a vector in the
convex hull of the input vectors at the fault-free nodes [9, 13]. The
d-dimensional vectors can be equivalently viewed as points in the d-dimensional
Euclidean space. Thus, the algorithms in [9, 13] require the fault-free nodes
to decide on a point in the d-dimensional space.
  In our recent work [arXiv:/1307.1051], we proposed a generalization of the
consensus problem, namely Byzantine convex consensus (BCC), which allows the
decision to be a convex polytope in the d-dimensional space, such that the
decided polytope is within the convex hull of the input vectors at the
fault-free nodes. We also presented an asynchronous approximate BCC algorithm.
  In this paper, we propose a new BCC algorithm with optimal fault-tolerance
that also agrees on a convex polytope that is as large as possible under
adversarial conditions. Our prior work [arXiv:/1307.1051] does not guarantee
the optimality of the output polytope."
"Applications like Yahoo, Facebook, Twitter have huge data which has to be
stored and retrieved as per client access. This huge data storage requires huge
database leading to increase in physical storage and becomes complex for
analysis required in business growth. This storage capacity can be reduced and
distributed processing of huge data can be done using Apache Hadoop which uses
Map-reduce algorithm and combines the repeating data so that entire data is
stored in reduced format. The paper describes performing a wordcount Map-Reduce
Job in Single Node Apache Hadoop cluster and compress data using
Lempel-Ziv-Oberhumer (LZO) algorithm."
"Query co-processing on graphics processors (GPUs) has become an effective
means to improve the performance of main memory databases. However, the
relatively low bandwidth and high latency of the PCI-e bus are usually
bottleneck issues for co-processing. Recently, coupled CPU-GPU architectures
have received a lot of attention, e.g. AMD APUs with the CPU and the GPU
integrated into a single chip. That opens up new opportunities for optimizing
query co-processing. In this paper, we experimentally revisit hash joins, one
of the most important join algorithms for main memory databases, on a coupled
CPU-GPU architecture. Particularly, we study the fine-grained co-processing
mechanisms on hash joins with and without partitioning. The co-processing
outlines an interesting design space. We extend existing cost models to
automatically guide decisions on the design space. Our experimental results on
a recent AMD APU show that (1) the coupled architecture enables fine-grained
co-processing and cache reuses, which are inefficient on discrete CPU-GPU
architectures; (2) the cost model can automatically guide the design and tuning
knobs in the design space; (3) fine-grained co-processing achieves up to 53%,
35% and 28% performance improvement over CPU-only, GPU-only and conventional
CPU-GPU co-processing, respectively. We believe that the insights and
implications from this study are initial yet important for further research on
query co-processing on coupled CPU-GPU architectures."
"As Grids are loosely-coupled congregations of geographically distributed
heterogeneous resources, the efficient utilization of the resources requires
the support of a sound Performance Prediction System (PPS). The performance
prediction of grid resources is helpful for both Resource Management Systems
and grid users to make optimized resource usage decisions. There have been many
PPS projects that span over several grid resources in several dimensions. In
this paper the taxonomy for describing the PPS architecture is discussed. The
taxonomy is used to categorize and identify approaches which are followed in
the implementation of the existing PPSs for Grids. The taxonomy and the survey
results are used to identify approaches and issues that have not been fully
explored in research."
"This work addresses Byzantine vector consensus (BVC), wherein the input at
each process is a d-dimensional vector of reals, and each process is expected
to decide on a decision vector that is in the convex hull of the input vectors
at the fault-free processes [3, 8]. The input vector at each process may also
be viewed as a point in the d-dimensional Euclidean space R^d, where d > 0 is a
finite integer. Recent work [3, 8] has addressed Byzantine vector consensus in
systems that can be modeled by a complete graph. This paper considers Byzantine
vector consensus in incomplete graphs. In particular, we address a particular
class of iterative algorithms in incomplete graphs, and prove a necessary
condition, and a sufficient condition, for the graphs to be able to solve the
vector consensus problem iteratively. We present an iterative Byzantine vector
consensus algorithm, and prove it correct under the sufficient condition. The
necessary condition presented in this paper for vector consensus does not match
with the sufficient condition for d > 1; thus, a weaker condition may
potentially suffice for Byzantine vector consensus."
"Counters are an important abstraction in distributed computing, and play a
central role in large scale geo-replicated systems, counting events such as web
page impressions or social network ""likes"". Classic distributed counters,
strongly consistent, cannot be made both available and partition-tolerant, due
to the CAP Theorem, being unsuitable to large scale scenarios. This paper
defines Eventually Consistent Distributed Counters (ECDC) and presents an
implementation of the concept, Handoff Counters, that is scalable and works
over unreliable networks. By giving up the sequencer aspect of classic
distributed counters, ECDC implementations can be made AP in the CAP design
space, while retaining the essence of counting. Handoff Counters are the first
CRDT (Conflict-free Replicated Data Type) based mechanism that overcomes the
identity explosion problem in naive CRDTs, such as G-Counters (where state size
is linear in the number of independent actors that ever incremented the
counter), by managing identities towards avoiding global propagation and
garbage collecting temporary entries. The approach used in Handoff Counters is
not restricted to counters, being more generally applicable to other data types
with associative and commutative operations."
"Cloud elasticity - the ability to use as much resources as needed at any
given time - and low cost - a user pays only for the resources it consumes -
represent solid incentives for many organizations to migrate some of their
computational activities to a public cloud. As the interest in cloud computing
grows, so does the size of the cloud computing centers and their energy
footprint. The realization that power consumption of cloud computing centers is
significant and it is expected to increase substantially in the future
motivates our interest in scheduling and scaling algorithms which minimize
power consumption. We propose energy-aware application scaling and resource
management algorithms. Though targeting primarily the Infrastructure as a
Service (IaaS), the system models and the algorithms we propose can be applied
to the other cloud delivery models and to private clouds."
"Particle systems are physical systems of simple computational particles that
can bond to neighboring particles and use these bonds to move from one spot to
another (non-occupied) spot. These particle systems are supposed to be able to
self-organize in order to adapt to a desired shape without any central control.
Self-organizing particle systems have many interesting applications like
coating objects for monitoring and repair purposes and the formation of
nano-scale devices for surgery and molecular-scale electronic structures. While
there has been quite a lot of systems work in this area, especially in the
context of modular self-reconfigurable robotic systems, only very little
theoretical work has been done in this area so far. We attempt to bridge this
gap by proposing a model inspired by the behavior of ameba that allows rigorous
algorithmic research on self-organizing particle systems."
"The trend towards highly parallel multi-processing is ubiquitous in all
modern computer architectures, ranging from handheld devices to large-scale HPC
systems; yet many applications are struggling to fully utilise the multiple
levels of parallelism exposed in modern high-performance platforms. In order to
realise the full potential of recent hardware advances, a mixed-mode between
shared-memory programming techniques and inter-node message passing can be
adopted which provides high-levels of parallelism with minimal overheads. For
scientific applications this entails that not only the simulation code itself,
but the whole software stack needs to evolve. In this paper, we evaluate the
mixed-mode performance of PETSc, a widely used scientific library for the
scalable solution of partial differential equations. We describe the addition
of OpenMP threaded functionality to the library, focusing on sparse
matrix-vector multiplication. We highlight key challenges in achieving good
parallel performance, such as explicit communication overlap using task-based
parallelism, and show how to further improve performance by explicitly load
balancing threads within MPI processes. Using a set of matrices extracted from
Fluidity, a CFD application code which uses the library as its linear solver
engine, we then benchmark the parallel performance of mixed-mode PETSc across
multiple nodes on several modern HPC architectures. We evaluate the parallel
scalability on Uniform Memory Access (UMA) systems, such as the Fujitsu
PRIMEHPC FX10 and IBM BlueGene/Q, as well as a Non-Uniform Memory Access (NUMA)
Cray XE6 platform. A detailed comparison is performed which highlights the
characteristics of each particular architecture, before demonstrating efficient
strong scalability of sparse matrix-vector multiplication with significant
speedups over the pure-MPI mode."
"Modern supercomputers are increasingly requiring the presence of accelerators
and co-processors. However, it has not been easy to achieve good performance on
such heterogeneous clusters. The key challenge has been to ensure good load
balance and that neither the CPU nor the accelerator is left idle. Traditional
approaches have offloaded entire computations to the accelerator, resulting in
an idle CPU, or have opted for task-level parallelism requiring large data
transfers between the CPU and the accelerator. True work-parallelism has been
hard as the Accelerators cannot directly communicate with other CPUs (besides
the host) and Accelerators. In this work, we present a new nested partition
scheme to overcome this problem. By partitioning the work assignment on a given
node asymmetrically into boundary and interior work, and assigning the interior
to the accelerator, we are able to achieve excellent efficiency while ensure
proper utilization of both the CPU and Accelerator resources. The problem used
for evaluating the new partition is an $hp$ discontinuous Galerkin spectral
element method for a coupled elastic--acoustic wave propagation problem."
"The conditional posterior Cramer-Rao lower bound (PCRLB) is an effective
sensor resource management criteria for large, geographically distributed
sensor networks. Existing algorithms for distributed computation of the PCRLB
(dPCRLB) are based on raw observations leading to significant communication
overhead to the estimation mechanism. This letter derives distributed
computational techniques for determining the conditional dPCRLB for quantized,
decentralized sensor networks (CQ/dPCRLB). Analytical expressions for the
CQ/dPCRLB are derived, which are particularly useful for particle filter-based
estimators. The CQ/dPCRLB is compared for accuracy with its centralized
counterpart through Monte-Carlo simulations."
"The Mailbox Problem was described and solved by Aguilera, Gafni, and Lamport
in their 2010 DC paper with an algorithm that uses two flag registers that
carry 14 values each. An interesting problem that they ask is whether there is
a mailbox algorithm with smaller flag values. We give a positive answer by
describing a mailbox algorithm with 6 and 4 values in the two flag registers."
"We consider the problem of managing a dynamic heterogeneous storage system in
a distributed way so that the amount of data assigned to a host in that system
is related to its capacity. Two central problems have to be solved for this:
(1) organizing the hosts in an overlay network with low degree and diameter so
that one can efficiently check the correct distribution of the data and route
between any two hosts, and (2) distributing the data among the hosts so that
the distribution respects the capacities of the hosts and can easily be adapted
as the set of hosts or their capacities change. We present distributed
protocols for these problems that are self-stabilizing and that do not need any
global knowledge about the system such as the number of nodes or the overall
capacity of the system. Prior to this work no solution was known satisfying
these properties."
"Cloud computing revolutionised the industry with its elastic, on-demand
approach to computational resources, but has lead to a tremendous impact on the
environment. Data centers constitute 1.1-1.5% of total electricity usage in the
world. Taking a more informed view of the electrical grid by analysing
real-time electricity prices, we set the foundations of a grid-conscious cloud.
We propose a scheduling algorithm that predicts electricity price peaks and
throttles energy consumption by pausing virtual machines. We evaluate the
approach on the OpenStack cloud manager through an empirical approach and show
reductions in energy consumption and costs. Finally, we define green instances
in which cloud providers can offer such services to their customers under
better pricing options."
"The majority of the literature on consensus assumes that protocols are
jointly started at all nodes of the distributed system. We show how to remove
this problematic assumption in semi-synchronous systems, where messages delays
and relative drifts of local clocks may vary arbitrarily within known bounds.
Our framework is self-stabilizing and efficient both in terms of communication
and time; more concretely, compared to a synchronous start in a synchronous
model of a non-self-stabilizing protocol, we achieve a constant-factor increase
in the time and communicated bits to complete an instance, plus an additive
communication overhead of O(n log n) broadcasted bits per time unit and node.
The latter can be further reduced, at an additive increase in time complexity."
"Cloud computing is a new computing paradigm which allows sharing of resources
on remote server such as hardware, network, storage using internet and provides
the way through which application, computing power, computing infrastructure
can be delivered to the user as a service. Cloud computing unique attribute
promise cost effective Information Technology Solution (IT Solution) to the
user. All computing needs are provided by the Cloud Service Provider (CSP) and
they can be increased or decreased dynamically as required by the user. As data
and Application are located at the server and may be beyond geographical
boundary, this leads a number of concern from the user prospective. The
objective of this paper is to explore the key issues of cloud computing which
is delaying its adoption."
This paper introduces the useful notion of Multi-Version Conflict notion.
"With the ease-of-programming, flexibility and yet efficiency, MapReduce has
become one of the most popular frameworks for building big-data applications.
MapReduce was originally designed for distributed-computing, and has been
extended to various architectures, e,g, multi-core CPUs, GPUs and FPGAs. In
this work, we focus on optimizing the MapReduce framework on Xeon Phi, which is
the latest product released by Intel based on the Many Integrated Core
Architecture. To the best of our knowledge, this is the first work to optimize
the MapReduce framework on the Xeon Phi.
  In our work, we utilize advanced features of the Xeon Phi to achieve high
performance. In order to take advantage of the SIMD vector processing units, we
propose a vectorization friendly technique for the map phase to assist the
auto-vectorization as well as develop SIMD hash computation algorithms.
Furthermore, we utilize MIMD hyper-threading to pipeline the map and reduce to
improve the resource utilization. We also eliminate multiple local arrays but
use low cost atomic operations on the global array for some applications, which
can improve the thread scalability and data locality due to the coherent L2
caches. Finally, for a given application, our framework can either
automatically detect suitable techniques to apply or provide guideline for
users at compilation time. We conduct comprehensive experiments to benchmark
the Xeon Phi and compare our optimized MapReduce framework with a
state-of-the-art multi-core based MapReduce framework (Phoenix++). By
evaluating six real-world applications, the experimental results show that our
optimized framework is 1.2X to 38X faster than Phoenix++ for various
applications on the Xeon Phi."
"Many real-world systems, such as social networks, rely on mining efficiently
large graphs, with hundreds of millions of vertices and edges. This volume of
information requires partitioning the graph across multiple nodes in a
distributed system. This has a deep effect on performance, as traversing edges
cut between partitions incurs a significant performance penalty due to the cost
of communication. Thus, several systems in the literature have attempted to
improve computational performance by enhancing graph partitioning, but they do
not support another characteristic of real-world graphs: graphs are inherently
dynamic, their topology evolves continuously, and subsequently the optimum
partitioning also changes over time.
  In this work, we present the first system that dynamically repartitions
massive graphs to adapt to structural changes. The system optimises graph
partitioning to prevent performance degradation without using data replication.
The system adopts an iterative vertex migration algorithm that relies on local
information only, making complex coordination unnecessary. We show how the
improvement in graph partitioning reduces execution time by over 50%, while
adapting the partitioning to a large number of changes to the graph in three
real-world scenarios."
"In this paper, we present a GPU implementation of a two-dimensional shallow
water model. Water simulations are useful for modeling floods, river/reservoir
behavior, and dam break scenarios. Our GPU implementation shows vast
performance improvements over the original Fortran implementation. By taking
advantage of the GPU, researchers and engineers will be able to study water
systems more efficiently and in greater detail."
"In this paper we present Simgrid, a toolkit for the versatile simulation of
large scale distributed systems, whose development effort has been sustained
for the last fifteen years. Over this time period SimGrid has evolved from a
one-laboratory project in the U.S. into a scientific instrument developed by an
international collaboration. The keys to making this evolution possible have
been securing of funding, improving the quality of the software, and increasing
the user base. In this paper we describe how we have been able to make advances
on all three fronts, on which we plan to intensify our efforts over the
upcoming years."
"The Partitioned Global Address Space (PGAS) programming model strikes a
balance between the locality-aware, but explicit, message-passing model and the
easy-to-use, but locality-agnostic, shared memory model. However, the PGAS rich
memory model comes at a performance cost which can hinder its potential for
scalability and performance. To contain this overhead and achieve full
performance, compiler optimizations may not be sufficient and manual
optimizations are typically added. This, however, can severely limit the
productivity advantage. Such optimizations are usually targeted at reducing
address translation overheads for shared data structures. This paper proposes a
hardware architectural support for PGAS, which allows the processor to
efficiently handle shared addresses. This eliminates the need for such
hand-tuning, while maintaining the performance and productivity of PGAS
languages. We propose to avail this hardware support to compilers by
introducing new instructions to efficiently access and traverse the PGAS memory
space. A prototype compiler is realized by extending the Berkeley Unified
Parallel C (UPC) compiler. It allows unmodified code to use the new
instructions without the user intervention, thereby creating a real productive
programming environment. Two implementations are realized: the first is
implemented using the full system simulator Gem5, which allows the evaluation
of the performance gain. The second is implemented using a softcore processor
Leon3 on an FPGA to verify the implementability and to parameterize the cost of
the new hardware and its instructions. The new instructions show promising
results for the NAS Parallel Benchmarks implemented in UPC. A speedup of up to
5.5x is demonstrated for unmodified and unoptimized codes. Unoptimized code
performance using this hardware was shown to also surpass the performance of
manually optimized code by up to 10%."
"Modern distributed systems employ atomic read-modify-write primitives to
coordinate concurrent operations. Such primitives are typically built on top of
a central server, or rely on an agreement protocol. Both approaches provide a
universal construction, that is, a general mechanism to construct atomic and
responsive objects. These two techniques are however known to be inherently
costly. As a consequence, they may result in bottlenecks in applications using
them for coordination. In this paper, we investigate another direction to
implement a universal construction. Our idea is to delegate the implementation
of the universal construction to the clients, and solely implement a
distributed shared atomic memory at the servers side. The construction we
propose is obstruction-free. It can be implemented in a purely asynchronous
manner, and it does not assume the knowledge of the participants. It is built
on top of grafarius and racing objects, two novel shared abstractions that we
introduce in detail. To assess the benefits of our approach, we present a
prototype implementation on top of the Cassandra data store, and compare it
empirically to the Zookeeper coordination service."
"In this paper we propose a distributed algorithm for the estimation and
control of the connectivity of ad-hoc networks in the presence of a random
topology. First, given a generic random graph, we introduce a novel stochastic
power iteration method that allows each node to estimate and track the
algebraic connectivity of the underlying expected graph. Using results from
stochastic approximation theory, we prove that the proposed method converges
almost surely (a.s.) to the desired value of connectivity even in the presence
of imperfect communication scenarios. The estimation strategy is then used as a
basic tool to adapt the power transmitted by each node of a wireless network,
in order to maximize the network connectivity in the presence of realistic
Medium Access Control (MAC) protocols or simply to drive the connectivity
toward a desired target value. Numerical results corroborate our theoretical
findings, thus illustrating the main features of the algorithm and its
robustness to fluctuations of the network graph due to the presence of random
link failures."
"Distributed consistency is perhaps the most discussed topic in distributed
systems today. Coordination protocols can ensure consistency, but in practice
they cause undesirable performance unless used judiciously. Scalable
distributed architectures avoid coordination whenever possible, but
under-coordinated systems can exhibit behavioral anomalies under fault, which
are often extremely difficult to debug. This raises significant challenges for
distributed system architects and developers. In this paper we present Blazes,
a cross-platform program analysis framework that (a) identifies program
locations that require coordination to ensure consistent executions, and (b)
automatically synthesizes application-specific coordination code that can
significantly outperform general-purpose techniques. We present two case
studies, one using annotated programs in the Twitter Storm system, and another
using the Bloom declarative language."
"Data center providers seek to minimize their total cost of ownership (TCO),
while power consumption has become a social concern. We present formulations to
minimize server energy consumption and server cost under three different data
center server setups (homogeneous, heterogeneous, and hybrid hetero-homogeneous
clusters) with dynamic temporal workload. Our studies show that the homogeneous
model significantly differs from the heterogeneous model in computational time
(by an order of magnitude). To be able to compute optimal configurations in
near real-time for large scale data centers, we propose two modes, aggregation
by maximum and aggregation by mean. In addition, we propose two aggregation
methods, static (periodic) aggregation and dynamic (aperiodic) aggregation. We
found that in the aggregation by maximum mode, the dynamic aggregation resulted
in cost savings of up to approximately 18% over the static aggregation. In the
aggregation by mean mode, the dynamic aggregation by mean could save up to
approximately 50% workload rearrangement compared to the static aggregation by
mean mode. Overall, our methodology helps to understand the trade-off in
energy-aware aggregation."
"This paper introduces novel method of simulation of lipid biomembranes based
on Metropolis Hastings algorithm and Graphic Processing Unit computational
power. Method gives up to 55 times computational boost in comparison to
classical computations. Extensive study of algorithm correctness is provided.
Analysis of simulation results and results obtained with classical simulation
methodologies are presented."
A fast fair solution for Reader-Writer Problem is presented.
"iDataCool is an HPC architecture jointly developed by the University of
Regensburg and the IBM Research and Development Lab B\""oblingen. It is based on
IBM's iDataPlex platform, whose air-cooling solution was replaced by a custom
water-cooling solution that allows for cooling water temperatures of 70C/158F.
The system is coupled to an adsorption chiller by InvenSor that operates
efficiently at these temperatures. Thus a significant portion of the energy
spent on HPC can be recovered in the form of chilled water, which can then be
used to cool other parts of the computing center. We describe the architecture
of iDataCool and present benchmarks of the cooling performance and the energy
(reuse) efficiency."
"In fork-join parallelism, a sequential program is split into a directed
acyclic graph of tasks linked by directed dependency edges, and the tasks are
executed, possibly in parallel, in an order consistent with their dependencies.
A popular and effective way to extend fork-join parallelism is to allow threads
to create futures. A thread creates a future to hold the results of a
computation, which may or may not be executed in parallel. That result is
returned when some thread touches that future, blocking if necessary until the
result is ready.
  Recent research has shown that while futures can, of course, enhance
parallelism in a structured way, they can have a deleterious effect on cache
locality. In the worst case, futures can incur $\Omega(P T_\infty + t
T_\infty)$ deviations, which implies $\Omega(C P T_\infty + C t T_\infty)$
additional cache misses, where $C$ is the number of cache lines, $P$ is the
number of processors, $t$ is the number of touches, and $T_\infty$ is the
\emph{computation span}. Since cache locality has a large impact on software
performance on modern multicores, this result is troubling.
  In this paper, however, we show that if futures are used in a simple,
disciplined way, then the situation is much better: if each future is touched
only once, either by the thread that created it, or by a thread to which the
future has been passed from the thread that created it, then parallel
executions with work stealing can incur at most $O(C P T^2_\infty)$ additional
cache misses, a substantial improvement. This structured use of futures is
characteristic of many (but not all) parallel applications."
"Virtual machine images and instances (VMs) in cloud computing centres are
typically designed as isolation containers for applications, databases and
networking functions. In order to build complex distributed applications,
multiple virtual machines must be connected, orchestrated and combined with
platform and infrastructure services from the hosting environment. There are
several reasons why sometimes it is beneficial to introduce a new layer,
Cloud-in-a-VM, which acts as a portable management interface to a cluster of
VMs. We reason about the benefits and present our Cloud-in-a-VM implementation
called Nested Cloud which allows consumers to become light-weight cloud
operators on demand and reap multiple advantages, including fully utilised
resource allocations. The practical usefulness and the performance of the
intermediate cloud stack VM are evaluated in a marketplace scenario."
"Underground cable power transmission and distribution system are susceptible
to faults. Accurate fault location for transmission lines is of vital
importance. A quick detection and analysis of faults is necessity of power
retailers and distributors. This paper reviews various fault locating methods
and highly computational methods proposed by research community that are
currently in use. The paper also presents some guidelines for design of fault
location and remote indication, for reducing power outages and reducing heavy
loss of revenue."
"In this paper we describe a new brute force algorithm for building the
$k$-Nearest Neighbor Graph ($k$-NNG). The $k$-NNG algorithm has many
applications in areas such as machine learning, bio-informatics, and clustering
analysis. While there are very efficient algorithms for data of low dimensions,
for high dimensional data the brute force search is the best algorithm. There
are two main parts to the algorithm: the first part is finding the distances
between the input vectors which may be formulated as a matrix multiplication
problem. The second is the selection of the $k$-NNs for each of the query
vectors. For the second part, we describe a novel graphics processing unit
(GPU) -based multi-select algorithm based on quick sort. Our optimization makes
clever use of warp voting functions available on the latest GPUs along with
use-controlled cache. Benchmarks show significant improvement over
state-of-the-art implementations of the $k$-NN search on GPUs."
"Modern Internet-scale storage systems often provide weak consistency in
exchange for better performance and resilience. An important weak consistency
property is k-atomicity, which bounds the staleness of values returned by read
operations. The k-atomicity-verification problem (or k-AV for short) is the
problem of deciding whether a given history of operations is k-atomic. The 1-AV
problem is equivalent to verifying atomicity/linearizability, a well-known and
solved problem. However, for k > 2, no polynomial-time k-AV algorithm is known.
  This paper makes the following contributions towards solving the k-AV
problem. First, we present a simple 2- AV algorithm called LBT, which is likely
to be efficient (quasilinear) for histories that arise in practice, although it
is less efficient (quadratic) in the worst case. Second, we present a more
involved 2-AV algorithm called FZF, which runs efficiently (quasilinear) even
in the worst case. To our knowledge, these are the first algorithms that solve
the 2-AV problem fully. Third, we show that the weighted k-AV problem, a
natural extension of the k-AV problem, is NP-complete."
"Paxos, Viewstamped Replication, and Zab are replication protocols that ensure
high-availability in asynchronous environments with crash failures. Various
claims have been made about similarities and differences between these
protocols. But how does one determine whether two protocols are the same, and
if not, how significant the differences are?
  We propose to address these questions using refinement mappings, where
protocols are expressed as succinct specifications that are progressively
refined to executable implementations. Doing so enables a principled
understanding of the correctness of the different design decisions that went
into implementing the various protocols. Additionally, it allowed us to
identify key differences that have a significant impact on performance."
"When orchestrating highly distributed and data-intensive Web service
workflows the geographical placement of the orchestration engine can greatly
affect the overall performance of a workflow. Orchestration engines are
typically run from within an organisations' network, and may have to transfer
data across long geographical distances, which in turn increases execution time
and degrades the overall performance of a workflow. In this paper we present
CloudForecast: a Web service framework and analysis tool which given a workflow
specification, computes the optimal Amazon EC2 Cloud region to automatically
deploy the orchestration engine and execute the workflow. We use geographical
distance of the workflow, network latency and HTTP round-trip time between
Amazon Cloud regions and the workflow nodes to find a ranking of Cloud regions.
This combined set of simple metrics effectively predicts where the workflow
orchestration engine should be deployed in order to reduce overall execution
time.
  We evaluate our approach by executing randomly generated data-intensive
workflows deployed on the PlanetLab platform in order to rank Amazon EC2 Cloud
regions. Our experimental results show that our proposed optimisation strategy,
depending on the particular workflow, can speed up execution time on average by
82.25% compared to local execution. We also show that the standard deviation of
execution time is reduced by an average of almost 65% using the optimisation
strategy."
"Grid Computing is a type of parallel and distributed systems that is designed
to provide reliable access to data and computational resources in wide area
networks. These resources are distributed in different geographical locations,
however are organized to provide an integrated service. Effective data
management in today`s enterprise environment is an important issue. Also,
Performance is one of the challenges of using these environments. For improving
the performance of file access and easing the sharing amongst distributed
systems, replication techniques are used. Data replication is a common method
used in distributed environments, where essential data is stored in multiple
locations, so that a user can access the data from a site in his area. In this
paper, we present a survey on basic and new replication techniques that have
been proposed by other researchers. After that, we have a full comparative
study on these replication strategies. Also, at the end of the paper, we
summarize the results and points of these replication techniques."
"In this work, we study protocols so that populations of distributed processes
can construct networks. In order to highlight the basic principles of
distributed network construction we keep the model minimal in all respects. In
particular, we assume finite-state processes that all begin from the same
initial state and all execute the same protocol (i.e. the system is
homogeneous). Moreover, we assume pairwise interactions between the processes
that are scheduled by an adversary. The only constraint on the adversary
scheduler is that it must be fair. In order to allow processes to construct
networks, we let them activate and deactivate their pairwise connections. When
two processes interact, the protocol takes as input the states of the processes
and the state of the their connection and updates all of them. Initially all
connections are inactive and the goal is for the processes, after interacting
and activating/deactivating connections for a while, to end up with a desired
stable network. We give protocols (optimal in some cases) and lower bounds for
several basic network construction problems such as spanning line, spanning
ring, spanning star, and regular network. We provide proofs of correctness for
all of our protocols and analyze the expected time to convergence of most of
them under a uniform random scheduler that selects the next pair of interacting
processes uniformly at random from all such pairs. Finally, we prove several
universality results by presenting generic protocols that are capable of
simulating a Turing Machine (TM) and exploiting it in order to construct a
large class of networks."
"Large-scale storage cluster systems need to manage a vast amount of data
locations. A naive data locations management maintains pairs of data ID and
nodes storing the data in tables. However, it is not practical when the number
of pairs is too large. To solve this problem, management using data
distribution algorithms, rather than management using tables, has been proposed
in recent research. It can distribute data by determining the node for storing
the data based on the datum ID. Such data distribution algorithms require the
ability to handle the addition or removal of nodes, short calculation time and
uniform data distribution in the capacity of each node. This paper proposes a
data distribution algorithm called ASURA (Advanced Scalable and Uniform storage
by Random number Algorithm) that satisfies these requirements. It achieves
following four characteristics: 1) minimum data movement to maintain data
distribution according to node capacity when nodes are added or removed, even
if data are replicated, 2) roughly sub-micro-seconds calculation time, 3) much
lower than 1% maximum variability between nodes in data distribution, and 4)
data distribution according to the capacity of each node. The evaluation
results show that ASURA is qualitatively and quantitatively competitive against
major data distribution algorithms such as Consistent Hashing, Weighted
Rendezvous Hashing and Random Slicing. The comparison results show benefits of
each algorithm; they show that ASURA has advantage in large scale-out storage
clusters."
"Load balance is important for MapReduce to reduce job duration, increase
parallel efficiency, etc. Previous work focuses on coarse-grained scheduling.
This study concerns fine-grained scheduling on MapReduce operations. Each
operation represents one invocation of the Map or Reduce function. Scheduling
MapReduce operations is difficult due to highly screwed operation loads, no
support to collect workload statistics, and high complexity of the scheduling
problem. So current implementations adopt simple strategies, leading to poor
load balance. To address these difficulties, we design an algorithm to schedule
operations based on the key distribution of intermediate pairs. The algorithm
involves a sub-program for selecting operations for task slots, and we name it
the Balanced Subset Sum (BSS) problem. We discuss properties of BSS and design
exact and approximation algorithms for it. To transparently incorporate these
algorithms into MapReduce, we design a communication mechanism to collect
statistics, and a pipeline within Reduce tasks to increase resource
utilization. To the best of our knowledge, this is the first work on scheduling
MapReduce workload at this fine-grained level. Experiments on PUMA [T+12]
benchmarks show consistent performance improvement. The job duration can be
reduced by up to 37%, compared with standard MapReduce."
"When a network application is implmented as a virtual machine on a cloud and
is used by a large number of users, the location of the virtual machine should
be selected carefully so that the response time experienced by users is
minimized. As the user population moves and/or increases, the virtual machine
may need to be migrated to a new location or replicated on many locations over
a wide-area network. Virtual machine migration and replication have been
studied extensively but in most cases are limited within a subnetwork to be
able to maintain service continuity. In this paper we introduce a distributed
cloud computing environment which facilitates the migration and replication of
a virtual machine over a wide area network. The mechanism is provided by an
overlay network of smart routers, each of which connects a cooperating data
center to the Internet. The proposed approach is analyzed and compared with
related works"
"Grid computing is a type of distributed computing which allows sharing of
computer resources through Internet. It not only allows us to share files but
also most of the software and hardware resources. An efficient resource
discovery mechanism is the fundamental requirements for grid computing systems,
as it supports resource management and scheduling of applications. Among
various discovery mechanisms,Peer-to-Peer (P2P) technology witnessed rapid
development and the key component for this success is efficient lookup
applications of P2P. Chord is a P2P structural model widely used as a routing
protocol to find resources in grid environment. Plenty of ideas are implemented
by researchers to improve the lookup performance of chord protocol in Grid
environment. In this paper, we discuss the recent researches made on Chord
Structured P2P protocol and present our proposed methods in which we use the
address of Recently Visited Node (RVN) and fuzzy technique to easily locate the
grid resources by reducing message complexity and time complexity."
"The energy consumption of computer and communication systems does not scale
linearly with the workload. A system uses a significant amount of energy even
when idle or lightly loaded. A widely reported solution to resource management
in large data centers is to concentrate the load on a subset of servers and,
whenever possible, switch the rest of the servers to one of the possible sleep
states. We propose a reformulation of the traditional concept of load balancing
aiming to optimize the energy consumption of a large-scale system: {\it
distribute the workload evenly to the smallest set of servers operating at an
optimal energy level, while observing QoS constraints, such as the response
time.} Our model applies to clustered systems; the model also requires that the
demand for system resources to increase at a bounded rate in each reallocation
interval. In this paper we report the VM migration costs for application
scaling."
"Future e-business models will rely on electronic contracts which are agreed
dynamically and adaptively by web services. Thus, the automatic negotiation of
Service Level Agreements (SLAs) between consumers and providers is key for
enabling service-based value chains.
  The process of finding appropriate providers for web services seems to be
simple. Consumers contact several providers and take the provider which offers
the best matching SLA. However, currently consumers are not able forecasting
the probability of finding a matching provider for their requested SLA. So
consumers contact several providers and check if their offers are matching. In
case of continuing faults, on the one hand consumers may adapt their Service
Level Objects (SLOs) of the required SLA or on the other hand simply accept
offered SLAs of the contacted providers.
  By forecasting the probability of finding a matching provider, consumers
could assess their chances of finding a provider offering the requested SLA. If
a low probability is predicted, consumers can immediately adapt their SLOs or
increase the numbers of providers to be contacted.
  Thus, this paper proposes an analytical forecast model, which allows
consumers to get a realistic assessment of the probability to find matching
providers. Additionally, we present an optimization algorithm based on the
forecast results, which allows adapting the SLO parameter ranges in order to
find at least one matching provider. Not only consumers, but also providers can
use this forecast model to predict the prospective demand. So providers are
able to assess the number of potential consumers based on their offers too.
  Justification of our approach is done by simulation of practical examples
checking our theoretical findings."
"We present a set of C functions implementing a distributed software voting
mechanism for EPX or similar message passing environments, and we place it
within the EFTOS framework (Embedded Fault-Tolerant Supercomputing, ESPRIT-IV
Project 21012) of software tools for enhancing the dependability of a user
application. The described mechanism can be used for instance to implement
restoring organs i.e., N-modular redundancy systems with N-replicated voters.
We show that, besides structural design goals like fault transparency, this
tool achieves replication transparency, a high degree of flexibility and
ease-of-use, and good performance."
"We describe a distributed, multimedia application which is being developed in
the framework of the ESPRIT-IV Project 21012 EFTOS (Embedded Fault-Tolerant
Supercomputing). The application dynamically sets up a hierarchy of HTML pages
reflecting the current status of an EFTOS-compliant dependable application
running on a Parsytec CC system. These pages are fed to a World-Wide Web
browser playing the role of a hypermedia monitor. The adopted approach allows
the user to concentrate on the high-level aspects of his/her application so to
quickly assess the quality of its current fault-tolerance design. This view of
the system lends itself well for being coupled with a tool to interactively
inject software faults in the user application; this tool is currently under
development."
"We describe the voting farm, a tool which implements a distributed software
voting mechanism for a number of parallel message passing systems. The tool,
developed in the framework of EFTOS (Embedded Fault-Tolerant Supercomputing),
can be used in stand-alone mode or in conjunction with other EFTOS fault
tolerance tools. In the former case, we describe how the mechanism can be
exploited, e.g., to implement restoring organs ($N\!$-modular redundancy
systems with $N\!$-replicated voters); in the latter case, we show how it is
possible for the user to implement in an easy and effective way a number of
different recovery strategies via a custom, high-level language. Combining such
strategies with the basic fault masking capabilities of the voting tool makes
it possible to set up complex fault-tolerant systems such as, for instance,
$N$-and-$M$-spare systems or gracefully degrading voting farms. We also report
about the impact that our tool can have on reliability, and we show how,
besides structural design goals like fault transparency, our tool achieves
replication transparency, a high degree of flexibility and ease-of-use, and
good performance."
"In this paper we describe an autotuning tool for optimization of OpenMP
applications on highly multicore and multithreaded architectures. Our work was
motivated by in-depth performance analysis of scientific applications and
synthetic benchmarks on IBM Power 775 architecture. The tool provides an
automatic code instrumentation of OpenMP parallel regions. Based on measurement
of chosen hardware performance counters the tool decides on the number of
parallel threads that should be used for execution of chosen code fragments."
"Spatial decomposition is a popular basis for parallelising code. Cast in the
frame of task parallelism, calculations on a spatial domain can be treated as a
task. If neighbouring domains interact and share results, access to the
specific data needs to be synchronized to avoid race conditions. This is the
case for a variety of applications, like most molecular dynamics and many
computational fluid dynamics codes. Here we present an unexpected problem which
can occur in dependency-driven task parallelization models like StarSs: the
tasks accessing a specific spatial domain are treated as interdependent, as
dependencies are detected automatically via memory addresses. Thus, the order
in which tasks are generated will have a severe impact on the dependency tree.
In the worst case, a complete serialization is reached and no two tasks can be
calculated in parallel. We present the problem in detail based on an example
from molecular dynamics, and introduce a theoretical framework to calculate the
degree of serialization. Furthermore, we present strategies to avoid this
unnecessary problem. We recommend treating these strategies as best practice
when using dependency-driven task parallel programming models like StarSs on
such scenarios."
"This paper focuses on compact deterministic self-stabilizing solutions for
the leader election problem. When the protocol is required to be \emph{silent}
(i.e., when communication content remains fixed from some point in time during
any execution), there exists a lower bound of Omega(\log n) bits of memory per
node participating to the leader election (where n denotes the number of nodes
in the system). This lower bound holds even in rings. We present a new
deterministic (non-silent) self-stabilizing protocol for n-node rings that uses
only O(\log\log n) memory bits per node, and stabilizes in O(n\log^2 n) rounds.
Our protocol has several attractive features that make it suitable for
practical purposes. First, the communication model fits with the model used by
existing compilers for real networks. Second, the size of the ring (or any
upper bound on this size) needs not to be known by any node. Third, the node
identifiers can be of various sizes. Finally, no synchrony assumption, besides
a weakly fair scheduler, is assumed. Therefore, our result shows that, perhaps
surprisingly, trading silence for exponential improvement in term of memory
space does not come at a high cost regarding stabilization time or minimal
assumptions."
"With advances in hardware and networking technologies and mass manufacturing,
the cost of high end hardware had fall dramatically in recent years. However,
software cost still remains high and is the dominant fraction of the overall
computing budget. Application sharing is a promising solution to reduce the
overall IT cost. Currently software licenses are still based on the number of
copies installed. An organization can thus reduce the IT cost if the users are
able to remotely access the software that is installed on certain computer
servers instead of running the software on every local computer. In this paper,
we propose a generic application sharing architecture for users' application
sharing in a cluster of closed operating systems such as Microsoft Windows. We
also propose a broker-mediated solution where we allow multiple users to access
a single user software license on a time multiplex basis through a single
logged in user. An application sharing tool called ShAppliT has been introduced
and implemented in Microsoft Windows operating system. We evaluated their
performance on CPU usage and memory consumption when a computer is hosting
multiple concurrent shared application sessions."
"Finding a maximum clique in a given graph is one of the fundamental NP-hard
problems. We compare two multi-core thread-parallel adaptations of a
state-of-the-art branch and bound algorithm for the maximum clique problem, and
provide a novel explanation as to why they are successful. We show that load
balance is sometimes a problem, but that the interaction of parallel search
order and the most likely location of solutions within the search space is
often the dominating consideration. We use this explanation to propose a new
low-overhead, scalable work splitting mechanism. Our approach uses explicit
early diversity to avoid strong commitment to the weakest heuristic advice, and
late resplitting for balance. More generally, we argue that for branch and
bound, parallel algorithm design should not be performed independently of the
underlying sequential algorithm."
"Atomic broadcast is an important communication primitive often used to
implement state-machine replication. Despite the large number of atomic
broadcast algorithms proposed in the literature, few papers have discussed how
to turn these algorithms into efficient executable protocols. This paper
focuses on a class of atomic broadcast algorithms based on Paxos, with its
corresponding desirable properties: safety under asynchrony assumptions,
liveness under weak synchrony assumptions, and resiliency-optimality. The paper
presents two protocols, M-Ring Paxos and U-Ring Paxos, derived from Paxos. The
protocols inherit the properties of Paxos and can be implemented very
efficiently. We report a detailed performance analysis of M-Ring Paxos and
U-Ring Paxos and compare them to other atomic broadcast protocols."
"This paper explores the problem of reaching approximate consensus in
synchronous point-to-point networks, where each directed link of the underlying
communication graph represents a communication channel between a pair of nodes.
We adopt the transient Byzantine link failure model [15, 16], where an
omniscient adversary controls a subset of the directed communication links, but
the nodes are assumed to be fault-free.
  Recent work has addressed the problem of reaching approximate consen- sus in
incomplete graphs with Byzantine nodes using a restricted class of iterative
algorithms that maintain only a small amount of memory across iterations [22,
21, 23, 12]. However, to the best of our knowledge, we are the first to
consider approximate consensus in the presence of Byzan- tine links. We extend
our past work that provided exact characterization of graphs in which the
iterative approximate consensus problem in the presence of Byzantine node
failures is solvable [22, 21]. In particular, we prove a tight necessary and
sufficient condition on the underlying com- munication graph for the existence
of iterative approximate consensus algorithms under transient Byzantine link
model. The condition answers (part of) the open problem stated in [16]."
"Data transfer and staging services are common components in Grid-based, or
more generally, in service-oriented applications. Security mechanisms play a
central role in such services, especially when they are deployed in sensitive
application fields like e-health. The adoption of WS-Security and related
standards to SOAP-based transfer services is, however, problematic as a
straightforward adoption of SOAP with MTOM introduces considerable
inefficiencies in the signature generation process when large data sets are
involved. This paper proposes a non-blocking, signature generation approach
enabling a stream-like processing with considerable performance enhancements."
"It is very common to use dynamic methods to detect deadlocks in MPI programs
for the reason that static methods have some restrictions. To guarantee high
reliability of some important MPI-based application software, a model of MPI
synchronization communication is abstracted and a type of static method is
devised to examine deadlocks in such modes. The model has three forms with
different complexity: sequential model, single-loop model and nested-loop
model. Sequential model is a base for all models. Single-loop model must be
treated with a special type of equation group and nested-loop model extends the
methods for the other two models. A standard Java-based software framework
originated from these methods is constructed for determining whether MPI
programs are free from synchronization communication deadlocks. Our practice
shows the software framework is better than those tools using dynamic methods
because it can dig out all synchronization communication deadlocks before an
MPI-based program goes into running."
"A model of MPI synchronization communication programs is presented and its
three basic simplified models are also defined. A series of theorems and
methods for deciding whether deadlocks will occur among the three models are
given and proved strictly. These theories and methods for simple models'
deadlock detection are the necessary base for real MPI program deadlock
detection. The methods are based on a static analysis through programs and with
runtime detection in necessary cases and they are able to determine before
compiling whether it will be deadlocked for two of the three basic models. For
another model, some deadlock cases can be found before compiling and others at
runtime. Our theorems can be used to prove the correctness of currently popular
MPI program deadlock detection algorithms. Our methods may decrease codes that
those algorithms need to change to MPI source or profiling interface and may
detects deadlocks ahead of program execution, thus the overheads can be reduced
greatly."
"Detecting deadlocks in MPI synchronization communication programs is very
difficult and need building program models. All complex models are based on
sequential models. The sequential model is mapped into a set of character
strings and its deadlock detection problem is translated into an equivalent
multi-queue string matching problem. An algorithm is devised and implemented to
statically detect deadlocks in sequential models of MPI synchronization
communication programs. The time and space complexity of the algorithm is O(n)
where n is the amount of message in model. The algorithm is better than usual
circle-detection methods and can adapt well to dynamic message stream."
"This paper analyses the requirements of performing parallel
transaction-oriented simulations with a special focus on the space-parallel
approach and discrete event simulation synchronisation algorithms that are
suitable for transaction-oriented simulation and the target environment of Ad
Hoc Grids. To demonstrate the findings a Java-based parallel
transaction-oriented simulator for the simulation language GPSS/H is
implemented on the basis of the most promising Shock Resistant Time Warp
synchronisation algorithm and using the Grid framework ProActive. The
validation of this parallel simulator shows that the Shock Resistant Time Warp
algorithm can successfully reduce the number of rolled back Transaction moves
but it also reveals circumstances in which the Shock Resistant Time Warp
algorithm can be outperformed by the normal Time Warp algorithm. The conclusion
of this paper suggests possible improvements to the Shock Resistant Time Warp
algorithm to avoid such problems."
"We consider a network of sensors deployed to sense a spatio-temporal field
and estimate a parameter of interest. We are interested in the case where the
temporal process sensed by each sensor can be modeled as a state-space process
that is perturbed by random noise and parametrized by an unknown parameter. To
estimate the unknown parameter from the measurements that the sensors
sequentially collect, we propose a distributed and recursive estimation
algorithm, which we refer to as the incremental recursive prediction error
algorithm. This algorithm has the distributed property of incremental gradient
algorithms and the on-line property of recursive prediction error algorithms.
We study the convergence behavior of the algorithm and provide sufficient
conditions for its convergence. Our convergence result is rather general and
contains as special cases the known convergence results for the incremental
versions of the least-mean square algorithm. Finally, we use the algorithm
developed in this paper to identify the source of a gas-leak (diffusing source)
in a closed warehouse and also report numerical simulations to verify
convergence."
"The Desktop Grid offers solutions to overcome several challenges and to
answer increasingly needs of scientific computing. This technology consists
mainly in exploiting PC resources, geographically dispersed, to treat time
consuming applications and/or important storage capacity requiring
applications. However, as resources number increases, the need for scalability,
self-organisation, dynamic reconfiguration, decentralization and performance
becomes more and more essential. In this context, this paper evaluates the
scalability and performance of P2P tools for registering and discovering
services (Publish/Subscribe systems). Three protocols are used in this purpose:
Bonjour, Avahi and Pastry. We have studied the behaviour of these protocols
related to two criteria: the elapsed time for registrations services and the
needed time to discover new services."
"In a bipartite max-min LP, we are given a bipartite graph $\myG = (V \cup I
\cup K, E)$, where each agent $v \in V$ is adjacent to exactly one constraint
$i \in I$ and exactly one objective $k \in K$. Each agent $v$ controls a
variable $x_v$. For each $i \in I$ we have a nonnegative linear constraint on
the variables of adjacent agents. For each $k \in K$ we have a nonnegative
linear objective function of the variables of adjacent agents. The task is to
maximise the minimum of the objective functions. We study local algorithms
where each agent $v$ must choose $x_v$ based on input within its
constant-radius neighbourhood in $\myG$. We show that for every $\epsilon>0$
there exists a local algorithm achieving the approximation ratio ${\Delta_I (1
- 1/\Delta_K)} + \epsilon$. We also show that this result is the best possible
-- no local algorithm can achieve the approximation ratio ${\Delta_I (1 -
1/\Delta_K)}$. Here $\Delta_I$ is the maximum degree of a vertex $i \in I$, and
$\Delta_K$ is the maximum degree of a vertex $k \in K$. As a methodological
contribution, we introduce the technique of graph unfolding for the design of
local approximation algorithms."
"The question of whether all shared objects with consensus number 2 belong to
Common2, the set of objects that can be implemented in a wait-free manner by
any type of consensus number 2, was first posed by Herlihy. In the absence of
general results, several researchers have obtained implementations for
restricted-concurrency versions of FIFO queues. We present the first Common2
algorithm for a queue with two enqueuers and any number of dequeuers."
"We consider an untrusted server storing shared data on behalf of clients. We
show that no storage access protocol can on the one hand preserve sequential
consistency and wait-freedom when the server is correct, and on the other hand
always preserve fork sequential consistency."
"Systems of systems (SoS) are a hot topic in our ""fully connected global
world"". Our aim is not to provide another definition of what SoS are, but
rather to focus on the adequacy of reusing standard system architecting
techniques within this approach in order to improve performance, fault
detection and safety issues in large-scale coupled systems that definitely
qualify as SoS, whatever the definition is. A key issue will be to secure the
availability of the services provided by the SoS despite the evolution of the
various systems composing the SoS. We will also tackle contracting issues and
responsibility transfers, as they should be addressed to ensure the expected
behavior of the SoS whilst the various independently contracted systems evolve
asynchronously."
"We study the applicability of distributed, local algorithms to 0/1 max-min
LPs where the objective is to maximise ${\min_k \sum_v c_{kv} x_v}$ subject to
${\sum_v a_{iv} x_v \le 1}$ for each $i$ and ${x_v \ge 0}$ for each $v$. Here
$c_{kv} \in \{0,1\}$, $a_{iv} \in \{0,1\}$, and the support sets ${V_i = \{v :
a_{iv} > 0 \}}$ and ${V_k = \{v : c_{kv}>0 \}}$ have bounded size; in
particular, we study the case $|V_k| \le 2$. Each agent $v$ is responsible for
choosing the value of $x_v$ based on information within its constant-size
neighbourhood; the communication network is the hypergraph where the sets $V_k$
and $V_i$ constitute the hyperedges. We present a local approximation algorithm
which achieves an approximation ratio arbitrarily close to the theoretical
lower bound presented in prior work."
"Several protocol efficiency metrics (e.g., scalability, search success rate,
routing reachability and stability) depend on the capability of preserving
structure even over the churn caused by the ad-hoc nodes joining or leaving the
network. Preserving the structure becomes more prohibitive due to the
distributed and potentially uncooperative nature of such networks, as in the
peer-to-peer (P2P) networks. Thus, most practical solutions involve
unstructured approaches while attempting to maintain the structure at various
levels of protocol stack. The primary focus of this paper is to investigate
construction and maintenance of scale-free topologies in a distributed manner
without requiring global topology information at the time when nodes join or
leave. We consider the uncooperative behavior of peers by limiting the number
of neighbors to a pre-defined hard cutoff value (i.e., no peer is a major hub),
and the ad-hoc behavior of peers by rewiring the neighbors of nodes leaving the
network. We also investigate the effect of these hard cutoffs and rewiring of
ad-hoc nodes on the P2P search efficiency."
"In this paper we propose a new practical P2P system based on a full
transposition network topology named TRANS-Net. Full transposition networks
achieve higher fault-tolerance and lower congestion among the class of
transposition networks. TRANS-Net provides an efficient lookup service i.e. k
hops with high probability, where k satisfies Theta(log_n m) less than k less
than Theta(log_2 m), where m denotes the number of system nodes and n is a
system parameter related to the maximum number that m can take (up to n!).
Experiments show that the look-up performance achieves the lower limit of the
complexity relation. TRANS-Net also preserves data locality and provides
efficient look-up performance for complex queries such as multi-dimensional
queries."
"Many networks in real-life typically contain parts in which some nodes are
more highly connected to each other than the other nodes of the network. The
collection of such nodes are usually called clusters, communities, cohesive
groups or modules. In graph terminology, it is called highly connected graph.
In this paper, we first prove some properties related to highly connected
graph. Based on these properties, we then redefine the highly connected
subgraph which results in an algorithm that determines whether a given graph is
highly connected in linear time. Then we present a computationally efficient
algorithm, called MOHCS, for mining overlapping highly connected subgraphs. We
have evaluated experimentally the performance of MOHCS using real and synthetic
data sets from computer-generated graph and yeast protein network. Our results
show that MOHCS is effective and reliable in finding overlapping highly
connected subgraphs. Keywords-component; Highly connected subgraph, clustering
algorithms, minimum cut, minimum degree"
"We present a new efficient localized algorithm to construct, for any given
quasi-unit disk graph G=(V,E) and any e > 0, a (1+e)-spanner for G of maximum
degree O(1) and total weight O(w(MST)), where w(MST) denotes the weight of a
minimum spanning tree for V. We further show that similar localized techniques
can be used to construct, for a given unit disk graph G = (V, E), a planar
Cdel(1+e)(1+pi/2)-spanner for G of maximum degree O(1) and total weight
O(w(MST)). Here Cdel denotes the stretch factor of the unit Delaunay
triangulation for V. Both constructions can be completed in O(1) communication
rounds, and require each node to know its own coordinates."
"In a world demanding the best performance from financial investments,
distributed applications occupy the first place among the proposed solutions.
This particularity is due to their distributed architecture which is able to
acheives high performance. Currently, many research works aim to develop tools
that facilitate the implementation of such applications. The urgent need for
such applications in all areas pushes researchers to accelerate this process.
However, the lack of standardization results in the absence of strategic
decisions taken by computer science community. In this article, we argue that
Java technology represents an elegant compromise ahead of the list of the
currently available solutions. In fact, by promoting the independence of
hardware and software, Java technology makes it possible to overcome pitfalls
that are inherent to the creation of distributed applications."
"To accommodate the needs of large-scale distributed P2P systems, scalable
data management strategies are required, allowing applications to efficiently
cope with continuously growing, highly dis tributed data. This paper addresses
the problem of efficiently stor ing and accessing very large binary data
objects (blobs). It proposesan efficient versioning scheme allowing a large
number of clients to concurrently read, write and append data to huge blobs
that are fragmented and distributed at a very large scale. Scalability under
heavy concurrency is achieved thanks to an original metadata scheme, based on a
distributed segment tree built on top of a Distributed Hash Table (DHT). Our
approach has been implemented and experimented within our BlobSeer prototype on
the Grid'5000 testbed, using up to 175 nodes."
"A snap-stabilizing algorithm ensures that it always behaves according to its
specifications whenever it starts from an arbitrary configuration. In this
paper, we interest in the message forwarding problem in a message-switched
network. We must manage network ressources in order to deliver messages to any
processor of the network. In this goal, we need information given by a routing
algorithm. But, due to the context of stabilization, this information can be
initially corrupted. It is why the existence of snap-stabilizing algorithms for
this task (proved in [CDV09]) implies that we can ask the system to begin
forwarding messages even if routing tables are initially corrupted. In this
paper, we generalize the previous result given a necessary and sufficient
condition to solve the forwarding problem in a snap-stabilizing way."
"Given an undirected graph and $0\le\epsilon\le1$, a set of nodes is called
$\epsilon$-near clique if all but an $\epsilon$ fraction of the pairs of nodes
in the set have a link between them. In this paper we present a fast
synchronous network algorithm that uses small messages and finds a near-clique.
Specifically, we present a constant-time algorithm that finds, with constant
probability of success, a linear size $\epsilon$-near clique if there exists an
$\epsilon^3$-near clique of linear size in the graph. The algorithm uses
messages of $O(\log n)$ bits. The failure probability can be reduced to
$n^{-\Omega(1)}$ in $O(\log n)$ time, and the algorithm also works if the graph
contains a clique of size $\Omega(n/\log^{\alpha}\log n)$ for some $\alpha \in
(0,1)$."
"We present the architecture and application of the distributed control in
public cluster, a parallel machine which is open for public access. Following
the nature of public cluster, the integrated distributed control system is
fully accessible through network using a user-friendly web interface. The
system is intended mainly to control the power of each node in a block of
parallel computers provided to certain users. This is especially important to
extend the life-time of related hardwares, and to reduce the whole running and
maintainance costs. The system consists of two parts : the master- and
node-controllers, and both are connected each other through RS-485 interface.
Each node-controller is assigned with a unique address to distinguish each of
them. We also discuss briefly the implementation of the system at the LIPI
Public Cluster."
"It is effective to improve the reliability and availability of large-scale
cluster systems through the analysis of failures. Existed failure analysis
methods understand and analyze failures from one or few dimension. The analysis
results are partial and with less precision because of the limitation of data
source. This paper presents multidimensional analysis based on graph mining to
analyze multi-source system logs, which is a promising failure analysis method
to get more complete and precise failure knowledge."
"Different departments of a large organization often run dedicated cluster
systems for different computing loads, like HPC (high performance computing)
jobs or Web service applications. In this paper, we have designed and
implemented a cloud management system software Phoenix Cloud to consolidate
heterogeneous workloads from different departments affiliated to the same
organization on the shared cluster system. We have also proposed cooperative
resource provisioning and management policies for a large organization and its
affiliated departments, running HPC jobs and Web service applications, to share
the consolidated cluster system. The experiments show that in comparison with
the case that each department operates its dedicated cluster system, Phoenix
Cloud significantly decreases the scale of the required cluster system for a
large organization, improves the benefit of the scientific computing
department, and at the same time provisions enough resources to the other
department running Web services with varying loads."
"We define and explore the concept of ideal stabilization. The program is
ideally stabilizing if its every state is legitimate. Ideal stabilization
allows the specification designer to prescribe with arbitrary degree of
precision not only the fault-free program behavior but also its recovery
operation. Specifications may or may not mention all possible states. We
identify approaches to designing ideal stabilization to both kinds of
specifications. For the first kind, we state the necessary condition for an
ideally stabilizing solution. On the basis of this condition we prove that
there is no ideally stabilizing solution to the leader election problem. We
illustrate the utility of the concept by providing examples of well-known
programs and proving them ideally stabilizing. Specifically, we prove ideal
stabilization of the conflict manager, the alternator, the propagation of
information with feedback and the alternating bit protocol."
"The International Telecommunication Union (ITU) Regional Radio Conference
(RRC06) established in 2006 a new frequency plan for the introduction of
digital broadcasting in European, African, Arab, CIS countries and Iran. The
preparation of the plan involved complex calculations under short deadline and
required dependable and efficient computing capability. The ITU designed and
deployed in-situ a dedicated PC farm, in parallel to the European Organization
for Nuclear Research (CERN) which provided and supported a system based on the
EGEE Grid. The planning cycle at the RRC06 required a periodic execution in the
order of 200,000 short jobs, using several hundreds of CPU hours, in a period
of less than 12 hours. The nature of the problem required dynamic
workload-balancing and low-latency access to the computing resources. We
present the strategy and key technical choices that delivered a reliable
service to the RRC06."
"For the past decade, HENP experiments have been heading towards a distributed
computing model in an effort to concurrently process tasks over enormous data
sets that have been increasing in size as a function of time. In order to
optimize all available resources (geographically spread) and minimize the
processing time, it is necessary to face also the question of efficient data
transfers and placements. A key question is whether the time penalty for moving
the data to the computational resources is worth the presumed gain. Onward to
the truly distributed task scheduling we present the technique using a
Constraint Programming (CP) approach. The CP technique schedules data transfers
from multiple resources considering all available paths of diverse
characteristic (capacity, sharing and storage) having minimum user's waiting
time as an objective. We introduce a model for planning data transfers to a
single destination (data transfer) as well as its extension for an optimal data
set spreading strategy (data placement). Several enhancements for a solver of
the CP model will be shown, leading to a faster schedule computation time using
symmetry breaking, branch cutting, well studied principles from job-shop
scheduling field and several heuristics. Finally, we will present the design
and implementation of a corner-stone application aimed at moving datasets
according to the schedule. Results will include comparison of performance and
trade-off between CP techniques and a Peer-2-Peer model from simulation
framework as well as the real case scenario taken from a practical usage of a
CP scheduler."
"Traffic Congestions and accidents are major concerns in today's
transportation systems. This thesis investigates how to optimize traffic flow
on highways, in particular for merging situations such as intersections where a
ramp leads onto the highway. In our work, cars are equipped with sensors that
can detect distance to neighboring cars, and communicate their velocity and
acceleration readings with one another. Sensor-enabled cars can locally
exchange sensed information about the traffic and adapt their behavior much
earlier than regular cars.
  We propose proactive algorithms for merging different streams of
sensor-enabled cars into a single stream. A proactive merging algorithm
decouples the decision point from the actual merging point. Sensor-enabled cars
allow us to decide where and when a car merges before it arrives at the actual
merging point. This leads to a significant improvement in traffic flow as
velocities can be adjusted appropriately. We compare proactive merging
algorithms against the conventional priority-based merging algorithm in a
controlled simulation environment. Experiment results show that proactive
merging algorithms outperform the priority-based merging algorithm in terms of
flow and delay."
"In bilateral accounting of resource consumption both the consumer and
provider independently measure the amount of resources consumed by the
consumer. The problem here is that potential disparities between the provider's
and consumer's accountings, might lead to conflicts between the two parties
that need to be resolved. We argue that with the proper mechanisms available,
most of these conflicts can be solved online, as opposite to in court
resolution; the design of such mechanisms is still a research topic; to help
cover the gap, in this paper we propose a peer--to--peer protocol for online
dispute resolution over storage consumption. The protocol is peer--to--peer and
takes into consideration the possible causes (e.g, transmission delays,
unsynchronized metric collectors, etc.) of the disparity between the provider's
and consumer's accountings to make, if possible, the two results converge."
"Information Fusion Systems are now widely used in different fusion contexts,
like scientific processing, sensor networks, video and image processing. One of
the current trends in this area is to cope with distributed systems. In this
context, we have defined and implemented a Dynamic Distributed Information
Fusion System runtime model. It allows us to cope with dynamic execution
supports while trying to maintain the functionalities of a given Dynamic
Distributed Information Fusion System. The paper presents our system, the
reconfiguration problems we are faced with and our solutions."
"Byzantine agreement algorithms typically assume implicit initial state
consistency and synchronization among the correct nodes and then operate in
coordinated rounds of information exchange to reach agreement based on the
input values. The implicit initial assumptions enable correct nodes to infer
about the progression of the algorithm at other nodes from their local state.
This paper considers a more severe fault model than permanent Byzantine
failures, one in which the system can in addition be subject to severe
transient failures that can temporarily throw the system out of its assumption
boundaries. When the system eventually returns to behave according to the
presumed assumptions it may be in an arbitrary state in which any
synchronization among the nodes might be lost, and each node may be at an
arbitrary state. We present a self-stabilizing Byzantine agreement algorithm
that reaches agreement among the correct nodes in an optimal ration of faulty
to correct, by using only the assumption of eventually bounded message
transmission delay. In the process of solving the problem, two additional
important and challenging building blocks were developed: a unique
self-stabilizing protocol for assigning consistent relative times to protocol
initialization and a Reliable Broadcast primitive that progresses at the speed
of actual message delivery time."
"Self-stabilizing distributed control is often modeled by token abstractions.
A system with a single token may implement mutual exclusion; a system with
multiple tokens may ensure that immediate neighbors do not simultaneously enjoy
a privilege. For a cyber-physical system, tokens may represent physical objects
whose movement is controlled. The problem studied in this paper is to ensure
that a synchronous system with m circulating tokens has at least d distance
between tokens. This problem is first considered in a ring where d is given
whilst m and the ring size n are unknown. The protocol solving this problem can
be uniform, with all processes running the same program, or it can be
non-uniform, with some processes acting only as token relays. The protocol for
this first problem is simple, and can be expressed with Petri net formalism. A
second problem is to maximize d when m is given, and n is unknown. For the
second problem, the paper presents a non-uniform protocol with a single
corrective process."
"In this paper we analyse the requirements of performing parallel
transaction-oriented simulations within loosely coupled systems like ad hoc
grids. We focus especially on the space-parallel approach to parallel
simulation and on discrete event synchronisation algorithms that are suitable
for transaction-oriented simulation and the target environment of ad hoc grids.
To demonstrate our findings, a Java-based parallel simulator for the
transaction-oriented language GPSS/H is implemented on the basis of the most
promising shock-resistant Time Warp (SRTW) synchronisation algorithm and using
the grid framework ProActive. The analysis of our parallel simulator, based on
experiments using the Grid5000 platform, shows that the SRTW algorithm can
successfully reduce the number of rolled back transaction moves but it also
reveals circumstances in which the SRTW algorithm can be outperformed by the
normal Time Warp algorithm. Finally, possible improvements to the SRTW
algorithm are proposed in order to avoid such problems."
"Consider a fully connected network where up to $t$ processes may crash, and
all processes start in an arbitrary memory state. The self-stabilizing firing
squad problem consists of eventually guaranteeing simultaneous response to an
external input. This is modeled by requiring that the non-crashed processes
""fire"" simultaneously if some correct process received an external ""GO"" input,
and that they only fire as a response to some process receiving such an input.
This paper presents FireAlg, the first self-stabilizing firing squad algorithm.
  The FireAlg algorithm is optimal in two respects: (a) Once the algorithm is
in a safe state, it fires in response to a GO input as fast as any other
algorithm does, and (b) Starting from an arbitrary state, it converges to a
safe state as fast as any other algorithm does."
"A typical enterprise uses a local area network of computers to perform its
business. During the off-working hours, the computational capacities of these
networked computers are underused or unused. In order to utilize this
computational capacity an application has to be recoded to exploit concurrency
inherent in a computation which is clearly not possible for legacy applications
without any source code. This thesis presents the design an implementation of a
distributed middleware which can automatically execute a legacy application on
multiple networked computers by parallelizing it. This middleware runs multiple
copies of the binary executable code in parallel on different hosts in the
network. It wraps up the binary executable code of the legacy application in
order to capture the kernel level data access system calls and perform them
distributively over multiple computers in a safe and conflict free manner. The
middleware also incorporates a dynamic scheduling technique to execute the
target application in minimum time by scavenging the available CPU cycles of
the hosts in the network. This dynamic scheduling also supports the CPU
availability of the hosts to change over time and properly reschedule the
replicas performing the computation to minimize the execution time. A prototype
implementation of this middleware has been developed as a proof of concept of
the design. This implementation has been evaluated with a few typical case
studies and the test results confirm that the middleware works as expected."
"The availability of Infrastructure-as-a-Service (IaaS) computing clouds gives
researchers access to a large set of new resources for running complex
scientific applications. However, exploiting cloud resources for large numbers
of jobs requires significant effort and expertise. In order to make it simple
and transparent for researchers to deploy their applications, we have developed
a virtual machine resource manager (Cloud Scheduler) for distributed compute
clouds. Cloud Scheduler boots and manages the user-customized virtual machines
in response to a user's job submission. We describe the motivation and design
of the Cloud Scheduler and present results on its use on both science and
commercial clouds."
"Traditionally, the development of computing systems has been focused on
performance improvements driven by the demand of applications from consumer,
scientific and business domains. However, the ever increasing energy
consumption of computing systems has started to limit further performance
growth due to overwhelming electricity bills and carbon dioxide footprints.
Therefore, the goal of the computer system design has been shifted to power and
energy efficiency. To identify open challenges in the area and facilitate
future advancements it is essential to synthesize and classify the research on
power and energy-efficient design conducted to date. In this work we discuss
causes and problems of high power / energy consumption, and present a taxonomy
of energy-efficient design of computing systems covering the hardware,
operating system, virtualization and data center levels. We survey various key
works in the area and map them to our taxonomy to guide future design and
development efforts. This chapter is concluded with a discussion of
advancements identified in energy-efficient computing and our vision on future
research directions."
"This document describes the Gloss software currently implemented. The
description of the Gloss demonstrator for multi-surface interaction can be
found in D17. The ongoing integration activity for the work described in D17
and D8 constitutes our development of infrastructure for a first smart space.
In this report, the focus is on infrastructure to support the implementation of
location aware services. A local architecture provides a framework for
constructing Gloss applications, termed assemblies, that run on individual
physical nodes. A global architecture defines an overlay network for linking
individual assemblies. Both local and global architectures are under active
development."
"This thesis investigates the application of autonomic management to a
distributed storage system. Effects on performance and resource consumption
were measured in experiments, which were carried out in a local area test-bed.
The experiments were conducted with components of one specific distributed
storage system, but seek to be applicable to a wide range of such systems, in
particular those exposed to varying conditions. The perceived characteristics
of distributed storage systems depend on their configuration parameters and on
various dynamic conditions. For a given set of conditions, one specific
configuration may be better than another with respect to measures such as
resource consumption and performance. Here, configuration parameter values were
set dynamically and the results compared with a static configuration. It was
hypothesised that under non-changing conditions this would allow the system to
converge on a configuration that was more suitable than any that could be set a
priori. Furthermore, the system could react to a change in conditions by
adopting a more appropriate configuration. Autonomic management was applied to
the peer-to-peer (P2P) and data retrieval components of ASA, a distributed
storage system. The effects were measured experimentally for various workload
and churn patterns. The management policies and mechanisms were implemented
using a generic autonomic management framework developed during this work. The
experimental evaluations of autonomic management show promising results, and
suggest several future research topics. The findings of this thesis could be
exploited in building other distributed storage systems that focus on
harnessing storage on user workstations, since these are particularly likely to
be exposed to varying, unpredictable conditions."
"Gradecast is a simple three-round algorithm presented by Feldman and Micali.
The current work presents a very simple algorithm that utilized Gradecast to
achieve Byzantine agreement. Two small variations of the presented algorithm
lead to improved algorithms for solving the Approximate agreement problem and
the Multi-consensus problem.
  An optimal approximate agreement algorithm was presented by Fekete, which
supports up to 1/4 n Byzantine nodes and has message complexity of O(n^k),
where n is the number of nodes and k is the number of rounds.
  Our solution to the approximate agreement problem is optimal, simple and
reduces the message complexity to O(k * n^3), while supporting up to 1/3 n
Byzantine nodes.
  Multi consensus was first presented by Bar-Noy et al. It consists of
consecutive executions of l Byzantine consensuses. Bar-Noy et al., show an
optimal amortized solution to this problem, assuming that all nodes start each
consensus instance at the same time, a property that cannot be guaranteed with
early stopping. Our solution is simpler, preserves round complexity optimality,
allows early stopping and does not require synchronized starts of the consensus
instances."
"In this paper we consider a synchronous message passing system in which in
every round an external adversary is able to send each processor up to k
messages with falsified sender identities and arbitrary content. It is formally
shown that this impersonation model is slightly stronger than the asynchronous
message passing model with crash failures. In particular, we prove that
(k+1)-set agreement can be solved in this model, while k-set agreement is
impossible, for any k>=1. The different strength of the asynchronous and
impersonation models is exhibited by the order preserving renaming problem, for
which an algorithm with n+k target namespace exists in the impersonation model,
while an exponentially larger namespace is required in case of asynchrony."
"This paper presents a simple local medium access control protocol, called
\textsc{Jade}, for multi-hop wireless networks with a single channel that is
provably robust against adaptive adversarial jamming. The wireless network is
modeled as a unit disk graph on a set of nodes distributed arbitrarily in the
plane. In addition to these nodes, there are adversarial jammers that know the
protocol and its entire history and that are allowed to jam the wireless
channel at any node for an arbitrary $(1-\epsilon)$-fraction of the time steps,
where $0<\epsilon<1$ is an arbitrary constant. We assume that the nodes cannot
distinguish between jammed transmissions and collisions of regular messages.
Nevertheless, we show that \textsc{Jade} achieves an asymptotically optimal
throughput if there is a sufficiently dense distribution of nodes."
"Developing data mining algorithms that are suitable for cloud computing
platforms is currently an active area of research, as is developing cloud
computing platforms appropriate for data mining. Currently, the most common
benchmark for cloud computing is the Terasort (and related) benchmarks.
Although the Terasort Benchmark is quite useful, it was not designed for data
mining per se. In this paper, we introduce a benchmark called MalStone that is
specifically designed to measure the performance of cloud computing middleware
that supports the type of data intensive computing common when building data
mining models. We also introduce MalGen, which is a utility for generating data
on clouds that can be used with MalStone."
"Consider an asynchronous network in a shared-memory environment consisting of
n nodes. Assume that up to f of the nodes might be Byzantine (n > 12f), where
the adversary is full-information and dynamic (sometimes called adaptive). In
addition, the non-Byzantine nodes may undergo transient failures. Nodes advance
in atomic steps, which consist of reading all registers, performing some
calculation and writing to all registers.
  This paper contains three main contributions. First, the clock-function
problem is defined, which is a generalization of the clock synchronization
problem. This generalization encapsulates previous clock synchronization
problem definitions while extending them to the current paper's model. Second,
a randomized asynchronous self-stabilizing Byzantine tolerant clock
synchronization algorithm is presented.
  In the construction of the clock synchronization algorithm, a building block
that ensures different nodes advance at similar rates is developed. This
feature is the third contribution of the paper. It is self-stabilizing and
Byzantine tolerant and can be used as a building block for different algorithms
that operate in an asynchronous self-stabilizing Byzantine model.
  The convergence time of the presented algorithm is exponential. Observe that
in the asynchronous setting the best known full-information dynamic Byzantine
agreement also has expected exponential convergence time, even though currently
there is no known reduction between the two."
"As ISPs begin to cooperate to expose their network locality information as
services, e.g., P4P, solutions based on locality information provision for P2P
traffic localization will soon approach their capability limits. A natural
question is: can we do any better provided that no further locality information
improvement can be made? This paper shows how the utility of locality
information could be limited by conventional P2P data scheduling algorithms,
even as sophisticated as the local rarest first policy.
  Network coding's simplified data scheduling makes it competent for improving
P2P application's throughput. Instead of only using locality information in the
topology construction, this paper proposes the locality-aware network coding
(LANC) that uses locality information in both the topology construction and
downloading decision, and demonstrates its exceptional ability for P2P traffic
localization. The randomization introduced by network coding enhances the
chance for a peer to find innovative blocks in its neighborhood. Aided by
proper locality-awareness, the probability for a peer to get innovative blocks
from its proximity will increase as well, resulting in more efficient use of
network resources. Extensive simulation results show that LANC can
significantly reduce P2P traffic redundancy without sacrificing
application-level performance. Aided by the same locality knowledge, the
traffic redundancies of LANC in most cases are less than 50\% of the current
best approach that does not use network coding."
"As more and more multi-tier services are developed from commercial
off-the-shelf components or heterogeneous middleware without source code
available, both developers and administrators need a request tracing tool to
(1) exactly know how a user request of interest travels through services of
black boxes; (2) obtain macro-level user request behavior information of
services without the necessity of inundating within massive logs. Previous
research efforts either accept imprecision of probabilistic correlation methods
or present precise but unscalable tracing approaches that have to collect and
analyze large amount of logs; Besides, previous precise request tracing
approaches of black boxes fail to propose macro-level abstractions that enables
debugging performance-in-the-large, and hence users have to manually interpret
massive logs. This paper introduces a precise, scalable and online request
tracing tool, named PreciseTracer, for multi-tier services of black boxes. Our
contributions are four-fold: first, we propose a precise request tracing
algorithm for multi-tier services of black boxes, which only uses
application-independent knowledge; second, we respectively present micro-level
and macro-level abstractions: component activity graphs and dominated causal
path patterns to represent causal paths of each individual request and
repeatedly executed causal paths that account for significant fractions; third,
we present two mechanisms: tracing on demand and sampling to significantly
increase system scalability; fourth, we design and implement an online request
tracing tool. PreciseTracer's fast response, low overhead and scalability make
it a promising tracing tool for large-scale production systems."
"One of the main advantages of Logic Programming (LP) is that it provides an
excellent framework for the parallel execution of programs. In this work we
investigate novel techniques to efficiently exploit parallelism from real-world
applications in low cost multi-core architectures. To achieve these goals, we
revive and redesign the YapOr system to exploit or-parallelism based on a
multi-threaded implementation. Our new approach takes full advantage of the
state-of-the-art fast and optimized YAP Prolog engine and shares the underlying
execution environment, scheduler and most of the data structures used to
support YapOr's model. Initial experiments with our new approach consistently
achieve almost linear speedups for most of the applications, proving itself as
a good alternative for exploiting implicit parallelism in the currently
available low cost multi-core architectures."
"The first cluster-based public computing for Monte Carlo simulation in
Indonesia is introduced. The system has been developed to enable public to
perform Monte Carlo simulation on a parallel computer through an integrated and
user friendly dynamic web interface. The beta version, so called
publicMC@BATAN, has been released and implemented for internal users at the
National Nuclear Energy Agency (BATAN). In this paper the concept and
architecture of publicMC@BATAN are presented."
"As energy proportional computing gradually extends the success of DVFS
(Dynamic voltage and frequency scaling) to the entire system, DVFS control
algorithms will play a key role in reducing server clusters' power consumption.
The focus of this paper is to provide accurate cluster-level DVFS control for
power saving in a server cluster. To achieve this goal, we propose a request
tracing approach that online classifies the major causal path patterns of a
multi-tier service and monitors their performance data as a guide for accurate
DVFS control. The request tracing approach significantly decreases the time
cost of performance profiling experiments that aim to establish the empirical
performance model. Moreover, it decreases the controller complexity so that we
can introduce a much simpler feedback controller, which only relies on the
single-node DVFS modulation at a time as opposed to varying multiple CPU
frequencies simultaneously. Based on the request tracing approach, we present a
hybrid DVFS control system that combines an empirical performance model for
fast modulation at different load levels and a simpler feedback controller for
adaption. We implement a prototype of the proposed system, called PowerTracer,
and conduct extensive experiments on a 3-tier platform. Our experimental
results show that PowerTracer outperforms its peer in terms of power saving and
system performance."
"Developing large-scale distributed applications can be a daunting task.
object-based environments have attempted to alleviate problems by providing
distributed objects that look like local objects. We advocate that this
approach has actually only made matters worse, as the developer needs to be
aware of many intricate internal details in order to adequately handle partial
failures. The result is an increase of application complexity. We present an
alternative in which distribution transparency is lessened in favor of clearer
semantics. In particular, we argue that a developer should always be offered
the unambiguous semantics of local objects, and that distribution comes from
copying those objects to where they are needed. We claim that it is often
sufficient to provide only small, immutable objects, along with facilities to
group objects into clusters."
"This paper considers parallel Gr\""obner bases algorithms on distributed
memory parallel computers with multi-core compute nodes. We summarize three
different Gr\""obner bases implementations: shared memory parallel, pure
distributed memory parallel and distributed memory combined with shared memory
parallelism. The last algorithm, called distributed hybrid, uses only one
control communication channel between the master node and the worker nodes and
keeps polynomials in shared memory on a node. The polynomials are transported
asynchronous to the control-flow of the algorithm in a separate distributed
data structure. The implementation is generic and works for all implemented
(exact) fields. We present new performance measurements and discuss the
performance of the algorithms."
"Erasure codes provide a storage efficient alternative to replication based
redundancy in (networked) storage systems. They however entail high
communication overhead for maintenance, when some of the encoded fragments are
lost and need to be replenished. Such overheads arise from the fundamental need
to recreate (or keep separately) first a copy of the whole object before any
individual encoded fragment can be generated and replenished. There has been
recently intense interest to explore alternatives, most prominent ones being
regenerating codes (RGC) and hierarchical codes (HC). We propose as an
alternative a new family of codes to improve the maintenance process, which we
call self-repairing codes (SRC), with the following salient features: (a)
encoded fragments can be repaired directly from other subsets of encoded
fragments without having to reconstruct first the original data, ensuring that
(b) a fragment is repaired from a fixed number of encoded fragments, the number
depending only on how many encoded blocks are missing and independent of which
specific blocks are missing. These properties allow for not only low
communication overhead to recreate a missing fragment, but also independent
reconstruction of different missing fragments in parallel, possibly in
different parts of the network. We analyze the static resilience of SRCs with
respect to traditional erasure codes, and observe that SRCs incur marginally
larger storage overhead in order to achieve the aforementioned properties. The
salient SRC properties naturally translate to low communication overheads for
reconstruction of lost fragments, and allow reconstruction with lower latency
by facilitating repairs in parallel. These desirable properties make
self-repairing codes a good and practical candidate for networked distributed
storage systems."
"Deadlock detection scheduling is an important, yet often overlooked problem
that can significantly affect the overall performance of deadlock handling.
Excessive initiation of deadlock detection increases overall message usage,
resulting in degraded system performance in the absence of deadlocks; while
insufficient initiation of deadlock detection increases the deadlock
persistence time, resulting in an increased deadlock resolution cost in the
presence of deadlocks. The investigation of this performance tradeoff, however,
is missing in the literature. This paper studies the impact of deadlock
detection scheduling on the overall performance of deadlock handling. In
particular, we show that there exists an optimal deadlock detection frequency
that yields the minimum long-run mean average cost, which is determined by the
message complexities of the deadlock detection and resolution algorithms being
used, as well as the rate of deadlock formation, denoted as $\lambda$. For the
best known deadlock detection and resolution algorithms, we show that the
asymptotically optimal frequency of deadlock detection scheduling that
minimizes the overall message overhead is ${\cal O}((\lambda n)^{1/3})$, when
the total number $n$ of processes is sufficiently large. Furthermore, we show
that in general fully distributed (uncoordinated) deadlock detection scheduling
cannot be performed as efficiently as centralized (coordinated) deadlock
detection scheduling."
"Cloud computing promises a radical shift in the provisioning of computing
resource within the enterprise. This paper describes the challenges that
decision makers face when assessing the feasibility of the adoption of cloud
computing in their organisations, and describes our Cloud Adoption Toolkit,
which has been developed to support this process. The toolkit provides a
framework to support decision makers in identifying their concerns, and
matching these concerns to appropriate tools/techniques that can be used to
address them. Cost Modeling is the most mature tool in the toolkit, and this
paper shows its effectiveness by demonstrating how practitioners can use it to
examine the costs of deploying their IT systems on the cloud. The Cost Modeling
tool is evaluated using a case study of an organization that is considering the
migration of some of its IT systems to the cloud. The case study shows that
running systems on the cloud using a traditional ""always on"" approach can be
less cost effective, and the elastic nature of the cloud has to be used to
reduce costs. Therefore, decision makers have to be able to model the
variations in resource usage and their systems deployment options to obtain
accurate cost estimates."
"We present MPWide, a platform independent communication library for
performing message passing between computers. Our library allows coupling of
several local MPI applications through a long distance network and is
specifically optimized for such communications. The implementation is
deliberately kept light-weight, platform independent and the library can be
installed and used without administrative privileges. The only requirements are
a C++ compiler and at least one open port to a wide area network on each site.
In this paper we present the library, describe the user interface, present
performance tests and apply MPWide in a large scale cosmological N-body
simulation on a network of two computers, one in Amsterdam and the other in
Tokyo."
"In this report, building on the deterministic multi-valued one-to-many
Byzantine agreement (broadcast) algorithm in our recent technical report [2],
we introduce a deterministic multi-valued all-to-all Byzantine agreement
algorithm (consensus), with linear complexity per bit agreed upon. The
discussion in this note is not self-contained, and relies heavily on the
material in [2] - please refer to [2] for the necessary background."
"Many secure communication libraries used by distributed systems, such as SSL,
TLS, and Kerberos, fail to make a clear distinction between the authentication,
session, and communication layers. In this paper we introduce CEDAR, the secure
communication library used by the Condor High Throughput Computing software,
and present the advantages to a distributed computing system resulting from
CEDAR's separation of these layers. Regardless of the authentication method
used, CEDAR establishes a secure session key, which has the flexibility to be
used for multiple capabilities. We demonstrate how a layered approach to
security sessions can avoid round-trips and latency inherent in network
authentication. The creation of a distinct session management layer allows for
optimizations to improve scalability by way of delegating sessions to other
components in the system. This session delegation creates a chain of trust that
reduces the overhead of establishing secure connections and enables centralized
enforcement of system-wide security policies. Additionally, secure channels
based upon UDP datagrams are often overlooked by existing libraries; we show
how CEDAR's structure accommodates this as well. As an example of the utility
of this work, we show how the use of delegated security sessions and other
techniques inherent in CEDAR's architecture enables US CMS to meet their
scalability requirements in deploying Condor over large-scale, wide-area grid
systems."
"In this note we briefly describe our Cholesky modification algorithm for
streaming multiprocessor architectures. Our implementation is available in C++
with Matlab binding, using CUDA to utilise the graphics processing unit (GPU).
Limited speed ups are possible due to the bandwidth bound nature of the
problem. Furthermore, a complex dependency pattern must be obeyed, requiring
multiple kernels to be launched. Nonetheless, this makes for an interesting
problem, and our approach can reduce the computation time by a factor of around
7 for matrices of size 5000 by 5000 and k=16, in comparison with the LINPACK
suite running on a CPU of comparable vintage. Much larger problems can be
handled however due to the O(n) scaling in required GPU memory of our method."
"This paper describes and analyzes a hierarchical gossip algorithm for solving
the distributed average consensus problem in wireless sensor networks. The
network is recursively partitioned into subnetworks. Initially, nodes at the
finest scale gossip to compute local averages. Then, using geographic routing
to enable gossip between nodes that are not directly connected, these local
averages are progressively fused up the hierarchy until the global average is
computed. We show that the proposed hierarchical scheme with $k$ levels of
hierarchy is competitive with state-of-the-art randomized gossip algorithms, in
terms of message complexity, achieving $\epsilon$-accuracy with high
probability after $O\big(n \log \log n \log \frac{kn}{\epsilon} \big)$
messages. Key to our analysis is the way in which the network is recursively
partitioned. We find that the optimal scaling law is achieved when subnetworks
at scale $j$ contain $O(n^{(2/3)^j})$ nodes; then the message complexity at any
individual scale is $O(n \log \frac{kn}{\epsilon})$, and the total number of
scales in the hierarchy grows slowly, as $\Theta(\log \log n)$. Another
important consequence of hierarchical construction is that the longest distance
over which messages are exchanged is $O(n^{1/3})$ hops (at the highest scale),
and most messages (at lower scales) travel shorter distances. In networks that
use link-level acknowledgements, this results in less congestion and resource
usage by reducing message retransmissions. Simulations illustrate that the
proposed scheme is more message-efficient than existing state-of-the-art
randomized gossip algorithms based on averaging along paths."
"This paper aims at providing a rigorous definition of self- organization, one
of the most desired properties for dynamic systems (e.g., peer-to-peer systems,
sensor networks, cooperative robotics, or ad-hoc networks). We characterize
different classes of self-organization through liveness and safety properties
that both capture information re- garding the system entropy. We illustrate
these classes through study cases. The first ones are two representative P2P
overlays (CAN and Pas- try) and the others are specific implementations of
\Omega (the leader oracle) and one-shot query abstractions for dynamic
settings. Our study aims at understanding the limits and respective power of
existing self-organized protocols and lays the basis of designing robust
algorithm for dynamic systems."
"We propose an algorithm that builds and maintains clusters over a network
subject to mobility. This algorithm is fully decentralized and makes all the
different clusters grow concurrently. The algorithm uses circulating tokens
that collect data and move according to a random walk traversal scheme. Their
task consists in (i) creating a cluster with the nodes it discovers and (ii)
managing the cluster expansion; all decisions affecting the cluster are taken
only by a node that owns the token. The size of each cluster is maintained
higher than $m$ nodes ($m$ is a parameter of the algorithm). The obtained
clustering is locally optimal in the sense that, with only a local view of each
clusters, it computes the largest possible number of clusters (\emph{ie} the
sizes of the clusters are as close to $m$ as possible). This algorithm is
designed as a decentralized control algorithm for large scale networks and is
mobility-adaptive: after a series of topological changes, the algorithm
converges to a clustering. This recomputation only affects nodes in clusters in
which topological changes happened, and in adjacent clusters."
"Most traditional alarm systems cannot address security threats in a
satisfactory manner. To alleviate this problem, we developed a high-confidence
cyber-physical alarm system (CPAS), a new kind of alarm systems. This system
establishes the connection of the Internet (i.e. TCP/IP) through GPRS/CDMA/3G.
It achieves mutual communication control among terminal equipments, human
machine interfaces and users by using the existing mobile communication
network. The CPAS will enable the transformation in alarm mode from traditional
one-way alarm to two-way alarm. The system has been successfully applied in
practice. The results show that the CPAS could avoid false alarms and satisfy
residents' security needs."
"The classic renaming protocol of Moir and Anderson (1995) uses a network of
Theta(n^2) splitters to assign unique names to n processes with unbounded
initial names. We show how to reduce this bound to Theta(n^{3/2}) splitters."
"Self-stabilizing systems have the ability to converge to a correct behavior
when started in any configuration. Most of the work done so far in the
self-stabilization area assumed either communication via shared memory or via
FIFO channels. This paper is the first to lay the bases for the design of
self-stabilizing message passing algorithms over unreliable non-FIFO channels.
We propose a fault-send-deliver optimal stabilizing data-link layer that
emulates a reliable FIFO communication channel over unreliable capacity bounded
non-FIFO channels."
"To harness the ever growing capacity and decreasing cost of storage,
providing an abstraction of dependable storage in the presence of crash-stop
and Byzantine failures is compulsory. We propose a decentralized Reed Solomon
coding mechanism with minimum communication overhead. Using a progressive data
retrieval scheme, a data collector contacts only the necessary number of
storage nodes needed to guarantee data integrity. The scheme gracefully adapts
the cost of successful data retrieval to the number of storage node failures.
Moreover, by leveraging the Welch-Berlekamp algorithm, it avoids unnecessary
computations. Compared to the state-of-the-art decoding scheme, the
implementation and evaluation results show that our progressive data retrieval
scheme has up to 35 times better computation performance for low Byzantine node
rates. Additionally, the communication cost in data retrieval is derived
analytically and corroborated by Monte-Carlo simulation results. Our
implementation is flexible in that the level of redundancy it provides is
independent of the number of data generating nodes, a requirement for
distributed storage systems"
"Cloud computing provides a computing platform for the users to meet their
demands in an efficient, cost-effective way. Virtualization technologies are
used in the clouds to aid the efficient usage of hardware. Virtual machines
(VMs) are utilized to satisfy the user needs and are placed on physical
machines (PMs) of the cloud for effective usage of hardware resources and
electricity in the cloud. Optimizing the number of PMs used helps in cutting
down the power consumption by a substantial amount.
  In this paper, we present an optimal technique to map virtual machines to
physical machines (nodes) such that the number of required nodes is minimized.
We provide two approaches based on linear programming and quadratic programming
techniques that significantly improve over the existing theoretical bounds and
efficiently solve the problem of virtual machine (VM) placement in data
centers."
"The question of what can be computed, and how efficiently, are at the core of
computer science. Not surprisingly, in distributed systems and networking
research, an equally fundamental question is what can be computed in a
\emph{distributed} fashion. More precisely, if nodes of a network must base
their decision on information in their local neighborhood only, how well can
they compute or approximate a global (optimization) problem? In this paper we
give the first poly-logarithmic lower bound on such local computation for
(optimization) problems including minimum vertex cover, minimum (connected)
dominating set, maximum matching, maximal independent set, and maximal
matching. In addition we present a new distributed algorithm for solving
general covering and packing linear programs. For some problems this algorithm
is tight with the lower bounds, for others it is a distributed approximation
scheme. Together, our lower and upper bounds establish the local computability
and approximability of a large class of problems, characterizing how much local
information is required to solve these tasks."
"Understanding and modelling resources of Internet end hosts is essential for
the design of desktop software and Internet-distributed applications. In this
paper we develop a correlated resource model of Internet end hosts based on
real trace data taken from the SETI@home project. This data covers a 5-year
period with statistics for 2.7 million hosts. The resource model is based on
statistical analysis of host computational power, memory, and storage as well
as how these resources change over time and the correlations between them. We
find that resources with few discrete values (core count, memory) are well
modeled by exponential laws governing the change of relative resource
quantities over time. Resources with a continuous range of values are well
modeled with either correlated normal distributions (processor speed for
integer operations and floating point operations) or log-normal distributions
(available disk space). We validate and show the utility of the models by
applying them to a resource allocation problem for Internet-distributed
applications, and demonstrate their value over other models. We also make our
trace data and tool for automatically generating realistic Internet end hosts
publicly available."
"In cloud computing environments, a large number of users access data stored
in highly available storage systems. To provide good performance to
geographically disperse users and allow operation even in the presence of
failures or network partitions, these systems often rely on optimistic
replication solutions that guarantee only eventual consistency. In this
scenario, it is important to be able to accurately and efficiently identify
updates executed concurrently. In this paper, first we review, and expose
problems with current approaches to causality tracking in optimistic
replication: these either lose information about causality or do not scale, as
they require replicas to maintain information that grows linearly with the
number of clients or updates. Then, we propose a novel solution that fully
captures causality while being very concise in that it maintains information
that grows linearly only with the number of servers that register updates for a
given data element, bounded by the degree of replication."
"Aggregation is an important building block of modern distributed
applications, allowing the determination of meaningful properties (e.g. network
size, total storage capacity, average load, majorities, etc.) that are used to
direct the execution of the system. However, the majority of the existing
aggregation algorithms exhibit relevant dependability issues, when prospecting
their use in real application environments. In this paper, we reveal some
dependability issues of aggregation algorithms based on iterative averaging
techniques, giving some directions to solve them. This class of algorithms is
considered robust (when compared to common tree-based approaches), being
independent from the used routing topology and providing an aggregation result
at all nodes. However, their robustness is strongly challenged and their
correctness often compromised, when changing the assumptions of their working
environment to more realistic ones. The correctness of this class of algorithms
relies on the maintenance of a fundamental invariant, commonly designated as
""mass conservation"". We will argue that this main invariant is often broken in
practical settings, and that additional mechanisms and modifications are
required to maintain it, incurring in some degradation of the algorithms
performance. In particular, we discuss the behavior of three representative
algorithms Push-Sum Protocol, Push-Pull Gossip protocol and Distributed Random
Grouping under asynchronous and faulty (with message loss and node crashes)
environments. More specifically, we propose and evaluate two new versions of
the Push-Pull Gossip protocol, which solve its message interleaving problem
(evidenced even in a synchronous operation mode)."
"As grids are in essence heterogeneous, dynamic, shared and distributed
environments, managing these kinds of platforms efficiently is extremely
complex. A promising scalable approach to deal with these intricacies is the
design of self-managing of autonomic applications. Autonomic applications adapt
their execution accordingly by considering knowledge about their own behaviour
and environmental conditions.QoS based User Driven scheduling for grid that
provides the self-optimizing ability in autonomic applications. Computational
grids to provide a user to solve large scale problem by spreading a single
large computation across multiple machines of physical location. QoS based User
Driven scheduler for grid also provides reliability of the grid systems and
increase the performance of the grid to reducing the execution time of job by
applying scheduling policies defined by the user. The main aim of this paper is
to distribute the computational load among the available grid nodes and to
developed a QoS based scheduling algorithm for grid and making grid more
reliable.Grid computing system is different from conventional distributed
computing systems by its focus on large scale resource sharing, where
processors and communication have significant inuence on Grid computing
reliability. Reliability capabilities initiated by end users from within
applications they submit to the grid for execution. Reliability of
infrastructure and management services that perform essential functions
necessary for grid systems to operate, such as resource allocation and
scheduling."
"A mobile ad hoc network (MANET), is a self-configuring network of mobile
devices connected by wireless links. In order to achieve stable clusters, the
cluster-heads maintaining the cluster should be stable with minimum overhead of
cluster re-elections. In this paper we propose a Probability Based Adaptive
Invoked Weighted Clustering Algorithm (PAIWCA) which can enhance the stability
of the clusters by taking battery power of the nodes into considerations for
the clustering formation and electing stable cluster-heads using cluster head
probability of a node. In this simulation study a comparison was conducted to
measure the performance of our algorithm with maximal weighted independent set
(MWIS) in terms of the number of clusters formed, the connectivity of the
network, dominant set updates,throughput of the overall network and packet
delivery ratio. The result shows that our algorithm performs better than
existing one and is also tunable to different kinds of network conditions."
"The Distributed object computing is a paradigm that allows objects to be
distributed across a heterogeneous network, and allows each of the components
to interoperate as a unified whole. A new generation of distributed
applications, such as telemedicine and e-commerce applications, are being
deployed in heterogeneous and ubiquitous computing environments. The objective
of this paper is to explore an applicability of a component based services in
ubiquitous computational environment. While the fundamental structure of
various distributed object components is similar, there are differences that
can profoundly impact an application developer or the administrator of a
distributed simulation exercise and to implement in Ubiquitous Computing
Environment."
"Cloud computing is one of the rapidly improving technologies. It provides
scalable resources needed for the ap- plications hosted on it. As cloud-based
services become more dynamic, resource provisioning becomes more challenging.
The QoS constrained resource allocation problem is considered in this paper, in
which customers are willing to host their applications on the provider's cloud
with a given SLA requirements for performance such as throughput and response
time. Since, the data centers hosting the applications consume huge amounts of
energy and cause huge operational costs, solutions that reduce energy
consumption as well as operational costs are gaining importance. In this work,
we propose an energy efficient mechanism that allocates the cloud resources to
the applications without violating the given service level agreements(SLA)
using Ant colony framework."
"In case of multiple node failures performance becomes very low as compare to
single node failure. Failures of nodes in cluster computing can be tolerated by
multiple fault tolerant computing. Existing recovery schemes are efficient for
single fault but not with multiple faults. Recovery scheme proposed in this
paper having two phases; sequentially phase, concurrent phase. In sequentially
phase, loads of all working nodes are uniformly and evenly distributed by
proposed dynamic rank based and load distribution algorithm. In concurrent
phase, loads of all failure nodes as well as new job arrival are assigned
equally to all available nodes by just finding the least loaded node among the
several nodes by failure nodes job allocation algorithm. Sequential and
concurrent executions of algorithms improve the performance as well better
resource utilization. Dynamic rank based algorithm for load redistribution
works as a sequential restoration algorithm and reassignment algorithm for
distribution of failure nodes to least loaded computing nodes works as a
concurrent recovery reassignment algorithm. Since load is evenly and uniformly
distributed among all available working nodes with less number of iterations,
low iterative time and communication overheads hence performance is improved.
Dynamic ranking algorithm is low overhead, high convergence algorithm for
reassignment of tasks uniformly among all available nodes. Reassignments of
failure nodes are done by a low overhead efficient failure job allocation
algorithm. Test results to show effectiveness of the proposed scheme are
presented."
"Solid State Disk technologies are increasingly replacing high-speed hard
disks as the storage technology in high-random-I/O environments. There are
several potentially I/O bound services within the typical LHC Tier-2 - in the
back-end, with the trend towards many-core architectures continuing, worker
nodes running many single-threaded jobs and storage nodes delivering many
simultaneous files can both exhibit I/O limited efficiency. We estimate the
effectiveness of affordable SSDs in the context of worker nodes, on a large
Tier-2 production setup using both low level tools and real LHC I/O intensive
data analysis jobs comparing and contrasting with high performance spinning
disk based solutions. We consider the applicability of each solution in the
context of its price/performance metrics, with an eye on the pragmatic issues
facing Tier-2 provision and upgrades"
"In this article we consider the inversion problem for polynomially computable
discrete functions. These functions describe behavior of many discrete systems
and are used in model checking, hardware verification, cryptanalysis, computer
biology and other domains. Quite often it is necessary to invert these
functions, i.e. to find an unknown preimage if an image and algorithm of
function computation are given. In general case this problem is computationally
intractable. However, many of it's special cases are very important in
practical applications. Thus development of algorithms that are applicable to
these special cases is of importance. The practical applicability of such
algorithms can be validated by their ability to solve the problems that are
considered to be computationally hard (for example cryptanalysis problems). In
this article we propose the technology of solving the inversion problem for
polynomially computable discrete functions. This technology was implemented in
distributed computing environments (parallel clusters and Grid-systems). It is
based on reducing the inversion problem for the considered function to some SAT
problem. We describe a general approach to coarse-grained parallelization for
obtained SAT problems. Efficiency of each parallelization scheme is determined
by the means of a special predictive function. The proposed technology was
validated by successful solving of cryptanalysis problems for some keystream
generators. The main practical result of this work is a complete cryptanalysis
of keystream generator A5/1 which was performed in a Grid system specially
built for this task."
"In this paper we consider the k-set agreement problem in distributed
message-passing systems using a round-based approach: Both synchrony of
communication and failures are captured just by means of the messages that
arrive within a round, resulting in round-by-round communication graphs that
can be characterized by simple communication predicates. We introduce the weak
communication predicate PSources(k) and show that it is tight for k-set
agreement, in the following sense: We (i) prove that there is no algorithm for
solving (k-1)-set agreement in systems characterized by PSources(k), and (ii)
present a novel distributed algorithm that achieves k-set agreement in runs
where PSources(k) holds. Our algorithm uses local approximations of the stable
skeleton graph, which reflects the underlying perpetual synchrony of a run. We
prove that this approximation is correct in all runs, regardless of the
communication predicate, and show that graph-theoretic properties of the stable
skeleton graph can be used to solve k-set agreement if PSources(k) holds."
"In the renaming problem, each process in a distributed system is issued a
unique name from a large name space, and the processes must coordinate with one
another to choose unique names from a much smaller name space. We show that
lower bounds on the solvability of renaming in an asynchronous distributed
system can be formulated as a purely topological question about the existence
of an equivariant chain map from a topological disk to a topological annulus.
Proving the non-existence of such a map implies the non-existence of a
distributed renaming algorithm in several related models of computation."
"Tuning numerical libraries has become more difficult over time, as systems
get more sophisticated. In particular, modern multicore machines make the
behaviour of algorithms hard to forecast and model. In this paper, we tackle
the issue of tuning a dense QR factorization on multicore architectures. We
show that it is hard to rely on a model, which motivates us to design a fully
empirical approach. We exhibit few strong empirical properties that enable us
to efficiently prune the search space. Our method is automatic, fast and
reliable. The tuning process is indeed fully performed at install time in less
than one and ten minutes on five out of seven platforms. We achieve an average
performance varying from 97% to 100% of the optimum performance depending on
the platform. This work is a basis for autotuning the PLASMA library and
enabling easy performance portability across hardware systems."
"Smartphones have recently gained significant popularity in heavy mobile
processing while users are increasing their expectations toward rich computing
experience. However, resource limitations and current mobile computing
advancements hinder this vision. Therefore, resource-intensive application
execution remains a challenging task in mobile computing that necessitates
device augmentation. In this article, smartphone augmentation approaches are
reviewed and classified in two main groups, namely hardware and software.
Generating high-end hardware is a subset of hardware augmentation approaches,
whereas conserving local resource and reducing resource requirements approaches
are grouped under software augmentation methods. Our study advocates that
consreving smartphones' native resources, which is mainly done via task
offloading, is more appropriate for already-developed applications than new
ones, due to costly re-development process. Cloud computing has recently
obtained momentous ground as one of the major cornerstone technologies in
augmenting smartphones. We present sample execution model for intensive mobile
applications and devised taxonomy of augmentation approaches. For better
comprehension, the results of this study are summarized in a table."
"Performance of data forwarding in Delay Tolerant Networks (DTNs) benefits
considerably if one can make use of human mobility in terms of social
structures. However, it is difficult and time-consuming to calculate the
centrality and similarity of nodes by using solutions for traditional social
networks, this is mainly because of the transient node contact and the
intermittently connected environment. In this work, we are interested in the
following question: Can we explore some other stable social attributes to
quantify the centrality and similarity of nodes? Taking GPS traces of human
walks from the real world, we find that there exist two known phenomena. One is
public hotspot, the other is personal hotspot. Motivated by this observation,
we present Hoten (hotspot and entropy), a novel routing metric to improve
routing performance in DTNs. First, we use the relative entropy between the
public hotspots and the personal hotspots to compute the centrality of nodes.
Then we utilize the inverse symmetrized entropy of the personal hotspots
between two nodes to compute the similarity between them. Third, we exploit the
entropy of personal hotspots of a node to estimate its personality. Besides, we
propose a method to ascertain the optimized size of hotspot. Finally, we
compare our routing strategy with other state-of-the-art routing schemes
through extensive trace-driven simulations, the results show that Hoten largely
outperforms other solutions, especially in terms of combined overhead/packet
delivery ratio and the average number of hops per message."
"In Cloud Computing platforms the addition of hardware monitoring devices to
gather power usage data can be impractical or uneconomical due to the large
number of machines to be metered. CloudMonitor, a monitoring tool that can
generate power models for software-based power estimation, can provide insights
to the energy costs of deployments without additional hardware. Accurate power
usage data leads to the possibility of Cloud providers creating a separate
tariff for power and therefore incentivizing software developers to create
energy-efficient applications."
"Recent trend of mobile computing is emerging toward executing
resource-intensive applications in mobile devices regardless of underlying
resource restrictions (e.g. limited processor and energy) that necessitate
imminent technologies. Prosperity of cloud computing in stationary computers
breeds Mobile Cloud Computing (MCC) technology that aims to augment computing
and storage capabilities of mobile devices besides conserving energy. However,
MCC is more heterogeneous and unreliable (due to wireless connectivity) compare
to cloud computing. Problems like variations in OS, data fragmentation, and
security and privacy discourage and decelerate implementation and pervasiveness
of MCC. In this paper, we describe MCC as a horizontal heterogeneous ecosystem
and identify thirteen critical metrics and approaches that influence on
mobile-cloud solutions and success of MCC. We divide them into three major
classes, namely ubiquity, trust, and energy efficiency and devise a tripod of
requirements in MCC. Our proposed tripod shows that success of MCC is
achievable by reducing mobility challenges (e.g. seamless connectivity,
fragmentation), increasing trust, and enhancing energy efficiency."
"This manuscript provides a model to characterize the energy savings of
network coded storage (NCS) in storage area networks (SANs). We consider
blocking probability of drives as our measure of performance. A mapping
technique to analyze SANs as independent M/G/K/K queues is presented, and
blocking probabilities for uncoded storage schemes and NCS are derived and
compared. We show that coding operates differently than the amalgamation of
file chunks and energy savings are shown to scale well with striping number. We
illustrate that for enterprise-level SANs energy savings of 20-50% can be
realized."
"We explore the interplay between architectures and algorithm design in the
context of shared-memory platforms and a specific graph problem of central
importance in scientific and high-performance computing, distance-1 graph
coloring. We introduce two different kinds of multithreaded heuristic
algorithms for the stated, NP-hard, problem. The first algorithm relies on
speculation and iteration, and is suitable for any shared-memory system. The
second algorithm uses dataflow principles, and is targeted at the
non-conventional, massively multithreaded Cray XMT system. We study the
performance of the algorithms on the Cray XMT and two multi-core systems, Sun
Niagara 2 and Intel Nehalem. Together, the three systems represent a spectrum
of multithreading capabilities and memory structure. As testbed, we use
synthetically generated large-scale graphs carefully chosen to cover a wide
range of input types. The results show that the algorithms have scalable
runtime performance and use nearly the same number of colors as the underlying
serial algorithm, which in turn is effective in practice. The study provides
insight into the design of high performance algorithms for irregular problems
on many-core architectures."
"We analyze the parallel performance of randomized interpolative decomposition
by decomposing low rank complex-valued Gaussian random matrices up to 64 GB. We
chose a Cray XMT supercomputer as it provides an almost ideal PRAM model
permitting quick investigation of parallel algorithms without obfuscation from
hardware idiosyncrasies. We obtain that on non-square matrices performance
becomes very good, with overall runtime over 70 times faster on 128 processors.
We also verify that numerically discovered error bounds still hold on matrices
nearly two orders of magnitude larger than those previously tested."
"Initial knowledge regarding group size can be crucial for collective
performance. We study this relation in the context of the {\em Ants Nearby
Treasure Search (ANTS)} problem \cite{FKLS}, which models natural cooperative
foraging behavior such as that performed by ants around their nest. In this
problem, $k$ (probabilistic) agents, initially placed at some central location,
collectively search for a treasure on the two-dimensional grid. The treasure is
placed at a target location by an adversary and the goal is to find it as fast
as possible as a function of both $k$ and $D$, where $D$ is the (unknown)
distance between the central location and the target. It is easy to see that
$T=\Omega(D+D^2/k)$ time units are necessary for finding the treasure.
Recently, it has been established that $O(T)$ time is sufficient if the agents
know their total number $k$ (or a constant approximation of it), and enough
memory bits are available at their disposal \cite{FKLS}. In this paper, we
establish lower bounds on the agent memory size required for achieving certain
running time performances. To the best our knowledge, these bounds are the
first non-trivial lower bounds for the memory size of probabilistic searchers.
For example, for every given positive constant $\epsilon$, terminating the
search by time $O(\log^{1-\epsilon} k \cdot T)$ requires agents to use
$\Omega(\log\log k)$ memory bits. Such distributed computing bounds may provide
a novel, strong tool for the investigation of complex biological systems."
"In this work, we consider a generalized fault model that can be used to
represent a wide range of failure scenarios, including correlated failures and
non-uniform node reliabilities. This fault model is general in the sense that
fault models studied in prior related work, such as f -total and f -local
models, are special cases of the generalized fault model. Under the generalized
fault model, we explore iterative approximate Byzantine consensus (IABC)
algorithms in arbitrary directed networks. We prove a necessary and sufficient
condition for the existence of IABC algorithms. The use of the generalized
fault model helps to gain a better understanding of IABC algorithms."
"In this article, hybrid parallel bidirectional sieve method is implemented by
SMP Cluster, the individual computational units joined together by the
communication network, are usually shared-memory systems with one or more
multicore processor. To high-efficiency optimization, we propose average divide
data into nodes, generating double-ended queues (deque) for sieve method that
are able to exploit dual-cores simultaneously start sifting out primes from the
head and tail.And each node create a FIFO queue as dynamic data buffer to ache
temporary data from another nodes send to. The approach obtains huge speedup
and efficiency on SMP Cluster."
"The addition of nuclear and neutrino physics to general relativistic fluid
codes allows for a more realistic description of hot nuclear matter in neutron
star and black hole systems. This additional microphysics requires that each
processor have access to large tables of data, such as equations of state, and
in large simulations the memory required to store these tables locally can
become excessive unless an alternative execution model is used. In this work we
present relativistic fluid evolutions of a neutron star obtained using a
message driven multi-threaded execution model known as ParalleX. These neutron
star simulations would require substantial memory overhead dedicated entirely
to the equation of state table if using a more traditional execution model. We
introduce a ParalleX component based on Futures for accessing large tables of
data, including out-of-core sized tables, which does not require substantial
memory overhead and effectively hides any increased network latency."
"We study the problem of leader election among mobile agents operating in an
arbitrary network modeled as an undirected graph. Nodes of the network are
unlabeled and all agents are identical. Hence the only way to elect a leader
among agents is by exploiting asymmetries in their initial positions in the
graph. Agents do not know the graph or their positions in it, hence they must
gain this knowledge by navigating in the graph and share it with other agents
to accomplish leader election. This can be done using meetings of agents, which
is difficult because of their asynchronous nature: an adversary has total
control over the speed of agents. When can a leader be elected in this
adversarial scenario and how to do it? We give a complete answer to this
question by characterizing all initial configurations for which leader election
is possible and by constructing an algorithm that accomplishes leader election
for all configurations for which this can be done."
"The aim of this paper is to provide a description of deep-learning-based
scheduling approach for academic-purpose high-performance computing systems.
The share of academic-purpose distributed computing systems (DCS) reaches 17.4
percents amongst TOP500 supercomputer sites (15.6 percents in performance
scale) that makes them a valuable object of research. The core of this approach
is to predict the future workflow of the system depending on the previously
submitted tasks using deep learning algorithm. Information on predicted tasks
is used by the resource management system (RMS) to perform efficient schedule."
"The paper proposes an alternative proof that Omega, an oracle that outputs a
process identifier and guarantees that eventually the same correct process
identifier is output at all correct processes, provides minimal information
about failures for solving consensus in read-write shared-memory systems: every
oracle that gives enough failure information to solve consensus can be used to
implement Omega.
  Unlike the original proof by Chandra, Hadzilacos and Toueg (CHT), the proof
presented in this paper builds upon the very fact that 2-process wait-free
consensus is impossible. Also, since the oracle that is used to implement can
solve consensus, the implementation is allowed to directly access consensus
objects. As a result, the proposed proof is shorter and conceptually simpler
than the original one."
"In the context of large-scale networks, the consideration of faults is an
evident necessity. This document is focussing on the self-stabilizing approach
which aims at conceiving algorithms ""repairing themselves"" in case of transient
faults, that is of faults implying an arbitrary modification of the states of
the processes. The document focuses on two different contexts, covering the
major part of my research work these last years. The first part of the document
is dedicated to the design and analysis of self-stabilizing algorithms for
networks of processes. The second part of the document is dedicated to the
design and analysis of self-stabilizing algorithms for autonomous entities
(i.e., software agents, robots, etc.) moving in a network."
"Considering the diverse nature of real-world distributed applications that
makes it hard to identify a representative subset of distributed benchmarks, we
focus on their underlying distributed algorithms. We present and characterize a
new kernel benchmark suite (named IMSuite) that simulates some of the classical
distributed algorithms in task parallel languages. We present multiple
variations of our kernels, broadly categorized under two heads: (a) varying
synchronization primitives (with and without fine grain synchronization
primitives); and (b) varying forms of parallelization (data parallel and
recursive task parallel). Our characterization covers interesting aspects of
distributed applications such as distribution of remote communication requests,
number of synchronization, task creation, task termination and atomic
operations. We study the behavior (execution time) of our kernels by varying
the problem size, the number of compute threads, and the input configurations.
We also present an involved set of input generators and output validators."
"This thesis expands upon an existing system called Golondrina that performs
autonomic workload management among a cluster of hardware nodes running
operating system-level virtualization. Golondrina works by identifying
localized resource stress situations and attempting to dissipate them by
reallocating system resources and, if necessary, migrating or replicating
virtual machines. It is predicted that, using Golondrina, efficiency of similar
systems can be further improved by achieving greater resource utilization on
the hardware nodes while maintaining resource availability for each virtual
machine.
  The following topics are discussed: virtualization technologies and
associated challenges relating to resource management, the architecture and
design of Golondrina, intelligent resource reallocation based on predefined
policies, and preliminary results demonstrating the effects of a memory
resource management policy on the performance of a web application hosted in a
virtual environment.
  This research makes a significant contribution to the study of virtualized
data centres since currently no other system considers virtual machine
replication and dynamic memory reallocation as an approach to workload
management."
"Real time processing for teamwork action recognition is a challenge, due to
complex computational models to achieve high system performance. Hence, this
paper proposes a framework based on Graphical Processing Units (GPUs) to
achieve a significant speed up in the performance of role based activity
recognition of teamwork. The framework can be applied in various fields,
especially athletic and military applications. Furthermore, the framework can
be customized for many action recognition applications. The paper presents the
stages of the framework where GPUs are the main tool for performance
improvement. The speedup is achieved by performing video processing and Machine
learning algorithms on GPU. Video processing and machine learning algorithms
covers all computations involved in our framework. Video processing tasks on
involves GPU implementation of Motion detection, segmentation and object
tracking algorithms. In addition, our framework is integrated with GPUCV, a GPU
version of OpenCV functions. Machine learning tasks are supported under our
framework with GPU implementations of Support Vector Machine (SVM) for object
classification and feature discretization, Hidden Marcov Model (HMM) for
activity recognition phase, and ID3 algorithm for role recognition of team
members. The system was tested against UC-Teamwork dataset and speedup of 20X
has been achieved on NVidia 9500GT graphics card (32 500MHZ processors)."
"The dynamic load-balancing framework in Charm++/AMPI, developed at the
University of Illinois, is based on using processor virtualization to allow
thread migration across processors. This framework has been successfully
applied to many scientific applications in the past, such as BRAMS, NAMD,
ChaNGa, and others. Most of these applications use only CPUs to perform their
operations. However, the use of GPUs to improve computational performance is
quickly getting massively disseminated in the high-performance computing
community. This paper aims to investigate how the same Charm++/AMPI framework
can be extended to balance load in a synthetic application inspired by the
BRAMS numerical forecast model, running mostly on GPUs rather than on CPUs.
Many major questions involving the use of GPUs with AMPI where handled in this
work, including: how to measure the GPU's load, how to use and share GPUs among
user-level threads, and what results are obtained when applying the mandatory
over-decomposition technique to a GPU-accelerated program."
"Collective communications are ubiquitous in parallel applications. We present
two new algorithms for performing a reduction. The operation associated with
our reduction needs to be associative and commutative. The two algorithms are
developed under two different communication models (unidirectional and
bidirectional). Both algorithms use a greedy scheduling scheme. For a
unidirectional, fully connected network, we prove that our greedy algorithm is
optimal when some realistic assumptions are respected. Previous algorithms fit
the same assumptions and are only appropriate for some given configurations.
Our algorithm is optimal for all configurations. We note that there are some
configuration where our greedy algorithm significantly outperform any existing
algorithms. This result represents a contribution to the state-of-the art. For
a bidirectional, fully connected network, we present a different greedy
algorithm. We verify by experimental simulations that our algorithm matches the
time complexity of an optimal broadcast (with addition of the computation).
Beside reversing an optimal broadcast algorithm, the greedy algorithm is the
first known reduction algorithm to experimentally attain this time complexity.
Simulations show that this greedy algorithm performs well in practice,
outperforming any state-of-the-art reduction algorithms. Positive experiments
on a parallel distributed machine are also presented."
"We demonstrate an implementation for an approximate rank-k SVD factorization,
combining well-known randomized projection techniques with previously
implemented map/reduce solutions in order to compute steps of the random
projection based SVD procedure, such QR and SVD. We structure the problem in a
way that it reduces to Cholesky and SVD factorizations on $k \times k$ matrices
computed on a single machine, greatly easing the computability of the problem."
"We found that a reliability model commonly used to estimate
Mean-Time-To-Data-Loss (MTTDL), while suitable for modeling RAID 0 and RAID 5,
fails to accurately model systems having a fault-tolerance greater than 1.
Therefore, to model the reliability of RAID 6, Triple-Replication, or k-of-n
systems requires an alternate technique. In this paper, we explore some
alternatives, and evaluate their efficacy by comparing their predictions to
simulations. Our main result is a new formula which more accurately models
storage system reliability."
"We consider the problem of forming a distributed queue in the adversarial
dynamic network model of Kuhn, Lynch, and Oshman (STOC 2010) in which the
network topology changes from round to round but the network stays connected.
This is a synchronous model in which network nodes are assumed to be fixed, the
communication links for each round are chosen by an adversary, and nodes do not
know who their neighbors are for the current round before they broadcast their
messages. Queue requests may arrive over rounds at arbitrary nodes and the goal
is to eventually enqueue them in a distributed queue. We present two algorithms
that give a total distributed ordering of queue requests in this model. We
measure the performance of our algorithms through round complexity, which is
the total number of rounds needed to solve the distributed queuing problem. We
show that in 1-interval connected graphs, where the communication links change
arbitrarily between every round, it is possible to solve the distributed
queueing problem in O(nk) rounds using O(log n) size messages, where n is the
number of nodes in the network and k <= n is the number of queue requests.
Further, we show that for more stable graphs, e.g. T-interval connected graphs
where the communication links change in every T rounds, the distributed queuing
problem can be solved in O(n+ (nk/min(alpha,T))) rounds using the same O(log n)
size messages, where alpha > 0 is the concurrency level parameter that captures
the minimum number of active queue requests in the system in any round. These
results hold in any arbitrary (sequential, one-shot concurrent, or dynamic)
arrival of k queue requests in the system. Moreover, our algorithms ensure
correctness in the sense that each queue request is eventually enqueued in the
distributed queue after it is issued and each queue request is enqueued exactly
once. We also provide an impossibility result for this distributed queuing
problem in this model. To the best of our knowledge, these are the first
solutions to the distributed queuing problem in adversarial dynamic networks."
"Any information is valuable as long as it has related data. If related data
are not put together, the information is meaningless as unrelated data has no
value. The mapped information is required only by authenticated users. So there
is no necessity to store related information together. If the relations of a
database are fragmented into chunks and these chunks are stored at different
cloud service providers, it could prevent from any privacy breach and the data
stored will be secure. It would also reduce the data transfer costs as the
entire data is not always required, for e.g. during updates. Also, instead of
storage of chunks at a single CSP, if each chunk or fragment is stored at
multiple CSPs it ensures availability and also permits concurrent access.
Additionally, it would prevent financial loss during cloud outages and also
prevent data lock-in. Replicating data chunks at multiple clouds situated at
geographically different locations would also have an additional decrease in
response time. The work attempts to select multiple cloud service providers
within a given budget so as to ensure maximum availability of data. The entire
data can be stored at each of the data centers selected depending on the budget
when there is no security or privacy issue. Data can also be stored in chunks
by replicating each data chunk at two or more cloud service providers.
Different chunks can be replicated at different service providers. The work
also attempts to select various cloud service providers to ensure maximum valid
data chunks within a given budget."
"We consider the problem of scheduling packets of different lengths via a
directed communication link prone to jamming errors. Dynamic packet arrivals
and errors are modelled by an adversary. We focus on estimating relative
throughput of online scheduling algorithms, that is, the ratio between the
throughputs achieved by the algorithm and the best scheduling for the same
arrival and error patterns. This framework allows more accurate analysis of
performance of online scheduling algorithms, even in worst-case arrival and
error scenarios. We design an online algorithm for scheduling packets of
arbitrary lengths, achieving optimal relative throughput in the range (1/3,1/2]
(the exact value depends on packet lengths). In other words, for any arrival
and jamming patterns, our solution gives throughput which is no more than c
times worse than the best possible scheduling for these patters, where c in [2;
3) is the inverse of relative throughput. Another algorithm we design makes use
of additional resources in order to achieve relative throughput 1, that is, it
achieves at least as high throughput as the best schedule without such
resources, for any arrival and jamming patterns. More precisely, we show that
if the algorithm can run with double speed, i.e., with twice higher frequency,
then its relative throughput is 1. This demonstrates that throughput of the
best online scheduling algorithms scales well with resource augmentation.
  Keywords: Packet scheduling, Dynamic packet arrivals, Adversarial jamming,
Online algorithms, Relative throughput, Resource augmentation."
"We consider robust resource allocation of services in Clouds. More
specifically, we consider the case of a large public or private Cloud platform
that runs a relatively small set of large and independent services. These
services are characterized by their demand along several dimensions (CPU,
memory,...) and by their quality of service requirements, that have been
defined through an SLA in the case of a public Cloud or fixed by the
administrator in the case of a private Cloud. This quality of service defines
the required robustness of the service, by setting an upper limit on the
probability that the provider fails to allocate the required quantity of
resources. This maximum probability of failure can be transparently turned into
a pair (price,penalty). Failures can indeed hit the platform, and resilience is
provided through service replication. Our contribution is two-fold. First, we
propose a resource allocation strategy whose complexity is logarithmic in the
number of resources, what makes it very efficient for large platforms. Second,
we propose an efficient algorithm based on rare events detection techniques in
order to estimate the robustness of an allocation, a problem that has been
proven to be P-complete. Finally, we provide an analysis of the proposed
strategy through an extensive set of simulations, both in terms of the overall
number of allocated resources and in terms of time necessary to compute the
allocation."
"Large-scale distributed graph-parallel computing is challenging. On one hand,
due to the irregular computation pattern and lack of locality, it is hard to
express parallelism efficiently. On the other hand, due to the scale-free
nature, real-world graphs are hard to partition in balance with low cut. To
address these challenges, several graph-parallel frameworks including Pregel
and GraphLab (PowerGraph) have been developed recently. In this paper, we
present an alternative framework, Graph Runtime Engine (GRE). While retaining
the vertex-centric programming model, GRE proposes two new abstractions: 1) a
Scatter-Combine computation model based on active message to exploit massive
fined-grained edge-level parallelism, and 2) a Agent-Graph data model based on
vertex factorization to partition and represent directed graphs. GRE is
implemented on commercial off-the-shelf multi-core cluster. We experimentally
evaluate GRE with three benchmark programs (PageRank, Single Source Shortest
Path and Connected Components) on real-world and synthetic graphs of millions
billion of vertices. Compared to PowerGraph, GRE shows 2.5~17 times better
performance on 8~16 machines (192 cores). Specifically, the PageRank in GRE is
the fastest when comparing to counterparts of other frameworks (PowerGraph,
Spark,Twister) reported in public literatures. Besides, GRE significantly
optimizes memory usage so that it can process a large graph of 1 billion
vertices and 17 billion edges on our cluster with totally 768GB memory, while
PowerGraph can only process less than half of this graph scale."
"The rapid growth of data volume brings big challenges to the data center
computing, and energy efficiency is one of the most concerned problems.
Researchers from various fields are now proposing solutions to green the data
center operations. Power usage effectiveness metric plays an important role in
the energy saving research. However, the exising usage effectiveness metrics
focus on measuring the relationship between the total facility energy consumed
and the IT equipment energy consumed, without reflecting the energy efficiency
of applications. In this paper, we analyze the requirements of
application-level metrics for power usage efficiency of the data centers, and
propose two novel energy efficiency metrics to provide strong guidance and
useful insight to data center design and optimization. We conduct comprehensive
experiments in the practical data centers using BigDataBench, a big data
benchmark suite, and the results demonstrate the rationality and efficiency of
AxPUE in measuring the actual computation energy consumption in data centers."
"In this paper we have classified the nodes of OTIS-cube based on their
eccentricities. OTIS (optical transpose interconnection system) is a large
scale optoelectronic computer architecture, proposed in \cite{KMKE92}, that
benefit from both optical and electronic technologies. We show that radius and
diameter of OTIS-$Q_n$ is $n+1$ and $2n+1$ respectively. We also show that
average eccentricity of OTIS-cube is $(3n/2+1)$.
  In \cite{D05}, a variant of OTIS-cube, called Enhanced OTIS-cube
(E-OTIS-$Q_n$) was proposed.
  E-OTIS-$Q_n$ is regular of degree $n+1$ and maximally fault-tolerant.
  In this paper we have given a classification of the nodes of E-OTIS cube and
derived expressions for the eccentricities of the nodes in each class. Based on
these results we show that radius and diameter of E-OTIS-$Q_n$ is $n+1$ and
$\lfloor {4n+4/3} \rfloor$ respectively. We have also computed the average
eccentricity of E-OTIS-$Q_n$ for values of $n$ upto 20."
"We formulate a modular approach to the design and analysis of a particular
class of mutual exclusion algorithms for shared memory multiprocessor systems.
Specifically, we consider algorithms that organize waiting processes into a
queue. Such algorithms can achieve O(1) remote memory reference (RMR)
complexity, which minimizes (asymptotically) the amount of traffic through the
processor-memory interconnect. We first describe a generic mutual exclusion
algorithm that relies on a linearizable implementation of a particular
queue-like data structure that we call MutexQueue. Next, we show two
implementations of MutexQueue using O(1) RMRs per operation based on
synchronization primitives commonly available in multiprocessors. These
implementations follow closely the queuing code embedded in previously
published mutual exclusion algorithms. We provide rigorous correctness proofs
and RMR complexity analyses of the algorithms we present."
"Partitioning an input graph over a set of workers is a complex operation.
Objectives are twofold: split the work evenly, so that every worker gets an
equal share, and minimize edge cut to achieve a good work locality (i.e.
workers can work independently). Partitioning a graph accessible from memory is
a notorious NP-complete problem. Motivated by the regain of interest for the
stream processing paradigm (where nodes and edges arrive as a flow to the
datacenter), we propose in this paper a stream-enabled graph partitioning
system that constantly seeks an optimum between those two objectives. We first
expose the hardness of partitioning using classic and static methods; we then
exhibit the cut versus load balancing tradeoff, from an application point of
view. With this tradeoff in mind, our approach translates the online
partitioning problem into a standard optimization problem. A greedy algorithm
handles the stream of incoming graph updates while optimizations are triggered
on demand to improve upon the greedy decisions. Using simulations, we show that
this approach is very efficient, turning a basic optimization strategy such as
hill climbing into an online partitioning solution that compares favorably to
literature's recent stream partitioning solutions."
"Although modern supercomputers are composed of multicore machines, one can
find scientists that still execute their legacy applications which were
developed to monocore cluster where memory hierarchy is dedicated to a sole
core. The main objective of this paper is to propose and evaluate an algorithm
that identify an efficient blocksize to be applied on MPI stencil computations
on multicore machines. Under the light of an extensive experimental analysis,
this work shows the benefits of identifying blocksizes that will dividing data
on the various cores and suggest a methodology that explore the memory
hierarchy available in modern machines."
"This short paper deals with parallel scientific applications using
non-blocking and periodic coordinated checkpointing to enforce resilience. We
provide a model and detailed formulas for total execution time and consumed
energy. We characterize the optimal period for both objectives, and we assess
the range of time/energy trade-offs to be made by instantiating the model with
a set of realistic scenarios for Exascale systems. We give a particular
emphasis to I/O transfers, because the relative cost of communication is
expected to dramatically increase, both in terms of latency and consumed
energy, for future Exascale platforms."
"In this paper, we revisit traditional checkpointing and rollback recovery
strategies, with a focus on silent data corruption errors. Contrarily to
fail-stop failures, such latent errors cannot be detected immediately, and a
mechanism to detect them must be provided. We consider two models: (i) errors
are detected after some delays following a probability distribution (typically,
an Exponential distribution); (ii) errors are detected through some
verification mechanism. In both cases, we compute the optimal period in order
to minimize the waste, i.e., the fraction of time where nodes do not perform
useful computations. In practice, only a fixed number of checkpoints can be
kept in memory, and the first model may lead to an irrecoverable failure. In
this case, we compute the minimum period required for an acceptable risk. For
the second model, there is no risk of irrecoverable failure, owing to the
verification mechanism, but the corresponding overhead is included in the
waste. Finally, both models are instantiated using realistic scenarios and
application/architecture parameters."
"We present a strong solution of the board game pentago, computed using
exhaustive parallel retrograde analysis in 4 hours on 98304 ($3 \times 2^{15}$)
threads of NERSC's Cray Edison. At $3.0 \times 10^{15}$ states, pentago is the
largest divergent game solved to date by two orders of magnitude, and the only
example of a nontrivial divergent game solved using retrograde analysis. Unlike
previous retrograde analyses, our computation was performed entirely in-core,
writing only a small portion of the results to disk; an out-of-core
implementation would have been much slower. Symmetry was used to reduce
branching factor and exploit instruction level parallelism. Despite a
theoretically embarrassingly parallel structure, asynchronous message passing
was required to fit the computation into available RAM, causing latency
problems on an older Cray machine. All code and data for the project are open
source, together with a website which combines database lookup and on-the-fly
computation to interactively explore the strong solution."
"Cloud computing is a newly emerging distributed computing which is evolved
from Grid computing. Task scheduling is the core research of cloud computing
which studies how to allocate the tasks among the physical nodes so that the
tasks can get a balanced allocation or each task's execution cost decreases to
the minimum or the overall system performance is optimal. Unlike the previous
task slices' sequential execution of an independent task in the model of which
the target is processing time, we build a model that targets at the response
time, in which the task slices are executed in parallel. Then we give its
solution with a method based on an improved adjusting entropy function. At
last, we design a new task scheduling algorithm. Experimental results show that
the response time of our proposed algorithm is much lower than the
game-theoretic algorithm and balanced scheduling algorithm and compared with
the balanced scheduling algorithm, game-theoretic algorithm is not necessarily
superior in parallel although its objective function value is better."
"One typical use case of large-scale distributed computing in data centers is
to decompose a computation job into many independent tasks and run them in
parallel on different machines, sometimes known as the ""embarrassingly
parallel"" computation. For this type of computation, one challenge is that the
time to execute a task for each machine is inherently variable, and the overall
response time is constrained by the execution time of the slowest machine. To
address this issue, system designers introduce task replication, which sends
the same task to multiple machines, and obtains result from the machine that
finishes first. While task replication reduces response time, it usually
increases resource usage. In this work, we propose a theoretical framework to
analyze the trade-off between response time and resource usage. We show that,
while in general, there is a tension between response time and resource usage,
there exist scenarios where replicating tasks judiciously reduces completion
time and resource usage simultaneously. Given the execution time distribution
for machines, we investigate the conditions for a scheduling policy to achieve
optimal performance trade-off, and propose efficient algorithms to search for
optimal or near-optimal scheduling policies. Our analysis gives insights on
when and why replication helps, which can be used to guide scheduler design in
large-scale distributed computing systems."
"In a virtualized environment, contextualization is the process of configuring
a VM instance for the needs of various deployment use cases. Contextualization
in CernVM can be done by passing a handwritten context to the user data field
of cloud APIs, when running CernVM on the cloud, or by using CernVM web
interface when running the VM locally. CernVM Online is a publicly accessible
web interface that unifies these two procedures. A user is able to define,
store and share CernVM contexts using CernVM Online and then apply them either
in a cloud by using CernVM Cloud Gateway or on a local VM with the single-step
pairing mechanism. CernVM Cloud Gateway is a distributed system that provides a
single interface to use multiple and different clouds (by location or type,
private or public). Cloud gateway has been so far integrated with OpenNebula,
CloudStack and EC2 tools interfaces. A user, with access to a number of clouds,
can run CernVM cloud agents that will communicate with these clouds using their
interfaces, and then use one single interface to deploy and scale CernVM
clusters. CernVM clusters are defined in CernVM Online and consist of a set of
CernVM instances that are contextualized and can communicate with each other."
"Cloud computing is an emerging technology in distributed computing which
facilitates pay per model as per user demand and requirement.Cloud consist of a
collection of virtual machine which includes both computational and storage
facility. The primary aim of cloud computing is to provide efficient access to
remote and geographically distributed resources. Cloud is developing day by day
and faces many challenges, one of them is scheduling. Scheduling refers to a
set of policies to control the order of work to be performed by a computer
system. A good scheduler adapts its scheduling strategy according to the
changing environment and the type of task. In this research paper we presented
a Generalized Priority algorithm for efficient execution of task and comparison
with FCFS and Round Robin Scheduling. Algorithm should be tested in cloud Sim
toolkit and result shows that it gives better performance compared to other
traditional scheduling algorithm."
"Virtualization technology has provided many benefits to organizations, but it
cannot provide automation. This causes operational expenditure (OpEx)
inefficiencies, which are solved by cloud computing (vCloud Director vApps).
Organizations have adopted virtualization technology to reduce IT costs and
meet business needs. In addition to improved CapEx efficiency, virtualization
has enabled organizations to respond to business needs faster. While
virtualization has dramatically optimized core IT infrastructures,
organizations struggle to reduce OpEx costs. Because virtualization only
addresses server consolidation, administrators are faced with the manual and
resource-intensive day-to-day tasks of managing the rest of the data center:
networking, storage, user management. This manuscript presents details on how
leverage vApps based on a virtualized platform to improve CapEx efficiency in
today s data center. The combination of virtualization and cloud computing can
transform the data center into a dynamic, scalable, and agile resource capable
of achieving significant CapEx and OpEx cost savings."
"Coherent causal memory (CCM) is causal memory in which prefixes of an
execution can be mapped to global memory states in a consistent way. While CCM
requires conflicting pairs of writes to be globally ordered, it allows writes
to remain unordered with respect to both reads and nonconflicting writes.
Nevertheless, it supports assertional, state-based program reasoning using
generalized Owicki-Gries proof outlines (where assertions can be attached to
any causal program edge). Indeed, we show that from a reasoning standpoint, CCM
differs from sequentially consistent (SC) memory only in that ghost code added
by the user is not allowed to introduce new write-write races.
  While CCM provides most of the formal reasoning leverage of SC memory, it is
much more efficiently implemented. As an illustration, we describe a simple
programming discipline that provides CCM on top of x86-TSO. The discipline is
considerably more relaxed than the one needed to ensure SC; for example, it
introduces no burden whatsoever for programs in which at most one thread writes
to any variable."
"Today, the importance of having 100% uptime for businesses and industries is
clear: financial reasons and often strict government regulations for certain
industries require 100% business continuity. The concept of business continuity
(BC), as Microsoft defines it: the ability of an organization to continue to
function even after a disastrous event, accomplished through the deployment of
redundant hardware and software, the use of fault tolerant systems, as well as
a solid backup and recovery strategy, directly relates to an organization s
ability to quickly restore and deploy IT backups and business operations in a
short period of time."
"Algorithms developed for scheduling applications on heterogeneous
multiprocessor system focus on asingle objective such as execution time, cost
or total data transmission time. However, if more than oneobjective (e.g.
execution cost and time, which may be in conflict) are considered, then the
problem becomes more challenging. This project is proposed to develop a
multiobjective scheduling algorithm using Evolutionary techniques for
scheduling a set of dependent tasks on available resources in a multiprocessor
environment which will minimize the makespan and reliability cost. A
Non-dominated sorting Genetic Algorithm-II procedure has been developed to get
the pareto- optimal solutions. NSGA-II is a Elitist Evolutionary algorithm, and
it takes the initial parental solution without any changes, in all iteration to
eliminate the problem of loss of some pareto-optimal solutions.NSGA-II uses
crowding distance concept to create a diversity of the solutions."
"In this paper we present a novel algorithm for concurrent lock-free internal
binary search trees (BST) and implement a Set abstract data type (ADT) based on
that. We show that in the presented lock-free BST algorithm the amortized step
complexity of each set operation - {\sc Add}, {\sc Remove} and {\sc Contains} -
is $O(H(n) + c)$, where, $H(n)$ is the height of BST with $n$ number of nodes
and $c$ is the contention during the execution. Our algorithm adapts to
contention measures according to read-write load. If the situation is
read-heavy, the operations avoid helping pending concurrent {\sc Remove}
operations during traversal, and, adapt to interval contention. However, for
write-heavy situations we let an operation help pending {\sc Remove}, even
though it is not obstructed, and so adapt to tighter point contention. It uses
single-word compare-and-swap (\texttt{CAS}) operations. We show that our
algorithm has improved disjoint-access-parallelism compared to similar existing
algorithms. We prove that the presented algorithm is linearizable. To the best
of our knowledge this is the first algorithm for any concurrent tree data
structure in which the modify operations are performed with an additive term of
contention measure."
"In order to achieve exascale performance it is important to detect potential
bottlenecks and identify strategies to overcome them. For this, both
applications and system software must be analysed and potentially improved. The
EU FP7 project Collaborative Research into Exascale Systemware, Tools &
Applications (CRESTA) chose the approach to co-design advanced simulation
applications and system software as well as development tools. In this paper,
we present the results of a co-design activity focused on the simulation code
NEK5000 that aims at performance improvements of collective communication
operations. We have analysed the algorithms that form the core of NEK5000's
communication module in order to assess its viability on recent computer
architectures before starting to improve its performance. Our results show that
the crystal router algorithm performs well in sparse, irregular collective
operations for medium and large processor number but improvements for even
larger system sizes of the future will be needed. We sketch the needed
improvements, which will make the communication algorithms also beneficial for
other applications that need to implement latency-dominated communication
schemes with short messages. The latency-optimised communication operations
will also become used in a runtime-system providing dynamic load balancing,
under development within CRESTA."
"Several organizations, like social networks, store and routinely analyze
large graphs as part of their daily operation. Such graphs are typically
distributed across multiple servers, and graph partitioning is critical for
efficient graph management. Existing partitioning algorithms focus on finding
graph partitions with good locality, but disregard the pragmatic challenges of
integrating partitioning into large-scale graph management systems deployed on
the cloud, such as dealing with the scale and dynamicity of the graph and the
compute environment.
  In this paper, we propose Spinner, a scalable and adaptive graph partitioning
algorithm based on label propagation designed on top of the Pregel model.
Spinner scales to massive graphs, produces partitions with locality and balance
comparable to the state-of-the-art and efficiently adapts the partitioning upon
changes. We describe our algorithm and its implementation in the Pregel
programming model that makes it possible to partition billion-vertex graphs. We
evaluate Spinner with a variety of synthetic and real graphs and show that it
can compute partitions with quality comparable to the state-of-the art. In
fact, by using Spinner in conjunction with the Giraph graph processing engine,
we speed up different applications by a factor of 2 relative to standard hash
partitioning."
"The tremendous increase in the size and heterogeneity of supercomputers makes
it very difficult to predict the performance of a scheduling algorithm.
Therefore, dynamic solutions, where scheduling decisions are made at runtime
have overpassed static allocation strategies. The simplicity and efficiency of
dynamic schedulers such as Hadoop are a key of the success of the MapReduce
framework. Dynamic schedulers such as StarPU, PaRSEC or StarSs are also
developed for more constrained computations, e.g. task graphs coming from
linear algebra. To make their decisions, these runtime systems make use of some
static information, such as the distance of tasks to the critical path or the
affinity between tasks and computing resources (CPU, GPU,...) and of dynamic
information, such as where input data are actually located. In this paper, we
concentrate on two elementary linear algebra kernels, namely the outer product
and the matrix multiplication. For each problem, we propose several dynamic
strategies that can be used at runtime and we provide an analytic study of
their theoretical performance. We prove that the theoretical analysis provides
very good estimate of the amount of communications induced by a dynamic
strategy and can be used in order to efficiently determine thresholds used in
dynamic scheduler, thus enabling to choose among them for a given problem and
architecture."
"The maximal sensitivity of the Smith-Waterman (SW) algorithm has enabled its
wide use in biological sequence database search. Unfortunately, the high
sensitivity comes at the expense of quadratic time complexity, which makes the
algorithm computationally demanding for big databases. In this paper, we
present SWAPHI, the first parallelized algorithm employing Xeon Phi
coprocessors to accelerate SW protein database search. SWAPHI is designed based
on the scale-and-vectorize approach, i.e. it boosts alignment speed by
effectively utilizing both the coarse-grained parallelism from the many
co-processing cores (scale) and the fine-grained parallelism from the 512-bit
wide single instruction, multiple data (SIMD) vectors within each core
(vectorize). By searching against the large UniProtKB/TrEMBL protein database,
SWAPHI achieves a performance of up to 58.8 billion cell updates per second
(GCUPS) on one coprocessor and up to 228.4 GCUPS on four coprocessors.
Furthermore, it demonstrates good parallel scalability on varying number of
coprocessors, and is also superior to both SWIPE on 16 high-end CPU cores and
BLAST+ on 8 cores when using four coprocessors, with the maximum speedup of
1.52 and 1.86, respectively. SWAPHI is written in C++ language (with a set of
SIMD intrinsics), and is freely available at http://swaphi.sourceforge.net."
"In this paper we introduce and study a new family of combinatorial simplicial
complexes, which we call immediate snapshot complexes. Our construction and
terminology is strongly motivated by theoretical distributed computing, as
these complexes are combinatorial models of the standard protocol complexes
associated to immediate snapshot read/write shared memory communication model.
In order to define the immediate snapshot complexes we need a new combinatorial
object, which we call a witness structure. These objects are indexing the
simplices in the immediate snapshot complexes, while a special operation on
them, called ghosting, describes the combinatorics of taking simplicial
boundary. In general, we develop the theory of witness structures and use it to
prove several combinatorial as well as topological properties of the immediate
snapshot complexes."
"With the advent of internet services, data started growing faster than it can
be processed. To personalize user experience, this enormous data has to be
processed in real time, in interactive fashion. In order to achieve faster data
processing often a statistical method called subsampling. Subsampling workloads
compute statistics from a random subset of sample data (i.e., a subsample).
Data-parallel platforms group these samples into tasks; each task subsamples
its data in parallel.
  Current, state-of-the-art platforms such as Hadoop are built for large tasks
that run for long periods of time, but applications with smaller average task
sizes suffer large overheads on these platforms. Tasks in subsampling workloads
are sized to minimize the number of overall cache misses, and these tasks can
complete in seconds. This technique can reduce the overall length of a
map-reduce job, but only when the savings from the cache miss rate reduction
are not eclipsed by the platform overhead of task creation and data
distribution.
  In this thesis, we propose a data-parallel platform with an efficient data
distribution component that breaks data-parallel subsampling workloads into
compute clusters with tiny tasks. Each tiny task completes in few hundreds of
milliseconds to seconds. Tiny tasks reduce processor cache misses caused by
random subsampling, which speeds up per-task running time. However, they cause
significant scheduling overheads and data distribution challenges. We propose a
task knee-pointing algorithm and a dynamic scheduler that schedules the tasks
to worker nodes based on the availability and response times of the data nodes.
We compare our framework against various configurations of BashReduce and
Hadoop. A detailed discussion of tiny task approach on two workloads, EAGLET
and Netflix movie rating is presented."
"We consider the enumeration of maximal bipartite cliques (bicliques) from a
large graph, a task central to many practical data mining problems in social
network analysis and bioinformatics. We present novel parallel algorithms for
the MapReduce platform, and an experimental evaluation using Hadoop MapReduce.
Our algorithm is based on clustering the input graph into smaller sized
subgraphs, followed by processing different subgraphs in parallel. Our
algorithm uses two ideas that enable it to scale to large graphs: (1) the
redundancy in work between different subgraph explorations is minimized through
a careful pruning of the search space, and (2) the load on different reducers
is balanced through the use of an appropriate total order among the vertices.
Our evaluation shows that the algorithm scales to large graphs with millions of
edges and tens of mil- lions of maximal bicliques. To our knowledge, this is
the first work on maximal biclique enumeration for graphs of this scale."
"We demonstrate algorithm-based fault tolerance for silent, transient data
corruption in ""black-box"" preconditioners. We consider both additive Schwarz
domain decomposition with an ILU(k) subdomain solver, and algebraic multigrid,
both implemented in the Trilinos library. We evaluate faults that corrupt
preconditioner results in both single and multiple MPI ranks. We then analyze
how our approach behaves when then application is scaled. Our technique is
based on a Selective Reliability approach that performs most operations in an
unreliable mode, with only a few operations performed reliably. We also
investigate two responses to faults and discuss the performance overheads
imposed by each. For a non-symmetric problem solved using GMRES and ILU, we
show that at scale our fault tolerance approach incurs only 22% overhead for
the worst case. With detection techniques, we are able to reduce this overhead
to 1.8% in the worst case."
"The immediate snapshot complexes were introduced as combinatorial models for
the protocol complexes in the context of theoretical distributed computing. In
the previous work we have developed a formal language of witness structures in
order to define and to analyze these complexes.
  In this paper, we study topology of immediate snapshot complexes. It was
known that these complexes are always pure and that they are pseudomanifolds.
Here we prove two further independent topological properties. First, we show
that immediate snapshot complexes are collapsible. Second, we show that these
complexes are homeomorphic to closed balls. Specifically, given any immediate
snapshot complex $P(\tr)$, we show that there exists a homeomorphism
$\varphi:\da^{|\supp\tr|-1}\ra P(\tr)$, such that $\varphi(\sigma)$ is a
subcomplex of $P(\tr)$, whenever $\sigma$ is a simplex in the simplicial
complex $\da^{|\supp\tr|-1}$."
"This work proposes a new and flexible unreliable failure detector whose
output is related to the trust level of a set of processes. By expressing the
relevance of each process of the set by an impact factor value, our approach
allows the tuning of the detector output, making possible a softer or stricter
monitoring. The idea behind our proposal is that, according to an acceptable
margin of failures and the impact factor assigned to processes, in some
scenarios, the failure of some low impact processes may not change the user
confidence in the set of processes, while the crash of a high impact factor
process may seriously affect it. We outline the application scenarios and the
proposed unreliable failure detector, giving a detailed account of the concept
on which it is based."
"Inspired by social networks and complex systems, we propose a core-periphery
network architecture that supports fast computation for many distributed
algorithms and is robust and efficient in number of links. Rather than
providing a concrete network model, we take an axiom-based design approach. We
provide three intuitive (and independent) algorithmic axioms and prove that any
network that satisfies all axioms enjoys an efficient algorithm for a range of
tasks (e.g., MST, sparse matrix multiplication, etc.). We also show the
minimality of our axiom set: for networks that satisfy any subset of the
axioms, the same efficiency cannot be guaranteed for any deterministic
algorithm."
"With growing use of internet and exponential growth in amount of data to be
stored and processed (known as 'big data'), the size of data centers has
greatly increased. This, however, has resulted in significant increase in the
power consumption of the data centers. For this reason, managing power
consumption of data centers has become essential. In this paper, we highlight
the need of achieving energy efficiency in data centers and survey several
recent architectural techniques designed for power management of data centers.
We also present a classification of these techniques based on their
characteristics. This paper aims to provide insights into the techniques for
improving energy efficiency of data centers and encourage the designers to
invent novel solutions for managing the large power dissipation of data
centers."
"This experience report presents the results of an extensive performance
evaluation conducted using four open-source implementations of Paxos deployed
in Amazon's EC2. Paxos is a fundamental algorithm for building fault-tolerant
services, at the core of state-machine replication. Implementations of Paxos
are currently used in many prototypes and production systems in both academia
and industry. Although all protocols surveyed in the paper implement Paxos,
they are optimized in a number of different ways, resulting in very different
behavior, as we show in the paper. We have considered a variety of
configurations and failure-free and faulty executions. In addition to reporting
our findings, we propose and assess additional optimizations to existing
implementations."
"State-machine replication, a fundamental approach to fault tolerance,
requires replicas to execute commands deterministically, which usually results
in sequential execution of commands. Sequential execution limits performance
and underuses servers, which are increasingly parallel (i.e., multicore). To
narrow the gap between state-machine replication requirements and the
characteristics of modern servers, researchers have recently come up with
alternative execution models. This paper surveys existing approaches to
parallel state-machine replication and proposes a novel optimistic protocol
that inherits the scalable features of previous techniques. Using a replicated
B+-tree service, we demonstrate in the paper that our protocol outperforms the
most efficient techniques by a factor of 2.4 times."
"A system-of-systems (SoS) is a large information processing system formed by
the integration of autonomous computer systems (called constituent systems,
CS), physical machines and humans for the purpose of providing new synergistic
services and/or more efficient economic processes. In a number of applications,
e.g robotics, the autonomous CSs must coordinate their actions in the temporal
domain to realize the desired objectives. In this paper we argue that the
introduction of a proper global physical time establishes a shared view about
the progress of physical time and helps to realize the temporal coordination of
the autonomous CSs. The available global time can also be used to simplify the
solution of many challenging problems within the SoS, such as distributed
resource allocation, and helps to improve the dependability and fault-tolerance
of the SoS."
"The specialty of desktop-as-a-service cloud computing is that user can access
their desktop and can execute applications in virtual desktops on remote
servers. Resource management and resource utilization are most significant in
the area of desktop-as-a-service, cloud computing; however, handling a large
amount of clients in the most efficient manner poses important challenges.
Especially deciding how many clients to handle on one server, and where to
execute the user applications at each time is important. This is because we
have to ensure maximum resource utilization along with user data
confidentiality, customer satisfaction, scalability, minimum Service level
agreement (SLA) violation etc. Assigning too many users to one server leads to
customer dissatisfaction, while assigning too little leads to higher
investments costs. So we have taken into consideration these two situations
also. We study different aspects to optimize the resource usage and customer
satisfaction. Here in this paper We proposed Intelligent Resource Allocation
(IRA) Technique which assures the above mentioned parameters like minimum SLA
violation. For this, priorities are assigned to user requests based on their
SLA Factors in order to maintain their confidentiality. The results of the
paper indicate that by applying IRA Technique to the already existing
overbooking mechanism will improve the performance of the system with
significant reduction in SLA violation."
"Atomic broadcasts play a central role in serialisable in-memory transactions.
Best performing ones block, when a node crashes, until a new view is installed.
We augment a new protocol for uninterrupted progress in the interim period."
"We study here the problem of determining the majority type in an arbitrary
connected network, each vertex of which has initially two possible types. The
vertices may have a few additional possible states and can interact in pairs
only if they share an edge. Any (population) protocol is required to stabilize
in the initial majority. We first present and analyze a protocol with 4 states
per vertex that always computes the initial majority value, under any fair
scheduler. As we prove, this protocol is optimal, in the sense that there is no
population protocol that always computes majority with fewer than 4 states per
vertex. However this does not rule out the existence of a protocol with 3
states per vertex that is correct with high probability. To this end, we
examine a very natural majority protocol with 3 states per vertex, introduced
in [Angluin et al. 2008] where its performance has been analyzed for the clique
graph. We study the performance of this protocol in arbitrary networks. We
prove that, when the two initial states are put uniformly at random on the
vertices, this protocol converges to the initial majority with probability
higher than the probability of converging to the initial minority. In contrast,
we present an infinite family of graphs, on which the protocol can fail whp,
even when the difference between the initial majority and the initial minority
is $n - \Theta(\ln{n})$. We also present another infinite family of graphs in
which the protocol of Angluin et al. takes an expected exponential time to
converge. These two negative results build upon a very positive result
concerning the robustness of the protocol on the clique. Surprisingly, the
resistance of the clique to failure causes the failure in general graphs. Our
techniques use new domination and coupling arguments for suitably defined
processes whose dynamics capture the antagonism between the states involved."
"User connectivity patterns in network applications are known to be
heterogeneous, and to follow periodic (daily and weekly) patterns. In many
cases, the regularity and the correlation of those patterns is problematic: for
network applications, many connected users create peaks of demand; in contrast,
in peer-to-peer scenarios, having few users online results in a scarcity of
available resources. On the other hand, since connectivity patterns exhibit a
periodic behavior, they are to some extent predictable. This work shows how
this can be exploited to anticipate future user connectivity and to have
applications proactively responding to it. We evaluate the probability that any
given user will be online at any given time, and assess the prediction on
six-month availability traces from three different Internet applications.
Building upon this, we show how our probabilistic approach makes it easy to
evaluate and optimize the performance in a number of diverse network
application models, and to use them to optimize systems. In particular, we show
how this approach can be used in distributed hash tables, friend-to-friend
storage, and cache pre-loading for social networks, resulting in substantial
gains in data availability and system efficiency at negligible costs."
"Novel energy-aware cloud management methods dynamically reallocate
computation across geographically distributed data centers to leverage regional
electricity price and temperature differences. As a result, a managed VM may
suffer occasional downtimes. Current cloud providers only offer high
availability VMs, without enough flexibility to apply such energy-aware
management. In this paper we show how to analyse past traces of dynamic cloud
management actions based on electricity prices and temperatures to estimate VM
availability and price values. We propose a novel SLA specification approach
for offering VMs with different availability and price values guaranteed over
multiple SLAs to enable flexible energy-aware cloud management. We determine
the optimal number of such SLAs as well as their availability and price
guaranteed values. We evaluate our approach in a user SLA selection simulation
using Wikipedia and Grid'5000 workloads. The results show higher customer
conversion and 39% average energy savings per VM."
"HTML5 WebSocket protocol brings real time communication in web browsers to a
new level. Daily, new products are designed to stay permanently connected to
the web. WebSocket is the technology enabling this revolution. WebSockets are
supported by all current browsers, but it is still a new technology in constant
evolution.
  WebSockets are slowly replacing older client-server communication
technologies. As opposed to comet-like technologies WebSockets' remarkable
performances is a result of the protocol's fully duplex nature and because it
doesn't rely on HTTP communications.
  To begin with this paper studies the WebSocket protocol and different
WebSocket servers implementations. This first theoretic part focuses more
deeply on heterogeneous implementations and OpenCL. The second part is a
benchmark of a new promising library.
  The real-time engine used for testing purposes is SocketCluster.
SocketCluster provides a highly scalable WebSocket server that makes use of all
available cpu cores on an instance. The scope of this work is reduced to
vertical scaling of SocketCluster."
"With the rapid development in wide area networks and low cost, powerful
computational resources, grid computing has gained its popularity. With the
advent of grid computing, space limitations of conventional distributed systems
can be overcome and underutilized computing resources at different locations
around the world can be put to distributed jobs. Workload and resource
management is the main key grid services at the service level of grid
infrastructures, out of which load balancing in the main concern for grid
developers. It has been found that load is the major problem which server
faces, especially when the number of users increases. A lot of research is
being done in the area of load management. This paper presents the various
mechanisms of load balancing in grid computing so that the readers will get an
idea of which algorithm would be suitable in different situations. Keywords:
wide area network, distributed computing, load balancing."
"Modern educational institutions widely used virtual laboratories and cloud
technologies. In practice must deal with security, processing speed and other
tasks. The paper describes the experience of the construction of an
experimental stand cloud computing and network management. Models and control
principles set forth herein."
"At present moment, there is a great interest in development of information
systems operating in cloud infrastructures. Generally, many of tasks remain
unresolved such as tasks of optimization of large databases in a hybrid cloud
infrastructure, quality of service (QoS) at different levels of cloud services,
dynamic control of distribution of cloud resources in application systems and
many others. Research and development of new solutions can be limited in case
of using emulators or international commercial cloud services, due to the
closed architecture and limited opportunities for experimentation. Article
provides answers to questions on the establishment of a pilot cloud practically
""at home"" with the ability to adjust the width of the emulation channel and
delays in data transmission. It also describes architecture and configuration
of the experimental setup. The proposed modular structure can be expanded by
available computing power."
"We consider the Do-All problem, where $p$ cooperating processors need to
complete $t$ similar and independent tasks in an adversarial setting. Here we
deal with a synchronous message passing system with processors that are subject
to crash failures. Efficiency of algorithms in this setting is measured in
terms of work complexity (also known as total available processor steps) and
communication complexity (total number of point-to-point messages). When work
and communication are considered to be comparable resources, then the overall
efficiency is meaningfully expressed in terms of effort defined as work +
communication. We develop and analyze a constructive algorithm that has work
${\cal O}( t + p \log p\, (\sqrt{p\log p}+\sqrt{t\log t}\, ) )$ and a
nonconstructive algorithm that has work ${\cal O}(t +p \log^2 p)$. The latter
result is close to the lower bound $\Omega(t + p \log p/ \log \log p)$ on work.
The effort of each of these algorithms is proportional to its work when the
number of crashes is bounded above by $c\,p$, for some positive constant $c <
1$. We also present a nonconstructive algorithm that has effort ${\cal O}(t + p
^{1.77})$."
"Software transactional memory implementations which allow transactions to
work on inconsistent states of shared data, risk to cause application visible
errors such as memory access violations or endless loops. Hence, many
implementations rely on repeated incremental validation of every read of the
transaction to always guarantee for a consistent view of shared data. Because
this eager validation technique generates significant processing costs several
proposals have been published to establish a sandbox for transactions, which
transparently prevents or suppresses those errors and thereby allows to reduce
the frequency of in-flight validations.
  The most comprehensive sandboxing concept of transactions in software
transactional memory based on deferred updates and considering unmanaged
languages, integrates multiple techniques such as signal interposition,
out-of-band validation and static and dynamic instrumentation. The latter
comprises the insertion of a validation barrier in front of every direct write
which addresses the execution stack of the thread and potentially results from
unvalidated reads.
  This paper basically results from a review of this sandboxing approach, which
revealed some improvements for sandboxing on C/C++. Based on knowledge about
the runtime environment and the compiler an error model has been developed to
identify critical paths to application visible errors. This analysis lead to a
concept for stack protection with less frequent validation, an alternative
out-of-band validation technique and revealed additional risks of so-called
waivered regions without instrumentation inside transactions."
"Provenance is derivative journal information about the origin and activities
of system data and processes. For a highly dynamic system like the cloud,
provenance can be accurately detected and securely used in cloud digital
forensic investigation activities. This paper proposes watchword oriented
provenance cognition algorithm for the cloud environment. Additionally
time-stamp based buffer verifying algorithm is proposed for securing the access
to the detected cloud provenance. Performance analysis of the novel algorithms
proposed here yields a desirable detection rate of 89.33% and miss rate of
8.66%. The securing algorithm successfully rejects 64% of malicious requests,
yielding a cumulative frequency of 21.43 for MR."
"Provenance is the derivation history of information about the origin of data
and processes. For a highly dynamic system such as the cloud, provenance must
be effectively detected to be used as proves to ensure accountability during
digital forensic investigations. This paper proposes active-threaded provenance
cognition algorithms that ensure effective and high speed detection of
provenance information in the activity layer of the cloud. The algorithms also
support encapsulation of the provenance information on specific targets.
Performance evaluation of the proposed algorithms reveal mean delay of 8.198
seconds that is below the pre-defined benchmark of 10 seconds. Standard
deviation and cumulative frequencies for delays are found to be 1.434 and 45.1%
respectively."
"With the advent of cloud computing, organizations are nowadays able to react
rapidly to changing demands for computational resources. Not only individual
applications can be hosted on virtual cloud infrastructures, but also complete
business processes. This allows the realization of so-called elastic processes,
i.e., processes which are carried out using elastic cloud resources. Despite
the manifold benefits of elastic processes, there is still a lack of solutions
supporting them.
  In this paper, we identify the state of the art of elastic Business Process
Management with a focus on infrastructural challenges. We conceptualize an
architecture for an elastic Business Process Management System and discuss
existing work on scheduling, resource allocation, monitoring, decentralized
coordination, and state management for elastic processes. Furthermore, we
present two representative elastic Business Process Management Systems which
are intended to counter these challenges. Based on our findings, we identify
open issues and outline possible research directions for the realization of
elastic processes and elastic Business Process Management."
"Heterogeneous multi core processors can offer diverse computing capabilities.
The efficiency of Market Basket Analysis Algorithm can be improved with
heterogeneous multi core processors. Market basket analysis algorithm utilises
apriori algorithm and is one of the popular data mining algorithms which can
utilise Map/Reduce framework to perform analysis. The algorithm generates
association rules based on transactional data and Map/Reduce motivates to
redesign and convert the existing sequential algorithms for efficiency. Hadoop
is the parallel programming platform built on Hadoop Distributed File
Systems(HDFS) for Map/Reduce computation that process data as (key, value)
pairs. In Hadoop map/reduce, the sequential jobs are parallelised and the Job
Tracker assigns parallel tasks to the Task Tracker. Based on single threaded or
multithreaded parallel tasks in the task tracker, execution is carried out in
the appropriate cores. For this, a new scheduler called MB Scheduler can be
developed. Switching between the cores can be made static or dynamic. The use
of heterogeneous multi core processors optimizes processing capabilities and
power requirements for a processor and improves the performance of the system."
"Orchestrating service-oriented workflows is typically based on a design model
that routes both data and control through a single point - the centralised
workflow engine. This causes scalability problems that include the unnecessary
consumption of the network bandwidth, high latency in transmitting data between
the services, and performance bottlenecks. These problems are highly prominent
when orchestrating workflows that are composed from services dispersed across
distant geographical locations. This paper presents a novel workflow
partitioning approach, which attempts to improve the scalability of
orchestrating large-scale workflows. It permits the workflow computation to be
moved towards the services providing the data in order to garner optimal
performance results. This is achieved by decomposing the workflow into smaller
sub workflows for parallel execution, and determining the most appropriate
network locations to which these sub workflows are transmitted and subsequently
executed. This paper demonstrates the efficiency of our approach using a set of
experimental workflows that are orchestrated over Amazon EC2 and across several
geographic network regions."
"Read-only caches are widely used in cloud infrastructures to reduce access
latency and load on backend databases. Operators view coherent caches as
impractical at genuinely large scale and many client-facing caches are updated
in an asynchronous manner with best-effort pipelines. Existing solutions that
support cache consistency are inapplicable to this scenario since they require
a round trip to the database on every cache transaction.
  Existing incoherent cache technologies are oblivious to transactional data
access, even if the backend database supports transactions. We propose T-Cache,
a novel caching policy for read-only transactions in which inconsistency is
tolerable (won't cause safety violations) but undesirable (has a cost). T-Cache
improves cache consistency despite asynchronous and unreliable communication
between the cache and the database. We define cache-serializability, a variant
of serializability that is suitable for incoherent caches, and prove that with
unbounded resources T-Cache implements this new specification. With limited
resources, T-Cache allows the system manager to choose a trade-off between
performance and consistency.
  Our evaluation shows that T-Cache detects many inconsistencies with only
nominal overhead. We use synthetic workloads to demonstrate the efficacy of
T-Cache when data accesses are clustered and its adaptive reaction to workload
changes. With workloads based on the real-world topologies, T-Cache detects
43-70% of the inconsistencies and increases the rate of consistent transactions
by 33-58%."
"Peer to peer (P2P) systems are moving from application specific architectures
to a generic service oriented design philosophy. This raises interesting
problems in connection with providing useful P2P middleware services capable of
dealing with resource assignment and management in a large-scale, heterogeneous
and unreliable environment. The slicing service, has been proposed to allow for
an automatic partitioning of P2P networks into groups (slices) that represent a
controllable amount of some resource and that are also relatively homogeneous
with respect to that resource. In this paper we propose two gossip-based
algorithms to solve the distributed slicing problem. The first algorithm speeds
up an existing algorithm sorting a set of uniform random numbers. The second
algorithm statistically approximates the rank of nodes in the ordering. The
scalability, efficiency and resilience to dynamics of both algorithms rely on
their gossip-based models. These algorithms are proved viable theoretically and
experimentally."
"Consider an asynchronous system with private channels and $n$ processes, up
to $t$ of which may be faulty. We settle a longstanding open question by
providing a Byzantine agreement protocol that simultaneously achieves three
properties:
  1. (optimal) resilience: it works as long as $n>3t$
  2. (almost-sure) termination: with probability one, all nonfaulty processes
terminate
  3. (polynomial) efficiency: the expected computation time, memory
consumption, message size, and number of messages sent are all polynomial in
$n$.
  Earlier protocols have achieved only two of these three properties. In
particular, the protocol of Bracha is not polynomially efficient, the protocol
of Feldman and Micali is not optimally resilient, and the protocol of Canetti
and Rabin does not have almost-sure termination. Our protocol utilizes a new
primitive called shunning (asynchronous) verifiable secret sharing (SVSS),
which ensures, roughly speaking, that either a secret is successfully shared or
a new faulty process is ignored from this point onwards by some nonfaulty
process."
"We describe a cloud based infrastructure that we have developed that is
optimized for wide area, high performance networks and designed to support data
mining applications. The infrastructure consists of a storage cloud called
Sector and a compute cloud called Sphere. We describe two applications that we
have built using the cloud and some experimental studies."
"We describe the design and implementation of a high performance cloud that we
have used to archive, analyze and mine large distributed data sets. By a cloud,
we mean an infrastructure that provides resources and/or services over the
Internet. A storage cloud provides storage services, while a compute cloud
provides compute services. We describe the design of the Sector storage cloud
and how it provides the storage services required by the Sphere compute cloud.
We also describe the programming paradigm supported by the Sphere compute
cloud. Sector and Sphere are designed for analyzing large data sets using
computer clusters connected with wide area high performance networks (for
example, 10+ Gb/s). We describe a distributed data mining application that we
have developed using Sector and Sphere. Finally, we describe some experimental
studies comparing Sector/Sphere to Hadoop."
"Data intensive applications often involve the analysis of large datasets that
require large amounts of compute and storage resources. While dedicated compute
and/or storage farms offer good task/data throughput, they suffer low resource
utilization problem under varying workloads conditions. If we instead move such
data to distributed computing resources, then we incur expensive data transfer
cost. In this paper, we propose a data diffusion approach that combines dynamic
resource provisioning, on-demand data replication and caching, and data
locality-aware scheduling to achieve improved resource efficiency under varying
workloads. We define an abstract ""data diffusion model"" that takes into
consideration the workload characteristics, data accessing cost, application
throughput and resource utilization; we validate the model using a real-world
large-scale astronomy application. Our results show that data diffusion can
increase the performance index by as much as 34X, and improve application
response time by over 506X, while achieving near-optimal throughputs and
execution times."
"Our work addresses the enabling of the execution of highly parallel
computations composed of loosely coupled serial jobs with no modifications to
the respective applications, on large-scale systems. This approach allows
new-and potentially far larger-classes of application to leverage systems such
as the IBM Blue Gene/P supercomputer and similar emerging petascale
architectures. We present here the challenges of I/O performance encountered in
making this model practical, and show results using both micro-benchmarks and
real applications on two large-scale systems, the BG/P and the SiCortex SC5832.
Our preliminary benchmarks show that we can scale to 4096 processors on the
Blue Gene/P and 5832 processors on the SiCortex with high efficiency, and can
achieve thousands of tasks/sec sustained execution rates for parallel workloads
of ordinary serial applications. We measured applications from two domains,
economic energy modeling and molecular dynamics."
"We have extended the Falkon lightweight task execution framework to make
loosely coupled programming on petascale systems a practical and useful
programming model. This work studies and measures the performance factors
involved in applying this approach to enable the use of petascale systems by a
broader user community, and with greater ease. Our work enables the execution
of highly parallel computations composed of loosely coupled serial jobs with no
modifications to the respective applications. This approach allows a new-and
potentially far larger-class of applications to leverage petascale systems,
such as the IBM Blue Gene/P supercomputer. We present the challenges of I/O
performance encountered in making this model practical, and show results using
both microbenchmarks and real applications from two domains: economic energy
modeling and molecular dynamics. Our benchmarks show that we can scale up to
160K processor-cores with high efficiency, and can achieve sustained execution
rates of thousands of tasks per second."
"Data-intensive applications often require exploratory analysis of large
datasets. If analysis is performed on distributed resources, data locality can
be crucial to high throughput and performance. We propose a ""data diffusion""
approach that acquires compute and storage resources dynamically, replicates
data in response to demand, and schedules computations close to data. As demand
increases, more resources are acquired, thus allowing faster response to
subsequent requests that refer to the same data; when demand drops, resources
are released. This approach can provide the benefits of dedicated hardware
without the associated high costs, depending on workload and resource
characteristics. The approach is reminiscent of cooperative caching,
web-caching, and peer-to-peer storage systems, but addresses different
application demands. Other data-aware scheduling approaches assume dedicated
resources, which can be expensive and/or inefficient if load varies
significantly. To explore the feasibility of the data diffusion approach, we
have extended the Falkon resource provisioning and task scheduling system to
support data caching and data-aware scheduling. Performance results from both
micro-benchmarks and a large scale astronomy application demonstrate that our
approach improves performance relative to alternative approaches, as well as
provides improved scalability as aggregated I/O bandwidth scales linearly with
the number of data cache nodes."
"This keynote paper: presents a 21st century vision of computing; identifies
various computing paradigms promising to deliver the vision of computing
utilities; defines Cloud computing and provides the architecture for creating
market-oriented Clouds by leveraging technologies such as VMs; provides
thoughts on market-based resource management strategies that encompass both
customer-driven service management and computational risk management to sustain
SLA-oriented resource allocation; presents some representative Cloud platforms
especially those developed in industries along with our current work towards
realising market-oriented resource allocation of Clouds by leveraging the 3rd
generation Aneka enterprise Grid technology; reveals our early thoughts on
interconnecting Clouds for dynamically creating an atmospheric computing
environment along with pointers to future community research; and concludes
with the need for convergence of competing IT paradigms for delivering our 21st
century vision."
"Platform virtualization helps solving major grid computing challenges: share
resource with flexible, user-controlled and custom execution environments and
in the meanwhile, isolate failures and malicious code. Grid resource management
tools will evolve to embrace support for virtual resource.
  We present two open source projects that transparently supply virtual
execution environments. Tycoon has been developed at HP Labs to optimise
resource usage in creating an economy where users bid to access virtual
machines and compete for CPU cycles. SmartDomains provides a peer-to-peer layer
that automates virtual machines deployment using a description language and
deployment engine from HP Labs. These projects demonstrate both client-server
and peer-to-peer approaches to virtual resource management. The first case
makes extensive use of virtual machines features for dynamic resource
allocation. The second translates virtual machines capabilities into a
sophisticated language where resource management components can be plugged in
configurations and architectures defined at deployment time.
  We propose to share our experience at CERN openlab developing SmartDomains
and deploying Tycoon to give an illustrative introduction to emerging research
in virtual resource management."
"The task management is a critical component for the computational grids. The
aim is to assign tasks on nodes according to a global scheduling policy and a
view of local resources of nodes. A peer-to-peer approach for the task
management involves a better scalability for the grid and a higher fault
tolerance. But some mechanisms have to be proposed to avoid the computation of
replicated tasks that can reduce the efficiency and increase the load of nodes.
In the same way, these mechanisms have to limit the number of exchanged
messages to avoid the overload of the network.
  In a previous paper, we have proposed two methods for the task management
called active and passive. These methods are based on a random walk: they are
fully distributed and fault tolerant. Each node owns a local tasks states set
updated thanks to a random walk and each node is in charge of the local
assignment. Here, we propose three methods to improve the efficiency of the
active method. These new methods are based on a circulating word. The nodes
local tasks states sets are updated thanks to periodical diffusions along trees
built from the circulating word. Particularly, we show that these methods
increase the efficiency of the active method: they produce less replicated
tasks. These three methods are also fully distributed and fault tolerant. On
the other way, the circulating word can be exploited for other applications
like the resources management or the nodes synchronization."
"This paper investigates the operator mapping problem for in-network
stream-processing applications. In-network stream-processing amounts to
applying one or more trees of operators in steady-state, to multiple data
objects that are continuously updated at different locations in the network.
The goal is to compute some final data at some desired rate. Different operator
trees may share common subtrees. Therefore, it may be possible to reuse some
intermediate results in different application trees. The first contribution of
this work is to provide complexity results for different instances of the basic
problem, as well as integer linear program formulations of various problem
instances. The second second contribution is the design of several
polynomial-time heuristics. One of the primary objectives of these heuristics
is to reuse intermediate results shared by multiple applications. Our
quantitative comparisons of these heuristics in simulation demonstrates the
importance of choosing appropriate processors for operator mapping. It also
allow us to identify a heuristic that achieves good results in practice."
"This paper contains the most important aspects of computing grids. Grid
computing allows high performance distributed systems to act as a single
computer. An overview of grids structure and techniques is given in order to
understand the way grids work."
"In this paper, we present a distributed implementation of a network based
multi-objective evolutionary algorithm, called EMO, by using Offspring. Network
based evolutionary algorithms have proven to be effective for multi-objective
problem solving. They feature a network of connections between individuals that
drives the evolution of the algorithm. Unfortunately, they require large
populations to be effective and a distributed implementation can leverage the
computation time. Most of the existing frameworks are limited to providing
solutions that are basic or specific to a given algorithm. Our Offspring
framework is a plug-in based software environment that allows rapid deployment
and execution of evolutionary algorithms on distributed computing environments
such as Enterprise Clouds. Its features and benefits are presented by
describing the distributed implementation of EMO."
"This paper presents a Grid portal for protein secondary structure prediction
developed by using services of Aneka, a .NET-based enterprise Grid technology.
The portal is used by research scientists to discover new prediction structures
in a parallel manner. An SVM (Support Vector Machine)-based prediction
algorithm is used with 64 sample protein sequences as a case study to
demonstrate the potential of enterprise Grids."
"We address the problem of finding nice labellings for event structures of
degree 3. We develop a minimum theory by which we prove that the labelling
number of an event structure of degree 3 is bounded by a linear function of the
height. The main theorem we present in this paper states that event structures
of degree 3 whose causality order is a tree have a nice labelling with 3
colors. Finally, we exemplify how to use this theorem to construct upper bounds
for the labelling number of other event structures of degree 3."
"In multiprocessor systems, various problems are treated with Lamport's
logical clock and the resultant logical time orders between operations.
However, one often needs to face the high complexities caused by the lack of
logical time order information in practice. In this paper, we utilize the
\emph{global clock} to infuse the so-called \emph{pending period} to each
operation in a multiprocessor system, where the pending period is a time
interval that contains the performed time of the operation. Further, we define
the \emph{physical time order} for any two operations with disjoint pending
periods. The physical time order is obeyed by any real execution in
multiprocessor systems due to that it is part of the truly happened operation
orders restricted by global clock, and it is then proven to be independent and
consistent with traditional logical time orders. The above novel yet
fundamental concepts enables new effective approaches for analyzing
multiprocessor systems, which are named \emph{pending period analysis} as a
whole. As a consequence of pending period analysis, many important problems of
multiprocessor systems can be tackled effectively. As a significant application
example, complete memory consistency verification, which was known as an
NP-hard problem, can be solved with the complexity of $O(n^2)$ (where $n$ is
the number of operations). Moreover, the two event ordering problems, which
were proven to be Co-NP-Hard and NP-hard respectively, can both be solved with
the time complexity of O(n) if restricted by pending period information."
"A CRDT is a data type whose operations commute when they are concurrent.
Replicas of a CRDT eventually converge without any complex concurrency control.
As an existence proof, we exhibit a non-trivial CRDT: a shared edit buffer
called Treedoc. We outline the design, implementation and performance of
Treedoc. We discuss how the CRDT concept can be generalised, and its
limitations."
"The parallel ordering of large graphs is a difficult problem, because on the
one hand minimum degree algorithms do not parallelize well, and on the other
hand the obtainment of high quality orderings with the nested dissection
algorithm requires efficient graph bipartitioning heuristics, the best
sequential implementations of which are also hard to parallelize. This paper
presents a set of algorithms, implemented in the PT-Scotch software package,
which allows one to order large graphs in parallel, yielding orderings the
quality of which is only slightly worse than the one of state-of-the-art
sequential algorithms. Our implementation uses the classical nested dissection
approach but relies on several novel features to solve the parallel graph
bipartitioning problem. Thanks to these improvements, PT-Scotch produces
consistently better orderings than ParMeTiS on large numbers of processors."
"We propose a model for deterministic distributed function computation by a
network of identical and anonymous nodes, with bounded computation and storage
capabilities that do not scale with the network size. Our goal is to
characterize the class of functions that can be computed within this model. In
our main result, we exhibit a class of non-computable functions, and prove that
every function outside this class can at least be approximated. The problem of
computing averages in a distributed manner plays a central role in our
development."
"Population protocols have been introduced as a model of sensor networks
consisting of very limited mobile agents with no control over their own
movement. A population protocol corresponds to a collection of anonymous
agents, modeled by finite automata, that interact with one another to carry out
computations, by updating their states, using some rules. Their computational
power has been investigated under several hypotheses but always when restricted
to finite size populations. In particular, predicates stably computable in the
original model have been characterized as those definable in Presburger
arithmetic. We study mathematically the convergence of population protocols
when the size of the population goes to infinity. We do so by giving general
results, that we illustrate through the example of a particular population
protocol for which we even obtain an asymptotic development. This example shows
in particular that these protocols seem to have a rather different
computational power when a huge population hypothesis is considered."
"Recently, a number of cloud platforms and services have been developed for
data intensive computing, including Hadoop, Sector, CloudStore (formerly KFS),
HBase, and Thrift. In order to benchmark the performance of these systems, to
investigate their interoperability, and to experiment with new services based
on flexible compute node and network provisioning capabilities, we have
designed and implemented a large scale testbed called the Open Cloud Testbed
(OCT). Currently the OCT has 120 nodes in four data centers: Baltimore, Chicago
(two locations), and San Diego. In contrast to other cloud testbeds, which are
in small geographic areas and which are based on commodity Internet services,
the OCT is a wide area testbed and the four data centers are connected with a
high performance 10Gb/s network, based on a foundation of dedicated lightpaths.
This testbed can address the requirements of extremely large data streams that
challenge other types of distributed infrastructure. We have also developed
several utilities to support the development of cloud computing systems and
services, including novel node and network provisioning services, a monitoring
system, and a RPC system. In this paper, we describe the OCT architecture and
monitoring system. We also describe some benchmarks that we developed and some
interoperability studies we performed using these benchmarks."
"Load balancing is the process of improving the Performance of a parallel and
distributed system through is distribution of load among the processors [1-2].
Most of the previous work in load balancing and distributed decision making in
general, do not effectively take into account the uncertainty and inconsistency
in state information but in fuzzy logic, we have advantage of using crisps
inputs. In this paper, we present a new approach for implementing dynamic load
balancing algorithm with fuzzy logic, which can face to uncertainty and
inconsistency of previous algorithms, further more our algorithm shows better
response time than round robin and randomize algorithm respectively 30.84
percent and 45.45 percent."
"In this paper we present high performance dynamically allocated multi-queue
(DAMQ) buffer schemes for fault tolerance systems on chip applications that
require an interconnection network. Two or four virtual channels shared the
same buffer space. On the message switching layer, we make improvement to boost
system performance when there are faults involved in the components
communication. The proposed schemes are when a node or a physical channel is
deemed as faulty, the previous hop node will terminate the buffer occupancy of
messages destined to the failed link. The buffer usage decisions are made at
switching layer without interactions with higher abstract layer, thus buffer
space will be released to messages destined to other healthy nodes quickly.
Therefore, the buffer space will be efficiently used in case fault occurs at
some nodes."
"This keynote paper: (1) presents the 21st century vision of computing and
identifies various IT paradigms promising to deliver computing as a utility;
(2) defines the architecture for creating market-oriented Clouds and computing
atmosphere by leveraging technologies such as virtual machines; (3) provides
thoughts on market-based resource management strategies that encompass both
customer-driven service management and computational risk management to sustain
SLA-oriented resource allocation; (4) presents the work carried out as part of
our new Cloud Computing initiative, called Cloudbus: (i) Aneka, a Platform as a
Service software system containing SDK (Software Development Kit) for
construction of Cloud applications and deployment on private or public Clouds,
in addition to supporting market-oriented resource management; (ii)
internetworking of Clouds for dynamic creation of federated computing
environments for scaling of elastic applications; (iii) creation of 3rd party
Cloud brokering services for building content delivery networks and e-Science
applications and their deployment on capabilities of IaaS providers such as
Amazon along with Grid mashups; (iv) CloudSim supporting modelling and
simulation of Clouds for performance studies; (v) Energy Efficient Resource
Allocation Mechanisms and Techniques for creation and management of Green
Clouds; and (vi) pathways for future research."
"Scientific computing often requires the availability of a massive number of
computers for performing large scale experiments. Traditionally, these needs
have been addressed by using high-performance computing solutions and installed
facilities such as clusters and super computers, which are difficult to setup,
maintain, and operate. Cloud computing provides scientists with a completely
new model of utilizing the computing infrastructure. Compute resources, storage
resources, as well as applications, can be dynamically provisioned (and
integrated within the existing infrastructure) on a pay per use basis. These
resources can be released when they are no more needed. Such services are often
offered within the context of a Service Level Agreement (SLA), which ensure the
desired Quality of Service (QoS). Aneka, an enterprise Cloud computing
solution, harnesses the power of compute resources by relying on private and
public Clouds and delivers to users the desired QoS. Its flexible and service
based infrastructure supports multiple programming paradigms that make Aneka
address a variety of different scenarios: from finance applications to
computational science. As examples of scientific computing in the Cloud, we
present a preliminary case study on using Aneka for the classification of gene
expression data and the execution of fMRI brain imaging workflow."
"ScotGrid is a distributed Tier-2 centre in the UK with sites in Durham,
Edinburgh and Glasgow. ScotGrid has undergone a huge expansion in hardware in
anticipation of the LHC and now provides more than 4MSI2K and 500TB to the LHC
VOs. Scaling up to this level of provision has brought many challenges to the
Tier-2 and we show in this paper how we have adopted new methods of organising
the centres, from fabric management and monitoring to remote management of
sites to management and operational procedures, to meet these challenges. We
describe how we have coped with different operational models at the sites,
where Glagsow and Durham sites are managed ""in house"" but resources at
Edinburgh are managed as a central university resource. This required the
adoption of a different fabric management model at Edinburgh and a special
engagement with the cluster managers. Challenges arose from the different job
models of local and grid submission that required special attention to resolve.
We show how ScotGrid has successfully provided an infrastructure for ATLAS and
LHCb Monte Carlo production. Special attention has been paid to ensuring that
user analysis functions efficiently, which has required optimisation of local
storage and networking to cope with the demands of user analysis. Finally,
although these Tier-2 resources are pledged to the whole VO, we have
established close links with our local physics user communities as being the
best way to ensure that the Tier-2 functions effectively as a part of the LHC
grid computing framework.."
"The ScotGrid distributed Tier-2 now provides more that 4MSI2K and 500TB for
LHC computing, which is spread across three sites at Durham, Edinburgh and
Glasgow. Tier-2 sites have a dual role to play in the computing models of the
LHC VOs. Firstly, their CPU resources are used for the generation of Monte
Carlo event data. Secondly, the end user analysis data is distributed across
the grid to the site's storage system and held on disk ready for processing by
physicists' analysis jobs. In this paper we show how we have designed the
ScotGrid storage and data management resources in order to optimise access by
physicists to LHC data. Within ScotGrid, all sites use the gLite DPM storage
manager middleware. Using the EGEE grid to submit real ATLAS analysis code to
process VO data stored on the ScotGrid sites, we present an analysis of the
performance of the architecture at one site, and procedures that may be
undertaken to improve such. The results will be presented from the point of
view of the end user (in terms of number of events processed/second) and from
the point of view of the site, which wishes to minimise load and the impact
that analysis activity has on other users of the system."
"There is a rapid increase in the size of data centres (DCs) used to provide
cloud computing services. It is commonly agreed that not all properties in the
middleware that manages DCs will scale linearly with the number of components.
Further, ""normal failure"" complicates the assessment of the per-formance of a
DC. However, unlike in other engineering domains, there are no well established
tools that allow the prediction of the performance and behav-iour of future
generations of DCs. SPECI, Simulation Program for Elastic Cloud
Infrastructures, is a simulation tool which allows exploration of aspects of
scaling as well as performance properties of future DCs."
"Integer factorization is a very hard computational problem. Currently no
efficient algorithm for integer factorization is publicly known. However, this
is an important problem on which it relies the security of many real world
cryptographic systems.
  I present an implementation of a fast factorization algorithm on MapReduce.
MapReduce is a programming model for high performance applications developed
originally at Google. The quadratic sieve algorithm is split into the different
MapReduce phases and compared against a standard implementation."
"Contrary to the sequential world, the processes involved in a distributed
system do not necessarily know when a computation is globally finished. This
paper investigates the problem of the detection of the termination of local
computations. We define four types of termination detection: no detection,
detection of the local termination, detection by a distributed observer,
detection of the global termination. We give a complete characterisation
(except in the local termination detection case where a partial one is given)
for each of this termination detection and show that they define a strict
hierarchy. These results emphasise the difference between computability of a
distributed task and termination detection. Furthermore, these
characterisations encompass all standard criteria that are usually formulated :
topological restriction (tree, rings, or triangu- lated networks ...),
topological knowledge (size, diameter ...), and local knowledge to distinguish
nodes (identities, sense of direction). These results are now presented as
corollaries of generalising theorems. As a very special and important case, the
techniques are also applied to the election problem. Though given in the model
of local computations, these results can give qualitative insight for similar
results in other standard models. The necessary conditions involve graphs
covering and quasi-covering; the sufficient conditions (constructive local
computations) are based upon an enumeration algorithm of Mazurkiewicz and a
stable properties detection algorithm of Szymanski, Shi and Prywes."
"Cloud computing is the latest effort in delivering computing resources as a
service. It represents a shift away from computing as a product that is
purchased, to computing as a service that is delivered to consumers over the
internet from large-scale data centres - or ""clouds"". Whilst cloud computing is
gaining growing popularity in the IT industry, academia appeared to be lagging
behind the rapid developments in this field. This paper is the first systematic
review of peer-reviewed academic research published in this field, and aims to
provide an overview of the swiftly developing advances in the technical
foundations of cloud computing and their research efforts. Structured along the
technical aspects on the cloud agenda, we discuss lessons from related
technologies; advances in the introduction of protocols, interfaces, and
standards; techniques for modelling and building clouds; and new use-cases
arising through cloud computing."
"In this paper, the severity prediction of drought through the implementation
of modern sensor networks is discussed. We describe how to design a drought
prediction system using wireless sensor networks. This paper will describe a
terrestrial interconnected wireless sensor network paradigm for the prediction
of severity of drought over a vast area of 10,000 sq km. The communication
architecture for sensor network is outlined and the protocols developed for
each layer is explored. The data integration model and sensor data analysis at
the central computer is explained. The advantages and limitations are discussed
along with the use of wireless standards. They are analyzed for its relevance.
Finally a conclusion is presented along with open research issues."
"With a goal of supporting the timely and cost-effective analysis of Terabyte
datasets on commodity components, we present and evaluate StoreTorrent, a
simple distributed filesystem with integrated fault tolerance for efficient
handling of small data records. Our contributions include an application-OS
pipelining technique and metadata structure to increase small write and read
performance by a factor of 1-10, and the use of peer-to-peer communication of
replica-location indexes to avoid transferring data during parallel analysis
even in a degraded state. We evaluated StoreTorrent, PVFS, and Gluster
filesystems using 70 storage nodes and 560 parallel clients on an 8-core/node
Ethernet cluster with directly attached SATA disks. StoreTorrent performed
parallel small writes at an aggregate rate of 1.69 GB/s, and supported reads
over the network at 8.47 GB/s. We ported a parallel analysis task and
demonstrate it achieved parallel reads at the full aggregate speed of the
storage node local filesystems."
"This paper deals with generating of an optimized route for multiple Vehicle
routing Problems (mVRP). We used a methodology of clustering the given cities
depending upon the number of vehicles and each cluster is allotted to a
vehicle. k- Means clustering algorithm has been used for easy clustering of the
cities. In this way the mVRP has been converted into VRP which is simple in
computation compared to mVRP. After clustering, an optimized route is generated
for each vehicle in its allotted cluster. Once the clustering had been done and
after the cities were allocated to the various vehicles, each cluster/tour was
taken as an individual Vehicle Routing problem and the steps of Genetic
Algorithm were applied to the cluster and iterated to obtain the most optimal
value of the distance after convergence takes place. After the application of
the various heuristic techniques, it was found that the Genetic algorithm gave
a better result and a more optimal tour for mVRPs in short computational time
than other Algorithms due to the extensive search and constructive nature of
the algorithm."
"Modern large-scale date centres, such as those used for cloud computing
service provision, are becoming ever-larger as the operators of those data
centres seek to maximise the benefits from economies of scale. With these
increases in size comes a growth in system complexity, which is usually
problematic. There is an increased desire for automated ""self-star""
configuration, management, and failure-recovery of the data-centre
infrastructure, but many traditional techniques scale much worse than linearly
as the number of nodes to be managed increases. As the number of nodes in a
median-sized data-centre looks set to increase by two or three orders of
magnitude in coming decades, it seems reasonable to attempt to explore and
understand the scaling properties of the data-centre middleware before such
data-centres are constructed. In [1] we presented SPECI, a simulator that
predicts aspects of large-scale data-centre middleware performance,
concentrating on the influence of status changes such as policy updates or
routine node failures. [...]. In [1] we used a first-approximation assumption
that such subscriptions are distributed wholly at random across the data
centre. In this present paper, we explore the effects of introducing more
realistic constraints to the structure of the internal network of
subscriptions. We contrast the original results [...] exploring the effects of
making the data-centre's subscription network have a regular lattice-like
structure, and also semi-random network structures resulting from parameterised
network generation functions that create ""small-world"" and ""scale-free""
networks. We show that for distributed middleware topologies, the structure and
distribution of tasks carried out in the data centre can significantly
influence the performance overhead imposed by the middleware."
"The basic idea behind Cloud computing is that resource providers offer
elastic resources to end users. In this paper, we intend to answer one key
question to the success of Cloud computing: in Cloud, can small or medium-scale
scientific computing communities benefit from the economies of scale? Our
research contributions are three-fold: first, we propose an enhanced scientific
public cloud model (ESP) that encourages small- or medium-scale organizations
to rent elastic resources from a public cloud provider; second, on a basis of
the ESP model, we design and implement the DawningCloud system that can
consolidate heterogeneous scientific workloads on a Cloud site; third, we
propose an innovative emulation methodology and perform a comprehensive
evaluation. We found that for two typical workloads: high throughput computing
(HTC) and many task computing (MTC), DawningCloud saves the resource
consumption maximally by 44.5% (HTC) and 72.6% (MTC) for service providers, and
saves the total resource consumption maximally by 47.3% for a resource provider
with respect to the previous two public Cloud solutions. To this end, we
conclude that for typical workloads: HTC and MTC, DawningCloud can enable
scientific communities to benefit from the economies of scale of public Clouds."
"This paper examines the problem of introducing advanced forms of
fault-tolerance via reconfiguration into safety-critical avionic systems. This
is required to enable increased availability after fault occurrence in
distributed integrated avionic systems(compared to static federated systems).
The approach taken is to identify a migration path from current architectures
to those that incorporate re-configuration to a lesser or greater degree. Other
challenges identified include change of the development process; incremental
and flexible timing and safety analyses; configurable kernels applicable for
safety-critical systems."
"After decades of engineering development and infrastructural investment,
Internet connections have become commodity product in many countries, and
Internet scale ""cloud computing"" has started to compete with traditional
software business through its technological advantages and economy of scale.
Cloud computing is a promising enabling technology of Internet ware Cloud
Computing is termed as the next big thing in the modern corporate world. Apart
from the present day software and technologies, cloud computing will have a
growing impact on enterprise IT and business activities in many large
organizations. This paper provides an insight to cloud computing, its impacts
and discusses various issues that business organizations face while
implementing cloud computing. Further, it recommends various strategies that
organizations need to adopt while migrating to cloud computing. The purpose of
this paper is to develop an understanding of cloud computing in the modern
world and its impact on organizations and businesses. Initially the paper
provides a brief description of the cloud computing model introduction and its
purposes. Further it discusses various technical and non-technical issues that
need to be overcome in order for the benefits of cloud computing to be realized
in corporate businesses and organizations. It then provides various
recommendations and strategies that businesses need to work on before stepping
into new technologies."
"The Low Latency Fault Tolerance (LLFT) system provides fault tolerance for
distributed applications, using the leader-follower replication technique. The
LLFT system provides application-transparent replication, with strong replica
consistency, for applications that involve multiple interacting processes or
threads. The LLFT system comprises a Low Latency Messaging Protocol, a
Leader-Determined Membership Protocol, and a Virtual Determinizer Framework.
The Low Latency Messaging Protocol provides reliable, totally ordered message
delivery by employing a direct group-to-group multicast, where the message
ordering is determined by the primary replica in the group. The
Leader-Determined Membership Protocol provides reconfiguration and recovery
when a replica becomes faulty and when a replica joins or leaves a group, where
the membership of the group is determined by the primary replica. The Virtual
Determinizer Framework captures the ordering information at the primary replica
and enforces the same ordering at the backup replicas for major sources of
non-determinism, including multi-threading, time-related operations and socket
communication. The LLFT system achieves low latency message delivery during
normal operation and low latency reconfiguration and recovery when a fault
occurs."
"P2P overlays provide a framework for building distributed applications
consisting of few to many resources with features including self-configuration,
scalability, and resilience to node failures. Such systems have been
successfully adopted in large-scale services for content delivery networks,
file sharing, and data storage. In small-scale systems, they can be useful to
address privacy concerns and for network applications that lack dedicated
servers. The bootstrap problem, finding an existing peer in the overlay,
remains a challenge to enabling these services for small-scale P2P systems. In
large networks, the solution to the bootstrap problem has been the use of
dedicated services, though creating and maintaining these systems requires
expertise and resources, which constrain their usefulness and make them
unappealing for small-scale systems. This paper surveys and summarizes
requirements that allow peers potentially constrained by network connectivity
to bootstrap small-scale overlays through the use of existing public overlays.
In order to support bootstrapping, a public overlay must support the following
requirements: a method for reflection in order to obtain publicly reachable
addresses, so peers behind network address translators and firewalls can
receive incoming connection requests; communication relaying to share public
addresses and communicate when direct communication is not feasible; and
rendezvous for discovering remote peers, when the overlay lacks stable
membership. After presenting a survey of various public overlays, we identify
two overlays that match the requirements: XMPP overlays, such as Google Talk
and Live Journal Talk, and Brunet, a structured overlay based upon Symphony. We
present qualitative experiences with prototypes that demonstrate the ability to
bootstrap small-scale private structured overlays from public Brunet or XMPP
infrastructures."
"This paper focuses on data structures for multi-core reachability, which is a
key component in model checking algorithms and other verification methods. A
cornerstone of an efficient solution is the storage of visited states. In
related work, static partitioning of the state space was combined with
thread-local storage and resulted in reasonable speedups, but left open whether
improvements are possible. In this paper, we present a scaling solution for
shared state storage which is based on a lockless hash table implementation.
The solution is specifically designed for the cache architecture of modern
CPUs. Because model checking algorithms impose loose requirements on the hash
table operations, their design can be streamlined substantially compared to
related work on lockless hash tables. Still, an implementation of the hash
table presented here has dozens of sensitive performance parameters (bucket
size, cache line size, data layout, probing sequence, etc.). We analyzed their
impact and compared the resulting speedups with related tools. Our
implementation outperforms two state-of-the-art multi-core model checkers (SPIN
and DiVinE) by a substantial margin, while placing fewer constraints on the
load balancing and search algorithms."
"We propose a new theoretical model for passively mobile Wireless Sensor
Networks. We call it the PALOMA model, standing for PAssively mobile
LOgarithmic space MAchines. The main modification w.r.t. the Population
Protocol model is that agents now, instead of being automata, are Turing
Machines whose memory is logarithmic in the population size n. Note that the
new model is still easily implementable with current technology. We focus on
complete communication graphs. We define the complexity class PLM, consisting
of all symmetric predicates on input assignments that are stably computable by
the PALOMA model. We assume that the agents are initially identical.
Surprisingly, it turns out that the PALOMA model can assign unique consecutive
ids to the agents and inform them of the population size! This allows us to
give a direct simulation of a Deterministic Turing Machine of O(nlogn) space,
thus, establishing that any symmetric predicate in SPACE(nlogn) also belongs to
PLM. We next prove that the PALOMA model can simulate the Community Protocol
model, thus, improving the previous lower bound to all symmetric predicates in
NSPACE(nlogn). Going one step further, we generalize the simulation of the
deterministic TM to prove that the PALOMA model can simulate a Nondeterministic
TM of O(nlogn) space. Although providing the same lower bound, the important
remark here is that the bound is now obtained in a direct manner, in the sense
that it does not depend on the simulation of a TM by a Pointer Machine.
Finally, by showing that a Nondeterministic TM of O(nlogn) space decides any
language stably computable by the PALOMA model, we end up with an exact
characterization for PLM: it is precisely the class of all symmetric predicates
in NSPACE(nlogn)."
"Resource management and scheduling plays a crucial role in achieving high
utilization of resources in grid computing environments. Due to heterogeneity
of resources, scheduling an application is significantly complicated and
challenging task in grid system. Most of the researches in this area are mainly
focused on to improve the performance of the grid system. There were some
allocation model has been proposed based on divisible load theory with
different type of workloads and a single originating processor. In this paper
we introduce a new resource allocation model with multiple load originating
processors as an economic model. Solutions for an optimal allocation of
fraction of loads to nodes obtained to minimize the cost of the grid users via
linear programming approach. It is found that the resource allocation model can
efficiently and effectively allocate workloads to proper resources.
Experimental results showed that the proposed model obtained the better
solution in terms of cost and time."
"Tree-based protocols are ubiquitous in distributed systems. They are
flexible, they perform generally well, and, in static conditions, their
analysis is mostly simple. Under churn, however, node joins and failures can
have complex global effects on the tree overlays, making analysis surprisingly
subtle. To our knowledge, few prior analytic results for performance estimation
of tree based protocols under churn are currently known. We study a simple
Bellman-Ford-like protocol which performs network size estimation over a
tree-shaped overlay. A continuous time Markov model is constructed which allows
key protocol characteristics to be estimated, including the expected number of
nodes at a given (perceived) distance to the root and, for each such node, the
expected (perceived) size of the subnetwork rooted at that node. We validate
the model by simulation, using a range of network sizes, node degrees, and
churn-to-protocol rates, with convincing results."
"The condition of t-resilience stipulates that an n-process program is only
obliged to make progress when at least n-t processes are correct. Put another
way, the live sets, the collection of process sets such that progress is
required if all the processes in one of these sets are correct, are all sets
with at least n-t processes.
  We show that the ability of arbitrary collection of live sets L to solve
distributed tasks is tightly related to the minimum hitting set of L, a minimum
cardinality subset of processes that has a non-empty intersection with every
live set. Thus, finding the computing power of L is NP-complete.
  For the special case of colorless tasks that allow participating processes to
adopt input or output values of each other, we use a simple simulation to show
that a task can be solved L-resiliently if and only if it can be solved
(h-1)-resiliently, where h is the size of the minimum hitting set of L.
  For general tasks, we characterize L-resilient solvability of tasks with
respect to a limited notion of weak solvability: in every execution where all
processes in some set in L are correct, outputs must be produced for every
process in some (possibly different) participating set in L. Given a task T, we
construct another task T_L such that T is solvable weakly L-resiliently if and
only if T_L is solvable weakly wait-free."
"A self-stabilizing protocol provides by definition a tolerance to transient
failures. Recently, a new class of self-stabilizing protocols appears. These
protocols provides also a tolerance to a given number of permanent failures. In
this article, we are interested in self-stabilizing protocols that deal with
Byzantines failures. We prove that, for some problems which not allow strict
stabilization (see [Nesterenko,Arora,2002]), there exist solutions that
tolerates Byzantine faults if we define a new criteria of tolerance."
"Nowadays we are faced with an increasing popularity of social software
including wikis, blogs, micro-blogs and online social networks such as Facebook
and MySpace. Unfortunately, the mostly used social services are centralized and
personal information is stored at a single vendor. This results in potential
privacy problems as users do not have much control over how their private data
is disseminated. To overcome this limitation, some recent approaches envisioned
replacing the single authority centralization of services by a peer-to-peer
trust-based approach where users can decide with whom they want to share their
private data. In this peer-to-peer collaboration it is very difficult to ensure
that after data is shared with other peers, these peers will not misbehave and
violate data privacy. In this paper we propose a mechanism that addresses the
issue of data privacy violation due to data disclosure to malicious peers. In
our approach trust values between users are adjusted according to their
previous activities on the shared data. Users share their private data by
specifying some obligations the receivers must follow. We log modifications
done by users on the shared data as well as the obligations that must be
followed when data is shared. By a log-auditing mechanism we detect users that
misbehaved and we adjust their associated trust values by using any existing
decentralized trust model."
"In this article we present a new format for storing sparse matrices. The
format is designed to perform well mainly on the GPU devices. We present its
implementation in CUDA. The performance has been tested on 1,600 different
types of matrices and we compare our format with the Hybrid format. We give
detailed comparison of both formats and show their strong and weak parts."
"The current trend of multicore architectures on shared memory systems
underscores the need of parallelism. While there are some programming model to
express parallelism, thread programming model has become a standard to support
these system such as OpenMP, and POSIX threads. MPI (Message Passing Interface)
which remains the dominant model used in high-performance computing today faces
this challenge.
  Previous version of MPI which is MPI-1 has no shared memory concept, and
Current MPI version 2 which is MPI-2 has a limited support for shared memory
systems. In this research, MPI-2 version of MPI will be compared with OpenMP to
see how well does MPI perform on multicore / SMP (Symmetric Multiprocessor)
machines.
  Comparison between OpenMP for thread programming model and MPI for message
passing programming model will be conducted on multicore shared memory machine
architectures to see who has a better performance in terms of speed and
throughput. Application used to assess the scalability of the evaluated
parallel programming solutions is matrix multiplication with customizable
matrix dimension.
  Many research done on a large scale parallel computing which using high scale
benchmark such as NSA Parallel Benchmark (NPB) for their testing standarization
[1]. This research will be conducted on a small scale parallel computing that
emphasize more on the performance evaluation between MPI and OpenMPI parallel
programming model using self created benchmark."
"The openPC is a set of open source tools that realizes a parallel machine and
distributed computing environment divisible into several independent blocks of
nodes, and each of them is remotely but fully in any means accessible for users
with a full ownership policy. The openPC components address fundamental issues
relating to security, resource access, resource allocation, compatibilities
with heterogeneous middlewares, user-friendly and integrated web-based
interfaces, hardware control and monitoring systems. These components have been
deployed successfully to the LIPI Public Cluster which is open for public use.
In this paper, the unique characteristics of openPC due to its rare
requirements are introduced, its components and a brief performance analysis
are discussed."
"In this paper we report on our re-engineering effort to refactor and unify
two somewhat disjoint Java distributed middleware technologies -- Jini and JMS
-- used in the implementation of the Demand Migration System (DMS). In doing
so, we refactor their parent Demand Migration Framework (DMF), within the
General Intensional Programming System (GIPSY). The complex Java-based GIPSY
project is used to investigate on the intensional and hybrid programming
paradigms."
"Advances in web technologies have driven massive content uploads and requests
that can be identified by the increased usage of multimedia web and social web
services. This situation enforces the content providers to scale their
infrastructure in order to cope with the extra provisioning of network traffic,
storage and other resources. Since the complexity and cost factors in scaling
the infrastructure exist, we propose a novel solution for providing and
delivering contents to clients by introducing a brokered collaborative content
delivery system. The architectural design of this system leverages content
redundancy and content distribution mechanisms in other content providers to
deliver contents to the clients. With the recent emergence of cloud computing,
we show that this system can also be adopted to run on the cloud. In this
paper, we focus on a brokering scheme to mediate user requests to the most
appropriate content provider based on a ranking system. The architecture
provides a novel Global Rank Value (GRV) concept in estimating content provider
capability and transforming the QoS requirement of a content request. A
fairness model that will bring this design to be attractive to the current
content delivery regime is also introduced. Through simulation, we show that
using fair provider selection, contents can be provisioned by a better pool of
qualified providers thus leveraging the collaboration and preventing potential
QoS violation that may occur when the size of pool is smaller."
"We show how to extend classical work-stealing to deal also with data parallel
tasks that can require any number of threads r >= 1 for their execution. We
explain in detail the so introduced idea of work-stealing with deterministic
team-building which in a natural way generalizes classical work-stealing. A
prototype C++ implementation of the generalized work-stealing algorithm has
been given and is briefly described. Building on this, a serious, well-known
contender for a best parallel Quicksort algorithm has been implemented, which
naturally relies on both task and data parallelism. For instance, sorting
2^27-1 randomly generated integers we could improve the speed-up from 5.1 to
8.7 on a 32-core Intel Nehalem EX system, being consistently better than the
tuned, task-parallel Cilk++ system."
"Robust distributed storage systems dedicated to wireless sensor networks
utilize several nodes to redundantly store sensed data so that when some
storage nodes fail, the sensed data can still be reconstructed. For the same
level of redundancy, erasure coding based approaches are known to require less
data storage space than replication methods.
  To maintain the same level of redundancy when one storage node fails, erasure
coded data can be restored onto some other storage node by having this node
download respective pieces from other live storage nodes. Previous works showed
that the benefits in using erasure coding for robust storage over replication
are made unappealing by the complication in regenerating lost data. More recent
work has, however, shown that the bandwidth for erasure coded data can be
further reduced by proposing Regenerating Coding, making erasure codes again
desirable for robust data storage.
  But none of these works on regenerating coding consider how these codes will
perform for data regeneration in wireless sensor networks. We therefore propose
an analytical model to quantify the network lifetime gains of regenerating
coding over classical schemes. We also propose a distributed algorithm, TROY,
that determines which nodes and routes to use for data regeneration. Our
analytical studies show that for certain topologies, TROY achieves maximum
network lifetime. Our evaluation studies in real sensor network traces show
that TROY achieves near optimal lifetime and performs better than baseline
algorithms."
"In hardware virtualization a hypervisor provides multiple Virtual Machines
(VMs) on a single physical system, each executing a separate operating system
instance. The hypervisor schedules execution of these VMs much as the scheduler
in an operating system does, balancing factors such as fairness and I/O
performance. As in an operating system, the scheduler may be vulnerable to
malicious behavior on the part of users seeking to deny service to others or
maximize their own resource usage.
  Recently, publically available cloud computing services such as Amazon EC2
have used virtualization to provide customers with virtual machines running on
the provider's hardware, typically charging by wall clock time rather than
resources consumed. Under this business model, manipulation of the scheduler
may allow theft of service at the expense of other customers, rather than
merely reallocating resources within the same administrative domain.
  We describe a flaw in the Xen scheduler allowing virtual machines to consume
almost all CPU time, in preference to other users, and demonstrate kernel-based
and user-space versions of the attack. We show results demonstrating the
vulnerability in the lab, consuming as much as 98% of CPU time regardless of
fair share, as well as on Amazon EC2, where Xen modifications protect other
users but still allow theft of service. In case of EC2, following the
responsible disclosure model, we have reported this vulnerability to Amazon;
they have since implemented a fix that we have tested and verified (See
Appendix B). We provide a novel analysis of the necessary conditions for such
attacks, and describe scheduler modifications to eliminate the vulnerability.
  We present experimental results demonstrating the effectiveness of these
defenses while imposing negligible overhead."
"For popular websites most important concern is to handle incoming load
dynamically among web servers, so that they can respond to their client without
any wait or failure. Different websites use different strategies to distribute
load among web servers but most of the schemes concentrate on only one factor
that is number of requests, but none of the schemes consider the point that
different type of requests will require different level of processing efforts
to answer, status record of all the web servers that are associated with one
domain name and mechanism to handle a situation when one of the servers is not
working. Therefore, there is a fundamental need to develop strategy for dynamic
load allocation on web side. In this paper, an effort has been made to
introduce a cluster based frame work to solve load distribution problem. This
framework aims to distribute load among clusters on the basis of their
operational capabilities. Moreover, the experimental results are shown with the
help of example, algorithm and analysis of the algorithm."
"The crux of software transactional memory (STM) is to combine an easy-to-use
programming interface with an efficient utilization of the concurrent-computing
abilities provided by modern machines. But does this combination come with an
inherent cost? We evaluate the cost of concurrency by measuring the amount of
expensive synchronization that must be employed in an STM implementation that
ensures positive concurrency, i.e., allows for concurrent transaction
processing in some executions. We focus on two popular progress conditions that
provide positive concurrency: progressiveness and permissiveness. We show that
in permissive STMs, providing a very high degree of concurrency, a transaction
performs a linear number of expensive synchronization patterns with respect to
its read-set size. In contrast, progressive STMs provide a very small degree of
concurrency but, as we demonstrate, can be implemented using at most one
expensive synchronization pattern per transaction. However, we show that even
in progressive STMs, a transaction has to ""protect"" (e.g., by using locks or
strong synchronization primitives) a linear amount of data with respect to its
write-set size. Our results suggest that looking for high degrees of
concurrency in STM implementations may bring a considerable synchronization
cost."
"Aneka is an Application Platform-as-a-Service (Aneka PaaS) for Cloud
Computing. It acts as a framework for building customized applications and
deploying them on either public or private Clouds. One of the key features of
Aneka is its support for provisioning resources on different public Cloud
providers such as Amazon EC2, Windows Azure and GoGrid. In this chapter, we
will present Aneka platform and its integration with one of the public Cloud
infrastructures, Windows Azure, which enables the usage of Windows Azure
Compute Service as a resource provider of Aneka PaaS. The integration of the
two platforms will allow users to leverage the power of Windows Azure Platform
for Aneka Cloud Computing, employing a large number of compute instances to run
their applications in parallel. Furthermore, customers of the Windows Azure
platform can benefit from the integration with Aneka PaaS by embracing the
advanced features of Aneka in terms of multiple programming models, scheduling
and management services, application execution services, accounting and pricing
services and dynamic provisioning services. Finally, in addition to the Windows
Azure Platform we will illustrate in this chapter the integration of Aneka PaaS
with other public Cloud platforms such as Amazon EC2 and GoGrid, and virtual
machine management platforms such as Xen Server. The new support of
provisioning resources on Windows Azure once again proves the adaptability,
extensibility and flexibility of Aneka."
"Self-stabilization is a versatile approach to fault-tolerance since it
permits a distributed system to recover from any transient fault that
arbitrarily corrupts the contents of all memories in the system. Byzantine
tolerance is an attractive feature of distributed systems that permits to cope
with arbitrary malicious behaviors. We consider the well known problem of
constructing a maximum metric tree in this context. Combining these two
properties leads to some impossibility results. In this paper, we provide two
necessary conditions to construct maximum metric tree in presence of transients
and (permanent) Byzantine faults."
"Despite of being quite similar agreement problems, consensus and general
k-set agreement require surprisingly different techniques for proving the
impossibility in asynchronous systems with crash failures: Rather than
relatively simple bivalence arguments as in the impossibility proof for
consensus (= 1-set agreement) in the presence of a single crash failure, known
proofs for the impossibility of k-set agreement in systems with at least k>1
crash failures use algebraic topology or a variant of Sperner's Lemma. In this
paper, we present a generic theorem for proving the impossibility of k-set
agreement in various message passing settings, which is based on a simple
reduction to the consensus impossibility in a certain subsystem. We demonstrate
the broad applicability of our result by exploring the
possibility/impossibility border of k-set agreement in several message-passing
system models: (i) asynchronous systems with crash failures, (ii) partially
synchronous processes with (initial) crash failures, and (iii) asynchronous
systems augmented with failure detectors. In (i) and (ii), the impossibility
part is just an instantiation of our main theorem, whereas the possibility of
achieving k-set agreement in (ii) follows by generalizing the consensus
algorithm for initial crashes by Fisher, Lynch and Patterson. In (iii),
applying our technique yields the exact border for the parameter k where k-set
agreement is solvable with the failure detector class (Sigma_k,Omega_k), for
(1<= k<= n-1), of Bonnet and Raynal. Considering that Sigma_k was shown to be
necessary for solving k-set agreement, this result yields new insights on the
quest for the weakest failure detector."
"Linearizability is the gold standard among algorithm designers for deducing
the correctness of a distributed algorithm using implemented shared objects
from the correctness of the corresponding algorithm using atomic versions of
the same objects. We show that linearizability does not suffice for this
purpose when processes can exploit randomization, and we discuss the existence
of alternative correctness conditions."
"Distributed processing across a networked environment suffers from
unpredictable behavior of speedup due to heterogeneous nature of the hardware
and software in the remote machines. It is challenging to get a better
performance from a distributed system by distributing task in an intelligent
manner such that the heterogeneous nature of the system do not have any effect
on the speedup ratio. This paper introduces homogenization, a technique that
distributes and balances the workload in such a manner that the user gets the
highest speedup possible from a distributed environment. Along with providing
better performance, homogenization is totally transparent to the user and
requires no interaction with the system."
"A computationally intensive large job, granulized to concurrent pieces and
operating in a dynamic environment should reduce the total processing time.
However, distributing jobs across a networked environment is a tedious and
difficult task. Job distribution in a Local Area Network based on Triangular
Dynamic Architecture (TDA) is a mechanism that establishes a dynamic
environment for job distribution, load balancing and distributed processing
with minimum interaction from the user. This paper introduces TDA and discusses
its architecture and shows the benefits gained by utilizing such architecture
in a distributed computing environment."
"Load balancing across a networked environment is a monotonous job. Moreover,
if the job to be distributed is a constraint satisfying one, the distribution
of load demands core intelligence. This paper proposes parallel processing
through Global Evaluation Function by means of randomly initialized agents for
solving Constraint Satisfaction Problems. A potential issue about the number of
agents in a machine under the invocation of distribution is discussed here for
securing the maximum benefit from Global Evaluation and parallel processing.
The proposed system is compared with typical solution that shows an exclusive
outcome supporting the nobility of parallel implementation of Global Evaluation
Function with certain number of agents in each invoked machine."
"This paper is concerned with the problem of implementing an unbounded
timestamp object from multi-writer atomic registers, in an asynchronous
distributed system of n processors with distinct identifiers where timestamps
are taken from an arbitrary universe. Ellen, Fatourou and Ruppert (2008) showed
that sqrt{n}/2-O(1) registers are required for any obstruction-free
implementation of long-lived timestamp systems from atomic registers (meaning
processors can repeatedly get timestamps). We improve this existing lower bound
in two ways. First we establish a lower bound of n/6 - O(1) registers for the
obstruction-free long-lived timestamp problem. Previous such linear lower
bounds were only known for constrained versions of the timestamp problem. This
bound is asymptotically tight; Ellen, Fatourou and Ruppert (2008) constructed a
wait-free algorithm that uses n-1 registers. Second we show that sqrt{n} - O(1)
registers are required for any obstruction-free implementation of one-shot
timestamp systems(meaning each processor can get a timestamp at most once). We
show that this bound is also asymptotically tight by providing a wait-free
one-shot timestamp system that uses fewer than 2 sqrt{n} registers, thus
establishing a space complexity gap between one-shot and long-lived timestamp
systems."
"The simple program and multiple data (SPMD) programming model is widely used
for both high performance computing and Cloud computing. In this paper, we
design and implement an innovative system, AutoAnalyzer, that automates the
process of debugging performance problems of SPMD-style parallel programs,
including data collection, performance behavior analysis, locating bottlenecks,
and uncovering their root causes. AutoAnalyzer is unique in terms of two
features: first, without any apriori knowledge, it automatically locates
bottlenecks and uncovers their root causes for performance optimization;
second, it is lightweight in terms of the size of performance data to be
collected and analyzed. Our contributions are three-fold: first, we propose two
effective clustering algorithms to investigate the existence of performance
bottlenecks that cause process behavior dissimilarity or code region behavior
disparity, respectively; meanwhile, we present two searching algorithms to
locate bottlenecks; second, on a basis of the rough set theory, we propose an
innovative approach to automatically uncovering root causes of bottlenecks;
third, on the cluster systems with two different configurations, we use two
production applications, written in Fortran 77, and one open source
code-MPIBZIP2 (http://compression.ca/mpibzip2/), written in C++, to verify the
effectiveness and correctness of our methods. For three applications, we also
propose an experimental approach to investigating the effects of different
metrics on locating bottlenecks."
"The memory consistency model is a fundamental system property characterizing
a multiprocessor. The relative merits of strict versus relaxed memory models
have been widely debated in terms of their impact on performance, hardware
complexity and programmability. This paper adds a new dimension to this
discussion: the impact of memory models on software reliability. By allowing
some instructions to reorder, weak memory models may expand the window between
critical memory operations. This can increase the chance of an undesirable
thread-interleaving, thus allowing an otherwise-unlikely concurrency bug to
manifest. To explore this phenomenon, we define and study a probabilistic model
of shared-memory parallel programs that takes into account such reordering. We
use this model to formally derive bounds on the \emph{vulnerability} to
concurrency bugs of different memory models. Our results show that for 2 (or a
small constant number of) concurrent threads, weaker memory models do indeed
have a higher likelihood of allowing bugs. On the other hand, we show that as
the number of parallel threads increases, the gap between the different memory
models becomes proportionally insignificant. This suggests the
counter-intuitive rule that \emph{as the number of parallel threads in the
system increases, the importance of using a strict memory model diminishes};
which potentially has major implications on the choice of memory consistency
models in future multi-core systems."
"This paper describes two tools that aim to support decision making during the
migration of IT systems to the cloud. The first is a modeling tool that
produces cost estimates of using public IaaS clouds. The tool enables IT
architects to model their applications, data and infrastructure requirements in
addition to their computational resource usage patterns. The tool can be used
to compare the cost of different cloud providers, deployment options and usage
scenarios. The second tool is a spreadsheet that outlines the benefits and
risks of using IaaS clouds from an enterprise perspective; this tool provides a
starting point for risk assessment. Two case studies were used to evaluate the
tools. The tools were useful as they informed decision makers about the costs,
benefits and risks of using the cloud."
"We put forward a formal model of anonymous systems. And we concentrate on the
anonymous failure detectors in our model. In particular, we give three examples
of anonymous failure detectors and show that they can be used to solve the
consensus problem and that they are equivalent to their classic counterparts.
Moreover, we show some relationship among them and provide a simple
classification of anonymous failure detectors."
"This paper presents an analytical framework to model fault-tolerance in
unstructured peer-to-peer overlays, represented as complex networks. We define
a distributed protocol peers execute for managing the overlay and reacting to
node faults. Based on the protocol, evolution equations are defined and
manipulated by resorting to generating functions. Obtained outcomes provide
insights on the nodes' degree probability distribution. From the study of the
degree distribution, it is possible to estimate other important metrics of the
peer-to-peer overlay, such as the diameter of the network. We study different
networks, characterized by three specific desired degree distributions, i.e.
nets with nodes having a fixed desired degree, random graphs and scale-free
networks. All these networks are assessed via the analytical tool and
simulation as well. Results show that the approach can be factually employed to
dynamically tune the average attachment rate at peers so that they maintain
their own desired degree and, in general, the desired network topology."
"Position verification in wireless sensor networks (WSNs) is quite tricky in
presence of attackers (malicious sensor nodes), who try to break the
verification protocol by reporting their incorrect positions (locations) during
the verification stage. In the literature of WSNs, most of the existing methods
of position verification have used trusted verifiers, which are in fact
vulnerable to attacks by malicious nodes. They also depend on some distance
estimation techniques, which are not accurate in noisy channels (mediums). In
this article, we propose a secure position verification scheme for WSNs in
noisy channels without relying on any trusted entities. Our verification scheme
detects and filters out all malicious nodes from the network with very high
probability."
"We consider the problem of distributed average consensus in a sensor network
where sensors exchange quantized information with their neighbors. We propose a
novel quantization scheme that exploits the increasing correlation between the
values exchanged by the sensors throughout the iterations of the consensus
algorithm. A low complexity, uniform quantizer is implemented in each sensor,
and refined quantization is achieved by progressively reducing the quantization
intervals during the convergence of the consensus algorithm. We propose a
recurrence relation for computing the quantization parameters that depend on
the network topology and the communication rate. We further show that the
recurrence relation can lead to a simple exponential model for the size of the
quantization step size over the iterations, whose parameters can be computed a
priori. Finally, simulation results demonstrate the effectiveness of the
progressive quantization scheme that leads to the consensus solution even at
low communication rate."
"We present a randomized distributed approximation algorithm for the metric
uncapacitated facility location problem. The algorithm is executed on a
bipartite graph in the Congest model yielding a (1.861 + epsilon) approximation
factor, where epsilon is an arbitrary small positive constant. It needs
O(n^{3/4}log_{1+epsilon}^2(n) communication rounds with high probability (n
denoting the number of facilities and clients). To the best of our knowledge,
our algorithm currently has the best approximation factor for the facility
location problem in a distributed setting. It is based on a greedy sequential
approximation algorithm by Jain et al. (J. ACM 50(6), pages: 795-824, 2003).
The main difficulty in executing this sequential algorithm lies in dealing with
situations, where multiple facilities are eligible for opening, but (in order
to preserve the approximation factor of the sequential algorithm) only a subset
of them can actually be opened. Note that while the presented runtime bound of
our algorithm is ""with high probability"", the approximation factor is not ""in
expectation"" but always guaranteed to be (1.861 + epsilon). Thus, our main
contribution is a sublinear time selection mechanism that, while increasing the
approximation factor by an arbitrary small additive term, allows us to decide
which of the eligible facilities to open."
"Cloud computing has made it possible for a user to be able to select a
computing service precisely when needed. However, certain factors such as
security of data and regulatory issues will impact a user's choice of using
such a service. A solution to these problems is the use of a hybrid cloud that
combines a user's local computing capabilities (for mission- or
organization-critical tasks) with a public cloud (for less influential tasks).
We foresee three challenges that must be overcome before the adoption of a
hybrid cloud approach: 1) data design: How to partition relations in a hybrid
cloud? The solution to this problem must account for the sensitivity of
attributes in a relation as well as the workload of a user; 2) data security:
How to protect a user's data in a public cloud with encryption while enabling
query processing over this encrypted data? and 3) query processing: How to
execute queries efficiently over both, encrypted and unencrypted data? This
paper addresses these challenges and incorporates their solutions into an
add-on tool for a Hadoop and Hive based cloud computing infrastructure."
"As a result of the phenomenal proliferation of modern mobile Internet-enabled
devices and the widespread utilization of wireless and cellular data networks,
mobile users are increasingly requiring services tailored to their current
context. High-level context information is typically obtained from context
services that aggregate raw context information sensed by various sensors and
mobile devices. Given the massive amount of sensed data, traditional context
services are lacking the necessary resources to store and process these data,
as well as to disseminate high-level context information to a variety of
potential context consumers. In this paper, we propose a novel framework for
context information provisioning, which relies on deploying context services on
the cloud and using context brokers to mediate between context consumers and
context services using a publish/subscribe model. Moreover, we describe a
multi-attributes decision algorithm for the selection of potential context
services that can fulfill context consumers' requests for context information.
The algorithm calculates the score of each context service, per context
information type, based on the quality-of-service (QoS) and quality-of-context
information (QoC) requirements expressed by the context consumer. One of the
benefits of the approach is that context providers can scale up and down, in
terms of cloud resources they use, depending on current demand for context
information. Besides, the selection algorithm allows ranking context services
by matching their QoS and QoC offers against the QoS and QoC requirements of
the context consumer."
"In this tutorial paper, we will firstly review some basic simulation concepts
and then introduce the parallel and distributed simulation techniques in view
of some new challenges of today and tomorrow. More in particular, in the last
years there has been a wide diffusion of many cores architectures and we can
expect this trend to continue. On the other hand, the success of cloud
computing is strongly promoting the everything as a service paradigm. Is
parallel and distributed simulation ready for these new challenges? The current
approaches present many limitations in terms of usability and adaptivity: there
is a strong need for new evaluation metrics and for revising the currently
implemented mechanisms. In the last part of the paper, we propose a new
approach based on multi-agent systems for the simulation of complex systems. It
is possible to implement advanced techniques such as the migration of simulated
entities in order to build mechanisms that are both adaptive and very easy to
use. Adaptive mechanisms are able to significantly reduce the communication
cost in the parallel/distributed architectures, to implement load-balance
techniques and to cope with execution environments that are both variable and
dynamic. Finally, such mechanisms will be used to build simulations on top of
unreliable cloud services."
"At present there are a number of barriers to creating an energy efficient
workload scheduler for a Private Cloud based data center. Firstly, the
relationship between different workloads and power consumption must be
investigated. Secondly, current hardware-based solutions to providing energy
usage statistics are unsuitable in warehouse scale data centers where low cost
and scalability are desirable properties. In this paper we discuss the effect
of different workloads on server power consumption in a Private Cloud platform.
We display a noticeable difference in energy consumption when servers are given
tasks that dominate various resources (CPU, Memory, Hard Disk and Network). We
then use this insight to develop CloudMonitor, a software utility that is
capable of >95% accurate power predictions from monitoring resource consumption
of workloads, after a ""training phase"" in which a dynamic power model is
developed."
"Nowadays, the High Performance Computing is part of the context of embedded
systems. Graphics Processing Units (GPUs) are more and more used in
acceleration of the most part of algorithms and applications. Over the past
years, not many efforts have been done to describe abstractions of applications
in relation to their target architectures. Thus, when developers need to
associate applications and GPUs, for example, they find difficulty and prefer
using API for these architectures. This paper presents a metamodel extension
for MARTE profile and a model for GPU architectures. The main goal is to
specify the task and data allocation in the memory hierarchy of these
architectures. The results show that this approach will help to generate code
for GPUs based on model transformations using Model Driven Engineering (MDE)."
"In this paper, we consider the problem of formation of a series of geometric
patterns [4] by a network of oblivious mobile robots that communicate only
through vision. So far, the problem has been studied in models where robots are
either assumed to have distinct identifiers or to be completely anonymous. To
generalize these results and to better understand how anonymity affects the
computational power of robots, we study the problem in a new model, introduced
recently in [5], in which n robots may share up to 1 <= h <= n different
identifiers. We present necessary and sufficient conditions, relating
symmetricity and homonymy, that makes the problem solvable. We also show that
in the case where h = n, making the identifiers of robots invisible does not
limit their computational power. This contradicts a result of [4]. To present
our algorithms, we use a function that computes the Weber point for many
regular and symmetric configurations. This function is interesting in its own
right, since the problem of finding Weber points has been solved up to now for
only few other patterns."
"Message Passing Interface (MPI) is widely used to implement parallel
programs. Although Windowsbased architectures provide the facilities of
parallel execution and multi-threading, little attention has been focused on
using MPI on these platforms. In this paper we use the dual core Window-based
platform to study the effect of parallel processes number and also the number
of cores on the performance of three MPI parallel implementations for some
sorting algorithms."
"The electrical and electronic engineering has used parallel programming to
solve its large scale complex problems for performance reasons. However, as
parallel programming requires a non-trivial distribution of tasks and data,
developers find it hard to implement their applications effectively. Thus, in
order to reduce design complexity, we propose an approach to generate code for
hybrid architectures (e.g. CPU + GPU) using OpenCL, an open standard for
parallel programming of heterogeneous systems. This approach is based on Model
Driven Engineering (MDE) and the MARTE profile, standard proposed by Object
Management Group (OMG). The aim is to provide resources to non-specialists in
parallel programming to implement their applications. Moreover, thanks to model
reuse capacity, we can add/change functionalities or the target architecture.
Consequently, this approach helps industries to achieve their time-to-market
constraints and confirms by experimental tests, performance improvements using
multi-GPU environments."
"Task reassignments in 2D mesh-connected systems (2D-MSs) have been researched
for several decades. We propose a hierarchical 2D mesh-connected system
(2D-HMS) in order to exploit the regular nature of a 2D-MS. In our approach
priority-based task assignments and reassignments in a 2D-HMS are represented
by tableaux and their algorithms. We show how task relocations for a
priority-based task reassignment in a 2D-HMS are reduced to a jeu de taquin
slide."
"We present and analyze a wait-free deterministic algorithm for solving the
at-most-once problem: how m shared-memory fail-prone processes perform
asynchronously n jobs at most once. Our algorithmic strategy provides for the
first time nearly optimal effectiveness, which is a measure that expresses the
total number of jobs completed in the worst case. The effectiveness of our
algorithm equals n-2m+2. This is up to an additive factor of m close to the
known effectiveness upper bound n-m+1 over all possible algorithms and improves
on the previously best known deterministic solutions that have effectiveness
only n-log m o(n). We also present an iterative version of our algorithm that
for any $m = O\left(\sqrt[3+\epsilon]{n/\log n}\right)$ is both
effectiveness-optimal and work-optimal, for any constant $\epsilon > 0$. We
then employ this algorithm to provide a new algorithmic solution for the
Write-All problem which is work optimal for any
$m=O\left(\sqrt[3+\epsilon]{n/\log n}\right)$."
"Distributed data storage systems are essential to deal with the need to store
massive volumes of data. In order to make such a system fault-tolerant, some
form of redundancy becomes crucial, incurring various overheads - most
prominently in terms of storage space and maintenance bandwidth requirements.
Erasure codes, originally designed for communication over lossy channels,
provide a storage efficient alternative to replication based redundancy,
however entailing high communication overhead for maintenance, when some of the
encoded fragments need to be replenished in news ones after failure of some
storage devices. We propose as an alternative a new family of erasure codes
called self-repairing codes (SRC) taking into account the peculiarities of
distributed storage systems, specifically the maintenance process. SRC has the
following salient features: (a) encoded fragments can be repaired directly from
other subsets of encoded fragments by downloading less data than the size of
the complete object, ensuring that (b) a fragment is repaired from a fixed
number of encoded fragments, the number depending only on how many encoded
blocks are missing and independent of which specific blocks are missing. This
paper lays the foundations by defining the novel self-repairing codes,
elaborating why the defined characteristics are desirable for distributed
storage systems. Then homomorphic self-repairing codes (HSRC) are proposed as a
concrete instance, whose various aspects and properties are studied and
compared - quantitatively or qualitatively with respect to other codes
including traditional erasure codes as well as other recent codes designed
specifically for storage applications."
"Classical list scheduling is a very popular and efficient technique for
scheduling jobs in parallel and distributed platforms. It is inherently
centralized. However, with the increasing number of processors, the cost for
managing a single centralized list becomes too prohibitive. A suitable approach
to reduce the contention is to distribute the list among the computational
units: each processor has only a local view of the work to execute. Thus, the
scheduler is no longer greedy and standard performance guarantees are lost.
  The objective of this work is to study the extra cost that must be paid when
the list is distributed among the computational units. We first present a
general methodology for computing the expected makespan based on the analysis
of an adequate potential function which represents the load unbalance between
the local lists. We obtain an equation on the evolution of the potential by
computing its expected decrease in one step of the schedule. Our main theorem
shows how to solve such equations to bound the makespan. Then, we apply this
method to several scheduling problems, namely, for unit independent tasks, for
weighted independent tasks and for tasks with precendence constraints. More
precisely, we prove that the time for scheduling a global workload W composed
of independent unit tasks on m processors is equal to W/m plus an additional
term proportional to log_2 W. We provide a lower bound which shows that this is
optimal up to a constant. This result is extended to the case of weighted
independent tasks. In the last setting, precedence task graphs, our analysis
leads to an improvement on the bound of Arora et al. We finally provide some
experiments using a simulator. The distribution of the makespan is shown to fit
existing probability laws. The additive term is shown by simulation to be
around 3 \log_2 W confirming the tightness of our analysis."
"In this paper, we consider the message forwarding problem that consists in
managing the network resources that are used to forward messages. Previous
works on this problem provide solutions that either use a significant number of
buffers (that is n buffers per processor, where n is the number of processors
in the network) making the solution not scalable or, they reserve all the
buffers from the sender to the receiver to forward only one message %while
using D buffers (where D refers to the diameter of the network) . The only
solution that uses a constant number of buffers per link was introduced in [1].
However the solution works only on a chain networks. In this paper, we propose
a snap-stabilizing algorithm for the message forwarding problem that uses the
same complexity on the number of buffers as [1] and works on tree topologies."
"High fidelity simulation of large-sized complex networks can be realized on a
distributed computing platform that leverages the combined resources of
multiple processors or machines. In a discrete event driven simulation, the
assignment of logical processes (LPs) to machines is a critical step that
affects the computational and communication burden on the machines, which in
turn affects the simulation execution time of the experiment. We study a
network partitioning game wherein each node (LP) acts as a selfish player. We
derive two local node-level cost frameworks which are feasible in the sense
that the aggregate state information required to be exchanged between the
machines is independent of the size of the simulated network model. For both
cost frameworks, we prove the existence of stable Nash equilibria in pure
strategies. Using iterative partition improvements, we propose game theoretic
partitioning algorithms based on the two cost criteria and show that each
descends in a global cost. To exploit the distributed nature of the system, the
algorithm is distributed, with each node's decision based on its local
information and on a few global quantities which can be communicated
machine-to-machine. We demonstrate the performance of our partitioning
algorithm on an optimistic discrete event driven simulation platform that
models an actual parallel simulator."
"We present a simple, parallel and distributed algorithm for setting up and
partitioning a sparse representation of a regular discretized simulation
domain. This method is scalable for a large number of processes even for
complex geometries and ensures load balance between the domains, reasonable
communication interfaces, and good data locality within the domain. Applying
this scheme to a list-based lattice Boltzmann flow solver can achieve similar
or even higher flow solver performance than widely used standard graph
partition based tools such as METIS and PT-SCOTCH."
"To support developers in writing reliable and efficient concurrent programs,
novel concurrent programming abstractions have been proposed in recent years.
Programming with such abstractions requires new analysis tools because the
execution semantics often differs considerably from established models. We
present a record-replay technique for programs written in SCOOP, an
object-oriented programming model for concurrency. The resulting tool enables
developers to reproduce the nondeterministic execution of a concurrent program,
a necessary prerequisite for debugging and testing."
"A method for selecting the best service for the storage of information by
Mamdani."
"It is very challenging part to keep safely all required data that are needed
in many applications for user in cloud. Storing our data in cloud may not be
fully trustworthy. Since client doesn't have copy of all stored data, he has to
depend on Cloud Service Provider. But dynamic data operations, Read-Solomon and
verification token construction methods don't tell us about total storage
capacity of server allocated space before and after the data addition in cloud.
So we have to introduce a new proposed system of efficient storage measurement
and space comparison algorithm with time management for measuring the total
allocated storage area before and after the data insertion in cloud. So by
using our proposed scheme, the value or weight of stored data before and after
is measured by client with specified time in cloud storage area with accuracy.
And here we also have proposed the multi-server restore point in server failure
condition. If there occurs any server failure, by using this scheme the data
can be recovered automatically in cloud server. Our proposed scheme efficiently
checks space for the in-outsourced data to maintain integrity. Here the TPA
necessarily doesn't have the delegation to audit user's data."
"It is not an easy task to securely maintain all essential data where it has
the need in many applications for clients in cloud. To maintain our data in
cloud, it may not be fully trustworthy because client doesn't have copy of all
stored data. But any authors don't tell us data integrity through its user and
CSP level by comparison before and after the data update in cloud. So we have
to establish new proposed system for this using our data reading protocol
algorithm to check the integrity of data before and after the data insertion in
cloud. Here the security of data before and after is checked by client with the
help of CSP using our ""effective automatic data reading protocol from user as
well as cloud level into the cloud"" with truthfulness. Also we have proposed
the multi-server data comparison algorithm with the calculation of overall data
in each update before its outsourced level for server restore access point for
future data recovery from cloud data server. Our proposed scheme efficiently
checks integrity in efficient manner so that data integrity as well as security
can be maintained in all cases by considering drawbacks of existing methods."
"The proliferation of sensing and monitoring applications motivates adoption
of the event stream model of computation. Though sliding windows are widely
used to facilitate effective event stream processing, it is greatly challenged
when the event sources are distributed and asynchronous. To address this
challenge, we first show that the snapshots of the asynchronous event streams
within the sliding window form a convex distributive lattice (denoted by
Lat-Win). Then we propose an algorithm to maintain Lat-Win at runtime. The
Lat-Win maintenance algorithm is implemented and evaluated on the open-source
context-aware middleware we developed. The evaluation results first show the
necessity of adopting sliding windows over asynchronous event streams. Then
they show the performance of detecting specified predicates within Lat-Win,
even when faced with dynamic changes in the computing environment."
"Data inconsistencies are present in the data collected over a large wireless
sensor network (WSN), usually deployed for any kind of monitoring applications.
Before passing this data to some WSN applications for decision making, it is
necessary to ensure that the data received are clean and accurate. In this
paper, we have used a statistical tool to examine the past data to fit in a
highly sophisticated prediction model i.e., ARIMA for a given sensor node and
with this, the model corrects the data using forecast value if any data anomaly
exists there. Another scheme is also proposed for detecting data anomaly at
sink among the aggregated data in the data are received from a particular
sensor node. The effectiveness of our methods are validated by data collected
over a real WSN application consisting of Crossbow IRIS Motes
\cite{Crossbow:2009}."
"The ever increasing demands for using resource-constrained mobile devices for
running more resource intensive applications nowadays has initiated the
development of cyber foraging solutions that offload parts or whole
computational intensive tasks to more powerful surrogate stationary computers
and run them on behalf of mobile devices as required. The choice of proper mix
of mobile devices and surrogates has remained an unresolved challenge though.
In this paper, we propose a new decision-making mechanism for cyber foraging
systems to select the best locations to run an application, based on context
metrics such as the specifications of surrogates, the specifications of mobile
devices, application specification, and communication network specification.
Experimental results show faster response time and lower energy consumption of
benched applications compared to when applications run wholly on mobile devices
and when applications are offloaded to surrogates blindly for execution."
"Unions of graph multiplier operators are an important class of linear
operators for processing signals defined on graphs. We present a novel method
to efficiently distribute the application of these operators. The proposed
method features approximations of the graph multipliers by shifted Chebyshev
polynomials, whose recurrence relations make them readily amenable to
distributed computation. We demonstrate how the proposed method can be applied
to distributed processing tasks such as smoothing, denoising, inverse
filtering, and semi-supervised classification, and show that the communication
requirements of the method scale gracefully with the size of the network."
"Twisted hypercube-like networks (THLNs) are an important class of
interconnection networks for parallel computing systems, which include most
popular variants of the hypercubes, such as crossed cubes, M\""obius cubes,
twisted cubes and locally twisted cubes. This paper deals with the
fault-tolerant hamiltonian connectivity of THLNs under the large fault model.
Let $G$ be an $n$-dimensional THLN and $F \subseteq V(G)\bigcup E(G)$, where $n
\geq 7$ and $|F| \leq 2n - 10$. We prove that for any two nodes $u,v \in V(G -
F)$ satisfying a simple necessary condition on neighbors of $u$ and $v$, there
exists a hamiltonian or near-hamiltonian path between $u$ and $v$ in $G-F$. The
result extends further the fault-tolerant graph embedding capability of THLNs."
"Partial mutual exclusion is the drinking philosophers problem for complete
graphs. It is the problem that a process may enter a critical section CS of its
code only when some finite set nbh of other processes are not in their critical
sections. For each execution of CS, the set nbh can be given by the
environment. We present a starvation free solution of this problem in a setting
with infinitely many processes, each with finite memory, that communicate by
asynchronous messages. The solution has the property of first-come
first-served, in so far as this can be guaranteed by asynchronous messages. For
every execution of CS and every process in nbh, between three and six messages
are needed. The correctness of the solution is argued with invariants and
temporal logic. It has been verified with the proof assistant PVS."
"This whitepaper describes the load-balancing performance issues that are
observed and tackled during the petascaling of the Vlasiator codes. Vlasiator
is a Vlasov-hybrid simulation code developed in Finnish Meteorological
Institute (FMI). Vlasiator models the communications associated with the
spatial grid operated on as a hypergraph and partitions the grid using the
parallel hypergraph partitioning scheme (PHG) of the Zoltan partitioning
framework. The result of partitioning determines the distribution of grid cells
to processors. It is observed that the partitioning phase takes a substantial
percentage of the overall computation time. Alternative
(graph-partitioning-based) schemes that perform almost as well as the
hypergraph partitioning scheme and that require less preprocessing overhead and
better balance are proposed and investigated. A comparison in terms of effect
on running time, preprocessing overhead and load-balancing quality of Zoltan's
PHG, ParMeTiS, and PT-SCOTCH are presented. Test results on J\""uelich
BlueGene/P cluster are presented."
"Multi-stage interconnection networks (MIN) can be designed to achieve fault
tolerance and collision solving by providing a set of disjoint paths. In this
paper, we are discussing the new simulator added to the tool designed for
developing fault tolerant MINs. The designed tool is one of its own kind and
will help the user in developing 2 and 3-disjoint path networks. The java
technology has been used to design the tool and have been tested on different
software platform."
"Consumption of online services and cloud computing offerings is on the rise,
largely due to compelling advantages over traditional local applications. From
a user perspective, these include zero-maintenance of software, the always-on
nature of such services, mashups of different applications and the networking
effect with other users. Associated disadvantages are known, but effective
means and tools to limit their effect are not yet well-established and not yet
generally available to service users. We propose (1) a user-centric model of
cloud elements beyond the conventional <SPI>aaS layers, including activities
across trust zones, and (2) a personal control console for all individual and
collaborative user activities in the cloud."
"The research paper emphasizes that the Stable Matching problems are the same
as the problems of stable configurations of Multi-stage Interconnection
Networks (MIN). We have discusses the Stability Problems of Existing Regular
Omega Multi-stage Interconnection Network (OMIN) and Proposed 3-Disjoint Paths
Omega Multi-stage Interconnection Network (3DON) using the approaches and
solutions provided by the Stable Matching Problem. Specifically, Stable
Marriage Problem is used as an example of Stable Matching. On application of
the concept of the Stable Marriage over the MINs states that OMIN is highly
stable in comparison to 3DON."
"The traditional models of distributed computing focus mainly on networks of
computer-like devices that can exchange large messages with their neighbors and
perform arbitrary local computations. Recently, there is a trend to apply
distributed computing methods to networks of sub-microprocessor devices, e.g.,
biological cellular networks or networks of nano-devices. However, the
suitability of the traditional distributed computing models to these types of
networks is questionable: do tiny bio/nano nodes ""compute"" and/or ""communicate""
essentially the same as a computer? In this paper, we introduce a new model
that depicts a network of randomized finite state machines operating in an
asynchronous environment. Although the computation and communication
capabilities of each individual device in the new model are, by design, much
weaker than those of a computer, we show that some of the most important and
extensively studied distributed computing problems can still be solved
efficiently."
"Symmetry breaking problems are among the most well studied in the field of
distributed computing and yet the most fundamental questions about their
complexity remain open. In this paper we work in the LOCAL model (where the
input graph and underlying distributed network are identical) and study the
randomized complexity of four fundamental symmetry breaking problems on graphs:
computing MISs (maximal independent sets), maximal matchings, vertex colorings,
and ruling sets. A small sample of our results includes
  - An MIS algorithm running in $O(\log^2\Delta + 2^{O(\sqrt{\log\log n})})$
time, where $\Delta$ is the maximum degree. This is the first MIS algorithm to
improve on the 1986 algorithms of Luby and Alon, Babai, and Itai, when $\log n
\ll \Delta \ll 2^{\sqrt{\log n}}$, and comes close to the $\Omega(\log \Delta)$
lower bound of Kuhn, Moscibroda, and Wattenhofer.
  - A maximal matching algorithm running in $O(\log\Delta + \log^4\log n)$
time. This is the first significant improvement to the 1986 algorithm of
Israeli and Itai. Moreover, its dependence on $\Delta$ is provably optimal.
  - A method for reducing symmetry breaking problems in low
arboricity/degeneracy graphs to low degree graphs. (Roughly speaking, the
arboricity or degeneracy of a graph bounds the density of any subgraph.)
Corollaries of this reduction include an $O(\sqrt{\log n})$-time maximal
matching algorithm for graphs with arboricity up to $2^{\sqrt{\log n}}$ and an
$O(\log^{2/3} n)$-time MIS algorithm for graphs with arboricity up to $2^{(\log
n)^{1/3}}$.
  Each of our algorithms is based on a simple, but powerful technique for
reducing a randomized symmetry breaking task to a corresponding deterministic
one on a poly$(\log n)$-size graph."
"The dynamic provisioning of virtualized resources offered by cloud computing
infrastructures allows applications deployed in a cloud environment to
automatically increase and decrease the amount of used resources. This
capability is called auto-scaling and its main purpose is to automatically
adjust the scale of the system that is running the application to satisfy the
varying workload with minimum resource utilization. The need for auto-scaling
is particularly important during workload peaks, in which applications may need
to scale up to extremely large-scale systems.
  Both the research community and the main cloud providers have already
developed auto-scaling solutions. However, most research solutions are
centralized and not suitable for managing large-scale systems, moreover cloud
providers' solutions are bound to the limitations of a specific provider in
terms of resource prices, availability, reliability, and connectivity.
  In this paper we propose DEPAS, a decentralized probabilistic auto-scaling
algorithm integrated into a P2P architecture that is cloud provider
independent, thus allowing the auto-scaling of services over multiple cloud
infrastructures at the same time. Our simulations, which are based on real
service traces, show that our approach is capable of: (i) keeping the overall
utilization of all the instantiated cloud resources in a target range, (ii)
maintaining service response times close to the ones obtained using optimal
centralized auto-scaling approaches."
"In this paper we present a new simulation model designed to evaluate the
dependability in distributed systems. This model extends the MONARC simulation
model with new capabilities for capturing reliability, safety, availability,
security, and maintainability requirements. The model has been implemented as
an extension of the multithreaded, process oriented simulator MONARC, which
allows the realistic simulation of a wide-range of distributed system
technologies, with respect to their specific components and characteristics.
The extended simulation model includes the necessary components to inject
various failure events, and provides the mechanisms to evaluate different
strategies for replication, redundancy procedures, and security enforcement
mechanisms, as well. The results obtained in simulation experiments presented
in this paper probe that the use of discrete-event simulators, such as MONARC,
in the design and development of distributed systems is appealing due to their
efficiency and scalability."
"A major impediment towards the industrial adoption of decentralized
distributed systems comes from the difficulty to theoretically prove that these
systems exhibit the required behavior. In this paper, we use probability theory
to analyze a decentralized auto-scaling algorithm in which each node
probabilistically decides to scale in or out. We prove that, in the context of
dynamic workloads, the average load of the system is maintained within a
variation interval with a given probability, provided that the number of nodes
and the variation interval length are higher than certain bounds. The paper
also proposes numerical algorithms for approximating these minimum bounds."
"This paper shows for the first time that distributed computing can be both
reliable and efficient in an environment that is both highly dynamic and
hostile. More specifically, we show how to maintain clusters of size $O(\log
N)$, each containing more than two thirds of honest nodes with high
probability, within a system whose size can vary \textit{polynomially} with
respect to its initial size. Furthermore, the communication cost induced by
each node arrival or departure is polylogarithmic with respect to $N$, the
maximal size of the system. Our clustering can be achieved despite the presence
of a Byzantine adversary controlling a fraction $\bad \leq \{1}{3}-\epsilon$ of
the nodes, for some fixed constant $\epsilon > 0$, independent of $N$. So far,
such a clustering could only be performed for systems who size can vary
constantly and it was not clear whether that was at all possible for polynomial
variances."
"Massively multicore processors, such as Graphics Processing Units (GPUs),
provide, at a comparable price, a one order of magnitude higher peak
performance than traditional CPUs. This drop in the cost of computation, as any
order-of-magnitude drop in the cost per unit of performance for a class of
system components, triggers the opportunity to redesign systems and to explore
new ways to engineer them to recalibrate the cost-to-performance relation. This
project explores the feasibility of harnessing GPUs' computational power to
improve the performance, reliability, or security of distributed storage
systems. In this context, we present the design of a storage system prototype
that uses GPU offloading to accelerate a number of computationally intensive
primitives based on hashing, and introduce techniques to efficiently leverage
the processing power of GPUs. We evaluate the performance of this prototype
under two configurations: as a content addressable storage system that
facilitates online similarity detection between successive versions of the same
file and as a traditional system that uses hashing to preserve data integrity.
Further, we evaluate the impact of offloading to the GPU on competing
applications' performance. Our results show that this technique can bring
tangible performance gains without negatively impacting the performance of
concurrently running applications."
"This report discusses many-task computing (MTC) generically and in the
context of the proposed Blue Waters systems, which is planned to be the largest
NSF-funded supercomputer when it begins production use in 2012. The aim of this
report is to inform the BW project about MTC, including understanding aspects
of MTC applications that can be used to characterize the domain and
understanding the implications of these aspects to middleware and policies.
Many MTC applications do not neatly fit the stereotypes of high-performance
computing (HPC) or high-throughput computing (HTC) applications. Like HTC
applications, by definition MTC applications are structured as graphs of
discrete tasks, with explicit input and output dependencies forming the graph
edges. However, MTC applications have significant features that distinguish
them from typical HTC applications. In particular, different engineering
constraints for hardware and software must be met in order to support these
applications. HTC applications have traditionally run on platforms such as
grids and clusters, through either workflow systems or parallel programming
systems. MTC applications, in contrast, will often demand a short time to
solution, may be communication intensive or data intensive, and may comprise
very short tasks. Therefore, hardware and software for MTC must be engineered
to support the additional communication and I/O and must minimize task dispatch
overheads. The hardware of large-scale HPC systems, with its high degree of
parallelism and support for intensive communication, is well suited for MTC
applications. However, HPC systems often lack a dynamic resource-provisioning
feature, are not ideal for task communication via the file system, and have an
I/O system that is not optimized for MTC-style applications. Hence, additional
software support is likely to be required to gain full benefit from the HPC
hardware."
"The future of computation is the Graphical Processing Unit, i.e. the GPU. The
promise that the graphics cards have shown in the field of image processing and
accelerated rendering of 3D scenes, and the computational capability that these
GPUs possess, they are developing into great parallel computing units. It is
quite simple to program a graphics processor to perform general parallel tasks.
But after understanding the various architectural aspects of the graphics
processor, it can be used to perform other taxing tasks as well. In this paper,
we will show how CUDA can fully utilize the tremendous power of these GPUs.
CUDA is NVIDIA's parallel computing architecture. It enables dramatic increases
in computing performance, by harnessing the power of the GPU. This paper talks
about CUDA and its architecture. It takes us through a comparison of CUDA C/C++
with other parallel programming languages like OpenCL and DirectCompute. The
paper also lists out the common myths about CUDA and how the future seems to be
promising for CUDA."
"Taking an interaction network oriented perspective in informatics raises the
challenge to describe deterministic finite systems which take part in networks
of nondeterministic interactions. The traditional approach to describe
processes as stepwise executable activities which are not based on the
ordinarily nondeterministic interaction shows strong centralization tendencies.
As suggested in this article, viewing processes and their interactions as
complementary can circumvent these centralization tendencies.
  The description of both, processes and their interactions is based on the
same building blocks, namely finite input output automata (or transducers).
Processes are viewed as finite systems that take part in multiple, ordinarily
nondeterministic interactions. The interactions between processes are described
as protocols.
  The effects of communication between processes as well as the necessary
coordination of different interactions within a processes are both based on the
restriction of the transition relation of product automata. The channel based
outer coupling represents the causal relation between the output and the input
of different systems. The coordination condition based inner coupling
represents the causal relation between the input and output of a single system.
  All steps are illustrated with the example of a network of resource
administration processes which is supposed to provide requesting user processes
exclusive access to a single resource."
"In distributed target tracking for wireless sensor networks, agreement on the
target state can be achieved by the construction and maintenance of a
communication path, in order to exchange information regarding local likelihood
functions. Such an approach lacks robustness to failures and is not easily
applicable to ad-hoc networks. To address this, several methods have been
proposed that allow agreement on the global likelihood through fully
distributed belief consensus (BC) algorithms, operating on local likelihoods in
distributed particle filtering (DPF). However, a unified comparison of the
convergence speed and communication cost has not been performed. In this paper,
we provide such a comparison and propose a novel BC algorithm based on belief
propagation (BP). According to our study, DPF based on metropolis belief
consensus (MBC) is the fastest in loopy graphs, while DPF based on BP consensus
is the fastest in tree graphs. Moreover, we found that BC-based DPF methods
have lower communication overhead than data flooding when the network is
sufficiently sparse."
"There is widespread agreement that cloud computing have proven cost cutting
and agility benefits. However, security and regulatory compliance issues are
continuing to challenge the wide acceptance of such technology both from social
and commercial stakeholders. An important facture behind this is the fact that
clouds and in particular public clouds are usually deployed and used within
broad geographical or even international domains. This implies that the
exchange of private and other protected data within the cloud environment would
be governed by multiple jurisdictions. These jurisdictions have a great degree
of harmonisation; however, they present possible conflicts that are hard to
negotiate at run time. So far, important efforts were played in order to deal
with regulatory compliance management for large distributed systems. However,
measurable solutions are required for the context of cloud. In this position
paper, we are suggesting an approach that starts with a conceptual model of
explicit regulatory requirements for exchanging private data on a
multijurisdictional environment and build on it in order to define metrics for
non-compliance or, in other terms, risks to compliance. These metrics will be
integrated within usual data access-control policies and will be checked at
policy analysis time before a decision to allow/deny the data access is made."
"With the emergence of new methodologies and technologies it has now become
possible to manage large amounts of environmental sensing data and apply new
integrated computing models to acquire information intelligence. This paper
advocates the application of cloud capacity to support the information,
communication and decision making needs of a wide variety of stakeholders in
the complex business of the management of urban and regional development. The
complexity lies in the interactions and impacts embodied in the concept of the
urban-ecosystem at various governance levels. This highlights the need for more
effective integrated environmental management systems. This paper offers a
user-orientated approach based on requirements for an effective management of
the urban-ecosystem and the potential contributions that can be supported by
the cloud computing community. Furthermore, the commonality of the influence of
the drivers of change at the urban level offers the opportunity for the cloud
computing community to develop generic solutions that can serve the needs of
hundreds of cities from Europe and indeed globally."
"The current BDII model relies on information gathering from agents that run
on each core node of a Grid. This information is then published into a Grid
wide information resource known as Top BDII. The Top level BDIIs are updated
typically in cycles of a few minutes each. A new BDDI architecture is proposed
and described in this paper based on the hypothesis that only a few attribute
values change in each BDDI information cycle and consequently it may not be
necessary to update each parameter in a cycle. It has been demonstrated that
significant performance gains can be achieved by exchanging only the
information about records that changed during a cycle. Our investigations have
led us to implement a low latency and fault tolerant BDII system that involves
only minimal data transfer and facilitates secure transactions in a Grid
environment."
"Ubiquitous computing environments are characterised by smart, interconnected
artefacts embedded in our physical world that are projected to provide useful
services to human inhabitants unobtrusively. Mobile devices are becoming the
primary tools of human interaction with these embedded artefacts and
utilisation of services available in smart computing environments such as
clouds. Advancements in capabilities of mobile devices allow a number of user
and environment related context consumers to be hosted on these devices.
Without a coordinating component, these context consumers and providers are a
potential burden on device resources; specifically the effect of uncoordinated
computation and communication with cloud-enabled services can negatively impact
the battery life. Therefore energy conservation is a major concern in realising
the collaboration and utilisation of mobile device based context-aware
applications and cloud based services. This paper presents the concept of a
context-brokering component to aid in coordination and communication of context
information between mobile devices and services deployed in a cloud
infrastructure. A prototype context broker is experimentally analysed for
effects on energy conservation when accessing and coordinating with cloud
services on a smart device, with results signifying reduction in energy
consumption."
"This report contains two related sets of results with different assumptions
on synchrony. The first part is about iterative algorithms in synchronous
systems. Following our previous work on synchronous iterative approximate
Byzantine consensus (IABC) algorithms, we provide a more intuitive tight
necessary and sufficient condition for the existence of such algorithms in
synchronous networks1. We believe this condition and the previous results also
hold in partially asynchronous algorithmic model.
  In the second part of the report, we explore the problem in asynchronous
networks. While the traditional Byzantine consensus is not solvable in
asynchronous systems, approximate Byzantine consensus can be solved using
iterative algorithms."
"For the first time, this paper systematically identifies three categories of
throughput oriented workloads in data centers: services, data processing
applications, and interactive real-time applications, whose targets are to
increase the volume of throughput in terms of processed requests or data, or
supported maximum number of simultaneous subscribers, respectively, and we coin
a new term high volume computing (in short HVC) to describe those workloads and
data center computer systems designed for them. We characterize and compare HVC
with other computing paradigms, e.g., high throughput computing,
warehouse-scale computing, and cloud computing, in terms of levels, workloads,
metrics, coupling degree, data scales, and number of jobs or service instances.
We also preliminarily report our ongoing work on the metrics and benchmarks for
HVC systems, which is the foundation of designing innovative data center
computer systems for HVC workloads."
"Consider a scenario where Alice wishes to send a message $m$ to Bob in a
time-slotted wireless network. However, there exists an adversary, Carol, who
aims to prevent the transmission of $m$ by jamming the communication channel.
There is a per-slot cost of $1$ to send, receive or jam $m$ on the channel, and
we are interested in how much Alice and Bob need to spend relative to Carol in
order to guarantee communication.
  Our approach is to design an algorithm in the framework of
resource-competitive analysis where the cost to correct network devices (i.e.,
Alice and Bob) is parameterized by the cost to faulty devices (i.e., Carol). We
present an algorithm that guarantees the successful transmission of $m$ and has
the following property: if Carol incurs a cost of $T$ to jam, then both Alice
and Bob have a cost of $O(T^{\varphi - 1} + 1)=O(T^{.62}+1)$ in expectation,
where $\varphi = (1+ \sqrt{5})/2$ is the golden ratio. In other words, it
possible for Alice and Bob to communicate while incurring asymptotically less
cost than Carol. We generalize to the case where Alice wishes to send $m$ to
$n$ receivers, and we achieve a similar result.
  Our findings hold even if (1) $T$ is unknown to either party; (2) Carol knows
the algorithms of both parties, but not their random bits; (3) Carol can jam
using knowledge of past actions of both parties; and (4) Carol can jam
reactively, so long as there is sufficient network traffic in addition to $m$."
"Ubiquitous sensing enabled by Wireless Sensor Network (WSN) technologies cuts
across many areas of modern day living. This offers the ability to measure,
infer and understand environmental indicators, from delicate ecologies and
natural resources to urban environments. The proliferation of these devices in
a communicating-actuating network creates the Internet of Things (IoT),
wherein, sensors and actuators blend seamlessly with the environment around us,
and the information is shared across platforms in order to develop a common
operating picture (COP). Fuelled by the recent adaptation of a variety of
enabling device technologies such as RFID tags and readers, near field
communication (NFC) devices and embedded sensor and actuator nodes, the IoT has
stepped out of its infancy and is the the next revolutionary technology in
transforming the Internet into a fully integrated Future Internet. As we move
from www (static pages web) to web2 (social networking web) to web3 (ubiquitous
computing web), the need for data-on-demand using sophisticated intuitive
queries increases significantly. This paper presents a cloud centric vision for
worldwide implementation of Internet of Things. The key enabling technologies
and application domains that are likely to drive IoT research in the near
future are discussed. A cloud implementation using Aneka, which is based on
interaction of private and public clouds is presented. We conclude our IoT
vision by expanding on the need for convergence of WSN, the Internet and
distributed computing directed at technological research community."
"The Signal-to-Interference-and-Noise-Ratio (SINR) physical model is one of
the legitimate models of wireless networks. Despite of the vast amount of study
done in design and analysis of centralized algorithms supporting wireless
communication under the SINR physical model, little is known about distributed
algorithms in this model, especially deterministic ones. In this work we
construct, in a deterministic distributed way, a backbone structure on the top
of a given wireless network, which can be used for transforming many algorithms
designed in a simpler model of ad hoc broadcast networks without interference
into the SINR physical model with uniform power of stations, without increasing
their asymptotic time complexity. The time cost of the backbone data structure
construction is only O(Delta polylog n) rounds, where Delta is roughly the
inverse of network density and n is the number of nodes in the whole network.
The core of the construction is a novel combinatorial structure called
SINR-selector, which is introduced and constructed in this paper. We
demonstrate the power of the backbone data structure by using it for obtaining
efficient O(D+Delta polylog n)-round and O(D+k+Delta polylog n)-round
deterministic distributed solutions for leader election and multi-broadcast,
respectively, where D is the network diameter and k is the number of messages
to be disseminated."
"Cloud Computing is emerging as a new computational paradigm shift.
Hadoop-MapReduce has become a powerful Computation Model for processing large
data on distributed commodity hardware clusters such as Clouds. In all Hadoop
implementations, the default FIFO scheduler is available where jobs are
scheduled in FIFO order with support for other priority based schedulers also.
In this paper we study various scheduler improvements possible with Hadoop and
also provided some guidelines on how to improve the scheduling in Hadoop in
Cloud Environments."
"Nowadays most of the cloud applications process large amount of data to
provide the desired results. Data volumes to be processed by cloud applications
are growing much faster than computing power. This growth demands new
strategies for processing and analyzing information. Dealing with large data
volumes requires two things: 1) Inexpensive, reliable storage 2) New tools for
analyzing unstructured and structured data. Hadoop is a powerful open source
software platform that addresses both of these problems. The current Hadoop
implementation assumes that computing nodes in a cluster are homogeneous in
nature. Hadoop lacks performance in heterogeneous clusters where the nodes have
different computing capacity. In this paper we address the issues that affect
the performance of hadoop in heterogeneous clusters and also provided some
guidelines on how to overcome these bottlenecks"
"Ability to find and get services is a key requirement in the development of
large-scale distributed sys- tems. We consider dynamic and unstable
environments, namely Peer-to-Peer (P2P) systems. In previous work, we designed
a service discovery solution called Distributed Lexicographic Placement Table
(DLPT), based on a hierar- chical overlay structure. A self-stabilizing version
was given using the Propagation of Information with Feedback (PIF) paradigm. In
this paper, we introduce the self-stabilizing COPIF (for Collaborative PIF)
scheme. An algo- rithm is provided with its correctness proof. We use this
approach to improve a distributed P2P framework designed for the services
discovery. Significantly efficient experimental results are presented."
"We implemented the pressure-implicit with splitting of operators (PISO) and
semi-implicit method for pressure-linked equations (SIMPLE) solvers of the
Navier-Stokes equations on Fermi-class graphics processing units (GPUs) using
the CUDA technology. We also introduced a new format of sparse matrices
optimized for performing elementary CFD operations, like gradient or divergence
discretization, on GPUs. We verified the validity of the implementation on
several standard, steady and unsteady problems. Computational effciency of the
GPU implementation was examined by comparing its double precision run times
with those of essentially the same algorithms implemented in OpenFOAM. The
results show that a GPU (Tesla C2070) can outperform a server-class 6-core,
12-thread CPU (Intel Xeon X5670) by a factor of 4.2."
"Consider a clique of n nodes, where in each synchronous round each pair of
nodes can exchange O(log n) bits. We provide deterministic constant-time
solutions for two problems in this model. The first is a routing problem where
each node is source and destination of n messages of size O(log n). The second
is a sorting problem where each node i is given n keys of size O(log n) and
needs to receive the ith batch of n keys according to the global order of the
keys. The latter result also implies deterministic constant-round solutions for
related problems such as selection or determining modes."
"Optimal resource utilization for executing tasks within the cloud is one of
the biggest challenges. In executing the task over a cloud, the resource
provisioner is responsible for providing the resources to create virtual
machines. To utilize the resources optimally, the resource provisioner has to
take care of the process of allocating resources to Virtual Machine Manager
(VMM). In this paper, an efficient way to utilize the resources, within the
cloud, to create virtual machines has been proposed considering optimum cost
based on performance factor. This performance factor depends upon the overall
cost of the resource, communication channel cost, reliability and popularity
factor. We have proposed a framework for communication between resource owner
and cloud using Resource Cloud Communication Paradigm (RCCP). We extend the
CloudSim[2] adding provisioner policies and Efficient Resource Allocation (ERA)
algorithm in VMM allocation policy as a decision support for resource
provisioner."
"In Cloud Computing Architecture, Brokers are responsible to provide services
to the end users. An Effective Cost Management System (ECMS) which works over
Secure Cloud Communication Paradigm (SCCP) helps in finding a communication
link with overall minimum cost of links. We propose an improved Broker Cloud
Communication Paradigm (BCCP) with integration of security issues. Two
algorithms are included, first is Secure Optimized Route Cost Finder (S-ORCF)
to find optimum route between broker and cloud on the behalf of cost factor and
second is Secure Optimized Route Management (S-ORM) to maintain optimum route.
These algorithms proposed with cryptographic integrity of the secure route
discovery process in efficient routing approaches between broker and cloud.
There is lack in Dynamic Source Routing Approach to verify whether any
intermediate node has been deleted, inserted or modified with no valid
authentication. We use symmetric cryptographic primitives, which is made
possible due to multisource broadcast encryption scheme. This paper outlines
the use of secure route discovery protocol (SRDP)that employs such a security
paradigm in cloud computing."
"In current scenario cloud computing is most widely increasing platform for
task execution. Lot of research is going on to cut down the cost and execution
time. In this paper, we propose an efficient algorithm to have an effective and
fast execution of task assigned by the user. We proposed an effective
communication framework between broker and virtual machine for assigning the
task and fetching the results in optimum time and cost using Broker Virtual
Machine Communication Framework (BVCF). We implement it over cloudsim under VM
scheduling policies by modification based on Virtual Machine Cost. Scheduling
over Virtual Machine as well as over Cloudlets and Retransmission of Cloudlets
are the basic building blocks of the proposed work on which the whole
architecture is dependent. Execution of cloudlets is being analyzed over Round
Robin and FCFS scheduling policy."
"Nowadays the number of available processing cores within computing nodes
which are used in recent clustered environments, are growing up with a rapid
rate. Despite this trend, the number of available network interfaces in such
computing nodes has almost been remained unchanged. This issue can lead to high
usage of network interface in many workloads, especially in heavy-communicating
workloads. As a result, network interface may raise as a performance bottleneck
and can drastically degrade the performance. The goal of this paper is to
introduce a new process mapping strategy in multi-core clusters aimed at
reducing network interface contention and improving inter-node communication
performance of parallel applications. Performance evaluation of the new mapping
algorithm in synthetic and real workloads indicates that the new strategy can
achieve 5% to 90% performance improvement in heavy communicating workloads,
compared to other well-known methods."
"Cloud computing is bringing a revolution in computing environment replacing
traditional software installations, licensing issues into complete on-demand
services through internet. Microsoft office 365 a cloud based office
application is available to clients online hence no need to buy and install the
software. On Facebook a social networking website, users upload videos which
uses cloud provider's storage service so less hardware cost for
clients.Virtualization technology has great contribution in advent of cloud
computing. Paper describes implementation of Private Cloud using open source
operating system Ubuntu 10.04 server edition, installation of Ubuntu Enterprise
Cloud with Eucalyptus 1.6.2 and providing CentOS 5.3 operating system through
cloud."
"A $t$-ruling set of a graph $G = (V, E)$ is a vertex-subset $S \subseteq V$
that is independent and satisfies the property that every vertex $v \in V$ is
at a distance of at most $t$ from some vertex in $S$. A \textit{maximal
independent set (MIS)} is a 1-ruling set. The problem of computing an MIS on a
network is a fundamental problem in distributed algorithms and the fastest
algorithm for this problem is the $O(\log n)$-round algorithm due to Luby
(SICOMP 1986) and Alon et al. (J. Algorithms 1986) from more than 25 years ago.
Since then the problem has resisted all efforts to yield to a sub-logarithmic
algorithm. There has been recent progress on this problem, most importantly an
$O(\log \Delta \cdot \sqrt{\log n})$-round algorithm on graphs with $n$
vertices and maximum degree $\Delta$, due to Barenboim et al. (Barenboim,
Elkin, Pettie, and Schneider, April 2012, arxiv 1202.1983; to appear FOCS
2012).
  We approach the MIS problem from a different angle and ask if O(1)-ruling
sets can be computed much more efficiently than an MIS? As an answer to this
question, we show how to compute a 2-ruling set of an $n$-vertex graph in
$O((\log n)^{3/4})$ rounds. We also show that the above result can be improved
for special classes of graphs such as graphs with high girth, trees, and graphs
of bounded arboricity.
  Our main technique involves randomized sparsification that rapidly reduces
the graph degree while ensuring that every deleted vertex is close to some
vertex that remains. This technique may have further applications in other
contexts, e.g., in designing sub-logarithmic distributed approximation
algorithms. Our results raise intriguing questions about how quickly an MIS (or
1-ruling sets) can be computed, given that 2-ruling sets can be computed in
sub-logarithmic rounds."
"Many modern network designs incorporate ""failover"" paths into routers'
forwarding tables. We initiate the theoretical study of the conditions under
which such resilient routing tables can guarantee delivery of packets."
"Cloud computing is a new technology widely studied in recent years. Now there
are many cloud platforms both in industry and in academic circle. How to
understand and use these platforms is a big issue. A detailed comparison has
been presented in this paper focused on the aspects such as the architecture,
characteristics, application and so on. To know the differences between open
source and close source in cloud environment we mention some examples for
Software-as-a-Service, Platform-as-a-Service, and Infrastructure-as-a-Service.
We made comparison between them. Before conclusion we demonstrate some
convergences and differences between open and closed platform, but we realized
open source should be the best option."
"We study the effect of communication delays on distributed consensus
algorithms. Two ways to model delays on a network are presented. The first
model assumes that each link delivers messages with a fixed (constant) amount
of delay, and the second model is more realistic, allowing for i.i.d.
time-varying bounded delays. In contrast to previous work studying the effects
of delays on consensus algorithms, the models studied here allow for a node to
receive multiple messages from the same neighbor in one iteration. The analysis
of the fixed delay model shows that convergence to a consensus is guaranteed
and the rate of convergence is reduced by no more than a factor O(B^2) where B
is the maximum delay on any link. For the time-varying delay model we also give
a convergence proof which, for row-stochastic consensus protocols, is not a
trivial consequence of ergodic matrix products. In both delay models, the
consensus value is no longer the average, even if the original protocol was an
averaging protocol. For this reason, we propose the use of a different
consensus algorithm called Push-Sum [Kempe et al. 2003]. We model delays in the
Push-Sum framework and show that convergence to the average consensus is
guaranteed. This suggests that Push-Sum might be a better choice from a
practical standpoint."
"Virtualization offers several benefits for optimal resource utilization over
traditional non-virtualized server farms. With improvements in internetworking
technologies and increase in network bandwidth speeds, a new era of computing
has been ushered in, that of grids and clouds. With several commercial cloud
providers coming up, each with their own APIs, application description formats,
and varying support for SLAs, vendor lock-in has become a serious issue for end
users. This article attempts to describe the problem, issues, possible
solutions and challenges in achieving cloud interoperability. These issues will
be analyzed in the ambit of the European project Contrail that is trying to
adopt open standards with available virtualization solutions to enhance users'
trust in the clouds by attempting to prevent vendor lock-ins, supporting and
enforcing SLAs together with adequate data protection for sensitive data."
"Cloud storage is fast securing its role as a major repository for both
consumers and business customers. Many companies now offer storage solutions,
sometimes for free for limited amounts of capacity. We have surveyed the
pricing plans of a selection of major cloud providers and compared them using
the unit price as the means of comparison. All the providers, excepting Amazon,
adopt a bundling pricing scheme; Amazon follows instead a block-declining
pricing policy. We compare the pricing plans through a double approach: a
pointwise comparison for each value of capacity, and an overall comparison
using a two-part tariff approximation and a Pareto-dominance criterion. Under
both approaches, most providers appear to offer pricing plans that are more
expensive and can be excluded from a procurement selection in favour of a
limited number of dominant providers."
"Pilot-Jobs support effective distributed resource utilization, and are
arguably one of the most widely-used distributed computing abstractions - as
measured by the number and types of applications that use them, as well as the
number of production distributed cyberinfrastructures that support them. In
spite of broad uptake, there does not exist a well-defined, unifying conceptual
model of Pilot-Jobs which can be used to define, compare and contrast different
implementations. Often Pilot-Job implementations are strongly coupled to the
distributed cyber-infrastructure they were originally designed for. These
factors present a barrier to extensibility and interoperability. This pa- per
is an attempt to (i) provide a minimal but complete model (P*) of Pilot-Jobs,
(ii) establish the generality of the P* Model by mapping various existing and
well known Pilot-Job frameworks such as Condor and DIANE to P*, (iii) derive an
interoperable and extensible API for the P* Model (Pilot-API), (iv) validate
the implementation of the Pilot-API by concurrently using multiple distinct
Pilot-Job frameworks on distinct production distributed cyberinfrastructures,
and (v) apply the P* Model to Pilot-Data."
"In the advent of large-scale multi-hop wireless technologies, such as MANET,
VANET, iThings, it is of utmost importance to devise efficient distributed
protocols to maintain network architecture and provide basic communication
tools. One of such fundamental communication tasks is broadcast, also known as
a 1-to-all communication. We propose several new efficient distributed
algorithms and evaluate their time performance both theoretically and by
simulations. First randomized algorithm accomplishes broadcast in O(D+log(1/d))
rounds with probability at least 1-d on any uniform-power network of n nodes
and diameter D, when equipped with local estimate of network density.
Additionally, we evaluate average performance of this protocols by simulations
on two classes of generated networks - uniform and social - and compare the
results with performance of exponential backoff heuristic. Ours is the first
provably efficient and well-scalable distributed solution for the (global)
broadcast task. The second randomized protocol developed in this paper does not
rely on the estimate of local density, and achieves only slightly higher time
performance O((D+log(1/d))log n). Finally, we provide a deterministic algorithm
achieving similar time O(D log^2 n), supported by theoretical analysis."
"To achieve reliability in distributed storage systems, data has usually been
replicated across different nodes. However the increasing volume of data to be
stored has motivated the introduction of erasure codes, a storage efficient
alternative to replication, particularly suited for archival in data centers,
where old datasets (rarely accessed) can be erasure encoded, while replicas are
maintained only for the latest data. Many recent works consider the design of
new storage-centric erasure codes for improved repairability. In contrast, this
paper addresses the migration from replication to encoding: traditionally
erasure coding is an atomic operation in that a single node with the whole
object encodes and uploads all the encoded pieces. Although large datasets can
be concurrently archived by distributing individual object encodings among
different nodes, the network and computing capacity of individual nodes
constrain the archival process due to such atomicity.
  We propose a new pipelined coding strategy that distributes the network and
computing load of single-object encodings among different nodes, which also
speeds up multiple object archival. We further present RapidRAID codes, an
explicit family of pipelined erasure codes which provides fast archival without
compromising either data reliability or storage overheads. Finally, we provide
a real implementation of RapidRAID codes and benchmark its performance using
both a cluster of 50 nodes and a set of Amazon EC2 instances. Experiments show
that RapidRAID codes reduce a single object's coding time by up to 90%, while
when multiple objects are encoded concurrently, the reduction is up to 20%."
"MapReduce, the popular programming paradigm for large-scale data processing,
has traditionally been deployed over tightly-coupled clusters where the data is
already locally available. The assumption that the data and compute resources
are available in a single central location, however, no longer holds for many
emerging applications in commercial, scientific and social networking domains,
where the data is generated in a geographically distributed manner. Further,
the computational resources needed for carrying out the data analysis may be
distributed across multiple data centers or community resources such as Grids.
In this paper, we develop a modeling framework to capture MapReduce execution
in a highly distributed environment comprising distributed data sources and
distributed computational resources. This framework is flexible enough to
capture several design choices and performance optimizations for MapReduce
execution. We propose a model-driven optimization that has two key features:
(i) it is end-to-end as opposed to myopic optimizations that may only make
locally optimal but globally suboptimal decisions, and (ii) it can control
multiple MapReduce phases to achieve low runtime, as opposed to single-phase
optimizations that may control only individual phases. Our model results show
that our optimization can provide nearly 82% and 64% reduction in execution
time over myopic and single-phase optimizations, respectively. We have modified
Hadoop to implement our model outputs, and using three different MapReduce
applications over an 8-node emulated PlanetLab testbed, we show that our
optimized Hadoop execution plan achieves 31-41% reduction in runtime over a
vanilla Hadoop execution. Our model-driven optimization also provides several
insights into the choice of techniques and execution parameters based on
application and platform characteristics."
"This paper describes a new scheduling algorithm to distribute jobs in server
farm systems. The proposed algorithm overcomes the starvation caused by SRPT
(Shortest Remaining Processing Time). This algorithm is used in process
scheduling in operating system approach. The algorithm was developed to be used
in dispatcher scheduling. This algorithm is non-preemptive discipline, similar
to SRPT, in which the priority of each job depends on its estimated run time,
and also the amount of time it has spent on waiting. Tasks in the servers are
served in order of priority to optimize the system response time. The
experiments show that the mean round around time is reduced in the server farm
system."
"We study the scalability of consensus-based distributed optimization
algorithms by considering two questions: How many processors should we use for
a given problem, and how often should they communicate when communication is
not free? Central to our analysis is a problem-specific value $r$ which
quantifies the communication/computation tradeoff. We show that organizing the
communication among nodes as a $k$-regular expander graph (Reingold, Vadhan,
and Wigderson, 2002) yields speedups, while when all pairs of nodes communicate
(as in a complete graph), there is an optimal number of processors that depends
on $r$. Surprisingly, a speedup can be obtained, in terms of the time to reach
a fixed level of accuracy, by communicating less and less frequently as the
computation progresses. Experiments on a real cluster solving metric learning
and non-smooth convex minimization tasks demonstrate strong agreement between
theory and practice."
"Cloud computing allows users to view computing in a new direction, as it uses
the existing technologies to provide better IT services at low-cost. To offer
high QOS to customers according SLA, cloud services broker or cloud service
provider uses individual cloud providers that work collaboratively to form a
federation of clouds. It is required in applications like Real-time online
interactive applications, weather research and forecasting etc., in which the
data and applications are complex and distributed. In these applications secret
data should be shared, so secure data sharing mechanism is required in
Federated clouds to reduce the risk of data intrusion, the loss of service
availability and to ensure data integrity. So In this paper we have proposed
zero knowledge data sharing scheme where Trusted Cloud Authority (TCA) will
control federated clouds for data sharing where the secret to be exchanged for
computation is encrypted and retrieved by individual cloud at the end. Our
scheme is based on the difficulty of solving the Discrete Logarithm problem
(DLOG) in a finite abelian group of large prime order which is NP-Hard. So our
proposed scheme provides data integrity in transit, data availability when one
of host providers are not available during the computation."
"As Clouds are complex, large-scale, and heterogeneous distributed systems,
management of their resources is a challenging task. They need automated and
integrated intelligent strategies for provisioning of resources to offer
services that are secure, reliable, and cost-efficient. Hence, effective
management of services becomes fundamental in software platforms that
constitute the fabric of computing Clouds. In this direction, this paper
identifies open issues in autonomic resource provisioning and presents
innovative management techniques for supporting SaaS applications hosted on
Clouds. We present a conceptual architecture and early results evidencing the
benefits of autonomic management of Clouds."
"In this work we consider the problem of gathering autonomous robots in the
plane. In particular, we consider non-transparent unit-disc robots (i.e., fat)
in an asynchronous setting. Vision is the only mean of coordination. Using a
state-machine representation we formulate the gathering problem and develop a
distributed algorithm that solves the problem for any number of robots.
  The main idea behind our algorithm is for the robots to reach a configuration
in which all the following hold: (a) The robots' centers form a convex hull in
which all robots are on the convex, (b) Each robot can see all other robots,
and (c) The configuration is connected, that is, every robot touches another
robot and all robots together form a connected formation. We show that starting
from any initial configuration, the robots, making only local decisions and
coordinate by vision, eventually reach such a configuration and terminate,
yielding a solution to the gathering problem."
"In this article, Conway's Game of Life using OpenMP parallel processing to
simulate several different parallel methods, experimental performance results
and compare to find the optimal solution of the parallelization of the Game of
Life. Finally pointed out the importance of the design of parallel algorithms
in solving the parallel problem."
"Contemporary high-performance service-oriented applications demand a
performance efficient run-time monitoring. In this paper, we analyze a
hierarchical publish-subscribe architecture for monitoring service-oriented
applications. The analyzed architecture is based on a tree topology and
publish-subscribe communication model for aggregation of distributed monitoring
data. In order to satisfy interoperability and platform independence of
service-orientation, monitoring reports are represented as XML documents. Since
XML formatting introduces a significant processing and network load, we analyze
the performance of monitoring architecture with respect to the number of
monitored nodes, the load of system machines, and the overall latency of the
monitoring system."
"We explore the correctness of the Certified Propagation Algorithm (CPA) [6,
1, 8, 5] in solving broadcast with locally bounded Byzantine faults. CPA allows
the nodes to use only local information regarding the network topology. We
provide a tight necessary and sufficient condition on the network topology for
the correctness of CPA. To the best of our knowledge, this work is the first to
solve the open problem in [8]. We also present some simple extensions of this
result"
"Tasks scheduling is the most challenging problem in the parallel computing.
Hence, the inappropriate scheduling will reduce or even abort the utilization
of the true potential of the parallelization. Genetic algorithm (GA) has been
successfully applied to solve the scheduling problem. The fitness evaluation is
the most time consuming GA operation for the CPU time, which affect the GA
performance. The proposed synchronous master-slave algorithm outperforms the
sequential algorithm in case of complex and high number of generations problem."
"Cloud computing is driven by economies of scale. A cloud system uses
virtualization technology to provide cloud resources (e.g. CPU, memory) to
users in form of virtual machines. Virtual machine (VM), which is a sandbox for
user application, fits well in the education environment to provide
computational resources for teaching and research needs. In resource
management, they want to reduce costs in operations by reducing expensive cost
of electronic bill of large-scale data center system. A lease-based model is
suitable for our Virtual Computing Lab, in which users ask resources on a lease
of virtual machines. This paper proposes two host selection policies, named MAP
(minimum of active physical hosts) and MAP-H2L, and four algorithms solving the
lease scheduling problem. FF-MAP, FF-MAP-H2L algorithms meet a trade-off
between the energy consumption and Quality of Service (e.g. performance). The
simulation on 7-day workload, which converted from LLNL Atlas log, showed the
FF-MAP and FF-MAP-H2L algorithms reducing 7.24% and 7.42% energy consumption
than existing greedy mapping algorithm in the leasing scheduler Haizea. In
addition, we introduce a ratio \theta of consolidation in HalfPI-FF-MAP and
PI-FF-MAP algorithms, in which \theta is \pi/2 and \pi, and results on their
simulations show that energy consumption decreased by 34.87% and 63.12%
respectively."
"In this paper we initiate a study of distributed deterministic broadcasting
in ad-hoc wireless networks with uniform transmission powers under the SINR
model. We design algorithms in two settings: with and without local knowledge
about immediate neighborhood. In the former setting, our solution has almost
optimal O(Dlog2 n) time cost, where n is the size of a network, D is the
eccentricity of the network and {1,...,N} is the set of possible node IDs. In
the latter case, we prove an Omega(n log N) lower bound and develop an
algorithm matching this formula, where n is the number of network nodes. As one
of the conclusions, we derive that the inherited cost of broadcasting
techniques in wireless networks is much smaller, by factor around
min{n/D,Delta}, than the cost of learning the immediate neighborhood. Finally,
we develop a O(D Delta log2 N) algorithm for the setting without local
knowledge, where Delta is the upper bound on the degree of the communication
graph of a network. This algorithm is close to a lower bound Omega(D Delta)."
"The cloud infrastructure services landscape advances steadily leaving users
in the agony of choice..."
"While many existing formal concept analysis algorithms are efficient, they
are typically unsuitable for distributed implementation. Taking the MapReduce
(MR) framework as our inspiration we introduce a distributed approach for
performing formal concept mining. Our method has its novelty in that we use a
light-weight MapReduce runtime called Twister which is better suited to
iterative algorithms than recent distributed approaches. First, we describe the
theoretical foundations underpinning our distributed formal concept analysis
approach. Second, we provide a representative exemplar of how a classic
centralized algorithm can be implemented in a distributed fashion using our
methodology: we modify Ganter's classic algorithm by introducing a family of
MR* algorithms, namely MRGanter and MRGanter+ where the prefix denotes the
algorithm's lineage. To evaluate the factors that impact distributed algorithm
performance, we compare our MR* algorithms with the state-of-the-art.
Experiments conducted on real datasets demonstrate that MRGanter+ is efficient,
scalable and an appealing algorithm for distributed problems."
"This paper investigates the execution of tree-shaped task graphs using
multiple processors. Each edge of such a tree represents a large IO file. A
task can only be executed if all input and output files fit into memory, and a
file can only be removed from memory after it has been consumed. Such trees
arise, for instance, in the multifrontal method of sparse matrix factorization.
The maximum amount of memory needed depends on the execution order of the
tasks. With one processor the objective of the tree traversal is to minimize
the required memory. This problem was well studied and optimal polynomial
algorithms were proposed.
  Here, we extend the problem by considering multiple processors, which is of
obvious interest in the application area of matrix factorization. With the
multiple processors comes the additional objective to minimize the time needed
to traverse the tree, i.e., to minimize the makespan. Not surprisingly, this
problem proves to be much harder than the sequential one. We study the
computational complexity of this problem and provide an inapproximability
result even for unit weight trees. Several heuristics are proposed, each with a
different optimization focus, and they are analyzed in an extensive
experimental evaluation using realistic trees."
"The main open question is how to calculate the effect of switching between
frequencies in DVFS technique on the lifetime of the cluster components. As
moving from one frequency to another in DVFS technique always gives a shock to
the component and consequently decreases the component lifetime, therefore, it
becomes interesting to answer the question of how fast a component can change
its speed in order to decrease power without changing its lifetime."
"The compass of Cloud infrastructure services advances steadily leaving users
in the agony of choice. To be able to select the best mix of service offering
from an abundance of possibilities, users must consider complex dependencies
and heterogeneous sets of criteria. Therefore, we present a PhD thesis proposal
on investigating an intelligent decision support system for selecting Cloud
based infrastructure services (e.g. storage, network, CPU)."
"Existing information theoretic work in decentralized detection is largely
focused on parallel configuration of Wireless Sensor Networks (WSNs), where an
individual hard or soft decision is computed at each sensor node and then
transmitted directly to the fusion node. Such an approach is not efficient for
large networks, where communication structure is likely to comprise of multiple
hops. On the other hand, decentralized detection problem investigated for
multi-hop networks is mainly concerned with reducing number and/or size of
messages by using compression and fusion of information at intermediate nodes.
In this paper an energy efficient multi-hop configuration of WSNs is proposed
to solve the detection problem in large networks with two objectives:
maximizing network lifetime and minimizing probability of error in the fusion
node. This optimization problem is considered under the constraint of total
consumed energy. The two objectives mentioned are achieved simultaneously in
the multi-hop configuration by exploring tradeoffs between different path
lengths and number of bits allocated to each node for quantization. Simulation
results show significant improvement in the proposed multi-hop configuration
compared with the parallel configuration in terms of energy efficiency and
detection accuracy for different size networks, especially in larger networks."
"Compressive Sensing (CS) method is a burgeoning technique being applied to
diverse areas including wireless sensor networks (WSNs). In WSNs, it has been
studied in the context of data gathering and aggregation, particularly aimed at
reducing data transmission cost and improving power efficiency. Existing CS
based data gathering work in WSNs assume fixed and uniform compression
threshold across the network, regard- less of the data field characteristics.
In this paper, we present a novel data aggregation architecture model that
combines a multi- resolution structure with compressed sensing. The compression
thresholds vary over the aggregation hierarchy, reflecting the underlying data
field. Compared with previous relevant work, the proposed model shows its
significant energy saving from theoretical analysis. We have also implemented
the proposed CS- based data aggregation framework on a SIDnet SWANS platform,
discrete event simulator commonly used for WSN simulations. Our experiments
show substantial energy savings, ranging from 37% to 77% for different nodes in
the networking depending on the position of hierarchy."
A survey of available techniques in hardware to reduce energy consumption
"We describe a distributed randomized algorithm computing approximate
distances and routes that approximate shortest paths. Let n denote the number
of nodes in the graph, and let HD denote the hop diameter of the graph, i.e.,
the diameter of the graph when all edges are considered to have unit weight.
Given 0 < eps <= 1/2, our algorithm runs in weak-O(n^(1/2 + eps) + HD)
communication rounds using messages of O(log n) bits and guarantees a stretch
of O(eps^(-1) log eps^(-1)) with high probability. This is the first
distributed algorithm approximating weighted shortest paths that uses small
messages and runs in weak-o(n) time (in graphs where HD in weak-o(n)). The time
complexity nearly matches the lower bounds of weak-Omega(sqrt(n) + HD) in the
small-messages model that hold for stateless routing (where routing decisions
do not depend on the traversed path) as well as approximation of the weigthed
diameter. Our scheme replaces the original identifiers of the nodes by labels
of size O(log eps^(-1) log n). We show that no algorithm that keeps the
original identifiers and runs for weak-o(n) rounds can achieve a
polylogarithmic approximation ratio.
  Variations of our techniques yield a number of fast distributed approximation
algorithms solving related problems using small messages. Specifically, we
present algorithms that run in weak-O(n^(1/2 + eps) + HD) rounds for a given 0
< eps <= 1/2, and solve, with high probability, the following problems:
  - O(eps^(-1))-approximation for the Generalized Steiner Forest (the running
time in this case has an additive weak-O(t^(1 + 2eps)) term, where t is the
number of terminals);
  - O(eps^(-2))-approximation of weighted distances, using node labels of size
O(eps^(-1) log n) and weak-O(n^(eps)) bits of memory per node;
  - O(eps^(-1))-approximation of the weighted diameter;
  - O(eps^(-3))-approximate shortest paths using the labels 1,...,n."
"A Content Distribution Network (CDN) can be defined as an overlay system that
replicates copies of contents at multiple points of a network, close to the
final users, with the objective of improving data access. CDN technology is
widely used for the distribution of large-sized contents, like in video
streaming. In this paper we address the problem of finding the best server for
each customer request in CDNs, in order to minimize the overall cost. We
consider the problem as a transportation problem and a distributed algorithm is
proposed to solve it. The algorithm is composed of two independent phases: a
distributed heuristic finds an initial solution that may be later improved by a
distributed transportation simplex algorithm. It is compared with the
sequential version of the transportation simplex and with an auction-based
distributed algorithm. Computational experiments carried out on a set of
instances adapted from the literature revealed that our distributed approach
has a performance similar to its sequential counterpart, in spite of not
requiring global information about the contents requests. Moreover, the results
also showed that the new method outperforms the based-auction distributed
algorithm."
"Distributed frameworks are gaining increasingly widespread use in
applications that process large amounts of data. One important example
application is large scale similarity search, for which Locality Sensitive
Hashing (LSH) has emerged as the method of choice, specially when the data is
high-dimensional. At its core, LSH is based on hashing the data points to a
number of buckets such that similar points are more likely to map to the same
buckets. To guarantee high search quality, the LSH scheme needs a rather large
number of hash tables. This entails a large space requirement, and in the
distributed setting, with each query requiring a network call per hash bucket
look up, this also entails a big network load. The Entropy LSH scheme proposed
by Panigrahy significantly reduces the number of required hash tables by
looking up a number of query offsets in addition to the query itself. While
this improves the LSH space requirement, it does not help with (and in fact
worsens) the search network efficiency, as now each query offset requires a
network call. In this paper, focusing on the Euclidian space under $l_2$ norm
and building up on Entropy LSH, we propose the distributed Layered LSH scheme,
and prove that it exponentially decreases the network cost, while maintaining a
good load balance between different machines. Our experiments also verify that
our scheme results in a significant network traffic reduction that brings about
large runtime improvement in real world applications."
"HEP Analysis Facility is a cluster designed and implemented in Scientific
Linux Cern 5.5 to grant High Energy Physics researchers one place where they
can go to undertake a particular task or to provide a parallel processing
architecture in which CPU resources are shared across a network and all
machines function as one large supercomputer."
"HEP Cluster is designed and implemented in Scientific Linux Cern 5.5 to grant
High Energy Physics researchers one place where they can go to undertake a
particular task or to provide a parallel processing architecture in which CPU
resources are shared across a network and all machines function as one large
supercomputer. It gives physicists a facility to access computers and data,
transparently, without having to consider location, operating system, account
administration, and other details. By using this facility researchers can
process their jobs much faster than the stand alone desktop systems. Keywords:
Cluster, Network, Storage, Parallel Computing & Gris."
"High Performance Computing is an internet based computing which makes
computer infrastructure and services available to the user for research
purpose. However, an important issue which needs to be resolved before High
Performance Computing Cluster with large pool of servers gain widespread
acceptance is the design of data centers with less energy consumption. It is
only possible when servers produce less heat and consume less power. Systems
reliability decreases with increase in temperature due to heat generation
caused by large power consumption as computing in high temperature is more
error-prone. Here in this paper our approach is to design and implement a high
performance cluster for high-end research in the High Energy Physics stream.
This involves the usage of fine grained power gating technique in
microprocessors and energy efficient algorithms that reduce the overall running
cost of the data center."
"Efficient resource allocation is one of the critical performance challenges
in an Infrastructure as a Service (IaaS) cloud. Virtual machine (VM) placement
and migration decision making methods are integral parts of these resource
allocation mechanisms. We present a novel virtual machine placement algorithm
which takes performance isolation amongst VMs and their continuous resource
usage into account while taking placement decisions. Performance isolation is a
form of resource contention between virtual machines interested in basic low
level hardware resources (CPU, memory, storage, and networks bandwidth).
Resource contention amongst multiple co-hosted neighbouring VMs form the basis
of the presented novel approach. Experiments are conducted to show the various
categories of applications and effect of performance isolation and resource
contention amongst them. A per-VM 3-dimensional Resource Utilization Vector
(RUV) has been continuously calculated and used for placement decisions while
taking conflicting resource interests of VMs into account. Experiments using
the novel placement algorithm: VUPIC, show effective improvements in VM
performance as well as overall resource utilization of the cloud."
"The Cloud infrastructure services landscape advances steadily leaving users
in the agony of choice. As a result, Cloud service identification and discovery
remains a hard problem due to different service descriptions, non standardised
naming conventions and heterogeneous types and features of Cloud services. In
this paper, we present an OWL based ontology, the Cloud Computing Ontology
(CoCoOn) that defines functional and non functional concepts, attributes and
relations of infrastructure services. We also present a system..."
"We consider a request processing system composed of organizations and their
servers connected by the Internet.
  The latency a user observes is a sum of communication delays and the time
needed to handle the request on a server. The handling time depends on the
server congestion, i.e. the total number of requests a server must handle. We
analyze the problem of balancing the load in a network of servers in order to
minimize the total observed latency. We consider both cooperative and selfish
organizations (each organization aiming to minimize the latency of the
locally-produced requests). The problem can be generalized to the task
scheduling in a distributed cloud; or to content delivery in an
organizationally-distributed CDNs.
  In a cooperative network, we show that the problem is polynomially solvable.
We also present a distributed algorithm iteratively balancing the load. We show
how to estimate the distance between the current solution and the optimum based
on the amount of load exchanged by the algorithm. During the experimental
evaluation, we show that the distributed algorithm is efficient, therefore it
can be used in networks with dynamically changing loads.
  In a network of selfish organizations, we prove that the price of anarchy
(the worst-case loss of performance due to selfishness) is low when the network
is homogeneous and the servers are loaded (the request handling time is high
compared to the communication delay). After relaxing these assumptions, we
assess the loss of performance caused by the selfishness experimentally,
showing that it remains low.
  Our results indicate that a network of servers handling requests can be
efficiently managed by a distributed algorithm. Additionally, even if the
network is organizationally distributed, with individual organizations
optimizing performance of their requests, the network remains efficient."
"P2P architecture is a viable option for enterprise backup. In contrast to
dedicated backup servers, nowadays a standard solution, making backups directly
on organization's workstations should be cheaper (as existing hardware is
used), more efficient (as there is no single bottleneck server) and more
reliable (as the machines are geographically dispersed).
  We present the architecture of a p2p backup system that uses pairwise
replication contracts between a data owner and a replicator. In contrast to
standard p2p storage systems using directly a DHT, the contracts allow our
system to optimize replicas' placement depending on a specific optimization
strategy, and so to take advantage of the heterogeneity of the machines and the
network. Such optimization is particularly appealing in the context of backup:
replicas can be geographically dispersed, the load sent over the network can be
minimized, or the optimization goal can be to minimize the backup/restore time.
However, managing the contracts, keeping them consistent and adjusting them in
response to dynamically changing environment is challenging.
  We built a scientific prototype and ran the experiments on 150 workstations
in the university's computer laboratories and, separately, on 50 PlanetLab
nodes. We found out that the main factor affecting the quality of the system is
the availability of the machines. Yet, our main conclusion is that it is
possible to build an efficient and reliable backup system on highly unreliable
machines (our computers had just 13% average availability)."
"Arbitrary usage of cloud computing, either private or public, can lead to
uneconomical energy consumption in data processing, storage and communication.
Hence, green cloud computing solutions aim not only to save energy but also
reduce operational costs and carbon footprints on the environment. In this
paper, an Integrated Green Cloud Architecture (IGCA) is proposed that comprises
of a client-oriented Green Cloud Middleware to assist managers in better
overseeing and configuring their overall access to cloud services in the
greenest or most energy-efficient way. Decision making, whether to use local
machine processing, private or public clouds, is smartly handled by the
middleware using predefined system specifications such as service level
agreement (SLA), Quality of service (QoS), equipment specifications and job
description provided by IT department. Analytical model is used to show the
feasibility to achieve efficient energy consumption while choosing between
local, private and public Cloud service provider (CSP)."
"In this paper, we examine the different measures of Fault Tolerance in a
Distributed Simulated Annealing process. Optimization by Simulated Annealing on
a distributed system is prone to various sources of failure. We analyse
simulated annealing algorithm, its architecture in distributed platform and
potential sources of failures. We examine the behaviour of tolerant distributed
system for optimization task. We present possible methods to overcome the
failures and achieve fault tolerance for the distributed simulated annealing
process. We also examine the implementation of Simulated Annealing in MapReduce
system and possible ways to prevent failures in reaching the global optima.
This paper will be beneficial to those who are interested in implementing a
large scale distributed simulated annealing optimization problem of industrial
or academic interest. We recommend hybrid tolerance technique to optimize the
trade-off between efficiency and availability."
"The GIPSY system provides a framework for a distributed multi-tier
demand-driven evaluation of heterogeneous programs, in which certain tiers can
generate demands, while others can respond to demands to work on them. They are
connected through a virtual network that can be flexibly reconfigured at
run-time. Although the demand generator components were originally designed
specifically for the eductive (demand-driven) evaluation of Lucid intensional
programs, the GIPSY's run-time's flexible framework design enables it to
perform the execution of various kinds of programs that can be evaluated using
the demand-driven computational model. Management of the GISPY networks has
become a tedious (although scripted) task that took manual command-line console
to do, which does not scale for large experiments. Therefore a new component
has been designed and developed to allow users to represent, visualize, and
interactively create, configure and seamlessly manage such a network as a
graph. Consequently, this work presents a Graphical GMT Manager, an interactive
graph-based assistant component for the GIPSY network creation and
configuration management. Besides allowing the management of the nodes and
tiers (mapped to hosts where store, workers, and generators reside), it lets
the user to visually control the network parameters and the interconnection
between computational nodes at run-time. In this paper we motivate and present
the key features of this newly implemented graph-based component. We give the
graph representation details, mapping of the graph nodes to tiers, tier groups,
and specific commands. We provide the requirements and design specification of
the tool and its implementation. Then we detail and discuss some experimental
results."
"In the last ten years host virtualization has brought a revolution in the way
almost every activity related to information technology is thought of and
performed. The use of virtualization for HPC and HTC computing, while eagerly
desired, has probably been one of the last steps of this revolution, the
performance loss due to the hardware abstraction layer being the cause that
slowed down a process that has been much faster in other fields. Nowadays the
widespread diffusion of virtualization and of new virtualization techniques
seem to have helped breaking this last barrier and virtual host computing
infrastructures for HPC and HTC are found in many data centers. In this
document the approach adopted at the INFN ""Laboratori Nazionali del Gran Sasso""
for providing computational resources via a virtual host based computing
facility is described. Particular evidence is given to the storage layout, to
the middleware architecture and to resource allocation strategies, as these are
issues for which a personalized solution was adopted. Other aspects may be
covered in the future within other documents."
"Apriori is one of the key algorithms to generate frequent itemsets. Analyzing
frequent itemset is a crucial step in analysing structured data and in finding
association relationship between items. This stands as an elementary foundation
to supervised learning, which encompasses classifier and feature extraction
methods. Applying this algorithm is crucial to understand the behaviour of
structured data. Most of the structured data in scientific domain are
voluminous. Processing such kind of data requires state of the art computing
machines. Setting up such an infrastructure is expensive. Hence a distributed
environment such as a clustered setup is employed for tackling such scenarios.
Apache Hadoop distribution is one of the cluster frameworks in distributed
environment that helps by distributing voluminous data across a number of nodes
in the framework. This paper focuses on map/reduce design and implementation of
Apriori algorithm for structured data analysis."
"Cloud computing is getting mature, and the interoperability and
standardization of the clouds is still waiting to be solved. This paper
discussed the interoperability among clouds about message transmission, data
transmission and virtual machine transfer. Starting from IEEE Pioneering Cloud
Computing Initiative, this paper discussed about standardization of the cloud
computing, especially intercloud cloud computing. This paper also discussed the
standardization from the market-oriented view."
"We present a binary routing tree protocol for distributed hash table
overlays. Using this protocol each peer can independently route messages to its
parent and two descendants on the fly without any maintenance, global context,
and synchronization. The protocol is then extended to support tree change
notification with similar efficiency. The resulting tree is almost perfectly
dense and balanced, and has O(1) stretch if the distributed hash table is
symmetric Chord. We use the tree routing protocol to overcome the main
impediment for implementation of local thresholding algorithms in peer-to-peer
systems -- their requirement for cycle free routing. Direct comparison of a
gossip-based algorithm and a corresponding local thresholding algorithm on a
majority voting problem reveals that the latter obtains superior accuracy using
a fraction of the communication overhead."
"We introduce new techniques for proving lower bounds on the running time of
randomized algorithms for asynchronous agreement against powerful adversaries.
In particular, we define a \emph{strongly adaptive adversary} that is
computationally unbounded and has a limited ability to corrupt a dynamic subset
of processors by erasing their memories. We demonstrate that the randomized
agreement algorithms designed by Ben-Or and Bracha to tolerate crash or
Byzantine failures in the asynchronous setting extend to defeat a strongly
adaptive adversary. These algorithms have essentially perfect correctness and
termination, but at the expense of exponential running time. In the case of the
strongly adaptive adversary, we show that this dismally slow running time is
\emph{inherent}: we prove that any algorithm with essentially perfect
correctness and termination against the strongly adaptive adversary must have
exponential running time. We additionally interpret this result as yielding an
enhanced understanding of the tools needed to simultaneously achieving perfect
correctness and termination as well as fast running time for randomized
algorithms tolerating crash or Byzantine failures."
"Parallel programmers face the often irreconcilable goals of programmability
and performance. HPC systems use distributed memory for scalability, thereby
sacrificing the programmability advantages of shared memory programming models.
Furthermore, the rapid adoption of heterogeneous architectures, often with
non-cache-coherent memory systems, has further increased the challenge of
supporting shared memory programming models. Our primary objective is to define
a memory consistency model that presents the familiar thread-based shared
memory programming model, but allows good application performance on
non-cache-coherent systems, including distributed memory clusters and
accelerator-based systems. We propose regional consistency (RegC), a new
consistency model that achieves this objective. Results on up to 256 processors
for representative benchmarks demonstrate the potential of RegC in the context
of our prototype distributed shared memory system."
"FDTD codes, such as Sophie developed at CEA/DAM, no longer take advantage of
the processor's increased computing power, especially recently with the raising
multicore technology. This is rooted in the fact that low order numerical
schemes need an important memory bandwidth to bring and store the computed
fields. The aim of this article is to present a programming method at the
software's architecture level that improves the memory access pattern in order
to reuse data in cache instead of constantly accessing RAM memory. We will
exhibit a more than two computing time improvement in practical applications.
The target audience of this article is made of computing scientists and of
electrical engineers that develop simulation codes with no specific knowledge
in computer science or electronics."
"Service-Oriented Computing (SOC) enables the composition of loosely coupled
service agents provided with varying Quality of Service (QoS) levels,
effectively forming a multiagent system (MAS). Selecting a (near-)optimal set
of services for a composition in terms of QoS is crucial when many functionally
equivalent services are available. As the number of distributed services,
especially in the cloud, is rising rapidly, the impact of the network on the
QoS keeps increasing. Despite this and opposed to most MAS approaches, current
service approaches depend on a centralized architecture which cannot adapt to
the network. Thus, we propose a scalable distributed architecture composed of a
flexible number of distributed control nodes. Our architecture requires no
changes to existing services and adapts from a centralized to a completely
distributed realization by adding control nodes as needed. Also, we propose an
extended QoS aggregation algorithm that allows to accurately estimate network
QoS. Finally, we evaluate the benefits and optimality of our architecture in a
distributed environment."
"This paper proposes using file system custom metadata as a bidirectional
communication channel between applications and the storage system. This channel
can be used to pass hints that enable cross-layer optimizations, an option
hindered today by the ossified file-system interface. We study this approach in
context of storage system support for large-scale workflow execution systems:
Our workflow optimized storage system (WOSS), exploits application hints to
provide per-file optimized operations, and exposes data location to enable
location-aware scheduling.
  This paper argues that an incremental adoption path for adopting cross-layer
optimizations in storage systems exists, presents the system architecture for a
workflow-optimized storage system and its integration with a workflow runtime
engine, and evaluates the proposed approach using synthetic as well as real
applications workloads."
"Scientific problems that depend on processing large amounts of data require
overcoming challenges in multiple areas: managing large-scale data
distribution, controlling co-placement and scheduling of data with compute
resources, and storing, transferring, and managing large volumes of data.
Although there exist multiple approaches to addressing each of these
challenges, an integrative approach is missing; furthermore, extending existing
functionality or enabling interoperable capabilities remains difficult at best.
We propose the concept of Pilot-Data to address the fundamental challenges of
co-placement and scheduling of data and compute in heterogeneous and
distributed environments with interoperability and extensibility as first-order
concerns. Pilot-Data is an extension of the Pilot-Job abstraction for
supporting the management of data in conjunction with compute tasks. Pilot-Data
separates logical data units from physical storage, thereby providing the basis
for efficient compute/data placement and scheduling. In this paper, we discuss
the design and implementation of the Pilot-Data prototype, demonstrate its use
by data-intensive applications on multiple production distributed
cyberinfrastructure and illustrate the advantages arising from flexible
execution modes enabled by Pilot-Data. Our experiments utilize an
implementation of Pilot-Data in conjunction with a scalable Pilot-Job (BigJob)
to establish the application performance that can be enabled by the use of
Pilot-Data. We demonstrate how the concept of Pilot-Data also provides the
basis upon which to build tools and support capabilities like affinity which in
turn can be used for advanced data-compute co-placement and scheduling."
"Transactional memory allows the user to declare sequences of instructions as
speculative \emph{transactions} that can either \emph{commit} or \emph{abort}.
If a transaction commits, it appears to be executed sequentially, so that the
committed transactions constitute a correct sequential execution. If a
transaction aborts, none of its instructions can affect other transactions.
  The popular criterion of \emph{opacity} requires that the views of aborted
transactions must also be consistent with the global sequential order
constituted by committed ones. This is believed to be important, since
inconsistencies observed by an aborted transaction may cause a fatal
irrecoverable error or waste of the system in an infinite loop. Intuitively, an
opaque implementation must ensure that no intermediate view a transaction
obtains before it commits or aborts can be affected by a transaction that has
not started committing yet, so called \emph{deferred-update} semantics.
  In this paper, we intend to grasp this intuition formally. We propose a
variant of opacity that explicitly requires the sequential order to respect the
deferred-update semantics. We show that our criterion is a safety property,
i.e., it is prefix- and limit-closed. Unlike opacity, our property also ensures
that a serialization of a history implies serializations of its prefixes.
Finally, we show that our property is equivalent to opacity if we assume that
no two transactions commit identical values on the same variable, and present a
counter-example for scenarios when the ""unique-write"" assumption does not hold."
"This paper describes the use of a distributed cloud computing system for
high-throughput computing (HTC) scientific applications. The distributed cloud
computing system is composed of a number of separate
Infrastructure-as-a-Service (IaaS) clouds that are utilized in a unified
infrastructure. The distributed cloud has been in production-quality operation
for two years with approximately 500,000 completed jobs where a typical
workload has 500 simultaneous embarrassingly-parallel jobs that run for
approximately 12 hours. We review the design and implementation of the system
which is based on pre-existing components and a number of custom components. We
discuss the operation of the system, and describe our plans for the expansion
to more sites and increased computing capacity."
"Given the diversity of commercial Cloud services, performance evaluations of
candidate services would be crucial and beneficial for both service customers
(e.g. cost-benefit analysis) and providers (e.g. direction of service
improvement). Before an evaluation implementation, the selection of suitable
factors (also called parameters or variables) plays a prerequisite role in
designing evaluation experiments. However, there seems a lack of systematic
approaches to factor selection for Cloud services performance evaluation. In
other words, evaluators randomly and intuitively concerned experimental factors
in most of the existing evaluation studies. Based on our previous taxonomy and
modeling work, this paper proposes a factor framework for experimental design
for performance evaluation of commercial Cloud services. This framework
capsules the state-of-the-practice of performance evaluation factors that
people currently take into account in the Cloud Computing domain, and in turn
can help facilitate designing new experiments for evaluating Cloud services."
"Self-stabilization ensures that, after any transient fault, the system
recovers in a finite time and eventually exhibits. Speculation consists in
guaranteeing that the system satisfies its requirements for any execution but
exhibits significantly better performances for a subset of executions that are
more probable. A speculative protocol is in this sense supposed to be both
robust and efficient in practice. We introduce the notion of speculative
stabilization which we illustrate through the mutual exclusion problem. We then
present a novel speculatively stabilizing mutual exclusion protocol. Our
protocol is self-stabilizing for any asynchronous execution. We prove that its
stabilization time for synchronous executions is diam(g)/2 steps (where diam(g)
denotes the diameter of the system). This complexity result is of independent
interest. The celebrated mutual exclusion protocol of Dijkstra stabilizes in n
steps (where n is the number of processes) in synchronous executions and the
question whether the stabilization time could be strictly smaller than the
diameter has been open since then (almost 40 years). We show that this is
indeed possible for any underlying topology. We also provide a lower bound
proof that shows that our new stabilization time of diam(g)/2 steps is optimal
for synchronous executions, even if asynchronous stabilization is not required."
"Rapid growth and proliferation of cloud computing services around the world
has increased the necessity and significance of improving the energy efficiency
of could implementations. Virtual machines (VM) comprise the backend of most,
if not all, cloud computing services. Several VMs are often consolidated on a
physical machine to better utilize its resources. We take into account the
cooling and network structure of the datacenter hosting the physical machines
when consolidating the VMs so that fewer racks and routers are employed,
without compromising the service-level agreements, so that unused routing and
cooling equipment can be turned off to reduce energy consumption. Our
experimental results on four benchmarks shows that our technique improves
energy consumption of servers, network equipment, and cooling systems by 2.5%,
18.8%, and 28.2% respectively, resulting in a total of 14.7% improvement on
average in the entire datacenter."
"The availability of powerful computing hardware in IaaS clouds makes cloud
computing attractive also for computational workloads that were up to now
almost exclusively run on HPC clusters.
  In this paper we present the VM-MAD Orchestrator software: an open source
framework for cloudbursting Linux-based HPC clusters into IaaS clouds but also
computational grids. The Orchestrator is completely modular, allowing flexible
configurations of cloudbursting policies. It can be used with any batch system
or cloud infrastructure, dynamically extending the cluster when needed. A
distinctive feature of our framework is that the policies can be tested and
tuned in a simulation mode based on historical or synthetic cluster accounting
data.
  In the paper we also describe how the VM-MAD Orchestrator was used in a
production environment at the FGCZ to speed up the analysis of mass
spectrometry-based protein data by cloudbursting to the Amazon EC2. The
advantages of this hybrid system are shown with a large evaluation run using
about hundred large EC2 nodes."
"Consider a network of n processes each of which has a d-dimensional vector of
reals as its input. Each process can communicate directly with all the
processes in the system; thus the communication network is a complete graph.
All the communication channels are reliable and FIFO (first-in-first-out). The
problem of Byzantine vector consensus (BVC) requires agreement on a
d-dimensional vector that is in the convex hull of the d-dimensional input
vectors at the non-faulty processes. We obtain the following results for
Byzantine vector consensus in complete graphs while tolerating up to f
Byzantine failures:
  * We prove that in a synchronous system, n >= max(3f+1, (d+1)f+1) is
necessary and sufficient for achieving Byzantine vector consensus.
  * In an asynchronous system, it is known that exact consensus is impossible
in presence of faulty processes. For an asynchronous system, we prove that n >=
(d+2)f+1 is necessary and sufficient to achieve approximate Byzantine vector
consensus.
  Our sufficiency proofs are constructive. We show sufficiency by providing
explicit algorithms that solve exact BVC in synchronous systems, and
approximate BVC in asynchronous systems.
  We also obtain tight bounds on the number of processes for achieving BVC
using algorithms that are restricted to a simpler communication pattern."
"We present the Hadoop Fair Sojourn Protocol (HFSP) scheduler, which
implements a size-based scheduling discipline for Hadoop. The benefits of
size-based scheduling disciplines are well recognized in a variety of contexts
(computer networks, operating systems, etc...), yet, their practical
implementation for a system such as Hadoop raises a number of important
challenges. With HFSP, which is available as an open-source project, we address
issues related to job size estimation, resource management and study the
effects of a variety of preemption strategies. Although the architecture
underlying HFSP is suitable for any size-based scheduling discipline, in this
work we revisit and extend the Fair Sojourn Protocol, which solves problems
related to job starvation that affect FIFO, Processor Sharing and a range of
size-based disciplines. Our experiments, in which we compare HFSP to standard
Hadoop schedulers, pinpoint at a significant decrease in average job sojourn
times - a metric that accounts for the total time a job spends in the system,
including waiting and serving times - for realistic workloads that we generate
according to production traces available in literature."
"Data availability is critical in distributed storage systems, especially when
node failures are prevalent in real life. A key requirement is to minimize the
amount of data transferred among nodes when recovering the lost or unavailable
data of failed nodes. This paper explores recovery solutions based on
regenerating codes, which are shown to provide fault-tolerant storage and
minimum recovery bandwidth. Existing optimal regenerating codes are designed
for single node failures. We build a system called CORE, which augments
existing optimal regenerating codes to support a general number of failures
including single and concurrent failures. We theoretically show that CORE
achieves the minimum possible recovery bandwidth for most cases. We implement
CORE and evaluate our prototype atop a Hadoop HDFS cluster testbed with up to
20 storage nodes. We demonstrate that our CORE prototype conforms to our
theoretical findings and achieves recovery bandwidth saving when compared to
the conventional recovery approach based on erasure codes."
"This paper deals with the impact of fault prediction techniques on
checkpointing strategies. We extend the classical first-order analysis of Young
and Daly in the presence of a fault prediction system, characterized by its
recall and its precision. In this framework, we provide an optimal algorithm to
decide when to take predictions into account, and we derive the optimal value
of the checkpointing period. These results allow to analytically assess the key
parameters that impact the performance of fault predictors at very large scale."
"Development of many futuristic technologies, such as MANET, VANET, iThings,
nano-devices, depend on efficient distributed communication protocols in
multi-hop ad hoc networks. A vast majority of research in this area focus on
design heuristic protocols, and analyze their performance by simulations on
networks generated randomly or obtained in practical measurements of some
(usually small-size) wireless networks. %some library. Moreover, they often
assume access to truly random sources, which is often not reasonable in case of
wireless devices. In this work we use a formal framework to study the problem
of broadcasting and its time complexity in any two dimensional Euclidean
wireless network with uniform transmission powers. For the analysis, we
consider two popular models of ad hoc networks based on the
Signal-to-Interference-and-Noise Ratio (SINR): one with opportunistic links,
and the other with randomly disturbed SINR. In the former model, we show that
one of our algorithms accomplishes broadcasting in $O(D\log^2 n)$ rounds, where
$n$ is the number of nodes and $D$ is the diameter of the network. If nodes
know a priori the granularity $g$ of the network, i.e., the inverse of the
maximum transmission range over the minimum distance between any two stations,
a modification of this algorithm accomplishes broadcasting in $O(D\log g)$
rounds.
  Finally, we modify both algorithms to make them efficient in the latter model
with randomly disturbed SINR, with only logarithmic growth of performance.
  Ours are the first provably efficient and well-scalable, under the two
models, distributed deterministic solutions for the broadcast task."
"We consider allocation problems that arise in the context of service
allocation in Clouds. More specifically, we assume on the one part that each
computing resource is associated to a capacity constraint, that can be chosen
using Dynamic Voltage and Frequency Scaling (DVFS) method, and to a probability
of failure. On the other hand, we assume that the service runs as a set of
independent instances of identical Virtual Machines. Moreover, there exists a
Service Level Agreement (SLA) between the Cloud provider and the client that
can be expressed as follows: the client comes with a minimal number of service
instances which must be alive at the end of the day, and the Cloud provider
offers a list of pairs (price,compensation), this compensation being paid by
the Cloud provider if it fails to keep alive the required number of services.
On the Cloud provider side, each pair corresponds actually to a guaranteed
success probability of fulfilling the constraint on the minimal number of
instances. In this context, given a minimal number of instances and a
probability of success, the question for the Cloud provider is to find the
number of necessary resources, their clock frequency and an allocation of the
instances (possibly using replication) onto machines. This solution should
satisfy all types of constraints during a given time period while minimizing
the energy consumption of used resources. We consider two energy consumption
models based on DVFS techniques, where the clock frequency of physical
resources can be changed. For each allocation problem and each energy model, we
prove deterministic approximation ratios on the consumed energy for algorithms
that provide guaranteed probability failures, as well as an efficient
heuristic, whose energy ratio is not guaranteed."
"This paper deals with the impact of fault prediction techniques on
checkpointing strategies. We suppose that the fault-prediction system provides
prediction windows instead of exact predictions, which dramatically complicates
the analysis of the checkpointing strategies. We propose a new approach based
upon two periodic modes, a regular mode outside prediction windows, and a
proactive mode inside prediction windows, whenever the size of these windows is
large enough. We are able to compute the best period for any size of the
prediction windows, thereby deriving the scheduling strategy that minimizes
platform waste. In addition, the results of this analytical evaluation are
nicely corroborated by a comprehensive set of simulations, which demonstrate
the validity of the model and the accuracy of the approach."
"Continuous availability of HPC systems built from commodity components have
become a primary concern as system size grows to thousands of processors. In
this paper, we present the analysis of 8-24 months of real failure data
collected from three HPC systems at the National Center for Supercomputing
Applications (NCSA) during 2001-2004. The results show that the availability is
98.7-99.8% and most outages are due to software halts. On the other hand, the
downtime are mostly contributed by hardware halts or scheduled maintenance. We
also used failure clustering analysis to identify several correlated failures."
"A group of mutually trusting clients outsources a computation service to a
remote server, which they do not fully trust and that may be subject to
attacks. The clients do not communicate with each other and would like to
verify the correctness of the remote computation and the consistency of the
server's responses. This paper first presents the Commutative-Operation
verification Protocol (COP) that ensures linearizability when the server is
correct and preserves fork-linearizability in any other case. All clients that
observe each other's operations are consistent, in the sense that their own
operations and those operations of other clients that they see are
linearizable. Second, this work extends COP through authenticated data
structures to Authenticated COP, which allows consistency verification of
outsourced services whose state is kept only remotely, by the server. This
yields the first fork-linearizable consistency verification protocol for
generic outsourced services that (1) relieves clients from storing the state,
(2) supports wait-free client operations, and (3) handles sequences of
arbitrary commutative operations."
"Data replication technologies enable efficient and highly-available data
access, thus gaining more and more interests in both the academia and the
industry. However, data replication introduces the problem of data consistency.
Modern commercial data replication systems often provide weak consistency for
high availability under certain failure scenarios. An important weak
consistency is Pipelined-RAM (PRAM) consistency. It allows different processes
to hold different views of data. To determine whether a data replication system
indeed provides PRAM consistency, we study the problem of Verifying PRAM
Consistency over read/write traces (or VPC, for short).
  We first identify four variants of VPC according to a) whether there are
Multiple shared variables (or one Single variable), and b) whether write
operations can assign Duplicate values (or only Unique values) for each shared
variable; the four variants are labeled VPC-SU, VPC-MU, VPC-SD, and VPC-MD.
Second, we present a simple VPC-MU algorithm, called RW-CLOSURE. It constructs
an operation graph $\mathcal{G}$ by iteratively adding edges according to three
rules. Its time complexity is $O(n^5)$, where n is the number of operations in
the trace. Third, we present an improved VPC-MU algorithm, called READ-CENTRIC,
with time complexity $O(n^4)$. Basically it attempts to construct the operation
graph $\mathcal{G}$ in an incremental and efficient way. Its correctness is
based on that of RW-CLOSURE. Finally, we prove that VPC-SD (so is VPC-MD) is
$\sf{NP}$-complete by reducing the strongly $\sf{NP}$-complete problem
3-PARTITION to it."
"Erasure codes are an integral part of many distributed storage systems aimed
at Big Data, since they provide high fault-tolerance for low overheads.
However, traditional erasure codes are inefficient on reading stored data in
degraded environments (when nodes might be unavailable), and on replenishing
lost data (vital for long term resilience). Consequently, novel codes optimized
to cope with distributed storage system nuances are vigorously being
researched. In this paper, we take an engineering alternative, exploring the
use of simple and mature techniques -juxtaposing a standard erasure code with
RAID-4 like parity. We carry out an analytical study to determine the efficacy
of this approach over traditional as well as some novel codes. We build upon
this study to design CORE, a general storage primitive that we integrate into
HDFS. We benchmark this implementation in a proprietary cluster and in EC2. Our
experiments show that compared to traditional erasure codes, CORE uses 50% less
bandwidth and is up to 75% faster while recovering a single failed node, while
the gains are respectively 15% and 60% for double node failures."
"Grid computing has attracted many researchers over a few years, and as a
result many new protocols have emerged and also evolved since its inception a
decade ago. Grid protocols play major role in implementing services that
facilitate coordinated resource sharing across diverse organizations. In this
paper, we provide comprehensive coverage of different core Grid protocols that
can be used in Global Grid Computing. We establish the classification of core
Grid protocols into i) Grid network communication and Grid data transfer
protocols, ii) Grid information security protocols, iii) Grid resource
information protocols, iv) Grid management protocols, and v) Grid interface
protocols, depending upon the kind of activities handled by these protocols.
All the classified protocols are also organized into layers of the Hourglass
model of Grid architecture to understand dependency among these protocols. We
also present the characteristics of each protocol. For better understanding of
these protocols, we also discuss applied protocols as examples from either
Globus toolkit or other popular Grid middleware projects. We believe that our
classification and characterization of Grid protocols will enable better
understanding of core Grid protocols and will motivate further research in the
area of Global Grid Computing."
"The present note points out a number of errors, omissions, redundancies and
arbitrary deviations from the standard terminology in the paper ""Resource
placement in Cartesian product of networks,"" by N. Imani, H. Sarbazi-Azad and
A.Y. Zomaya [J. Parallel Distrib. Comput. 70 (2010) 481-495]."
"The latest trends in high-performance computing systems show an increasing
demand on the use of a large scale multicore systems in a efficient way, so
that high compute-intensive applications can be executed reasonably well.
However, the exploitation of the degree of parallelism available at each
multicore component can be limited by the poor utilization of the memory
hierarchy available. Actually, the multicore architecture introduces some
distinct features that are already observed in shared memory and distributed
environments. One example is that subsets of cores can share different subsets
of memory. In order to achieve high performance it is imperative that a careful
allocation scheme of an application is carried out on the available cores,
based on a scheduling model that considers the main performance bottlenecks, as
for example, memory contention. In this paper, the {\em Multicore Cluster
Model} (MCM) is proposed, which captures the most relevant performance
characteristics in multicores systems such as the influence of memory hierarchy
and contention. Better performance was achieved when a load balance strategy
for a Branch-and-Bound application applied to the Partitioning Sets Problem is
based on MCM, showing its efficiency and applicability to modern systems."
"For large scale distributed storage systems, flash memories are an excellent
choice because flash memories consume less power, take lesser floor space for a
target throughput and provide faster access to data. In a traditional
distributed filesystem, even distribution is required to ensure load-balancing,
balanced space utilisation and failure tolerance. In the presence of flash
memories, in addition, we should also ensure that the number of writes to these
different flash storage nodes are evenly distributed, to ensure even wear of
flash storage nodes, so that unpredictable failures of storage nodes are
avoided. This requires that we distribute updates and do garbage collection,
across the flash storage nodes. We have motivated the distributed wearlevelling
problem considering the replica placement algorithm for HDFS. Viewing the
wearlevelling across flash storage nodes as a distributed co-ordination
problem, we present an alternate design, to reduce the message communication
cost across participating nodes. We demonstrate the effectiveness of our design
through simulation"
"In this work, we extend the topology-based approach for characterizing
computability in asynchronous crash-failure distributed systems to asynchronous
Byzantine systems. We give the first theorem with necessary and sufficient
conditions to solve arbitrary tasks in asynchronous Byzantine systems where an
adversary chooses faulty processes. In our adversarial formulation, outputs of
non-faulty processes are constrained in terms of inputs of non-faulty processes
only. For colorless tasks, an important subclass of distributed problems, the
general result reduces to an elegant model that effectively captures the
relation between the number of processes, the number of failures, as well as
the topological structure of the task's simplicial complexes."
"We design, implement, and evaluate GPU-based algorithms for the maximum
cardinality matching problem in bipartite graphs. Such algorithms have a
variety of applications in computer science, scientific computing,
bioinformatics, and other areas. To the best of our knowledge, ours is the
first study which focuses on GPU implementation of the maximum cardinality
matching algorithms. We compare the proposed algorithms with serial and
multicore implementations from the literature on a large set of real-life
problems where in majority of the cases one of our GPU-accelerated algorithms
is demonstrated to be faster than both the sequential and multicore
implementations."
"In this article, we establish orientation and connectivity based criteria for
the agreement algorithm to achieve asymptotic consensus in the context of
time-varying topology and communication delays. These criteria unify and extend
many earlier convergence results on the agreement algorithm for deterministic
and discrete-time multiagent systems."
"Parallel computing using accelerators has gained widespread research
attention in the past few years. In particular, using GPUs for general purpose
computing has brought forth several success stories with respect to time taken,
cost, power, and other metrics. However, accelerator based computing has
signifi- cantly relegated the role of CPUs in computation. As CPUs evolve and
also offer matching computational resources, it is important to also include
CPUs in the computation. We call this the hybrid computing model. Indeed, most
computer systems of the present age offer a degree of heterogeneity and
therefore such a model is quite natural.
  We reevaluate the claim of a recent paper by Lee et al.(ISCA 2010). We argue
that the right question arising out of Lee et al. (ISCA 2010) should be how to
use a CPU+GPU platform efficiently, instead of whether one should use a CPU or
a GPU exclusively. To this end, we experiment with a set of 13 diverse
workloads ranging from databases, image processing, sparse matrix kernels, and
graphs. We experiment with two different hybrid platforms: one consisting of a
6-core Intel i7-980X CPU and an NVidia Tesla T10 GPU, and another consisting of
an Intel E7400 dual core CPU with an NVidia GT520 GPU. On both these platforms,
we show that hybrid solutions offer good advantage over CPU or GPU alone
solutions. On both these platforms, we also show that our solutions are 90%
resource efficient on average.
  Our work therefore suggests that hybrid computing can offer tremendous
advantages at not only research-scale platforms but also the more realistic
scale systems with significant performance gains and resource efficiency to the
large scale user community."
"Modern distributed systems use names everywhere. Lockservices such as Chubby
and ZooKeeper provide an effective mechanism for mapping from application names
to server instances, but proper usage of them requires a large amount of
error-prone boiler-plate code.
  Application programmers often try to write wrappers to abstract away this
logic, but it turns out there is a more general and easier way of handling the
issue. We show that by extending the existing name resolution capabilities of
RPC libraries, we can remove the need for such annoying boiler-plate code while
at the same time making our services more robust."
"This paper presents a non-blocking Patricia trie implementation for an
asynchronous shared-memory system using Compare&Swap. The trie implements a
linearizable set and supports three update operations: insert adds an element,
delete removes an element and replace replaces one element by another. The
replace operation is interesting because it changes two different locations of
tree atomically. If all update operations modify different parts of the trie,
they run completely concurrently. The implementation also supports a wait-free
find operation, which only reads shared memory and never changes the data
structure. Empirically, we compare our algorithms to some existing set
implementations."
"Search pattern experienced by the processor to search an element in secondary
storage devices follows a random sequence. Formally, it is a random walk and
its modeling is crucial in studying performance metrics like memory access
time. In this paper, we first model the random walk using extended Fibonacci
series. Our simulation is done on a parallel computing model (PRAM) with EREW
strategy. Three search primitives are proposed under parallel computing model
and each primitive is thoroughly tested on an array of size $10^7$ with the
size of random walk being $10^4$. Our findings reveal that search primitive
with pointer jumping is better than the other two primitives. Our key
contribution lies in modeling random walk as an extended Fibonacci series
generator and simulating the same with various search primitives."
"We present a simple, work-optimal and synchronization-free solution to the
problem of stably merging in parallel two given, ordered arrays of m and n
elements into an ordered array of m+n elements. The main contribution is a new,
simple, fast and direct algorithm that determines, for any prefix of the stably
merged output sequence, the exact prefixes of each of the two input sequences
needed to produce this output prefix. More precisely, for any given index
(rank) in the resulting, but not yet constructed output array representing an
output prefix, the algorithm computes the indices (co-ranks) in each of the two
input arrays representing the required input prefixes without having to merge
the input arrays. The co-ranking algorithm takes O(log min(m,n)) time steps.
The algorithm is used to devise a perfectly load-balanced, stable, parallel
merge algorithm where each of p processing elements has exactly the same number
of input elements to merge. Compared to other approaches to the parallel merge
problem, our algorithm is considerably simpler and can be faster up to a factor
of two. Compared to previous algorithms for solving the co-ranking problem, the
algorithm given here is direct and maintains stability in the presence of
repeated elements at no extra space or time cost. When the number of processing
elements p does not exceed (m+n)/log min(m,n), the parallel merge algorithm has
optimal speedup. It is easy to implement on both shared and distributed memory
parallel systems."
"Graphics processors, or GPUs, have recently been widely used as accelerators
in the shared environments such as clusters and clouds. In such shared
environments, many kernels are submitted to GPUs from different users, and
throughput is an important metric for performance and total ownership cost.
Despite the recently improved runtime support for concurrent GPU kernel
executions, the GPU can be severely underutilized, resulting in suboptimal
throughput. In this paper, we propose Kernelet, a runtime system with dynamic
slicing and scheduling techniques to improve the throughput of concurrent
kernel executions on the GPU. With slicing, Kernelet divides a GPU kernel into
multiple sub-kernels (namely slices). Each slice has tunable occupancy to allow
co-scheduling with other slices and to fully utilize the GPU resources. We
develop a novel and effective Markov chain based performance model to guide the
scheduling decision. Our experimental results demonstrate up to 31.1% and 23.4%
performance improvement on NVIDIA Tesla C2050 and GTX680 GPUs, respectively."
"The increasing number of processing elements and decreas- ing memory to core
ratio in modern high-performance platforms makes efficient strong scaling a key
requirement for numerical algorithms. In order to achieve efficient scalability
on massively parallel systems scientific software must evolve across the entire
stack to exploit the multiple levels of parallelism exposed in modern
architectures. In this paper we demonstrate the use of hybrid MPI/OpenMP
parallelisation to optimise parallel sparse matrix-vector multiplication in
PETSc, a widely used scientific library for the scalable solution of partial
differential equations. Using large matrices generated by Fluidity, an open
source CFD application code which uses PETSc as its linear solver engine, we
evaluate the effect of explicit communication overlap using task-based
parallelism and show how to further improve performance by explicitly load
balancing threads within MPI processes. We demonstrate a significant speedup
over the pure-MPI mode and efficient strong scaling of sparse matrix-vector
multiplication on Fujitsu PRIMEHPC FX10 and Cray XE6 systems."
"This study focuses on the performance of two classical dense linear algebra
algorithms, the LU and the QR factorizations, on multilevel hierarchical
platforms. We first introduce a new model called Hierarchical Cluster Platform
(HCP), encapsulating the characteristics of such platforms. The focus is set on
reducing the communication requirements of studied algorithms at each level of
the hierarchy. Lower bounds on communications are therefore extended with
respect to the HCP model. We then introduce multilevel LU and QR algorithms
tailored for those platforms, and provide a detailed performance analysis. We
also provide a set of numerical experiments and performance predictions
demonstrating the need for such algorithms on large platforms."
"Replication is a standard technique for fault tolerance in distributed
systems modeled as deterministic finite state machines (DFSMs or machines). To
correct f crash or f/2 Byzantine faults among n different machines, replication
requires nf additional backup machines. We present a solution called fusion
that requires just f additional backup machines. First, we build a framework
for fault tolerance in DFSMs based on the notion of Hamming distances. We
introduce the concept of an (f,m)-fusion, which is a set of m backup machines
that can correct f crash faults or f/2 Byzantine faults among a given set of
machines. Second, we present an algorithm to generate an (f,f)-fusion for a
given set of machines. We ensure that our backups are efficient in terms of the
size of their state and event sets. Our evaluation of fusion on the widely used
MCNC'91 benchmarks for DFSMs show that the average state space savings in
fusion (over replication) is 38% (range 0-99%). To demonstrate the practical
use of fusion, we describe its potential application to the MapReduce
framework. Using a simple case study, we compare replication and fusion as
applied to this framework. While a pure replication-based solution requires 1.8
million map tasks, our fusion-based solution requires only 1.4 million map
tasks with minimal overhead during normal operation or recovery. Hence, fusion
results in considerable savings in state space and other resources such as the
power needed to run the backup tasks."
"Over the last two decades, scientific workflow management systems (SWfMS)
have emerged as a means to facilitate the design, execution, and monitoring of
reusable scientific data processing pipelines. At the same time, the amounts of
data generated in various areas of science outpaced enhancements in
computational power and storage capabilities. This is especially true for the
life sciences, where new technologies increased the sequencing throughput from
kilobytes to terabytes per day. This trend requires current SWfMS to adapt:
Native support for parallel workflow execution must be provided to increase
performance; dynamically scalable ""pay-per-use"" compute infrastructures have to
be integrated to diminish hardware costs; adaptive scheduling of workflows in
distributed compute environments is required to optimize resource utilization.
In this survey we give an overview of parallelization techniques for SWfMS,
both in theory and in their realization in concrete systems. We find that
current systems leave considerable room for improvement and we propose key
advancements to the landscape of SWfMS."
"Workload consolidation, sharing physical resources among multiple workloads,
is a promising technique to save cost and energy in cluster computing systems.
This paper highlights a few challenges of workload consolidation for Hadoop as
one of the current state-of-the-art data-intensive cluster computing system.
Through a systematic step-by-step procedure, we investigate challenges for
efficient server consolidation in Hadoop environments. To this end, we first
investigate the inter-relationship between last level cache (LLC) contention
and throughput degradation for consolidated workloads on a single physical
server employing Hadoop distributed file system (HDFS). We then investigate the
general case of consolidation on multiple physical servers so that their
throughput never falls below a desired/predefined utilization level. We use our
empirical results to model consolidation as a classic two-dimensional bin
packing problem and then design a computationally efficient greedy algorithm to
achieve minimum throughput degradation on multiple servers. Results are very
promising and show that our greedy approach is able to achieve near optimal
solution in all experimented cases."
"A mobile ad hoc network (MANET) is a wireless network that uses multi-hop
peer-to- peer routing instead of static network infrastructure to provide
network connectivity. MANETs have applications in rapidly deployed and dynamic
military and civilian systems. The network topology in a MANET usually changes
with time. Therefore, there are new challenges for routing protocols in MANETs
since traditional routing protocols may not be suitable for MANETs. In recent
years, a variety of new routing protocols targeted specifically at this
environment have been developed, but little performance information on each
protocol and no realistic performance comparison between them is available.
This paper presents the results of a detailed packet-level simulation comparing
three multi-hop wireless ad hoc network routing protocols that cover a range of
design choices: DSR, NFPQR, and clustered NFPQR. By applying queuing
methodology to the introduced routing protocol the reliability and throughput
of the network is increased."
"High performance networks (e.g. Infiniband) rely on zero-copy operations for
performance. Zero-copy operations, as the name implies, avoid copying buffers
for sending and receiving data. Instead, hardware devices directly read and
write to application specified areas of memory. Since these networks can send
and receive at nearly the same speed as the memory bus inside machines,
zero-copy operations are necessary to achieve peak performance for many
applications.
  Unfortunately, programming with zero-copy APIs is a *giant pain*. Users must
carefully avoid using buffers that may be accessed by a device. Typically this
either results in spaghetti code (where every access to a buffer is checked
before usage), or blocking operations (which pretty much defeat the whole point
of zero-copy).
  We show that by abusing memory protection hardware, we can offer the best of
both worlds: a simple zero-copy mechanism which allows for non-blocking send
and receives while protecting against incorrect accesses."
"The application of the Reformulation Linearization Technique (RLT) to the
Quadratic Assignment Problem (QAP) leads to a tight linear relaxation with huge
dimensions that is hard to solve. Previous works found in the literature show
that these relaxations combined with branch-and-bound algorithms belong to the
state-of-the-art of exact methods for the QAP. For the level 3 RLT (RLT3),
using this relaxation is prohibitive in conventional machines for instances
with more than 22 locations due to memory limitations. This paper presents a
distributed version of a dual ascent algorithm for the RLT3 QAP relaxation that
approximately solves it for instances with up to 30 locations for the first
time. Although, basically, the distributed algorithm has been implemented on
top of its sequential conterpart, some changes, which improved not only the
parallel performance but also the quality of solutions, were proposed here.
When compared to other lower bounding methods found in the literature, our
algorithm generates the best known lower bounds for 26 out of the 28 tested
instances, reaching the optimal solution in 18 of them."
"This paper presents a self-organizing protocol for dynamic (unstructured P2P)
overlay networks, which allows to react to the variability of node arrivals and
departures. Through local interactions, the protocol avoids that the departure
of nodes causes a partitioning of the overlay. We show that it is sufficient to
have knowledge about 1st and 2nd neighbours, plus a simple interaction P2P
protocol, to make unstructured networks resilient to node faults. A simulation
assessment over different kinds of overlay networks demonstrates the viability
of the proposal."
"High Performance Computing (HPC) has evolved over the past decades into
increasingly complex and powerful systems. Current HPC systems consume several
MWs of power, enough to power small towns, and are in fact soon approaching the
limits of the power available to them. Estimates are with the given current
technology, achieving exascale will require hundreds of MW, which is not
feasible from multiple perspectives. Architecture and technology researchers
are aggressively addressing this; however as past history is shown, innovation
at these levels are not sufficient and have to be accompanied with innovations
at higher levels (algorithms, programming, runtime, OS) to achieve the multiple
orders of magnitude reduction - i.e., a comprehensive cross-layer and
application-aware strategy is required. Furthermore, energy/power-efficiency
has to be addressed in combination with quality of solutions, performance and
reliability and other objectives and appropriate tradeoffs are required."
"An emerging internet based super computing model is represented by cloud
computing. Cloud computing is the convergence and evolution of several concepts
from virtualization, distributed storage, grid, and automation management to
enable a more flexible approach for deploying and scaling applications.
However, cloud computing moves the application software and databases to the
large data centers, where the management of the data and services may not be
fully trustworthy. The concept of cloud computing on the basis of the various
definitions available in the industry and the characteristics of cloud
computing are being analyzed in this paper. The paper also describes the main
cloud service providers and their products followed by primary cloud computing
operating systems."
"In recent times cloud computing has appeared as a new model for hosting and
conveying services over the Internet. This model is striking to business
vendors as it eradicates the requirement for users to plan in advance, and it
permits the organization to start from low level and then add more resources
only if there is an increase in the service demand. Even though cloud computing
presents greater opportunities not only to information technology industry, but
every organization involved in utilizing the computing in one way or the other,
it is still in infancy with many problems to be fixed. The paper discusses
research challenges in cloud computing."
"Distributed Cyber Physical Systems designed for different scenario must be
capable enough to perform in an efficient manner in every situation. Earlier
approaches, such as CORBA, has performed but with different time constraints.
Therefore, there was the need to design reconfigurable, robust, validated and
consistent real time middle ware systems with end-to-end timing. In the
DCPS-HMM we have proposed the processor efficiency and data validation which
may proof crucial in implementing various distributed systems such as credit
card systems or file transfer through network."
"Cloud computing has given the new face to the distributed field. Two main
issues are discussed in this paper, (I) the process of finding the efficient
virtual machine by using the concept of load balancing algorithm. (II)
Reallocation of the Virtual Machines i.e. migration of the Virtual Machines
when cloud provider is not available with the required Virtual Machines. We
have discussed about the different load balancing algorithms which are used for
deciding the efficient Virtual Machine for the allocation to the client on
demand. While in the second issue is concern we have discuss about different
modules available for the migration of Virtual Machines from one source machine
to the other target machine. At last discussion about the different simulators
available for the cloud are carried out in this paper."
"Since beginning of Grid computing, scheduling of dependent tasks application
has attracted attention of researchers due to NP-Complete nature of the
problem. In Grid environment, scheduling is deciding about assignment of tasks
to available resources. Scheduling in Grid is challenging when the tasks have
dependencies and resources are heterogeneous. The main objective in scheduling
of dependent tasks is minimizing make-span. Due to NP-complete nature of
scheduling problem, exact solutions cannot generate schedule efficiently.
Therefore, researchers apply heuristic or random search techniques to get
optimal or near to optimal solution of such problems. In this paper, we show
how Genetic Algorithm can be used to solve dependent task scheduling problem.
We describe how initial population can be generated using random assignment and
height based approaches. We also present design of crossover and mutation
operators to enable scheduling of dependent tasks application without violating
dependency constraints. For implementation of GA based scheduling, we explore
and analyze SimGrid and GridSim simulation toolkits. From results, we found
that SimGrid is suitable, as it has support of SimDag API for DAG applications.
We found that GA based approach can generate schedule for dependent tasks
application in reasonable time while trying to minimize make-span."
"Analyzing a distributed computation is a hard problem in general due to the
combinatorial explosion in the size of the state-space with the number of
processes in the system. By abstracting the computation, unnecessary
explorations can be avoided. Computation slicing is an approach for abstracting
dis- tributed computations with respect to a given predicate. We focus on
regular predicates, a family of predicates that covers a large number of
commonly used predicates for runtime verification. The existing algorithms for
computation slicing are centralized in nature in which a single process is
responsible for computing the slice in either offline or online manner. In this
paper, we present a distributed online algorithm for computing the slice of a
distributed computation with respect to a regular predicate. Our algorithm
distributes the work and storage requirements across the system, thus reducing
the space and computation complexities per process. In addition, for
conjunctive predicates, our algorithm also reduces the message load per
process."
"Self-stabilization ensures that, after any transient fault, the system
recovers in a finite time and eventually exhibits a correct behaviour.
Speculation consists in guaranteeing that the system satisfies its requirements
for any execution but exhibits significantly better performances for a subset
of executions that are more probable. A speculative protocol is in this sense
supposed to be both robust and efficient in practice. We introduce the notion
of speculative stabilization which we illustrate through the mutual exclusion
problem. We then present a novel speculatively stabilizing mutual exclusion
protocol. Our protocol is self-stabilizing for any asynchronous execution. We
prove that its stabilization time for synchronous executions is diam(g)/2 steps
(where diam(g) denotes the diameter of the system). This complexity result is
of independent interest. The celebrated mutual exclusion protocol of Dijkstra
stabilizes in n steps (where n is the number of processes) in synchronous
executions and the question whether the stabilization time could be strictly
smaller than the diameter has been open since then (almost 40 years). We show
that this is indeed possible for any underlying topology. We also provide a
lower bound proof that shows that our new stabilization time of diam(g)/2 steps
is optimal for synchronous executions, even if asynchronous stabilization is
not required."
"COSA is a novel CFD system based on the compressible Navier-Stokes model for
unsteady aerodynamics and aeroelasticity of fixed structures, rotary wings and
turbomachinery blades. It includes a steady, time domain, and harmonic balance
flow solver.
  COSA has primarily been parallelised using MPI, but there is also a hybrid
parallelisation that adds OpenMP functionality to the MPI parallelisation to
enable larger number of cores to be utilised for a given simulation as the MPI
parallelisation is limited to the number of geometric partitions (or blocks) in
the simulation, or to exploit multi-threaded hardware where appropriate. This
paper outlines the work undertaken to optimise these two parallelisation
strategies, improving the efficiency of both and therefore reducing the
computational time required to compute simulations. We also analyse the power
consumption of the code on a range of leading HPC systems to further understand
the performance of the code."
"We study robust and efficient distributed algorithms for searching, storing,
and maintaining data in dynamic Peer-to-Peer (P2P) networks. P2P networks are
highly dynamic networks that experience heavy node churn (i.e., nodes join and
leave the network continuously over time). Our goal is to guarantee, despite
high node churn rate, that a large number of nodes in the network can store,
retrieve, and maintain a large number of data items. Our main contributions are
fast randomized distributed algorithms that guarantee the above with high
probability (whp) even under high adversarial churn:
  1. A randomized distributed search algorithm that (whp) guarantees that
searches from as many as $n - o(n)$ nodes ($n$ is the stable network size)
succeed in ${O}(\log n)$-rounds despite ${O}(n/\log^{1+\delta} n)$ churn, for
any small constant $\delta > 0$, per round. We assume that the churn is
controlled by an oblivious adversary (that has complete knowledge and control
of what nodes join and leave and at what time, but is oblivious to the random
choices made by the algorithm).
  2. A storage and maintenance algorithm that guarantees (whp) data items can
be efficiently stored (with only $\Theta(\log{n})$ copies of each data item)
and maintained in a dynamic P2P network with churn rate up to
${O}(n/\log^{1+\delta} n)$ per round. Our search algorithm together with our
storage and maintenance algorithm guarantees that as many as $n - o(n)$ nodes
can efficiently store, maintain, and search even under ${O}(n/\log^{1+\delta}
n)$ churn per round. Our algorithms require only polylogarithmic in $n$ bits to
be processed and sent (per round) by each node.
  To the best of our knowledge, our algorithms are the first-known,
fully-distributed storage and search algorithms that provably work under highly
dynamic settings (i.e., high churn rates per step)."
"Modern GPUs are able to perform significantly more arithmetic operations than
transfers of a single word to or from global memory. Hence, many GPU kernels
are limited by memory bandwidth and cannot exploit the arithmetic power of
GPUs. However, the memory locality can be often improved by kernel fusion when
a sequence of kernels is executed and some kernels in this sequence share data.
  In this paper, we show how kernels performing map, reduce or their nested
combinations can be fused automatically by our source-to-source compiler. To
demonstrate the usability of the compiler, we have implemented several BLAS-1
and BLAS-2 routines and show how the performance of their sequences can be
improved by fusions.
  Compared to similar sequences using CUBLAS, our compiler is able to generate
code that is up to 2.61x faster for the examples tested."
"Service-oriented workflows are typically executed using a centralised
orchestration approach that presents significant scalability challenges. These
challenges include the consumption of network bandwidth, degradation of
performance, and single-points of failure. We provide a decentralised
orchestration architecture that attempts to address these challenges. Our
architecture adopts a design model that permits the computation to be moved
""closer"" to services in a workflow. This is achieved by partitioning workflows
specified using our simple dataflow language into smaller fragments, which may
be sent to remote locations for execution."
"Environmental science is often fragmented: data is collected using mismatched
formats and conventions, and models are misaligned and run in isolation. Cloud
computing offers a lot of potential in the way of resolving such issues by
supporting data from different sources and at various scales, by facilitating
the integration of models to create more sophisticated software services, and
by providing a sustainable source of suitable computational and storage
resources. In this paper, we highlight some of our experiences in building the
Environmental Virtual Observatory pilot (EVOp), a tailored cloud-based
infrastructure and associated web-based tools designed to enable users from
different backgrounds to access data concerning different environmental issues.
We review our architecture design, the current deployment and prototypes. We
also reflect on lessons learned. We believe that such experiences are of
benefit to other scientific communities looking to assemble virtual
observatories or similar virtual research environments."
"In this paper we introduce algorithms for the construction of scale-free
networks and for clustering around the nerve centers, nodes with a high
connectivity in a scale-free networks. We argue that such overlay networks
could support self-organization in a complex system like a cloud computing
infrastructure and allow the implementation of optimal resource management
policies."
"IT based scientific research requires high computational resources. The
limitation on funding and infrastructure led the high performance computing era
from supercomputer to cluster and grid computing technology. Parallel
application running well on cluster computer as well as supercomputer, one of
the type is embarrassingly parallel application. Many scientist loves EP
because it doesn't need any sophisticated technique but gives amazing
performance. This paper discuss the bioinformatics research that used
embarrassingly application and show its performance on cluster computer."