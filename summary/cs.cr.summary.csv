summary
"We investigate, in the Shannon model, the security of constructions
corresponding to double and (two-key) triple DES. That is, we consider
F_{k1}(F_{k2}(.)) and F_{k1}(F_{k2}^{-1}(F_{k1}(.))) with the component
functions being ideal ciphers. This models the resistance of these
constructions to ``generic'' attacks like meet in the middle attacks. We obtain
the first proof that composition actually increases the security of these
constructions in some meaningful sense. We compute a bound on the probability
of breaking the double cipher as a function of the number of computations of
the base cipher made, and the number of examples of the composed cipher seen,
and show that the success probability is the square of that for a single key
cipher. The same bound holds for the two-key triple cipher. The first bound is
tight and shows that meet in the middle is the best possible generic attack
against the double cipher."
"A security policy states the acceptable actions of an information system, as
the actions bear on security. There is a pressing need for organizations to
declare their security policies, even informal statements would be better than
the current practice. But, formal policy statements are preferable to support
(1) reasoning about policies, e.g., for consistency and completeness, (2)
automated enforcement of the policy, e.g., using wrappers around legacy systems
or after the fact with an intrusion detection system, and (3) other formal
manipulation of policies, e.g., the composition of policies. We present LaSCO,
the Language for Security Constraints on Objects, in which a policy consists of
two parts: the domain (assumptions about the system) and the requirement (what
is allowed assuming the domain is satisfied). Thus policies defined in LaSCO
have the appearance of conditional access control statements. LaSCO policies
are specified as expressions in logic and as directed graphs, giving a visual
view of policy. LaSCO has a simple semantics in first order logic (which we
provide), thus permitting policies we write, even for complex policies, to be
very perspicuous. LaSCO has syntax to express many of the situations we have
found to be useful on policies or, more interesting, the composition of
policies. LaSCO has an object-oriented structure, permitting it to be useful to
describe policies on the objects and methods of an application written in an
object-oriented language, in addition to the traditional policies on operating
system objects. A LaSCO specification can be automatically translated into
executable code that checks an invocation of a program with respect to a
policy. The implementation of LaSCO is in Java, and generates wrappers to check
Java programs with respect to a policy."
"We present here a generalization of the work done by Rabin and Ben-Or. We
give a protocol for multiparty computation which tolerates any Q^2 active
adversary structure based on the existence of a broadcast channel, secure
communication between each pair of participants, and a monotone span program
with multiplication tolerating the structure. The secrecy achieved is
unconditional although we allow an exponentially small probability of error.
This is possible due to a protocol for computing the product of two values
already shared by means of a homomorphic commitment scheme which appeared
originally in a paper of Chaum, Evertse and van de Graaf."
"These notes are a brief introduction to the RSA algorithm and modular
arithmetic. They are intended for an undergraduate audience."
"This paper provides a proof of the proposed Internet standard Transport Level
Security protocol using the Gong-Needham-Yahalom logic. It is intended as a
teaching aid and hopes to show to students: the potency of a formal method for
protocol design; some of the subtleties of authenticating parties on a network
where all messages can be intercepted; the design of what should be a widely
accepted standard."
"Research in the field of electronic signature confirmation has been active
for some 20 years now. Unfortunately present certificate-based solutions also
come from that age when no-one knew about online data transmission. The
official standardized X.509 framework also depends heavily on offline
operations, one of the most complicated ones being certificate revocation
handling. This is done via huge Certificate Revocation Lists which are both
inconvenient and expencive. Several improvements to these lists are proposed
and in this report we try to analyze them briefly. We conclude that although it
is possible to do better than in the original X.509 setting, none of the
solutions presented this far is good enough."
The paper was retracted.
"In this dissertation, we present LaSCO, the Language for Security Constraints
on Objects, a new approach to expressing security policies using policy graphs
and present a method for enforcing policies so expressed. Other approaches for
stating security policies fall short of what is desirable with respect to
either policy clarity, executability, or the precision with which a policy may
be expressed. However, LaSCO is designed to have those three desirable
properties of a security policy language as well as: relevance for many
different systems, statement of policies at an appropriate level of detail,
user friendliness for both casual and expert users, and amenability to formal
reasoning. In LaSCO, the constraints of a policy are stated as directed graphs
annotated with expressions describing the situation under which the policy
applies and what the requirement is. LaSCO may be used for such diverse
applications as executing programs, file systems, operating systems,
distributed systems, and networks.
  Formal operational semantics have been defined for LaSCO. An architecture for
implementing LaSCO on any system, is presented along with an implementation of
the system-independent portion in Perl. Using this, we have implemented LaSCO
for Java programs, preventing Java programs from violating policy. A GUI to
facilitate writing policies is provided. We have studied applying LaSCO to a
network as viewed by GrIDS, a distributed intrusion detection system for large
networks, and propose a design. We conclude that LaSCO has characteristics that
enable its use on different types of systems throughout the process of
precisely expressing a policy, understanding the implications of a policy, and
implementing it on a system."
"We take a critical look at the relationship between the security of
cryptographic schemes in the Random Oracle Model, and the security of the
schemes that result from implementing the random oracle by so called
""cryptographic hash functions"". The main result of this paper is a negative
one: There exist signature and encryption schemes that are secure in the Random
Oracle Model, but for which any implementation of the random oracle results in
insecure schemes.
  In the process of devising the above schemes, we consider possible
definitions for the notion of a ""good implementation"" of a random oracle,
pointing out limitations and challenges."
"In this short note we want to introduce {\em anonymous oblivious transfer} a
new cryptographic primitive which can be proven to be strictly more powerful
than oblivious transfer. We show that all functions can be robustly realized by
multi party protocols with {\em anonymous oblivious transfer}. No assumption
about possible collusions of cheaters or disruptors have to be made.
Furthermore we shortly discuss how to realize anonymous oblivious transfer with
oblivious broadcast or by quantum cryptography. The protocol of anonymous
oblivious transfer was inspired by a quantum protocol: the anonymous quantum
channel."
"With oblivious transfer multiparty protocols become possible even in the
presence of a faulty majority. But all known protocols can be aborted by just
one disruptor.
  This paper presents more robust solutions for multiparty protocols with
oblivious transfer. This additional robustness against disruptors weakens the
security of the protocol and the guarantee that the result is correct. We can
observe a trade off between robustness against disruption and security and
correctness.
  We give an application to quantum multiparty protocols. These allow the
implementation of oblivious transfer and the protocols of this paper relative
to temporary assumptions, i.e., the security increases after the termination of
the protocol."
"This paper discusses mixing of chaotic systems as a dependable method for
secure communication. Distribution of the entropy function for steady state as
well as plaintext input sequences are analyzed. It is shown that the mixing of
chaotic sequences results in a sequence that does not have any state dependence
on the information encrypted by them. The generated output states of such a
cipher approach the theoretical maximum for both complexity measures and cycle
length. These features are then compared with some popular ciphers."
"Suppose there is a group of N people some of whom possess a specific
property. For example, their wealth is above or below a threshold, they voted
for a particular candidate, they have a certain disease, etc. The group wants
to find out how many of its members posses the property -- without revealing
the identities. Unless of course it turns out that all members do or do not
have the attribute of interest. However, in all other cases the counting
algorithm should guarantee that nobody can find out if a particular individual
possesses the property unless all the other N-1 members of the group collude.
  The present article describes a method to solve the confidential counting
problem with only 3*N-2 pairwise communications, or 2*N broadcasts (the last
N-1 pairwise communications are merely to announce the result). The counting
algorithm does not require any trusted third parties. All communications
between parties involved can be conducted in public without compromising the
security of counting."
"We consider zero knowledge interactive proofs in a richer, more realistic
communication environment. In this setting, one may simultaneously engage in
many interactive proofs, and these proofs may take place in an asynchronous
fashion. It is known that zero-knowledge is not necessarily preserved in such
an environment; we show that for a large class of protocols, it cannot be
preserved. Any 4 round (computational) zero-knowledge interactive proof (or
argument) for a non-trivial language L is not black-box simulatable in the
asynchronous setting."
"A proof is concurrent zero-knowledge if it remains zero-knowledge when many
copies of the proof are run in an asynchronous environment, such as the
Internet. It is known that zero-knowledge is not necessarily preserved in such
an environment. Designing concurrent zero-knowledge proofs is a fundamental
issue in the study of zero-knowledge since known zero-knowledge protocols
cannot be run in a realistic modern computing environment. In this paper we
present a concurrent zero-knowledge proof systems for all languages in NP.
Currently, the proof system we present is the only known proof system that
retains the zero-knowledge property when copies of the proof are allowed to run
in an asynchronous environment. Our proof system has $\tilde{O}(\log^2 k)$
rounds (for a security parameter $k$), which is almost optimal, as it is shown
by Canetti Kilian Petrank and Rosen that black-box concurrent zero-knowledge
requires $\tilde{\Omega}(\log k)$ rounds.
  Canetti, Goldreich, Goldwasser and Micali introduced the notion of {\em
resettable} zero-knowledge, and modified an earlier version of our proof system
to obtain the first resettable zero-knowledge proof system. This protocol
requires $k^{\theta(1)}$ rounds. We note that their technique also applies to
our current proof system, yielding a resettable zero-knowledge proof for NP
with $\tilde{O}(\log^2 k)$ rounds."
"This paper discusses the security considerations for remote electronic voting
in public elections. In particular, we examine the feasibility of running
national federal elections over the Internet. The focus of this paper is on the
limitations of the current deployed infrastructure in terms of the security of
the hosts and the Internet itself. We conclude that at present, our
infrastructure is inadequate for remote Internet voting."
"The early promises of DNA computing to deliver a massively parallel
architecture well-suited to computationally hard problems have so far been
largely unkept. Indeed, it is probably fair to say that only toy problems have
been addressed experimentally. Recent experimental development on algorithmic
self-assembly using DNA tiles seem to offer the most promising path toward a
potentially useful application of the DNA computing concept. In this paper, we
explore new geometries for algorithmic self-assembly, departing from those
previously described in the literature. This enables us to carry out
mathematical operations like binary multiplication or cyclic convolution
product. We then show how to use the latter operation to implement an attack
against the well-known public-key crypto system NTRU."
"The approach for a network behavior description in terms of numerical
time-dependant functions of the protocol parameters is suggested. This provides
a basis for application of methods of mathematical and theoretical physics for
information flow analysis on network and for extraction of patterns of typical
network behavior. The information traffic can be described as a trajectory in
multi-dimensional parameter-time space with dimension about 10-12. Based on
this study some algorithms for the proposed intrusion detection system are
discussed."
"We propose pretty simple password-authenticated key-exchange protocol which
is based on the difficulty of solving DDH problem. It has the following
advantages: (1) Both $y_1$ and $y_2$ in our protocol are independent and thus
they can be pre-computed and can be sent independently. This speeds up the
protocol. (2) Clients and servers can use almost the same algorithm. This
reduces the implementation costs without accepting replay attacks and abuse of
entities as oracles."
"Random beacons-information sources that broadcast a stream of random digits
unknown by anyone beforehand-are useful for various cryptographic purposes. But
such beacons can be easily and undetectably sabotaged, so that their output is
known beforehand by a dishonest party, who can use this information to defeat
the cryptographic protocols supposedly protected by the beacon. We explore a
strategy to reduce this hazard by combining the outputs from several
noninteracting (eg spacelike-separated) beacons by XORing them together to
produce a single digit stream which is more trustworthy than any individual
beacon, being random and unpredictable if at least one of the contributing
beacons is honest. If the contributing beacons are not spacelike separated, so
that a dishonest beacon can overhear and adapt to earlier outputs of other
beacons, the beacons' trustworthiness can still be enhanced to a lesser extent
by a time sharing strategy. We point out some disadvantages of alternative
trust amplification methods based on one-way hash functions."
"An approach for real-time network monitoring in terms of numerical
time-dependant functions of protocol parameters is suggested. Applying complex
systems theory for information f{l}ow analysis of networks, the information
traffic is described as a trajectory in multi-dimensional parameter-time space
with about 10-12 dimensions. The network traffic description is synthesized by
applying methods of theoretical physics and complex systems theory, to provide
a robust approach for network monitoring that detects known intrusions, and
supports developing real systems for detection of unknown intrusions. The
methods of data analysis and pattern recognition presented are the basis of a
technology study for an automatic intrusion detection system that detects the
attack in the reconnaissance stage."
"An important problem of modern cryptography concerns secret public-key
computations in algebraic structures. We construct homomorphic cryptosystems
being (secret) epimorphisms f:G --> H, where G, H are (publically known) groups
and H is finite. A letter of a message to be encrypted is an element h element
of H, while its encryption g element of G is such that f(g)=h. A homomorphic
cryptosystem allows one to perform computations (operating in a group G) with
encrypted information (without knowing the original message over H).
  In this paper certain homomorphic cryptosystems are constructed for the first
time for non-abelian groups H (earlier, homomorphic cryptosystems were known
only in the Abelian case). In fact, we present such a system for any solvable
(fixed) group H."
"Public-key cryptosystems are suggested based on invariants of groups. We give
also an overview of the known cryptosystems which involve groups."
"The pit recording of file, the coefficient of compression are introduced. The
theoretical limit of the information compression as minimal coefficient of
compression for the given length of alphabet are found."
"The clones of MV2 algorithm for any radix are discussed. The three various
examples of ones are represented."
"We explain how a differential fault analysis (DFA) works on AES 128, 192 or
256 bits."
"In this paper homomorphic cryptosystems are designed for the first time over
any finite group. Applying Barrington's construction we produce for any boolean
circuit of the logarithmic depth its encrypted simulation of a polynomial size
over an appropriate finitely generated group."
"In this note, we describe a probabilistic attack on public key cryptosystems
based on the word/conjugacy problems for finitely presented groups of the type
proposed recently by Anshel, Anshel and Goldfeld. In such a scheme, one makes
use of the property that in the given group the word problem has a polynomial
time solution, while the conjugacy problem has no known polynomial solution. An
example is the braid group from topology in which the word problem is solvable
in polynomial time while the only known solutions to the conjugacy problem are
exponential. The attack in this paper is based on having a canonical
representative of each string relative to which a length function may be
computed. Hence the term length attack. Such canonical representatives are
known to exist for the braid group."
"Strand spaces are a popular framework for the analysis of security protocols.
Strand spaces have some similarities to a formalism used successfully to model
protocols for distributed systems, namely multi-agent systems. We explore the
exact relationship between these two frameworks here. It turns out that a key
difference is the handling of agents, which are unspecified in strand spaces
and explicit in multi-agent systems. We provide a family of translations from
strand spaces to multi-agent systems parameterized by the choice of agents in
the strand space. We also show that not every multi-agent system of interest
can be expressed as a strand space. This reveals a lack of expressiveness in
the strand-space framework that can be characterized by our translation. To
highlight this lack of expressiveness, we show one simple way in which strand
spaces can be extended to model more systems."
"The basic properties of RSA cryptosystems and some classical attacks on them
are described. Derived from geometric properties of the Euler functions, the
Euler function rays, a new ansatz to attack RSA cryptosystems is presented. A
resulting, albeit inefficient, algorithm is given. It essentially consists of a
loop with starting value determined by the Euler function ray and with step
width given by a function $\omega_e(n)$ being a multiple of the order
$\mathrm{ord}_n(e)$, where $e$ denotes the public key exponent and $n$ the RSA
modulus. For $n=pq$ and an estimate $r<\sqrt{pq}$ for the smaller prime factor
$p$, the running time is given by $T(e,n,r) = O((r-p)\ln e \ln n \ln r).$"
"A group authentication protocol authenticates pre-defined groups of
individuals such that:
  - No individual is identified
  - No knowledge of which groups can be successfully authenticated is known to
the verifier
  - No sensitive data is exposed
  The paper presents a group authentication protocol based on splitting the
private keys of the Naccache-Stern public-key cryptosystem in such a way that
the Boolean expression defining the authenticable groups is implicit in the
split."
"We propose a new homomorphic public-key cryptosystem over arbitrary
nonidentity finite group based on the difficulty of the membership problem for
groups of integer matrices. Besides, a homomorphic cryptosystem is designed for
the first time over finite commutative rings."
"We introduce the use of Fourier analysis on lattices as an integral part of a
lattice based construction. The tools we develop provide an elegant description
of certain Gaussian distributions around lattice points. Our results include
two cryptographic constructions which are based on the worst-case hardness of
the unique shortest vector problem. The main result is a new public key
cryptosystem whose security guarantee is considerably stronger than previous
results ($O(n^{1.5})$ instead of $O(n^7)$). This provides the first alternative
to Ajtai and Dwork's original 1996 cryptosystem. Our second result is a family
of collision resistant hash functions which, apart from improving the security
in terms of the unique shortest vector problem, is also the first example of an
analysis which is not based on Ajtai's iterative step. Surprisingly, both
results are derived from one theorem which presents two indistinguishable
distributions on the segment $[0,1)$. It seems that this theorem can have
further applications and as an example we mention how it can be used to solve
an open problem related to quantum computation."
"In the paper we discuss how to share the secrets, that are graphs. So, far
secret sharing schemes were designed to work with numbers. As the first step,
we propose conditions for ""graph to number"" conversion methods. Hence, the
existing schemes can be used, without weakening their properties. Next, we show
how graph properties can be used to extend capabilities of secret sharing
schemes. This leads to proposal of using such properties for number based
secret sharing."
"At the beginning some results from the field of graph theory are presented.
Next we show how to share a secret that is proper n-coloring of the graph, with
the known structure. The graph is described and converted to the form, where
colors assigned to vertices form the number with entries from Zn. A secret
sharing scheme (SSS) for the graph coloring is proposed. The proposed method is
applied to the public-key cryptosystem called ""Polly Cracker"". In this case the
graph structure is a public key, while proper 3-colouring of the graph is a
private key. We show how to share the private key. Sharing particular
n-coloring (color-to-vertex assignment) for the known-structure graph is
presented next."
"A {k,n}-threshold scheme based on two-dimensional memory cellular automata is
proposed to share images in a secret way. This method allows to encode an image
into n shared images so that only qualified subsets of k or more shares can
recover the secret image, but any k-1 or fewer of them gain no information
about the original image. The main characteristics of this new scheme are: each
shared image has the same size that the original one, and the recovered image
is exactly the same than the secret image; i.e., there is no loss of
resolution."
"The paper study counter-dependent pseudorandom generators; the latter are
generators such that their state transition function (and output function) is
being modified dynamically while working: For such a generator the recurrence
sequence of states satisfies a congruence $x_{i+1}\equiv f_i(x_i)\pmod{2^n}$,
while its output sequence is of the form $z_{i}=F_i(u_i)$. The paper introduces
techniques and constructions that enable one to compose generators that output
uniformly distributed sequences of a maximum period length and with high linear
and 2-adic spans. The corresponding stream chipher is provably strong against a
known plaintext attack (up to a plausible conjecture). Both state transition
function and output function could be key-dependent, so the only information
available to a cryptanalyst is that these functions belong to some
(exponentially large) class. These functions are compositions of standard
machine instructions (such as addition, multiplication, bitwise logical
operations, etc.) The compositions should satisfy rather loose conditions; so
the corresponding generators are flexible enough and could be easily
implemented as computer programs."
"Unsolicited bulk email (aka. spam) is a major problem on the Internet. To
counter spam, several techniques, ranging from spam filters to mail protocol
extensions like hashcash, have been proposed. In this paper we investigate the
effectiveness of several spam filtering techniques and technologies. Our
analysis was performed by simulating email traffic under different conditions.
We show that genetic algorithm based spam filters perform best at server level
and naive Bayesian filters are the most appropriate for filtering at user
level."
"A discrete-time discrete-value pseudo-chaotic encoder/decoder system is
presented. The pseudo-chaotic module is a 3D discrete version of the well-known
Lorenz dynamical system. Scaling and biasing transformations as well as natural
number arithmetics are employed in order to simplify realizations on a small
size Field Programmable Gate Array (FPGA. The encryption ability is improved by
using only the least significant byte of one of the pseudo chaotic state
variables as the key to encrypt the plain text. The key is periodically
perturbed by another chaotic state variable. The statistical properties of the
pseudo chaotic cipher are compared with those of other pseudo-random generators
available in the literature. As an example of applicability of the technique, a
full duplex communication system is designed and constructed using FPGA's as
technological framework."
"The paper study counter-dependent pseudorandom number generators based on
$m$-variate ($m>1$) ergodic mappings of the space of 2-adic integers $\Z_2$.
The sequence of internal states of these generators is defined by the
recurrence law $\mathbf x_{i+1}= H^B_i(\mathbf x_i)\bmod{2^n}$, whereas their
output sequence is %while its output sequence is of the $\mathbf
z_{i}=F^B_i(\mathbf x_i)\mod 2^n$; here $\mathbf x_j, \mathbf z_j$ are
$m$-dimensional vectors over $\Z_2$. It is shown how the results obtained for a
univariate case could be extended to a multivariate case."
"A new scheme for transmitting sensitive data is proposed, the proposed scheme
depends on partitioning the output of a block encryption module using the
Chinese Remainder Theorem among a set of channels. The purpose of using the
Chinese Remainder Theorem is to hide the cipher text in order to increase the
difficulty of attacking the cipher. The theory, implementation and the security
of this scheme are described in this paper."
"In this paper we design a stream cipher that uses the algebraic structure of
the multiplicative group $\bbbz_p^*$ (where p is a big prime number used in
ElGamal algorithm), by defining a quasigroup of order $p-1$ and by doing
quasigroup string transformations. The cryptographical strength of the proposed
stream cipher is based on the fact that breaking it would be at least as hard
as solving systems of multivariate polynomial equations modulo big prime number
$p$ which is NP-hard problem and there are no known fast randomized or
deterministic algorithms for solving it. Unlikely the speed of known ciphers
that work in $\bbbz_p^*$ for big prime numbers $p$, the speed of this stream
cipher both in encryption and decryption phase is comparable with the fastest
symmetric-key stream ciphers."
"We propose a cipher similar to the One Time Pad and McEliece cipher based on
a subband coding scheme. The encoding process is an approximation to the One
Time Pad encryption scheme. We present results of numerical experiments which
suggest that a brute force attack to the proposed scheme does not result in all
possible plaintexts, as the One Time Pad does, but still the brute force attack
does not compromise the system. However, we demonstrate that the cipher is
vulnerable to a chosen-plaintext attack."
"Security of computers and the networks that connect them is increasingly
becoming of great significance. Computer security is defined as the protection
of computing systems against threats to confidentiality, integrity, and
availability. There are two types of intruders: external intruders, who are
unauthorized users of the machines they attack, and internal intruders, who
have permission to access the system with some restrictions. This chapter
presents a soft computing approach to detect intrusions in a network. Among the
several soft computing paradigms, we investigated fuzzy rule-based classifiers,
decision trees, support vector machines, linear genetic programming and an
ensemble method to model fast and efficient intrusion detection systems.
Empirical results clearly show that soft computing approach could play a major
role for intrusion detection."
"In this paper, we present a novel encryption-less algorithm to enhance
security in transmission of data in networks. The algorithm uses an intuitively
simple idea of a 'jigsaw puzzle' to break the transformed data into multiple
parts where these parts form the pieces of the puzzle. Then these parts are
packaged into packets and sent to the receiver. A secure and efficient
mechanism is provided to convey the information that is necessary for obtaining
the original data at the receiver-end from its parts in the packets, that is,
for solving the 'jigsaw puzzle'. The algorithm is designed to provide
information-theoretic (that is, unconditional) security by the use of a
one-time pad like scheme so that no intermediate or unintended node can obtain
the entire data. An authentication code is also used to ensure authenticity of
every packet."
"This article describes in depth several ways of exploiting buffer overflows
in the UNIX operating systems."
"In peer-to-peer systems, attrition attacks include both traditional,
network-level denial of service attacks as well as application-level attacks in
which malign peers conspire to waste loyal peers' resources. We describe
several defenses for LOCKSS, a peer-to-peer digital preservation system, that
help ensure that application-level attacks even from powerful adversaries are
less effective than simple network-level attacks, and that network-level
attacks must be intense, wide-spread, and prolonged to impair the system."
"Electronic bait (honeypots) are network resources whose value consists of
being attacked and compromised. These are often computers which do not have a
task in the network, but are otherwise indestinguishable from regular
computers. Such bait systems could be interconnected (honeynets). These
honeynets are equipped with special software, facilitating forensic anylisis of
incidents. Taking average of the wide variety of recorded data it is possible
to learn considerable more about the behaviour of attackers in networks than
with traditional methods. This article is an introduction into electronic bait
and a description of the setup and first experiences of such a network deployed
at RWTH Aachen University.
  -----
  Als elektronische Koeder (honeypots) bezeichnet man Netzwerkressourcen, deren
Wert darin besteht, angegriffen und kompromittiert zu werden. Oft sind dies
Computer, die keine spezielle Aufgabe im Netzwerk haben, aber ansonsten nicht
von regulaeren Rechnern zu unterscheiden sind. Koeder koennen zu
Koeder-Netzwerken (honeynets) zusammengeschlossen werden. Sie sind mit
spezieller Software ausgestattet, die die Forensik einer eingetretenen
Schutzzielverletzung erleichtert. Durch die Vielfalt an mitgeschnittenen Daten
kann man deutlich mehr ueber das Verhalten von Angreifern in Netzwerken lernen
als mit herkoemmlichen forensischen Methoden. Dieser Beitrag stellt die
Philosophie der Koeder-Netzwerke vor und beschreibt die ersten Erfahrungen, die
mit einem solchen Netzwerk an der RWTH Aachen gemacht wurden."
"In 2004, W. C. Ku and S. M. Chen proposed an efficient remote user
authentication scheme using smart cards to solve the security problems of Chien
et al.'s scheme. Recently, Hsu and Yoon et al. pointed out the security
weaknesses of the Ku and Chen's scheme Furthermore, Yoon et al. also proposed a
new efficient remote user authentication scheme using smart cards. Yoon et al.
also modified the password change phase of Ku and Chen's scheme. This paper
analyzes that password change phase of Yoon et al's modified scheme is still
insecure."
"Logs are one of the most fundamental resources to any security professional.
It is widely recognized by the government and industry that it is both
beneficial and desirable to share logs for the purpose of security research.
However, the sharing is not happening or not to the degree or magnitude that is
desired. Organizations are reluctant to share logs because of the risk of
exposing sensitive information to potential attackers. We believe this
reluctance remains high because current anonymization techniques are weak and
one-size-fits-all--or better put, one size tries to fit all. We must develop
standards and make anonymization available at varying levels, striking a
balance between privacy and utility. Organizations have different needs and
trust other organizations to different degrees. They must be able to map
multiple anonymization levels with defined risks to the trust levels they share
with (would-be) receivers. It is not until there are industry standards for
multiple levels of anonymization that we will be able to move forward and
achieve the goal of widespread sharing of logs for security researchers."
"This paper proposes a signature scheme where the signatures are generated by
the cooperation of a number of people from a given group of senders and the
signatures are verified by a certain number of people from the group of
recipients. Shamir's threshold scheme and Schnorr's signature scheme are used
to realize the proposed scheme."
"This report surveys different PKI technologies such as PKIX and SPKI and the
issues of PKI that affect scalability. Much focus is spent on certificate
revocation methodologies and status verification systems such as CRLs,
Delta-CRLs, CRS, Certificate Revocation Trees, Windowed Certificate Revocation,
OCSP, SCVP and DVCS."
"This paper presents a directed signature scheme with the property that the
signature can be verified only with the help of signer or signature receiver.
We also propose its applications to share verification of signatures and to
threshold cryptosystems."
"In this paper, we propose a Directed Threshold Multi-Signature Scheme. In
this threshold signature scheme, any malicious set of signers cannot
impersonate any other set of signers to forge the signatures. In case of
forgery, it is possible to trace the signing set. This threshold signature
scheme is applicable when the message is sensitive to the signature receiver;
and the signatures are generated by the cooperation of a number of people from
a given group of senders."
"Directed signature scheme is applicable when the signed message contains
information sensitive to the receiver, because only receiver can directly
verify the signature and that he/she can prove its validity to any third party,
whenever necessary. This paper presents two applications of directed signature
scheme. (i) Directed &#8211;Delegated Signature Scheme. This scheme combines
the idea of proxy signatures with directed signature scheme. (ii) Allocation of
registration number. This scheme proposes a registration scheme in which the
registration number cannot be forged and misused."
"Since 1981, when Lamport introduced the remote user authentication scheme
using table, a plenty of schemes had been proposed with tables or without table
using. Recently Das et al. proposed a dynamic id-based remote user
authentication scheme. They claimed that their scheme is secure against
ID-theft, and can resist the reply attacks, forgery attacks, insider attacks an
so on. In this paper we show that Das et al's scheme is completly insecure and
using of this scheme is like an open server access without password."
"We model a private key`s life cycle as a finite state machine. The states are
the key`s phases of life and the transition functions describe tasks to be done
with the key. Based on this we define and describe the key authority, a trust
center module, which potentiates the easy enforcement of secure management of
private keys in hierarchical public key infrastructures. This is done by
assembling all trust center tasks concerning the crucial handling of private
keys within one centralized module. As this module resides under full control
of the trust center`s carrier it can easily be protected by well-known
organizational and technical measures."
"The PIN/TAN-system is an authentication and authorization scheme used in
e-business. Like other similar schemes it is successfully attacked by
criminals. After shortly classifying the various kinds of attacks we accomplish
malicious code attacks on real World Wide Web transaction systems. In doing so
we find that it is really easy to outflank these systems. This is even
supported by the users' behavior. We give a few simple behavior rules to
improve this situation. But their impact is limited. Also the providers support
the attacks by having implementation flaws in their installations. Finally we
show that the PIN/TAN-system is not suitable for usage in highly secure
applications."
"Directed signature is the solution of such problems when the signed message
contains information sensitive to the signature receiver. Generally, in many
application of directed signature, the signer is generally a single person. But
when the message is on behalf of an organization, a valid sensitive message may
require the approval of several people. Threshold signature schemes are used to
solve these problems. This paper presents a threshold directed signature
scheme."
"We propose a new simple \emph{trace} logic that can be used to specify
\emph{local security properties}, i.e. security properties that refer to a
single participant of the protocol specification. Our technique allows a
protocol designer to provide a formal specification of the desired security
properties, and integrate it naturally into the design process of cryptographic
protocols. Furthermore, the logic can be used for formal verification. We
illustrate the utility of our technique by exposing new attacks on the well
studied protocol TMN."
"Chebyshev polynomials have been recently proposed for designing public-key
systems. Indeed, they enjoy some nice chaotic properties, which seem to be
suitable for use in Cryptography. Moreover, they satisfy a semi-group property,
which makes possible implementing a trapdoor mechanism. In this paper we study
a public key cryptosystem based on such polynomials, which provides both
encryption and digital signature. The cryptosystem works on real numbers and is
quite efficient. Unfortunately, from our analysis it comes up that it is not
secure. We describe an attack which permits to recover the corresponding
plaintext from a given ciphertext. The same attack can be applied to produce
forgeries if the cryptosystem is used for signing messages. Then, we point out
that also other primitives, a Diffie-Hellman like key agreement scheme and an
authentication scheme, designed along the same lines of the cryptosystem, are
not secure due to the aforementioned attack. We close the paper by discussing
the issues and the possibilities of constructing public key cryptosystems on
real numbers."
"In this paper we present an image retrieval system based on Gabor texture
features, steganography, and mobile agents.. By employing the information
hiding technique, the image attributes can be hidden in an image without
degrading the image quality. Thus the image retrieval process becomes simple.
Java based mobile agents manage the query phase of the system. Based on the
simulation results, the proposed system not only shows the efficiency in hiding
the attributes but also provides other advantages such as: (1) fast
transmission of the retrieval image to the receiver, (2) searching made easy."
"National Root CAs enable legally binding E-Business and E-Government
transactions. This is a report about the development, the evaluation and the
certification of the new certification services system for the German National
Root CA. We illustrate why a new certification services system was necessary,
and which requirements to the new system existed. Then we derive the tasks to
be done from the mentioned requirements. After that we introduce the initial
situation at the beginning of the project. We report about the very process and
talk about some unfamiliar situations, special approaches and remarkable
experiences. Finally we present the ready IT system and its impact to
E-Business and E-Government."
"We present a framework for extending the functionality of LDAP servers from
their typical use as a public directory in public key infrastructures. In this
framework the LDAP servers are used for administrating infrastructure
processes. One application of this framework is a method for providing
proof-of-possession, especially in the case of encryption keys. Another one is
the secure delivery of software personal security environments."
"This paper proposes the Intra Trustcenter Protocol (ITP), a flexible and
secure management protocol for communication between arbitrary trustcenter
components. Unlike other existing protocols (like PKCS#7, CMP or XKMS) ITP
focuses on the communication within a trustcenter. It is powerful enough for
transferring complex messages which are machine and human readable and easy to
understand. In addition it includes an extension mechanism to be prepared for
future developments."
"In this paper we provide a guide for public key infrastructure designers and
administrators when planning for directory services. We concentrate on the LDAP
directories and how they can be used to successfully publish PKI information.
We analyse their available mechanisms and propose a best practice guide for use
in PKI. We then take a look into the German Signature Act and Ordinance and
discuss their part as far as directories concerning. Finally, we translate
those to the LDAP directories practices."
"Web services security specifications are typically expressed as a mixture of
XML schemas, example messages, and narrative explanations. We propose a new
specification language for writing complementary machine-checkable descriptions
of SOAP-based security protocols and their properties. Our TulaFale language is
based on the pi calculus (for writing collections of SOAP processors running in
parallel), plus XML syntax (to express SOAP messaging), logical predicates (to
construct and filter SOAP messages), and correspondence assertions (to specify
authentication goals of protocols). Our implementation compiles TulaFale into
the applied pi calculus, and then runs Blanchet's resolution-based protocol
verifier. Hence, we can automatically verify authentication properties of SOAP
protocols."
"An XML web service is, to a first approximation, an RPC service in which
requests and responses are encoded in XML as SOAP envelopes, and transported
over HTTP. We consider the problem of authenticating requests and responses at
the SOAP-level, rather than relying on transport-level security. We propose a
security abstraction, inspired by earlier work on secure RPC, in which the
methods exported by a web service are annotated with one of three security
levels: none, authenticated, or both authenticated and encrypted. We model our
abstraction as an object calculus with primitives for defining and calling web
services. We describe the semantics of our object calculus by translating to a
lower-level language with primitives for message passing and cryptography. To
validate our semantics, we embed correspondence assertions that specify the
correct authentication of requests and responses. By appeal to the type theory
for cryptographic protocols of Gordon and Jeffrey's Cryptyc, we verify the
correspondence assertions simply by typing. Finally, we describe an
implementation of our semantics via custom SOAP headers."
"The remarkably long-standing problem of cryptography is to generate
completely secure key. It is widely believed that the task cannot be achieved
within classical cryptography. However, there is no proof in support of this
belief. We present an incredibly simple classical cryptosystem which can
generate completely secure key."
"Distributed intrustion detection systems detect attacks on computer systems
by analyzing data aggregated from distributed sources. The distributed nature
of the data sources allows patterns in the data to be seen that might not be
detectable if each of the sources were examined individually. This paper
describes the various approaches that have been developed to share and analyze
data in such systems, and discusses some issues that must be addressed before
fully decentralized distributed intrusion detection systems can be made viable."
"In this thesis, we propose some directed signature schemes. In addition, we
have discussed their applications in different situations. In this thesis, we
would like to discuss the security aspects during the design process of the
proposed directed digital signature schemes. The security of the most digital
signature schemes widely use in practice is based on the two difficult
problems, viz; the problem of factoring integers (The RSA scheme) and the
problem of finding discrete logarithms over finite fields (The ElGamal scheme).
The proposed works in this thesis is divided into seven chapters."
"Over the recent months it has become clear that the current generation of
cryptographic hashing algorithms are insufficient to meet future needs. The ASH
family of algorithms provides modifications to the existing SHA-2 family. These
modifications are designed with two main goals: 1) Providing increased
collision resistance. 2) Increasing mitigation of security risks
post-collision. The unique public/private sections and salt/pepper design
elements provide increased flexibility for a broad range of applications. The
ASH family is a new generation of cryptographic hashing algorithms."
"In 2000, Hwang and Li proposed a remote user authentication scheme using
smart cards to solve the problems of Lamport scheme. Later, Chan- Chang, Shen-
Lin- Hwang and then Chang-Hwang pointed out some attacks on Hwang &#8211;
Li&#8217;s scheme. In 2003, Shen, Lin and Hwang also proposed a modified scheme
to remove these attacks. In the same year, Leung-Cheng-Fong-Chan showed that
modified scheme proposed by Shen-Lin-Hwang is still insecure. In 2004, Awasthi
and Lal enhanced Shen-Lin-Hwang&#8217;s scheme to overcome its security
pitfalls. This paper analyses that the user U/smart card does not provide
complete information for the execution and proper running of the login phase of
the Awasthi- Lal&#8217;s scheme. Furthermore, this paper also modifies the
Awasthi- Lal&#8217;s scheme for the proper functioning."
"In this paper, we propose a Directed threshold multisignature scheme without
SDC. This signature scheme is applicable when the message is sensitive to the
signature receiver; and the signatures are generated by the cooperation of a
number of people from a given group of senders. In this scheme, any malicious
set of signers cannot impersonate any other set of signers to forge the
signatures. In case of forgery, it is possible to trace the signing set."
"Getting an unbiased result is a remarkably long standing problem of
collective observation/measurement. It is pointed out that quantum coin tossing
can generate unbiased result defeating dishonesty."
"We propose a method for engineering security protocols that are aware of
timing aspects. We study a simplified version of the well-known Needham
Schroeder protocol and the complete Yahalom protocol, where timing information
allows the study of different attack scenarios. We model check the protocols
using UPPAAL. Further, a taxonomy is obtained by studying and categorising
protocols from the well known Clark Jacob library and the Security Protocol
Open Repository (SPORE) library. Finally, we present some new challenges and
threats that arise when considering time in the analysis, by providing a novel
protocol that uses time challenges and exposing a timing attack over an
implementation of an existing security protocol."
"A simple un-entanglement based quantum bit commitment scheme is presented.
Although commitment is unconditionally secure but concealment is not."
"One-way hash chains have been used in many micropayment schemes due to their
simplicity and efficiency. In this paper we introduce the notion of
multi-dimensional hash chains, which is a new generalization of traditional
one-way hash chains. We show that this construction has storage-computational
complexity of O(logN) per chain element, which is comparable with the best
result reported in recent literature. Based on multi-dimensional hash chains,
we then propose two cash-like micropayment schemes, which have a number of
advantages in terms of efficiency and security. We also point out some possible
improvements to PayWord and similar schemes by using multi-dimensional hash
chains"
"During the last years, large-scale simulations of realistic physical
environments which support the interaction of multiple participants over the
Internet have become increasingly available and economically significant, most
notably in the computer gaming industry. Such systems, commonly called
networked virtual environments (NVEs), are usually based on a client-server
architecture where for performance reasons and bandwidth restrictions, the
simulation is partially deferred to the clients. This inevitable architectural
choice renders the simulation vulnerable to attacks against the semantic
integrity of the simulation: malicious clients may attempt to compromise the
physical and logical laws governing the simulation, or to alter the causality
of events a posteriori. In this paper, we initiate the systematic study of
semantic integrity in NVEs from a security point of view. We argue that naive
policies to enforce semantic integrity involve intolerable network load, and
are therefore not practically feasible. We present a new semantic integrity
protocol based on cryptographic primitives which enables the server system to
audit the local computations of the clients on demand. Our approach facilitates
low network and CPU load, incurs reasonable engineering overhead, and maximally
decouples the auditing process from the soft real time constraints of the
simulation."
"We propose a new detection algorithm that uses structural relationships
between senders and recipients of email as the basis for the identification of
spam messages. Users and receivers are represented as vectors in their
reciprocal spaces. A measure of similarity between vectors is constructed and
used to group users into clusters. Knowledge of their classification as past
senders/receivers of spam or legitimate mail, comming from an auxiliary
detection algorithm, is then used to label these clusters probabilistically.
This knowledge comes from an auxiliary algorithm. The measure of similarity
between the sender and receiver sets of a new message to the center vector of
clusters is then used to asses the possibility of that message being legitimate
or spam. We show that the proposed algorithm is able to correct part of the
false positives (legitimate messages classified as spam) using a testbed of one
week smtp log."
"An authenticated encryption scheme allows messages to be encrypted and
authenticated simultaneously. In 2003, Ma and Chen proposed such a scheme with
public verifiability. That is, in their scheme the receiver can efficiently
prove to a third party that a message is indeed originated from a specific
sender. In this paper, we first identify two security weaknesses in the Ma-Chen
authenticated encryption scheme. Then, based on the Schnorr signature, we
proposed an efficient and secure improved scheme such that all the desired
security requirements are satisfied."
"Internet worms have become a widespread threat to system and network
operations. In order to fight them more efficiently, it is necessary to analyze
newly discovered worms and attack patterns. This paper shows how techniques
based on Kolmogorov Complexity can help in the analysis of internet worms and
network traffic. Using compression, different species of worms can be clustered
by type. This allows us to determine whether an unknown worm binary could in
fact be a later version of an existing worm in an extremely simple, automated,
manner. This may become a useful tool in the initial analysis of malicious
binaries. Furthermore, compression can also be useful to distinguish different
types of network traffic and can thus help to detect traffic anomalies: Certain
anomalies may be detected by looking at the compressibility of a network
session alone. We furthermore show how to use compression to detect malicious
network sessions that are very similar to known intrusion attempts. This
technique could become a useful tool to detect new variations of an attack and
thus help to prevent IDS evasion. We provide two new plugins for Snort which
demonstrate both approaches."
"In 2000, Hwang and Li proposed a new remote user authentication scheme using
smart cards. In the same year, Chan and Cheng pointed out that Hwang and
Li&#8217;s scheme is not secure against the masquerade attack. Further, in
2003, Shen, Lin and Hwang pointed out a different type of attack on Hwang and
Li&#8217;s scheme and presented a modified scheme to remove its security
pitfalls. This paper presents an improved scheme which is secure against
Chan-Cheng and all the extended attacks."
"In 2002, Chien&#8211;Jan&#8211;Tseng introduced an efficient remote user
authentication scheme using smart cards. Further, in 2004, W. C. Ku and S. M.
Chen proposed an efficient remote user authentication scheme using smart cards
to solve the security problems of Chien et al.&#8217;s scheme. Recently, Hsu
and Yoon et al. pointed out the security weakness of the Ku and Chen&#8217;s
scheme Furthermore, Yoon et al. modified the password change phase of Ku and
Chen&#8217;s scheme and they also proposed a new efficient remote user
authentication scheme using smart cards. This paper analyzes that the modified
scheme of Yoon et al. still vulnerable to parallel session attack."
"Steganography is about how to send secret message covertly. And the purpose
of steganalysis is to not only detect the existence of the hidden message but
also extract it. So far there have been many reliable detecting methods on
various steganographic algorithms, while there are few approaches that can
extract the hidden information. In this paper, the difficulty of extracting
hidden information, which is essentially a kind of privacy, is analyzed with
information-theoretic method in the terms of unicity distance of steganographic
key (abbreviated stego key). A lower bound for the unicity distance is
obtained, which shows the relations between key rate, message rate, hiding
capacity and difficulty of extraction. Furthermore the extracting attack to
steganography is viewed as a special kind of cryptanalysis, and an effective
method on recovering the stego key of popular LSB replacing steganography in
spatial images is presented by combining the detecting technique of
steganalysis and correlation attack of cryptanalysis together. The analysis for
this method and experimental results on steganographic software ``Hide and Seek
4.1"" are both accordant with the information-theoretic conclusion."
"In some cases, the original signer may delegate its signing power to a
specified proxy group while ensuring individual accountability of each
participantsigner. The proxy signature scheme that achieves such purpose is
called the multi-proxy signature scheme and the signature generated by the
specified proxy group is called multi-proxy signature for the original signer.
Recently such scheme has been discussed by Lin et al. Lins scheme is based on
partial delegation by Mambo et al. In present chapter we introduce a new
multi-proxy signature scheme, which requires less computational overhead in
comparison to Lin et al, and also fulfill the requirement of partial delegation
with warrant simultaneously."
"Since 1981, when Lamport introduced the remote user authentication scheme
using table, a plenty of schemes had been proposed with table and without table
using. In 1993, Chang and Wu [5] introduced Remote password authentication
scheme with smart cards. A number of remote authentication schemes with smart
cards have been proposed since then. These schemes allow a valid user to login
a remote server and access the services provided by the remote server. But
still there is no scheme to authenticate the remote proxy user. In this paper
we propose firstly, a protocol to authenticate a proxy user remotely using
smartcards."
"Blind signature schemes enable a useful protocol that guarantee the anonymity
of the participants while Signcryption offers authentication of message and
confidentiality of messages at the same time and more efficiently. In this
paper, we present a blind signcryption scheme that combines the functionality
of blind signature and signcryption. This blind Signcryption is useful for
applications that are based on anonymity untracebility and unlinkability."
"In 2001, Rivest et al. firstly introduced the concept of ring signatures. A
ring signature is a simplified group signature without any manager. It protects
the anonymity of a signer. The first scheme proposed by Rivest et al. was based
on RSA cryptosystem and certificate based public key setting. The first ring
signature scheme based on DLP was proposed by Abe, Ohkubo, and Suzuki. Their
scheme is also based on the general certificate-based public key setting too.
In 2002, Zhang and Kim proposed a new ID-based ring signature scheme using
pairings. Later Lin and Wu proposed a more efficient ID-based ring signature
scheme. Both these schemes have some inconsistency in computational aspect.
  In this paper we propose a new ID-based ring signature scheme and a proxy
ring signature scheme. Both the schemes are more efficient than existing one.
These schemes also take care of the inconsistencies in above two schemes."
"This work presents two new construction techniques for q-ary Gossip codes
from tdesigns and Traceability schemes. These Gossip codes achieve the shortest
code length specified in terms of code parameters and can withstand erasures in
digital fingerprinting applications. This work presents the construction of
embedded Gossip codes for extending an existing Gossip code into a bigger code.
It discusses the construction of concatenated codes and realisation of erasure
model through concatenated codes."
"To study how to design steganographic algorithm more efficiently, a new
coding problem -- steganographic codes (abbreviated stego-codes) -- is
presented in this paper. The stego-codes are defined over the field with
$q(q\ge2)$ elements. Firstly a method of constructing linear stego-codes is
proposed by using the direct sum of vector subspaces. And then the problem of
linear stego-codes is converted to an algebraic problem by introducing the
concept of $t$th dimension of vector space. And some bounds on the length of
stego-codes are obtained, from which the maximum length embeddable (MLE) code
is brought up. It is shown that there is a corresponding relation between MLE
codes and perfect error-correcting codes. Furthermore the classification of all
MLE codes and a lower bound on the number of binary MLE codes are obtained
based on the corresponding results on perfect codes. Finally hiding redundancy
is defined to value the performance of stego-codes."
"To remove key escrow problem and avoid the need of secure channel in ID based
cryptosystem Lee et al. proposed a secure key issuing protocol. However we show
that it suffers from impersonation, insider attacks and incompetency of the key
privacy authorities. We also cryptanalyze Sui et al.'s separable and anonymous
key issuing protocol."
"The recent developments in the mobile technology (mobile phones, middleware)
created a need for new methods of protecting the code transmitted through the
network. The proposed mechanisms not only secure the compiled program, but also
the data, that can be gathered during its ""journey"". The oldest and the
simplest methods are more concentrated on integrity of the code itself and on
the detection of unauthorized manipulation. Other, more advanced proposals
protect not only the code but also the execution state and the collected data.
The paper is divided into two parts. The first one is mostly devoted to
different methods of securing the code and protecting its integrity; starting
from watermarking and fingerprinting, up to methods designed specially for
mobile agent systems: encrypted function, cryptographic traces, time limited
black-box security, chained-MAC protocol, publicly-verifiable chained digital
signatures The second part presents new concept for providing mobile agents
with integrity protection, based on a zero-knowledge proof system."
"Some protected password change protocols were proposed. However, the previous
protocols were easily vulnerable to several attacks such as denial of service,
password guessing, stolen-verifier and impersonation atacks etc. Recently,
Chang et al. proposed a simple authenticated key agreement and protected
password change protocol for enhancing the security and efficiency. In this
paper, authors shall show that password guessing, denial of service and
known-key attacks can work in their password change protocol. At the same time,
authors shall propose a new password change protocol to withstand all the
threats of security."
"Identity Management is becoming more and more important in business systems
as they are opened for third parties including trading partners, consumers and
suppliers. This paper presents an approach securing a system without any
knowledge of the system source code. The security module adds to the existing
system authentication and authorisation based on aspect oriented programming
and the liberty alliance framework, an upcoming industrie standard providing
single sign on. In an initial training phase the module is adapted to the
application which is to be secured. Moreover the use of hardware tokens and
proactive computing is demonstrated. The high modularisation is achived through
use of AspectJ, a programming language extension of Java."
"Copyright protection is a major issue in distributing digital content. On the
other hand, improvements to usability are sought by content users. In this
paper, we propose a secure {\it traitor tracing scheme against key exposure
(TTaKE)} which contains the properties of both a traitor tracing scheme and a
forward secure public key cryptosystem. Its structure fits current digital
broadcasting systems and it may be useful in preventing traitors from making
illegal decoders and in minimizing the damage from accidental key exposure. It
can improve usability through these properties."
"Honesty has never been scientifically proved to be the best policy in any
case. It is pointed out that only honest person can prevent his dishonest
partner to bias the outcome of quantum coin tossing."
"In 1949, Shannon proved the perfect secrecy of the Vernam cryptographic
system,also popularly known as the One-Time Pad (OTP). Since then, it has been
believed that the perfectly random and uncompressible OTP which is transmitted
needs to have a length equal to the message length for this result to be true.
In this paper, we prove that the length of the transmitted OTP which actually
contains useful information need not be compromised and could be less than the
message length without sacrificing perfect secrecy. We also provide a new
interpretation for the OTP encryption by treating the message bits as making
True/False statements about the pad, which we define as a private-object. We
introduce the paradigm of private-object cryptography where messages are
transmitted by verifying statements about a secret-object. We conclude by
suggesting the use of Formal Axiomatic Systems for investing N bits of secret."
"In this document, a formal approach to encrypt, decrypt, transmit and receive
information using colors is explored. A piece of information consists of set of
symbols with a definite property imposed on the generating set. The symbols are
usually encoded using ascii scheme. A linear to 3d transformation is presented.
The change of axis from traditional xyz to rgb is highlighted and its effect
are studied. A point in this new axis is then represented as a unique color and
a vector or matrix is associated with it, making it amenable to standard vector
or matrix operations. A formal notion on hybrid cryptography is introduced as
the algorithm lies on the boundary of symmetric and asymmetric cryptography. No
discussion is complete, without mentioning reference to communication aspects
of secure information in a channel. Transmission scheme pertaining to light as
carrier is introduced and studied. Key-exchanges do not come under the scope of
current frame of document."
"In this paper, facts existing in different domains are explored, which are
comparable by their end result. Properties of various domains and the facts
that are part of such a unit are also presented, examples of comparison and
methods of usage as means of zero-knowledge protocols are given, finally a
zero-knowledge protocol based on afore-mentioned concept is given."
"In this paper we try to unify the frameworks of definitions of semantic
security, indistinguishability and non-malleability by defining semantic
security in comparison based framework. This facilitates the study of relations
among these goals against different attack models and makes the proof of the
equivalence of semantic security and indistinguishability easier and more
understandable. Besides, our proof of the equivalence of semantic security and
indistinguishability does not need any intermediate goals such as non
devidability to change the definition framework."
"A first multi-proxy multi-signcryption scheme from pairings, which
efficiently combines a multi-proxy multi-signature scheme with a signcryption,
is proposed. Its security is analyzed in detail. In our scheme, a proxy
signcrypter group could be authorized as a proxy agent by the cooperation of
all members in the original signcrypter group. Then the proxy signcryptions can
be generated by the cooperation of all the signcrypters in the authorized proxy
signcrypter group on behalf of the original signcrypter group. The correctness
and the security of this scheme are proved."
"We propose four different identification schemes that make use of bilinear
pairings, and prove their security under certain computational assumptions.
Each of the schemes is more efficient and/or more secure than any known
pairing-based identification scheme."
"Lal and Chaturvedi proposed two authentication schemes based on the
difficulty of the Root Problem in the braid group. We point out that the first
scheme is not really as secure as the Root Problem, and describe an efficient
way to crack it. The attack works for any group."
"This report presents a taxonomy of vulnerabilities created as a part of an
effort to develop a framework for deriving verification and validation
strategies to assess software security. This taxonomy is grounded in a
theoretical model of computing, which establishes the relationship between
vulnerabilities, software applications and the computer system resources. This
relationship illustrates that a software application is exploited by violating
constraints imposed by computer system resources and assumptions made about
their usage. In other words, a vulnerability exists in the software application
if it allows violation of these constraints and assumptions. The taxonomy
classifies these constraints and assumptions. The model also serves as a basis
for the classification scheme the taxonomy uses, in which the computer system
resources such as, memory, input/output, and cryptographic resources serve as
categories and subcategories. Vulnerabilities, which are expressed in the form
of constraints and assumptions, are classified according to these categories
and subcategories. This taxonomy is both novel and distinctively different from
other taxonomies found in the literature."
"We examine the security of existing radio navigation protocols and attempt to
define secure, scalable replacements."
"In this paper, we present a variant of Waters' Identity-Based Encryption
scheme with a much smaller public-key size (only a few kilobytes). We show that
this variant is semantically secure against passive adversaries in the standard
model.\smallskip
  In essence, the new scheme divides Waters' public key size by a factor $\ell$
at the cost of (negligibly) reducing security by $\ell$ bits. Therefore, our
construction settles an open question asked by Waters and constitutes the first
fully secure {\sl practical} Identity-Based Encryption scheme"
"We present Poseidon, a new anomaly based intrusion detection system. Poseidon
is payload-based, and presents a two-tier architecture: the first stage
consists of a Self-Organizing Map, while the second one is a modified PAYL
system. Our benchmarks on the 1999 DARPA data set show a higher detection rate
and lower number of false positives than PAYL and PHAD."
"Many computer-based authentication schemata are based on pass- words. Logging
on a computer, reading email, accessing content on a web server are all
examples of applications where the identification of the user is usually
accomplished matching the data provided by the user with data known by the
application.
  Such a widespread approach relies on some assumptions, whose satisfaction is
of foremost importance to guarantee the robustness of the solution. Some of
these assumptions, like having a ""secure"" chan- nel to transmit data, or having
sound algorithms to check the correct- ness of the data, are not addressed by
this paper. We will focus on two simple issues: the problem of using adequate
passwords and the problem of managing passwords.
  The proposed solution, the pathword, is a method that guarantees:
  1 that the passwords generated with the help of a pathword are adequate (i.e.
that they are not easy to guess),
  2 that managing pathwords is more user friendly than managing passwords and
that pathwords are less amenable to problems typical of passwords."
"To resist algebraic attack, a Boolean function should possess good algebraic
immunity (AI). Several papers constructed symmetric functions with the maximum
algebraic immunity $\lceil \frac{n}{2}\rceil $. In this correspondence we prove
that for each odd $n$, there is exactly one trivial balanced $n$-variable
symmetric Boolean function achieving the algebraic immunity $\lceil
\frac{n}{2}\rceil $. And we also obtain a necessary condition for the algebraic
normal form of a symmetric Boolean function with maximum algebraic immunity."
"The union cost is used, so that an efficient algorithm for computing the
k-error linear complexity of a sequence with period 2pn over GF(q) is
presented, where p and q are odd primes, and q is a primitive root of modulo
p2."
"A fast algorithm is presented for determining the linear complexity and the
minimal polynomial of periodic sequences over GF(q) with period q n p m, where
p is a prime, q is a prime and a primitive root modulo p2. The algorithm
presented here generalizes both the algorithm in [4] where the period of a
sequence over GF(q) is p m and the algorithm in [5] where the period of a
binary sequence is 2 n p m . When m=0, the algorithm simplifies the generalized
Games-Chan algorithm."
"Based on the definition of generalized partially bent functions, using the
theory of linear transformation, the relationship among generalized partially
bent functions over ring Z N, generalized bent functions over ring Z N and
affine functions is discussed. When N is a prime number, it is proved that a
generalized partially bent function can be decomposed as the addition of a
generalized bent function and an affine function. The result obtained here
generalizes the main works concerning partially bent functions by Claud Carlet
in [1]."
"In this paper we propose a multi-map orbit hopping chaotic stream cipher that
utilizes the idea of spread spectrum mechanism for secure digital
communications and fundamental chaos characteristics of mixing, unpredictable,
and extremely sensitive to initial conditions. The design, key and subkeys, and
detail implementation of the system are addressed. A variable number of well
studied chaotic maps form a map bank. And the key determines how the system
hops between multiple orbits, and it also determines the number of maps, the
number of orbits for each map, and the number of sample points for each orbits.
A detailed example is provided."
"Let $\underline{a}$ be an \textit{l}-sequence generated by a
feedback-with-carry shift register with connection integer $q=p^{e}$, where $
p$ is an odd prime and $e\geq 1$. Goresky and Klapper conjectured that when $
p^{e}\notin \{5,9,11,13\}$, all decimations of $\underline{a}$ are cyclically
distinct. When $e=1$ and $p>13$, they showed that the set of distinct
decimations is large and, in some cases, all deciamtions are distinct. In this
article, we further show that when $e\geq 2$ and$ p^{e}\neq 9$, all decimations
of $\underline{a}$ are also cyclically distinct."
"Artin's braid groups have been recently suggested as a new source for
public-key cryptography. In this paper we propose the first undeniable
signature schemes using the conjugacy problem and the decomposition problem in
the braid groups which are believed to be hard problems."
"We describe a novel way in which students can learn the cipher systems
without much supervision. In this work we focus on learning symmetric ciphers
by altering them using the agile development approach. Two agile approaches the
eXtreme Programming (XP) and the closely related Test-Driven Development (TDD)
are mentioned or discussed. To facilitate this development we experiment with
an approach that is based on refactoring, with JUnit serves as the automatic
testing framework. In this work we exemplify our learning approach by
test-infecting the Vernam cipher, an aged but still widely used stream cipher.
One can replace the cipher with another symmetric cipher with the same
behavior. Software testing is briefly described. Just-in-time introduction to
Object-oriented programming (OOP), exemplified by using JavaTM, is advocated.
Refactoring exercises, as argued, are kept strategically simple so that they do
not become intensive class redesign exercises. The use of free or open-source
tools and frameworks is mentioned."
"In the UNIX/Linux environment the kernel can log every command process
created by every user using process accounting. This data has many potential
uses, including the investigation of security incidents. However, process
accounting data is also sensitive since it contains private user information.
Consequently, security system administrators have been hindered from sharing
these logs. Given that many interesting security applications could use process
accounting data, it would be useful to have a tool that could protect private
user information in the logs. For this reason we introduce SCRUB-PA, a tool
that uses multi-level multi-dimensional anonymization on process accounting log
files in order to provide different levels of privacy protection. It is our
goal that SCRUB-PA will promote the sharing of process accounting logs while
preserving privacy."
"This paper introduces the use of decimal sequences in a code division
multiple access (CDMA) based watermarking system to hide information for
authentication in black and white images. Matlab version 6.5 was used to
implement the algorithms discussed in this paper. The advantage of using
d-sequences over PN sequences is that one can choose from a variety of prime
numbers which provides a more flexible system."
"The paper develops a novel approach to stream cipher design: Both the state
update function and the output function of the corresponding pseudorandom
generators are compositions of arithmetic and bitwise logical operations, which
are standard instructions of modern microprocessors. Moreover, both the state
update function and the output function are being modified dynamically during
the encryption. Also, these compositions could be keyed, so the only
information available to an attacker is that these functions belong to some
exponentially large class.
  The paper shows that under rather loose conditions the output sequence is
uniformly distributed, achieves maximum period length and has high linear
complexity and high $\ell$-error linear complexity. Ciphers of this kind are
flexible: One could choose a suitable combination of instructions to obtain due
performance without affecting the quality of the output sequence. Finally, some
evidence is given that a key recovery problem for (reasonably designed) stream
ciphers of this kind is intractable up to plausible conjectures."
"The paper analyzes a new public key cryptosystem whose security is based on a
matrix version of the discrete logarithm problem over an elliptic curve. It is
shown that the complexity of solving the underlying problem for the proposed
system is dominated by the complexity of solving a fixed number of discrete
logarithm problems in the group of an elliptic curve. Using an adapted Pollard
rho algorithm it is shown that this problem is essentially as hard as solving
one discrete logarithm problem in the group of an elliptic curve."
"Artin's braid groups have been recently suggested as a new source for
public-key cryptography. In this paper we propose the first group signature
schemes based on the conjugacy problem, decomposition problem and root problem
in the braid groups which are believed to be hard problems."
"We propose the use of the cubic transformation for public-key applications
and digital signatures. Transformations modulo a prime p or a composite n=pq,
where p and q are primes, are used in such a fashion that each transformed
value has only 3 roots that makes it a more efficient transformation than the
squaring transformation of Rabin, which has 4 roots. Such a transformation,
together with additional tag information, makes it possible to uniquely invert
each transformed value. The method may be used for other exponents as well."
"The established techniques for legal-for-trade registration of weight values
meet the legal requirements, but in praxis they show serious disadvantages. We
report on the first implementation of intrinsically legal-for-trade objects,
namely weight values signed by the scale, that is accepted by the approval
authority. The strict requirements from both the approval- and the
verification-authority as well as the limitations due to the hardware of the
scale were a special challenge. The presented solution fulfills all legal
requirements and eliminates the existing practical disadvantages."
"This paper proposes a new recursive technique using d-sequences to generate
random numbers."
"Significant research has been done in the area of Role Based Access Control
[RBAC]. Within this research there has been a thread of work focusing on adding
parameters to the role and permissions within RBAC. The primary benefit of
parameter support in RBAC comes in the form of a significant increase in
specificity in how permissions may be granted. This paper focuses on
implementing a parameterized implementation based heavily upon existing
standards."
"This paper analyzes the performance of Kak's three stage quantum
cryptographic protocol based on public key cryptography against a
man-in-the-middle attack. A method for protecting against such an attack is
presented using certificates distributed by a trusted third party."
"Horizontal integration of access technologies to networks and services should
be accompanied by some kind of convergence of authentication technologies. The
missing link for the federation of user identities across the technological
boundaries separating authentication methods can be provided by trusted
computing platforms. The concept of establishing transitive trust by trusted
computing enables the desired crossdomain authentication functionality. The
focus of target application scenarios lies in the realm of mobile networks and
devices."
"This paper presents watermarking algorithms using d-sequences so that the
peak signal to noise ratio (PSNR) is maximized and the distortion introduced in
the image due to the embedding is minimized. By exploiting the cross
correlation property of decimal sequences, the concept of embedding more than
one watermark in the same cover image is investigated."
"We present simple implementations of Kak's three-stage quantum cryptography
protocol. The case where the transformation is applied to more than one qubit
at the same time is also considered."
"Basic role based access control [RBAC] provides a mechanism for segregating
access privileges based upon a user's hierarchical roles within an
organization. This model doesn't scale well when there is tight integration of
multiple hierarchies. In a case where there is joint-tenancy and a requirement
for different levels of disclosure based upon a user's hierarchy, or in our
case, organization or company, basic RBAC requires these hierarchies to be
effectively merged. Specific roles that effectively represent both the user's
organizations and roles must be translated to fit within the merged hierarchy
to be used to control access. Essentially, users from multiple organizations
are served from a single role base with roles designed to constrain their
access as needed.
  Our work proposes, through parameterized roles and privileges, a means for
accurately representing both users' roles within their respective hierarchies
for providing access to controlled objects. Using this method will reduce the
amount of complexity required in terms of the number of roles and privileges.
The resulting set of roles, privileges, and objects will make modeling and
visualizing the access role hierarchy significantly simplified. This paper will
give some background on role based access control, parameterized roles and
privileges, and then focus on how RBAC with parameterized roles and privileges
can be leveraged as an access control solution for the problems presented by
joint tenancy."
"We introduce what --if some kind of group action exists-- is a truly
(information theoretically) safe cryptographic communication system: a protocol
which provides \emph{zero} information to any passive adversary having full
access to the channel."
"In this paper we present an approach for specifying and prioritizing
information security requirements in organizations. It is important to
prioritize security requirements since hundred per cent security is not
achievable and the limited resources available should be directed to satisfy
the most important ones. We propose to link explicitly security requirements
with the organization's business vision, i.e. to provide business rationale for
security requirements. The rationale is then used as a basis for comparing the
importance of different security requirements. A conceptual framework is
presented, where the relationships between business vision, critical impact
factors and valuable assets (together with their security requirements) are
shown."
"This paper presents an introduction to the Aryabhata algorithm for finding
multiplicative inverses and solving linear congruences, both of which have
applications in cryptography. We do so by the use of the least absolute
remainders. The exposition of the Aryabhata algorithm provided here can have
performance that could exceed what was described recently by Rao and Yang."
"We present APHRODITE, an architecture designed to reduce false positives in
network intrusion detection systems. APHRODITE works by detecting anomalies in
the output traffic, and by correlating them with the alerts raised by the NIDS
working on the input traffic. Benchmarks show a substantial reduction of false
positives and that APHRODITE is effective also after a ""quick setup"", i.e. in
the realistic case in which it has not been ""trained"" and set up optimally"
"This paper explains the recent developments in security and encryption. The
Butterfly cipher and quantum cryptography are reviewed and compared. Examples
of their relative uses are discussed and suggestions for future developments
considered. In addition application to network security together with a
substantial review of classification of encryption systems and a summary of
security weaknesses are considered."
"This paper presents protocols for Kak's cubic transformation and proposes a
modification to Diffie-Hellman key exchange protocol in order to achieve
asymmetric oblivious exchange of keys."
"After a brief introduction to a new chaotic stream cipher Mmohocc which
utilizes the fundamental chaos characteristics of mixing, unpredictability, and
sensitivity to initial conditions, we conducted the randomness statistical
tests against the keystreams generated by the cipher. Two batteries of most
stringent randomness tests, namely the NIST Suite and the Diehard Suite, were
performed. The results showed that the keystreams have successfully passed all
the statistical tests. We conclude that Mmohocc can generate high-quality
pseudorandom numbers from a statistical point of view."
"This paper modifies Kak's three-stage protocol so that it can guarantee
secure transmission of information. Although avoiding man-in-the-middle attack
is our primary objective in the introduction of classical authentication inside
the three-stage protocol, we also benefit from the inherent advantages of the
chosen classical authentication protocol. We have tried to implement ideas like
key distribution center, session key, time-stamp, and nonce, within the quantum
cryptography protocol."
"We introduce knowledge flow analysis, a simple and flexible formalism for
checking cryptographic protocols. Knowledge flows provide a uniform language
for expressing the actions of principals, assump- tions about intruders, and
the properties of cryptographic primitives. Our approach enables a generalized
two-phase analysis: we extend the two-phase theory by identifying the necessary
and sufficient proper- ties of a broad class of cryptographic primitives for
which the theory holds. We also contribute a library of standard primitives and
show that they satisfy our criteria."
"This paper proposes an algorithm for oblivious transfer using elliptic
curves. Also, we present its application to chosen one-out-of-two oblivious
transfer."
"One improves an algebraic attack of NTRU due to Silverman, Smart and
Vercauteren; the latter considered the first 2 bits of a Witt vector attached
to the research of the secret key; here the first 4 bits are considered, which
provides additional equations of degrees 4 and 8."
"Algebraic immunity has been proposed as an important property of Boolean
functions. To resist algebraic attack, a Boolean function should possess high
algebraic immunity. It is well known now that the algebraic immunity of an
$n$-variable Boolean function is upper bounded by $\left\lceil {\frac{n}{2}}
\right\rceil $. In this paper, for an odd integer $n$, we present a
construction method which can efficiently generate a Boolean function of $n$
variables with maximum algebraic immunity, and we also show that any such
function can be generated by this method. Moreover, the number of such Boolean
functions is greater than $2^{2^{n-1}}$."
"In this paper we introduce a new chaotic stream cipher Mmohocc which utilizes
the fundamental chaos characteristics. The designs of the major components of
the cipher are given. Its cryptographic properties of period, auto- and
cross-correlations, and the mixture of Markov processes and spatiotemporal
effects are investigated. The cipher is resistant to the related-key-IV
attacks, Time/Memory/Data tradeoff attacks, algebraic attacks, and chosen-text
attacks. The keystreams successfully passed two batteries of statistical tests
and the encryption speed is comparable with RC4."
"Although good encryption functions are probabilistic, most symbolic models do
not capture this aspect explicitly. A typical solution, recently used to prove
the soundness of such models with respect to computational ones, is to
explicitly represent the dependency of ciphertexts on random coins as labels.
In order to make these label-based models useful, it seems natural to try to
extend the underlying decision procedures and the implementation of existing
tools. In this paper we put forth a more practical alternative based on the
following soundness theorem. We prove that for a large class of security
properties (that includes rather standard formulations for secrecy and
authenticity properties), security of protocols in the simpler model implies
security in the label-based model. Combined with the soundness result of
(\textbf{?}) our theorem enables the translation of security results in
unlabeled symbolic models to computational security."
"An efficient archive securing the integrity of VoIP-based two-party
conversations is presented. The solution is based on chains of hashes and
continuously chained electronic signatures. Security is concentrated in a
single, efficient component, allowing for a detailed analysis."
"Due to the convergence of various mobile access technologies like UMTS, WLAN,
and WiMax the need for a new supporting infrastructure arises. This
infrastructure should be able to support more efficient ways to authenticate
users and devices, potentially enabling novel services based on the security
provided by the infrastructure. In this paper we exhibit some usage scenarios
from the mobile domain integrating trusted computing, which show that trusted
computing offers new paradigms for implementing trust and by this enables new
technical applications and business scenarios. The scenarios show how the
traditional boundaries between technical and authentication domains become
permeable while a high security level is maintained."
"FLAIM (Framework for Log Anonymization and Information Management) addresses
two important needs not well addressed by current log anonymizers. First, it is
extremely modular and not tied to the specific log being anonymized. Second, it
supports multi-level anonymization, allowing system administrators to make
fine-grained trade-offs between information loss and privacy/security concerns.
In this paper, we examine anonymization solutions to date and note the above
limitations in each. We further describe how FLAIM addresses these problems,
and we describe FLAIM's architecture and features in detail."
"We present a concept to achieve non-repudiation for natural language
conversations by electronically signing packet-based, digital, voice
communication. Signing a VoIP-based conversation means to protect the integrity
and authenticity of the bidirectional data stream and its temporal sequence
which together establish the security context of the communication. Our concept
is conceptually close to the protocols that embody VoIP and provides a high
level of inherent security. It enables signatures over voice as true
declarations of will, in principle between unacquainted speakers. We point to
trusted computing enabled devices as possible trusted signature terminals for
voice communication."
"We propose a simple universal (that is, distribution--free) steganographic
system in which covertexts with and without hidden texts are statistically
indistinguishable. The stegosystem can be applied to any source generating
i.i.d. covertexts with unknown distribution, and the hidden text is transmitted
exactly, with zero probability of error. Moreover, the proposed steganographic
system has two important properties. First, the rate of transmission of hidden
information approaches the Shannon entropy of the covertext source as the size
of blocks used for hidden text encoding tends to infinity. Second, if the size
of the alphabet of the covertext source and its minentropy tend to infinity
then the number of bits of hidden text per letter of covertext tends to
$\log(n!)/n$ where $n$ is the (fixed) size of blocks used for hidden text
encoding. The proposed stegosystem uses randomization."
"In this paper we resolve an open problem regarding resettable zero knowledge
in the bare public-key (BPK for short) model: Does there exist constant round
resettable zero knowledge argument with concurrent soundness for $\mathcal{NP}$
in BPK model without assuming \emph{sub-exponential hardness}? We give a
positive answer to this question by presenting such a protocol for any language
in $\mathcal{NP}$ in the bare public-key model assuming only
collision-resistant hash functions against \emph{polynomial-time} adversaries."
"Source data for computer network security analysis takes different forms
(alerts, incidents, logs) and each source may be voluminous. Due to the
challenge this presents for data management, this has often lead to security
stovepipe operations which focus primarily on a small number of data sources
for analysis with little or no automated correlation between data sources
(although correlation may be done manually). We seek to address this systemic
problem.
  In previous work we developed a unified correlated logging system (UCLog)
that automatically processes alerts from different devices. We take this work
one step further by presenting the architecture and applications of UCLog+
which adds the new capability to correlate between alerts and incidents and raw
data located on remote logs. UCLog+ can be used for forensic analysis including
queries and report generation but more importantly it can be used for
near-real-time situational awareness of attack patterns in progress. The
system, implemented with open source tools, can also be a repository for secure
information sharing by different organizations."
"We review the fingerprinting scheme by Tardos and show that it has a much
better performance than suggested by the proofs in Tardos' original paper. In
particular, the length of the codewords can be significantly reduced.
  First we generalize the proofs of the false positive and false negative error
probabilities with the following modifications: (1) we replace Tardos'
hard-coded numbers by variables and (2) we allow for independently chosen false
positive and false negative error rates. It turns out that all the
collusion-resistance properties can still be proven when the code length is
reduced by a factor of more than 2.
  Second, we study the statistical properties of the fingerprinting scheme, in
particular the average and variance of the accusations. We identify which
colluder strategy forces the content owner to employ the longest code. Using a
gaussian approximation for the probability density functions of the
accusations, we show that the required false negative and false positive error
rate can be achieved with codes that are a factor 2 shorter than required for
rigid proofs.
  Combining the results of these two approaches, we show that the Tardos scheme
can be used with a code length approximately 5 times shorter than in the
original construction."
"Reputation and recommendation systems are fundamental for the formation of
community market places. Yet, they are easy targets for attacks which disturb a
market's equilibrium and are often based on cheap pseudonyms used to submit
ratings. We present a method to price ratings using trusted computing, based on
pseudonymous tickets."
"McLean's notion of Selective Interleaving Functions (SIFs) is perhaps the
best-known attempt to construct a framework for expressing various security
properties. We examine the expressive power of SIFs carefully. We show that
SIFs cannot capture nondeducibility on strategies (NOS). We also prove that the
set of security properties expressed with SIFs is not closed under conjunction,
from which it follows that separability is strictly stronger than double
generalized noninterference. However, we show that if we generalize the notion
of SIF in a natural way, then NOS is expressible, and the set of security
properties expressible by generalized SIFs is closed under conjunction."
"With the rapid spread of various mobile terminals in our society, the
importance of secure positioning is growing for wireless networks in
adversarial settings. Recently, several authors have proposed a secure
positioning mechanism of mobile terminals which is based on the geometric
property of wireless node placement, and on the postulate of modern physics
that a propagation speed of information never exceeds the velocity of light. In
particular, they utilize the measurements of the round-trip time of radio
signal propagation and bidirectional communication for variants of the
challenge-and-response. In this paper, we propose a novel means to construct
the above mechanism by use of unidirectional communication instead of
bidirectional communication. Our proposal is based on the assumption that a
mobile terminal incorporates a high-precision inner clock in a tamper-resistant
protected area. In positioning, the mobile terminal uses its inner clock and
the time and location information broadcasted by radio from trusted stations.
Our proposal has a major advantage in protecting the location privacy of mobile
terminal users, because the mobile terminal need not provide any information to
the trusted stations through positioning procedures. Besides, our proposal is
free from the positioning error due to claimant's processing-time fluctuations
in the challenge-and-response, and is well-suited for mobile terminals in the
open air, or on the move at high speed, in terms of practical usage. We analyze
the security, the functionality, and the feasibility of our proposal in
comparison to previous proposals."
"Technical security is only part of E-Commerce security operations; human
usability and security perception play major and sometimes dominating factors.
For instance, slick websites with impressive security icons but no real
technical security are often perceived by users to be trustworthy (and thus
more profitable) than plain vanilla websites that use powerful encryption for
transmission and server protection. We study one important type of E-Commerce
transaction website, E-Tax Filing, that is exposed to large populations. We
assess a large number of international (5), Federal (USA), and state E-Tax
filing websites (38) for both technical security protection and human
perception of security. As a result of this assessment, we identify security
best practices across these E-Tax Filing websites and recommend additional
security techniques that have not been found in current use by E-Tax Filing
websites."
"For a secret sharing scheme, two parameters $d_{min}$ and $d_{cheat}$ are
defined in [12] and [13]. These two parameters measure the error-correcting
capability and the secret-recovering capability of the secret sharing scheme
against cheaters. Some general properties of the parameters have been studied
in [12,[9] and [13]. The MDS secret-sharing scheme was defined in [12] and it
is proved that MDS perfect secret sharing scheme can be constructed for any
monotone access structure. The famous Shamir $(k,n)$ threshold secret sharing
scheme is the MDS with $d_{min}=d_{cheat}=n-k+1$. In [3] we proposed the linear
secret sharing scheme from algebraic-geometric codes. In this paper the linear
secret sharing scheme from AG-codes on elliptic curves is studied and it is
shown that many of them are MDS linear secret sharing scheme."
"Oblivious transfer is a primitive of paramount importance in cryptography or,
more precisely, two- and multi-party computation due to its universality.
Unfortunately, oblivious transfer cannot be achieved in an unconditionally
secure way for both parties from scratch. Therefore, it is a natural question
what information-theoretic primitives or computational assumptions oblivious
transfer can be based on.
  The results in our thesis are threefold. First, we present a protocol that
implements oblivious transfer from a weakened oblivious transfer called
universal oblivious transfer, where one of the two players may get additional
information. Our reduction is about twice as efficient as previous results.
  Weak oblivious transfer is an even weaker form of oblivious transfer, where
both players may obtain additional information about the other player's input,
and where the output can contain errors. We give a new, weaker definition of
weak oblivious transfer, as well as new reductions with a more detailed
analysis.
  Finally, we carry over our results to the computational setting and show how
a weak oblivious transfer that is sometimes incorrect and only mildly secure
against computationally bounded adversaries can be strengthened."
"From the motivation of algebraic attacks to stream and block
ciphers([1,2,7,13,14,15]), the concept of {\em algebraic immunity} (AI) was
introduced in [21] and studied in [3,5,10,11,17,18,19,20,21]. High algebraic
immunity is a necessary condition for resisting algebraic attacks. In this
paper, we give some lower bounds on algebraic immunity of Boolean functions.
The results are applied to give lower bounds on AI of symmetric Boolean
functions and rotation symmetric Boolean functions. Some balanced rotation
symmetric Boolean functions with their AI near the maximum possible value
$\lceil \frac{n}{2}\rceil$ are constructed."
"This paper presents a robust and transparent scheme of watermarking that
exploits the human visual systems' sensitivity to frequency, along with local
image characteristics obtained from the spatial domain. The underlying idea is
generating a visual mask based on the visual systems' perception of image
content. This mask is used to embed a decimal sequence while keeping its
amplitude below the distortion sensitivity of the image pixel. We consider
texture, luminance, corner and the edge information in the image to generate a
mask that makes the addition of the watermark imperceptible to the human eye."
"We consider a type of zero-knowledge protocols that are of interest for their
practical applications within networks like the Internet: efficient
zero-knowledge arguments of knowledge that remain secure against concurrent
man-in-the-middle attacks. In an effort to reduce the setup assumptions
required for efficient zero-knowledge arguments of knowledge that remain secure
against concurrent man-in-the-middle attacks, we consider a model, which we
call the Authenticated Public-Key (APK) model. The APK model seems to
significantly reduce the setup assumptions made by the CRS model (as no trusted
party or honest execution of a centralized algorithm are required), and can be
seen as a slightly stronger variation of the Bare Public-Key (BPK) model from
\cite{CGGM,MR}, and a weaker variation of the registered public-key model used
in \cite{BCNP}. We then define and study man-in-the-middle attacks in the APK
model. Our main result is a constant-round concurrent non-malleable
zero-knowledge argument of knowledge for any polynomial-time relation
(associated to a language in $\mathcal{NP}$), under the (minimal) assumption of
the existence of a one-way function family. Furthermore,We show time-efficient
instantiations of our protocol based on known number-theoretic assumptions. We
also note a negative result with respect to further reducing the setup
assumptions of our protocol to those in the (unauthenticated) BPK model, by
showing that concurrently non-malleable zero-knowledge arguments of knowledge
in the BPK model are only possible for trivial languages."
"Conjugacy is not the only possible primitive for designing braid-based
protocols. To illustrate this principle, we describe a Fiat--Shamir-style
authentication protocol that be can be implemented using any binary operation
that satisfies the left self-distributive law. Conjugation is an example of
such an operation, but there are other examples, in particular the shifted
conjugation on Artin's braid group B\_oo, and the finite Laver tables. In both
cases, the underlying structures have a high combinatorial complexity, and they
lead to difficult problems."
"The binomial multichannel algorithm is proposed. Some its properties are
discussed."
"We consider the problem of private computation of approximate Heavy Hitters.
Alice and Bob each hold a vector and, in the vector sum, they want to find the
B largest values along with their indices. While the exact problem requires
linear communication, protocols in the literature solve this problem
approximately using polynomial computation time, polylogarithmic communication,
and constantly many rounds. We show how to solve the problem privately with
comparable cost, in the sense that nothing is learned by Alice and Bob beyond
what is implied by their input, the ideal top-B output, and goodness of
approximation (equivalently, the Euclidean norm of the vector sum). We give
lower bounds showing that the Euclidean norm must leak by any efficient
algorithm."
"In this paper, we propose a unification algorithm for the theory $E$ which
combines unification algorithms for $E\_{\std}$ and $E\_{\ACUN}$ (ACUN
properties, like XOR) but compared to the more general combination methods uses
specific properties of the equational theories for further optimizations. Our
optimizations drastically reduce the number of non-deterministic choices, in
particular those for variable identification and linear orderings. This is
important for reducing both the runtime of the unification algorithm and the
number of unifiers in the complete set of unifiers. We emphasize that obtaining
a ``small'' set of unifiers is essential for the efficiency of the constraint
solving procedure within which the unification algorithm is used. The method is
implemented in the CL-Atse tool for security protocol analysis."
"This paper presents a quasigroup encryptor that has very good scrambling
properties. We show that the output of the encryptor maximizes the output
entropy and the encrypted output for constant and random inputs is very
similar. The system architecture of the quasigroup encryptor and the
autocorrelation properties of the output sequences are provided."
"Differential Power Analysis (DPA) presents a major challenge to
mathematically-secure cryptographic protocols. Attackers can break the
encryption by measuring the energy consumed in the working digital circuit. To
prevent this type of attack, this paper proposes the use of reversible logic
for designing the ALU of a cryptosystem. Ideally, reversible circuits dissipate
zero energy. Thus, it would be of great significance to apply reversible logic
to designing secure cryptosystems. As far as is known, this is the first
attempt to apply reversible logic to developing secure cryptosystems. In a
prototype of a reversible ALU for a crypto-processor, reversible designs of
adders and Montgomery multipliers are presented. The reversible designs of a
carry propagate adder, four-to-two and five-to-two carry save adders are
presented using a reversible TSG gate. One of the important properties of the
TSG gate is that it can work singly as a reversible full adder. In order to
design the reversible Montgomery multiplier, novel reversible sequential
circuits are also proposed which are integrated with the proposed adders to
design a reversible modulo multiplier. It is intended that this paper will
provide a starting point for developing cryptosystems secure against DPA
attacks."
"It has been found that an algorithm can generate true random numbers on
classical computer. The algorithm can be used to generate unbreakable message
PIN (personal identification number) and password."
"An Extended Visual Cryptography Scheme (EVCS) was proposed by Ateniese et al.
[3] to protect a binary secret image with meaningful (innocent-looking) shares.
This is implemented by concatenating an extended matrix to each basis matrix.
The minimum size of the extended matrix was obtained from a hypergraph coloring
model and the scheme was designed for binary images only [3]. In this paper, we
give a more concise derivation for this matrix extension for color images.
Furthermore, we present a (k, n) scheme to protect multiple color images with
meaningful shares. This scheme is an extension of the (n, n) VCS for multiple
binary images proposed in Droste scheme [2]."
"Confidentiality, integrity and authentication are more relevant issues in Ad
hoc networks than in wired fixed networks. One way to address these issues is
the use of symmetric key cryptography, relying on a secret key shared by all
members of the network. But establishing and maintaining such a key (also
called the session key) is a non-trivial problem. We show that Group Key
Agreement (GKA) protocols are suitable for establishing and maintaining such a
session key in these dynamic networks. We take an existing GKA protocol, which
is robust to connectivity losses and discuss all the issues for good
functioning of this protocol in Ad hoc networks. We give implementation details
and network parameters, which significantly reduce the computational burden of
using public key cryptography in such networks."
"This paper presents two attacks against Achterbahn-128/80, the last version
of one of the stream cipher proposals in the eSTREAM project. The attack
against the 80-bit variant, Achterbahn-80, has complexity 2^{56.32}. The attack
against Achterbahn-128 requires 2^{75.4} operations and 2^{61} keystream bits.
These attacks are based on an improvement of the attack due to Hell and
Johansson against Achterbahn version 2 and also on an algorithm that makes
profit of the short lengths of the constituent registers.
  *****
  Ce papier pr\'{e}sente deux attaques sur Achterbahn-128/80, la derni\`{e}re
version d'un des algorithmes propos\'{e}s dans le cadre de eSTREAM. L'attaque
sur la version de 80 bits, Achterbahn-80, est en 2^{56.32}. L'attaque sur
Achterbahn-128 a besoin de 2^{75.4} calculs et 2^{61} bits de suite chiffrante.
Ces attaques sont bas\'{e}es sur une am\'{e}lioration de l'attaque propos\'{e}e
par Hell et Johansson sur la version 2 d'Achterbahn et aussi sur un algorithme
qui tire profit des petites longueurs des registres."
"Recently, various side-channel attacks on widely used encryption methods have
been discovered. Extensive research is currently undertaken to develop new
types of combined encryption and authentication mechanisms. Developers of
security systems ask whether to implement methods recommended by international
standards or to choose one of the new proposals. We explain the nature of the
attacks and how they can be avoided, and recommend a sound, provably secure
solution: the CCM standard."
"Automatic security protocol analysis is currently feasible only for small
protocols. Since larger protocols quite often are composed of many small
protocols, compositional analysis is an attractive, but non-trivial approach.
  We have developed a framework for compositional analysis of a large class of
security protocols. The framework is intended to facilitate automatic as well
as manual verification of large structured security protocols. Our approach is
to verify properties of component protocols in a multi-protocol environment,
then deduce properties about the composed protocol. To reduce the complexity of
multi-protocol verification, we introduce a notion of protocol independence and
prove a number of theorems that enable analysis of independent component
protocols in isolation.
  To illustrate the applicability of our framework to real-world protocols, we
study a key establishment sequence in WiMax consisting of three subprotocols.
Except for a small amount of trivial reasoning, the analysis is done using
automatic tools."
"We show that two new key exchange protocols with security based on the triple
DP may have security based on the MSCSP."
"We consider a reasonably simple voting system which can be implemented for
web-based ballots. Simplicity, modularity and the requirement of compatibility
with current web browsers leads to a system which satisfies a set of security
requirements for a ballot system which is not complete but sufficient in many
cases. Due to weak-eligibility and vote-selling, this system cannot be used for
political or similar ballots."
"We describe a practical implementation of the modular eballot system proposed
in ref.[1]"
"We present a method to secure the complete path between a server and the
local human user at a network node. This is useful for scenarios like internet
banking, electronic signatures, or online voting. Protection of input
authenticity and output integrity and authenticity is accomplished by a
combination of traditional and novel technologies, e.g., SSL, ActiveX, and
DirectX. Our approach does not require administrative privileges to deploy and
is hence suitable for consumer applications. Results are based on the
implementation of a proof-of-concept application for the Windows platform."
"In the recent years, several practical methods have been published to compute
collisions on some commonly used hash functions. In this paper we present a
method to take into account, at the symbolic level, that an intruder actively
attacking a protocol execution may use these collision algorithms in reasonable
time during the attack. Our decision procedure relies on the reduction of
constraint solving for an intruder exploiting the collision properties of hush
functions to constraint solving for an intruder operating on words."
"Delivery of content to mobile devices gains increasing importance in
industrial environments to support employees in the field. An important
application are e-mail push services like the fashionable Blackberry. These
systems are facing security challenges regarding data transport to, and storage
of the data on the end user equipment. The emerging Trusted Computing
technology offers new answers to these open questions."
"Numerous research studies have been investigated on proxy signatures over the
last decade. This survey reviews the research progress on proxy signatures,
analyzes a few notable proposals, and provides an overall remark of these
proposals."
"This paper presents an identity based multi-proxy multi-signcryption scheme
from pairings. In this scheme a proxy signcrypter group could authorized as a
proxy agent by the coopration of all members in the original signcryption
group. Then the proxy signcryption can be generated by the cooperation of all
the signcrypters in the authorized proxy signcrypter group on the behalf of the
original signcrypter group. As compared to the scheme of Liu and Xiao, the
proposed scheme provides public verifiability of the signature along with
simplified key management."
"Finding low-weight multiples of a binary polynomial is a difficult problem
arising in the context of stream ciphers cryptanalysis. The classical algorithm
to solve this problem is based on a time memory trade-off. We will present an
improvement to this approach using discrete logarithm rather than a direct
representation of the involved polynomials. This gives an algorithm which
improves the theoretical complexity, and is also very flexible in practice."
"Trusted Computing is a security base technology that will perhaps be
ubiquitous in a few years in personal computers and mobile devices alike.
Despite its neutrality with respect to applications, it has raised some privacy
concerns. We show that trusted computing can be applied for service access
control in a manner protecting users' privacy. We construct a ticket system --
a concept which is at the heart of Identity Management -- relying solely on the
capabilities of the trusted platform module and the standards specified by the
Trusted Computing Group. Two examples show how it can be used for pseudonymous
and protected service access."
"We present a concept to achieve non-repudiation for natural language
conversations over the Internet. The method rests on chained electronic
signatures applied to pieces of packet-based, digital, voice communication. It
establishes the integrity and authenticity of the bidirectional data stream and
its temporal sequence and thus the security context of a conversation. The
concept is close to the protocols for Voice over the Internet (VoIP), provides
a high level of inherent security, and extends naturally to multilateral
non-repudiation, e.g., for conferences. Signatures over conversations can
become true declarations of will in analogy to electronically signed, digital
documents. This enables binding verbal contracts, in principle between
unacquainted speakers, and in particular without witnesses. A reference
implementation of a secure VoIP archive is exhibited."
"We describe a concept to employ Trusted Computing technology to secure
Conditional Access Systems (CAS) for DVB. Central is the embedding of a trusted
platform module (TPM) into the set-top-box or residential home gateway. Various
deployment scenarios exhibit possibilities of charging co-operation with mobile
network operators (MNO), or other payment providers."
"We investigate the bit-search type irregular decimation algorithms that are
used within LFSR-based stream ciphers. In particular, we concentrate on BSG and
ABSG, and consider two different setups for the analysis. In the first case,
the input is assumed to be a m-sequence; we show that all possible output
sequences can be classified into two sets, each of which is characterized by
the equivalence of their elements up to shifts. Furthermore, we prove that the
cardinality of each of these sets is equal to the period of one of its elements
and subsequently derive the first known bounds on the expected output period
(assuming that no subperiods exist). In the second setup, we work in a
probabilistic framework and assume that the input sequence is evenly
distributed (i.e., independent identically distributed Bernoulli process with
probability 1/2). Under these assumptions, we derive closed-form expressions
for the distribution of the output length and the output rate, which is shown
to be asymptotically Gaussian-distributed and concentrated around the mean with
exponential tightness."
"In this letter we assert that we have reconstructed the nonlinear filter
function of LILI-128 stream cipher on IBM notebook PC using MATLAB. Our
reconstruction need approximately 2^12~2^13 and the attack consumes 5825.016
sec (using tic and toc sentences of MATLAB) or 5825.016/3600=1.6181hours. We
got the expression of the nonlinear filter function fd of Lili-128 which has 46
items from liner items to nonlinear items based on complexity, the phase space
reconstruction, Clustering and nonlinear prediction. We have verified our
reconstruction result correctness by simulating the overview of Lili-128
keystream generators using our getting fd and implement designers reference
module of the Lili-128 stream cipher, and two methods produce the same
synchronous keystream sequence on same initial state, so that our research work
proves that the nonlinear filter function of LILI-128 stream cipher is
successfully reconstructed."
"This paper compares the popular quantum key distribution (QKD) protocol BB84
with the more recent Kak's three-stage protocol and the latter is shown to be
more secure. A theoretical representation of an authentication-aided version of
Kak's three-stage protocol is provided that makes it possible to deal with the
man-in-the-middle attack."
"In this paper, we present a new identity-based encryption (IBE) scheme using
bilinear pairings. Our IBE scheme enjoys the same \textsf{Key Extraction} and
\textsf{Decryption} algorithms with the famous IBE scheme of Boneh and Franklin
(BF-IBE for short), while differs from the latter in that it has modified
\textsf{Setup} and \textsf{Encryption} algorithms.
  Compared with BF-IBE, we show that ours are more practical in a multiple
private key generator (PKG) environment, mainly due to that the session secret
$g_{ID}$ could be pre-computed \emph{before} any interaction, and the sender
could encrypt a message using $g_{ID}$ prior to negotiating with the intended
recipient(s). As an application of our IBE scheme, we also derive an escrowed
ElGamal scheme which possesses certain good properties in practice."
"In this paper we propose a general definition of secrecy for cryptographic
protocols in the Dolev-Yao model. We give a sufficient condition ensuring
secrecy for protocols where rules have encryption depth at most two, that is
satisfied by almost all practical protocols. The only allowed primitives in the
class of protocols we consider are pairing and encryption with atomic keys.
Moreover, we describe an algorithm of practical interest which transforms a
cryptographic protocol into a secure one from the point of view of secrecy,
without changing its original goal with respect to secrecy of nonces and keys,
provided the protocol satisfies some conditions. These conditions are not very
restrictive and are satisfied for most practical protocols."
"We illustrate through example 1 and 2 that the condition at theorem 1 in [8]
dissatisfies necessity, and the converse proposition of fact 1.1 in [8] does
not hold, namely the condition Z/M - L/Ak < 1/(2 Ak^2) is not sufficient for
f(i) + f(j) = f(k). Illuminate through an analysis and ex.3 that there is a
logic error during deduction of fact 1.2, which causes each of fact 1.2, 1.3, 4
to be invalid. Demonstrate through ex.4 and 5 that each or the combination of
qu+1 > qu * D at fact 4 and table 1 at fact 2.2 is not sufficient for f(i) +
f(j) = f(k), property 1, 2, 3, 4, 5 each are invalid, and alg.1 based on fact 4
and alg.2 based on table 1 are disordered and wrong logically. Further,
manifest through a repeated experiment and ex.5 that the data at table 2 is
falsified, and the example in [8] is woven elaborately. We explain why Cx = Ax
* W^f(x) (% M) is changed to Cx = (Ax * W^f(x))^d (% M) in REESSE1+ v2.1. To
the signature fraud, we point out that [8] misunderstands the existence of T^-1
and Q^-1 % (M-1), and forging of Q can be easily avoided through moving H.
Therefore, the conclusion of [8] that REESSE1+ is not secure at all (which
connotes that [8] can extract a related private key from any public key in
REESSE1+) is fully incorrect, and as long as the parameter Omega is fitly
selected, REESSE1+ with Cx = Ax * W^f(x) (% M) is secure."
"This paper presents an experimental study and the lessons learned from the
observation of the attackers when logged on a compromised machine. The results
are based on a six months period during which a controlled experiment has been
run with a high interaction honeypot. We correlate our findings with those
obtained with a worldwide distributed system of lowinteraction honeypots."
"A secure human identification protocol aims at authenticating human users to
a remote server when even the users' inputs are not hidden from an adversary.
Recently, the authors proposed a human identification protocol in the RSA
Conference 2007, which is loosely based on the ability of humans to efficiently
process an image. The advantage being that an automated adversary is not
effective in attacking the protocol without human assistance. This paper
extends that work by trying to solve some of the open problems. First, we
analyze the complexity of defeating the proposed protocols by quantifying the
workload of a human adversary. Secondly, we propose a new construction based on
textual CAPTCHAs (Reverse Turing Tests) in order to make the generation of
automated challenges easier. We also present a brief experiment involving real
human users to find out the number of possible attributes in a given image and
give some guidelines for the selection of challenge questions based on the
results. Finally, we analyze the previously proposed protocol in detail for the
relationship between the secrets. Our results show that we can construct human
identification protocols based on image evaluation with reasonably
``quantified'' security guarantees based on our model."
"Key-exchange protocols have been overlooked as a possible means for
implementing oblivious transfer (OT). In this paper we present a protocol for
mutual exchange of secrets, 1-out-of-2 OT and coin flipping similar to
Diffie-Hellman protocol using the idea of obliviously exchanging encryption
keys. Since, Diffie-Hellman scheme is widely used, our protocol may provide a
useful alternative to the conventional methods for implementation of oblivious
transfer and a useful primitive in building larger cryptographic schemes."
"Internet worms cause billions of dollars in damage yearly, affecting millions
of users worldwide. For countermeasures to be deployed timeously, it is
necessary to use an automated system to detect the spread of a worm. This paper
discusses a method of determining the presence of a worm, based on routing
information currently available from Internet routers. An autoencoder, which is
a specialized type of neural network, was used to detect anomalies in normal
routing behavior. The autoencoder was trained using information from a single
router, and was able to detect both global instability caused by worms as well
as localized routing instability."
"We introduce a new approach for cryptanalysis of key agreement protocols
based on noncommutative groups. This approach uses functions that estimate the
distance of a group element to a given subgroup. We test it against the
Shpilrain-Ushakov protocol, which is based on Thompson's group F."
"Fuzzy sketches, introduced as a link between biometry and cryptography, are a
way of handling biometric data matching as an error correction issue. We focus
here on iris biometrics and look for the best error-correcting code in that
respect. We show that two-dimensional iterative min-sum decoding leads to
results near the theoretical limits. In particular, we experiment our
techniques on the Iris Challenge Evaluation (ICE) database and validate our
findings."
"It is well known that, in theory, the general secure multi-party computation
problem is solvable using circuit evaluation protocols. However, the
communication complexity of the resulting protocols depend on the size of the
circuit that expresses the functionality to be computed and hence can be
impractical. Hence special solutions are needed for specific problems for
efficiency reasons. The point inclusion problem in computational geometry is a
special multiparty computation and has got many applications. Previous
protocols for the secure point inclusion problem are not adequate. In this
paper we modify some known solutions to the point inclusion problem in
computational geometry to the frame work of secure two-party computation."
"When studying safety properties of (formal) protocol models, it is customary
to view the scheduler as an adversary: an entity trying to falsify the safety
property. We show that in the context of security protocols, and in particular
of anonymizing protocols, this gives the adversary too much power; for
instance, the contents of encrypted messages and internal computations by the
parties should be considered invisible to the adversary.
  We restrict the class of schedulers to a class of admissible schedulers which
better model adversarial behaviour. These admissible schedulers base their
decision solely on the past behaviour of the system that is visible to the
adversary.
  Using this, we propose a definition of anonymity: for all admissible
schedulers the identity of the users and the observations of the adversary are
independent stochastic variables. We also develop a proof technique for typical
cases that can be used to proof anonymity: a system is anonymous if it is
possible to `exchange' the behaviour of two users without the adversary
`noticing'."
"FreeBSD was one of the first widely deployed free operating systems to
provide mandatory access control. It supports a number of classic MAC models.
This tutorial paper addresses exploiting this implementation to enforce typical
enterprise security policies of varying complexities."
"We present six multiparty protocols with information-theoretic security that
tolerate an arbitrary number of corrupt participants. All protocols assume
pairwise authentic private channels and a broadcast channel (in a single case,
we require a simultaneous broadcast channel). We give protocols for veto, vote,
anonymous bit transmission, collision detection, notification and anonymous
message transmission. Not assuming an honest majority, in most cases, a single
corrupt participant can make the protocol abort. All protocols achieve
functionality never obtained before without the use of either computational
assumptions or of an honest majority."
"This paper introduces a variation on Kak's three-stage quanutm key
distribution protocol which allows for defence against the man in the middle
attack. In addition, we introduce a new protocol, which also offers similar
resiliance against such an attack."
"We give a new two-pass authentication scheme, whichis a generalisation of an
authentication scheme of Sibert-Dehornoy-Girault based on the Diffie-Hellman
conjugacy problem. Compared to the above scheme, for some parameters it is more
efficient with respect to multiplications. We sketch a proof that our
authentication scheme is secure. We give a new key agreement protocols."
"Recently the AAGL (Anshel-Anshel-Goldfeld-Lemieux) has been proposed which
can be used for RFID tags. We give algorithms for the problem (we call the
MSCSPv) on which the security of the AAGL protocol is based upon. Hence we give
various attacks for general parameters on the recent AAGL protocol proposed.
One of our attacks is a deterministic algorithm which has space complexity and
time complexity both atleast exponentialin the worst case. In a better case
using a probabilistic algorithm the time complexity canbe
O(|XSS(ui')^L5*(n^(1+e)) and the space complexity can be O(|XSS(ui')|^L6),
where the element ui' is part of a public key, n is the index of braid group,
XSS is a summit type set and e is a constant in a limit. The above shows the
AAGL protocol is potentially not significantly more secure as using key
agreement protocols based on the conjugacy problem such as the AAG
(Anshel-Anshel-Goldfeld) protocol because both protocols can be broken with
complexity which do not significantly differ. We think our attacks can be
improved."
"We show that a number of cryptographic protocols using non-commutative
semigroups including the Cha-Ko-Lee-Han-Cheon braid group public-key
cryptosystem and related public-key cryptosystems such as the Shpilrain-Ushakov
public-key cryptosystems are based on the MSCSP."
"The most exciting recent development in nonlinear dynamics is realization
that chaos can be useful. One application involves ""Secure Communication"". Two
piecewise linear systems with switching nonlinearities have been taken as chaos
generators. In the present work the phenomenon of secure communication with
chaos masking has been investigated experimentally. In this investigation chaos
which is generated from two chaos generators is masked with the massage signal
to be transmitted, thus makes communication is more secure."
"In this work we present a new structure for multiplication in finite fields.
This structure is based on a digit-level LFSR (Linear Feedback Shift Register)
multiplier in which the area of digit-multipliers are reduced using the
Karatsuba method. We compare our results with the other works in the literature
for F_{3^97}. We also propose new formulas for multiplication in F_{3^{6*97}}.
These new formulas reduce the number of F_{3^97}-multiplications from 18 to 15.
The fields F_{3^{97}} and F_{3^{6*97}} are relevant in the context of
pairing-based cryptography."
"In this paper, we present a generic attack for ciphers, which is in essence a
collision attack on the secret keys of ciphers ."
"This paper examines the randomness of d-sequences, which are decimal
sequences to an arbitrary base. Our motivation is to check their suitability
for application to cryptography, spread-spectrum systems and use as
pseudorandom sequence."
"Side channel attacks are a major security concern for smart cards and other
embedded devices. They analyze the variations on the power consumption to find
the secret key of the encryption algorithm implemented within the security IC.
To address this issue, logic gates that have a constant power dissipation
independent of the input signals, are used in security ICs. This paper presents
a design methodology to create fully connected differential pull down networks.
Fully connected differential pull down networks are transistor networks that
for any complementary input combination connect all the internal nodes of the
network to one of the external nodes of the network. They are memoryless and
for that reason have a constant load capacitance and power consumption. This
type of networks is used in specialized logic gates to guarantee a constant
contribution of the internal nodes into the total power consumption of the
logic gate."
"The hybrid hiding encryption algorithm, as its name implies, embraces
concepts from both steganography and cryptography. In this exertion, an
improved micro-architecture Field Programmable Gate Array (FPGA) implementation
of this algorithm is presented. This design overcomes the observed limitations
of a previously-designed micro-architecture. These observed limitations are: no
exploitation of the possibility of parallel bit replacement, and the fact that
the input plaintext was encrypted serially, which caused a dependency between
the throughput and the nature of the used secret key. This dependency can be
viewed by some as vulnerability in the security of the implemented
micro-architecture. The proposed modified micro-architecture is constructed
using five basic modules. These modules are; the message cache, the message
alignment module, the key cache, the comparator, and at last the encryption
module. In this work, we provide comprehensive simulation and implementation
results. These are: the timing diagrams, the post-implementation timing and
routing reports, and finally the floor plan. Moreover, a detailed comparison
with other FPGA implementations is made available and discussed."
"The widening spectrum of applications and services provided by portable and
embedded devices bring a new dimension of concerns in security. Most of those
embedded systems (pay-TV, PDAs, mobile phones, etc...) make use of external
memory. As a result, the main problem is that data and instructions are
constantly exchanged between memory (RAM) and CPU in clear form on the bus.
This memory may contain confidential data like commercial software or private
contents, which either the end-user or the content provider is willing to
protect. The goal of this paper is to clearly describe the problem of
processor-memory bus communications in this regard and the existing techniques
applied to secure the communication channel through encryption - Performance
overheads implied by those solutions will be extensively discussed in this
paper."
"Securing communication channels is especially needed in wireless
environments. But applying cipher mechanisms in software is limited by the
calculation and energy resources of the mobile devices. If hardware is applied
to realize cryptographic operations cost becomes an issue. In this paper we
describe an approach which tackles all these three points. We implemented a
hardware accelerator for polynomial multiplication in extended Galois fields
(GF) applying Karatsuba's method iteratively. With this approach the area
consumption is reduced to 2.1 mm^2 in comparison to. 6.2 mm^2 for the standard
application of Karatsuba's method i.e. for recursive application. Our approach
also reduces the energy consumption to 60 per cent of the original approach.
The price we have to pay for these achievement is the increased execution time.
In our implementation a polynomial multiplication takes 3 clock cycles whereas
the recurisve Karatsuba approach needs only one clock cycle. But considering
area, energy and calculation speed we are convinced that the benefits of our
approach outweigh its drawback."
"As digital content services gain importance in the mobile world, Digital
Rights Management (DRM) applications will become a key component of mobile
terminals. This paper examines the effect dedicated hardware macros for
specific cryptographic functions have on the performance of a mobile terminal
that supports version 2 of the open standard for Digital Rights Management
defined by the Open Mobile Alliance (OMA). Following a general description of
the standard, the paper contains a detailed analysis of the cryptographic
operations that have to be carried out before protected content can be
accessed. The combination of this analysis with data on execution times for
specific algorithms realized in hardware and software has made it possible to
build a model which has allowed us to assert that hardware acceleration for
specific cryptographic algorithms can significantly reduce the impact DRM has
on a mobile terminal's processing performance and battery life."
"In this paper, we investigate the best pixel expansion of the various models
of visual cryptography schemes. In this regard, we consider visual cryptography
schemes introduced by Tzeng and Hu [13]. In such a model, only minimal
qualified sets can recover the secret image and that the recovered secret image
can be darker or lighter than the background. Blundo et al. [4] introduced a
lower bound for the best pixel expansion of this scheme in terms of minimal
qualified sets. We present another lower bound for the best pixel expansion of
the scheme. As a corollary, we introduce a lower bound, based on an induced
matching of hypergraph of qualified sets, for the best pixel expansion of the
aforementioned model and the traditional model of visual cryptography realized
by basis matrices. Finally, we study access structures based on graphs and we
present an upper bound for the smallest pixel expansion in terms of strong
chromatic index."
"In the private matching problem, a client and a server each hold a set of $n$
input elements. The client wants to privately compute the intersection of these
two sets: he learns which elements he has in common with the server (and
nothing more), while the server gains no information at all. In certain
applications it would be useful to have a private matching protocol that
reports a match even if two elements are only similar instead of equal. Such a
private matching protocol is called \emph{fuzzy}, and is useful, for instance,
when elements may be inaccurate or corrupted by errors.
  We consider the fuzzy private matching problem, in a semi-honest environment.
Elements are similar if they match on $t$ out of $T$ attributes. First we show
that the original solution proposed by Freedman et al. is incorrect.
Subsequently we present two fuzzy private matching protocols. The first,
simple, protocol has bit message complexity $O(n \binom{T}{t} (T
\log{|D|}+k))$. The second, improved, protocol has a much better bit message
complexity of $O(n T (\log{|D|}+k))$, but here the client incurs a O(n) factor
time complexity. Additionally, we present protocols based on the computation of
the Hamming distance and on oblivious transfer, that have different, sometimes
more efficient, performance characteristics."
"Key substitution vulnerable signature schemes are signature schemes that
permit an intruder, given a public verification key and a signed message, to
compute a pair of signature and verification keys such that the message appears
to be signed with the new signature key. A digital signature scheme is said to
be vulnerable to destructive exclusive ownership property (DEO) If it is
computationaly feasible for an intruder, given a public verification key and a
pair of message and its valid signature relatively to the given public key, to
compute a pair of signature and verification keys and a new message such that
the given signature appears to be valid for the new message relatively to the
new verification key. In this paper, we prove decidability of the insecurity
problem of cryptographic protocols where the signature schemes employed in the
concrete realisation have this two properties."
"Yoon et al. proposed a new efficient remote user authentication scheme using
smart cards to solve the security problems of W. C. Ku and S. M. Chen scheme.
This paper reviews Yoon et al. scheme and then proves that the password change
phase of Yoon et al. scheme is still insecure. This paper also proves that the
Yoon et al. is still vulnerable to parallel session attack."
"Trojan horses', 'logic bombs', 'armoured viruses' and 'cryptovirology' are
terms recalling war gears. In fact, concepts of attack and defence drive the
world of computer virology, which looks like a war universe in an information
society. This war has several shapes, from invasions of a network by worms, to
military and industrial espionage ..."
"This note considers reciprocal of primes in binary representation and shows
that the conjecture that 0s exceed 1s in most cases continues to hold for
primes less one million. The conjecture has also been tested for ternary
representation with similar results. Some applications of this result to
cryptography are discussed."
"This paper presents how to make use of the advantage of round-off error
effect in some research areas. The float-point operation complies with the
reproduce theorem without the external random perturbation. The computation
uncertainty principle and the high nonlinear of chaotic system guarantee the
numerical error is random and departure from the analytical result. Combining
these two properties we can produce unilateral one-way function and provide a
case of utilizing this function to construct encryption algorithm. The
multiple-precision (MP) library is used to analyze nonlinear dynamics systems
and achieve the code. As an example, we provide a scheme of encrypting a
plaintext by employing the one-way function with Lorenz system. Since the
numerical solution used in this scheme is beyond the maximum effective
computation time (MECT) and it cannot satisfy the requirements of return-map
analysis and phase space reconstruction, it can block some existing attacks."
"The paper presents an authentication scheme for remote systems using smart
card. The scheme prevents the scenario of many logged in users with the same
login identity, and does not require password/verifier table to validate the
users' login request. The scheme provides a user-friendly password change
option, and withstands the replay, impersonation, stolen-verifier, guessing,
and denial-of-service attacks."
"In this paper, we will present a new key exchange cryptosystem based on
linear algebra, which take less operations but weaker in security than
Diffie-Hellman's one."
"A problem based on the Extended Euclidean Algorithm applied to a class of
polynomials with many factors is presented and believed to be hard. If so, it
is a one-way function well suited for applications in digital signicatures."
"Prime reciprocals have applications in coding and cryptography and for
generation of random sequences. This paper investigates the structural
redundancy of prime reciprocals in base 10 in a manner that parallels an
earlier study for binary prime reciprocals. Several different kinds of
structural relationships amongst the digits in reciprocal sequences are
classified with respect to the digit in the least significant place of the
prime. It is also shown that the frequency of digit 0 exceeds that of every
other digit when the entire set of prime reciprocal sequences is considered."
"Conventional Non-Linear Feedback Shift Registers (NLFSRs) use the Fibonacci
configuration in which the value of the first bit is updated according to some
non-linear feedback function of previous values of other bits, and each
remaining bit repeats the value of its previous bit. We show how to transform
the feedback function of a Fibonacci NLFSR into several smaller feedback
functions of individual bits. Such a transformation reduces the propagation
time, thus increasing the speed of pseudo-random sequence generation. The
practical significance of the presented technique is that is makes possible
increasing the keystream generation speed of any Fibonacci NLFSR-based stream
cipher with no penalty in area."
"Codes have been used for centuries to convey secret information.To a
cryptanalyst, the interception of a code is only the first step in recovering a
secret message.Deoxyribonucleic acid (DNA) is a biological and molecular
code.Through the work of Marshall Nirenberg and others, DNA is now understood
to specify for amino acids in triplet codes of bases.The possibilty of DNA
encoding secret information in a natural language is explored, since a code is
expected to have a distinct mathematical solution."
"Since the introduction at Crypto'05 by Juels and Weis of the protocol HB+, a
lightweight protocol secure against active attacks but only in a detection
based-model, many works have tried to enhance its security. We propose here a
new approach to achieve resistance against Man-in-The-Middle attacks. Our
requirements - in terms of extra communications and hardware - are surprisingly
low."
"We study the problem of preventing double spending in electronic payment
schemes in a distributed fashion. This problem occurs, for instance, when the
spending of electronic coins needs to be controlled by a large collection of
nodes (eg. in a peer-to-peer (P2P) system) instead of one central bank.
Contrary to the commonly held belief that this is fundamentally impossible, we
propose several solutions that do achieve a reasonable level of double spending
prevention, and analyse their efficiency under varying assumptions."
"In wireless ad-hoc broadcast networks the pairing problem consists of
establishing a (long-term) connection between two specific physical nodes in
the network that do not yet know each other. We focus on the ephemeral version
of this problem. Ephemeral pairings occur, for example, when electronic
business cards are exchanged between two people that meet, or when one pays at
a check-out using a wireless wallet.
  This problem can, in more abstract terms, be phrased as an ephemeral key
exchange problem: given a low bandwidth authentic (or private) communication
channel between two nodes, and a high bandwidth broadcast channel, can we
establish a high-entropy shared secret session key between the two nodes
without relying on any a priori shared secret information.
  Apart from introducing this new problem, we present several ephemeral key
exchange protocols, both for the case of authentic channels as well as for the
case of private channels."
"The concept of universal designated verifier signatures was introduced by
Steinfeld, Bull, Wang and Pieprzyk at Asiacrypt 2003. These signatures can be
used as standard publicly verifiable digital signatures but have an additional
functionality which allows any holder of a signature to designate the signature
to any desired verifier. This designated verifier can check that the message
was indeed signed, but is unable to convince anyone else of this fact. We
propose new efficient constructions for pairing-based short signatures. Our
first scheme is based on Boneh-Boyen signatures and its security can be
analyzed in the standard security model. We prove its resistance to forgery
assuming the hardness of the so-called strong Diffie-Hellman problem, under the
knowledge-of-exponent assumption. The second scheme is compatible with the
Boneh-Lynn-Shacham signatures and is proven unforgeable, in the random oracle
model, under the assumption that the computational bilinear Diffie-Hellman
problem is untractable. Both schemes are designed for devices with constrained
computation capabilities since the signing and the designation procedure are
pairing-free. Finally, we present extensions of these schemes in the multi-user
setting proposed by Desmedt in 2003."
"In 1998, Blaze, Bleumer, and Strauss suggested a cryptographic primitive
named proxy re-signatures where a proxy turns a signature computed under
Alice's secret key into one from Bob on the same message. The semi-trusted
proxy does not learn either party's signing key and cannot sign arbitrary
messages on behalf of Alice or Bob. At CCS 2005, Ateniese and Hohenberger
revisited the primitive by providing appropriate security definitions and
efficient constructions in the random oracle model. Nonetheless, they left open
the problem of designing a multi-use unidirectional scheme where the proxy is
able to translate in only one direction and signatures can be re-translated
several times.
  This paper solves this problem, suggested for the first time 10 years ago,
and shows the first multi-hop unidirectional proxy re-signature schemes. We
describe a random-oracle-using system that is secure in the
Ateniese-Hohenberger model. The same technique also yields a similar
construction in the standard model (i.e. without relying on random oracles).
Both schemes are efficient and require newly defined -- but falsifiable --
Diffie-Hellman-like assumptions in bilinear groups."
"We propose a general way of constructing zero-knowledge authentication
schemes from actions of a semigroup on a set, without exploiting any specific
algebraic properties of the set acted upon. Then we give several concrete
realizations of this general idea, and in particular, we describe several
zero-knowledge authentication schemes where forgery (a.k.a. impersonation) is
NP-hard. Computationally hard problems that can be employed in these
realizations include (Sub)graph Isomorphism, Graph Colorability, Diophantine
Problem, and many others."
"Recently, Liaw et al. proposed a remote user authentication scheme using
smart cards. Their scheme has claimed a number of features e.g. mutual
authentication, no clock synchronization, no verifier table, flexible user
password change, etc. We show that Liaw et al.'s scheme is completely insecure.
By intercepting a valid login message in Liaw et al.'s scheme, any unregistered
user or adversary can easily login to the remote system and establish a session
key."
"Several of the basic cryptographic constructs have associated algebraic
structures. Formal models proposed by Dolev and Yao to study the
(unconditional) security of public key protocols form a group. The security of
some types of protocols can be neatly formulated in this algebraic setting. We
investigate classes of two-party protocols. We then consider extension of the
formal algebraic framework to private-key protocols. We also discuss concrete
realization of the formal models. In this case, we propose a definition in
terms of pseudo-free groups."
"This note investigates the size of the guard band for non-periodic discrete
Hilbert transform, which has recently been proposed for data hiding and
security applications. It is shown that a guard band equal to the duration of
the message is sufficient for a variety of analog signals and is, therefore,
likely to be adequate for discrete or digital data."
"Deep packet inspection is widely recognized as a powerful way which is used
for intrusion detection systems for inspecting, deterring and deflecting
malicious attacks over the network. Fundamentally, almost intrusion detection
systems have the ability to search through packets and identify contents that
match with known attacks. In this paper, we survey the deep packet inspection
implementations techniques, research challenges and algorithms. Finally, we
provide a comparison between the different applied systems."
"The security of wireless sensor networks is an active topic of research where
both symmetric and asymmetric key cryptography issues have been studied. Due to
their computational feasibility on typical sensor nodes, symmetric key
algorithms that use the same key to encrypt and decrypt messages have been
intensively studied and perfectly deployed in such environment. Because of the
wireless sensor's limited infrastructure, the bottleneck challenge for
deploying these algorithms is the key distribution. For the same reason of
resources restriction, key distribution mechanisms which are used in
traditional wireless networks are not efficient for sensor networks.
  To overcome the key distribution problem, several key pre-distribution
algorithms and techniques that assign keys or keying material for the networks
nodes in an offline phase have been introduced recently. In this paper, we
introduce a supplemental distribution technique based on the communication
pattern and deployment knowledge modeling. Our technique is based on the
hierarchical grid deployment. For granting a proportional security level with
number of dependent sensors, we use different polynomials in different orders
with different weights. In seek of our proposed work's value, we provide a
detailed analysis on the used resources, resulting security, resiliency, and
connectivity compared with other related works."
"In this note, we provide the first 22-step collisions for SHA-256 and
SHA-512. Detailed technique of generating these collisions will be provided in
the next revision of this note."
"In discrete logarithm based cryptography, a method by Pohlig and Hellman
allows solving the discrete logarithm problem efficiently if the group order is
known and has no large prime factors. The consequence is that such groups are
avoided. In the past, there have been proposals for cryptography based on
cyclic infrastructures. We will show that the Pohlig-Hellman method can be
adapted to certain cyclic infrastructures, which similarly implies that certain
infrastructures should not be used for cryptography. This generalizes a result
by M\""uller, Vanstone and Zuccherato for infrastructures obtained from
hyperelliptic function fields.
  We recall the Pohlig-Hellman method, define the concept of a cyclic
infrastructure and briefly describe how to obtain such infrastructures from
certain function fields of unit rank one. Then, we describe how to obtain
cyclic groups from discrete cyclic infrastructures and how to apply the
Pohlig-Hellman method to compute absolute distances, which is in general a
computationally hard problem for cyclic infrastructures. Moreover, we give an
algorithm which allows to test whether an infrastructure satisfies certain
requirements needed for applying the Pohlig-Hellman method, and discuss whether
the Pohlig-Hellman method is applicable in infrastructures obtained from number
fields. Finally, we discuss how this influences cryptography based on cyclic
infrastructures."
"The MIFARE Classic is the most widely used contactless smart card in the
market. Its design and implementation details are kept secret by its
manufacturer. This paper studies the architecture of the card and the
communication protocol between card and reader. Then it gives a practical,
low-cost, attack that recovers secret information from the memory of the card.
Due to a weakness in the pseudo-random generator, we are able to recover the
keystream generated by the CRYPTO1 stream cipher. We exploit the malleability
of the stream cipher to read all memory blocks of the first sector of the card.
Moreover, we are able to read any sector of the memory of the card, provided
that we know one memory block within this sector. Finally, and perhaps more
damaging, the same holds for modifying memory blocks."
"We consider the problem of building robust fuzzy extractors, which allow two
parties holding similar random variables W, W' to agree on a secret key R in
the presence of an active adversary. Robust fuzzy extractors were defined by
Dodis et al. in Crypto 2006 to be noninteractive, i.e., only one message P,
which can be modified by an unbounded adversary, can pass from one party to the
other. This allows them to be used by a single party at different points in
time (e.g., for key recovery or biometric authentication), but also presents an
additional challenge: what if R is used, and thus possibly observed by the
adversary, before the adversary has a chance to modify P. Fuzzy extractors
secure against such a strong attack are called post-application robust.
  We construct a fuzzy extractor with post-application robustness that extracts
a shared secret key of up to (2m-n)/2 bits (depending on error-tolerance and
security parameters), where n is the bit-length and m is the entropy of W. The
previously best known result, also of Dodis et al., extracted up to (2m-n)/3
bits (depending on the same parameters)."
"At Crypto'07, Goyal introduced the concept of Accountable Authority
Identity-Based Encryption as a convenient tool to reduce the amount of trust in
authorities in Identity-Based Encryption. In this model, if the Private Key
Generator (PKG) maliciously re-distributes users' decryption keys, it runs the
risk of being caught and prosecuted. Goyal proposed two constructions: the
first one is efficient but can only trace well-formed decryption keys to their
source; the second one allows tracing obfuscated decryption boxes in a model
(called weak black-box model) where cheating authorities have no decryption
oracle. The latter scheme is unfortunately far less efficient in terms of
decryption cost and ciphertext size. In this work, we propose a new
construction that combines the efficiency of Goyal's first proposal with a very
simple weak black-box tracing mechanism. Our scheme is described in the
selective-ID model but readily extends to meet all security properties in the
adaptive-ID sense, which is not known to be true for prior black-box schemes."
"This paper considers interactions between cellular automata and cryptology.
It is known that non-linear elementary rule which is correlation-immune don't
exist. This results limits the use of cellular automata as pseudo-random
generators suitable for cryptographic applications. In addition, for this kind
of pseudo-random generators, a successful cryptanalysis was proposed by Meier
and Staffelbach. However, other ways to design cellular automata capable to
generate good pseudo-random sequences remain and will be discussed in the end
of this article."
"We consider the enciphering of a data stream while being compressed by a LZ
algorithm. This has to be compared to the classical encryption after
compression methods used in security protocols. Actually, most cryptanalysis
techniques exploit patterns found in the plaintext to crack the cipher;
compression techniques reduce these attacks. Our scheme is based on a LZ
compression in which a Vernam cipher has been added. We make some security
remarks by trying to measure its randomness with statistical tests. Such a
scheme could be employed to increase the speed of security protocols and to
decrease the computing power for mobile devices."
"we will present an estimation for the upper-bound of the amount of 16-bytes
plaintexts for English texts, which indicates that the block ciphers with block
length no more than 16-bytes will be subject to recover plaintext attacks in
the occasions of plaintext -known or plaintext-chosen attacks."
"Array restructuring operations obscure arrays. Our work aims on java source
code obfuscation containing arrays. Our main proposal is Classes with
restructured array members and obscured member methods for setting, getting
array elements and to get the length of arrays. The class method definition
codes are obscured through index transformation and constant hiding. The
instantiated objects of these classes are used for source code writing. A tool
named JDATATRANS is developed for generating classes and to the best of our
knowledge this is the first tool available for array restructuring, on java
source codes."
"Recently, Indesteege et al. [1] had described attacks against 23 and 24-step
SHA-512 at SAC '08. Their attacks are based on the differential path by Nikolic
and Biryukov [2]. The reported complexities are $2^{44.9}$ and $2^{53}$ calls
to the respective step reduced SHA-512 hash function. They provided colliding
message pairs for 23-step SHA-512 but did not provide a colliding message pair
for 24-step SHA-512. In this note we provide a colliding message pair for
23-step SHA-512 and the first colliding message pair for 24-step SHA-512. Our
attacks use the differential path first described by Sanadhya and Sarkar at
ACISP '08 [3]. The complexities of our attacks are $2^{16.5}$ and $2^{34.5}$
calls to the respective step reduced SHA-512 hash function. Complete details of
the attacks will be provided in an extended version of this note."
"This paper presents a twist to the generation of binary random sequences by
starting with decimal sequences. Rather than representing the prime reciprocal
sequence directly in base 2, we first right the prime reciprocal in base 10 and
then convert it into the binary form. The autocorrelation and cross-correlation
properties of these binary random (BRD) sequences are discussed."
"This paper attempt has been made to explain a fuzzy commitment scheme. In the
conventional Commitment schemes, both committed string m and valid opening key
are required to enable the sender to prove the commitment. However there could
be many instances where the transmission involves noise or minor errors arising
purely because of the factors over which neither the sender nor the receiver
have any control. The fuzzy commitment scheme presented in this paper is to
accept the opening key that is close to the original one in suitable distance
metric, but not necessarily identical. The concept itself is illustrated with
the help of simple situation."
"We have designed a tiered security system for mobile devices where each
security tier holds user-defined security triggers and actions. It has a
friendly interface that allows users to easily define and configure the
different circumstances and actions they need according to context. The system
can be set up and activated from any browser or directly on the mobile device
itself. When the security system is operated from a Web site or server, its
configuration can be readily shared across multiple devices. When operated
directly from the mobile device, no server is needed for activation. Many
different types of security circumstances and actions can be set up and
employed from its tiers. Security circumstances can range from temporary
misplacement of a mobile device at home to malicious theft in a hostile region.
Security actions can range from ringing a simple alarm to automatically
erasing, overwriting, and re-erasing drives."
"Covert channel techniques are used by attackers to transfer data in a way
prohibited by the security policy. There are two main categories of covert
channels: timing channels and storage channels. This paper introduces a new
storage channel technique called a protocol channel. A protocol channel
switches one of at least two protocols to send a bit combination to a
destination. The main goal of a protocol channel is that packets containing
covert information look equal to all other packets within a network, what makes
a protocol channel hard to detect."
"Software obfuscation or obscuring a software is an approach to defeat the
practice of reverse engineering a software for using its functionality
illegally in the development of another software. Java applications are more
amenable to reverse engineering and re-engineering attacks through methods such
as decompilation because Java class files store the program in a semi complied
form called 'byte' codes. The existing obfuscation systems obfuscate the Java
class files. Obfuscated source code produce obfuscated byte codes and hence two
level obfuscation (source code and byte code level) of the program makes it
more resilient to reverse engineering attacks. But source code obfuscation is
much more difficult due to richer set of programming constructs and the scope
of the different variables used in the program and only very little progress
has been made on this front. Hence programmers resort to adhoc manual ways of
obscuring their program which makes it difficult for its maintenance and
usability. To address this issue partially, we developed a user friendly tool
JDATATRANS to obfuscate Java source code by obscuring the array usages. Using
various array restructuring techniques such as 'array splitting', 'array
folding' and 'array flattening', in addition to constant hiding, our system
obfuscate the input Java source code and produce an obfuscated Java source code
that is functionally equivalent to the input program. We also perform a number
of experiments to measure the potency, resilience and cost incurred by our
tool."
"Ensuring compliance of organizations to federal regulations is a growing
concern. This paper presents a framework and methods to verify whether an
implemented low-level security policy is compliant to a high-level security
policy. Our compliance checking framework is based on organizational and
security metadata to support refinement of high-level concepts to
implementation specific instances. Our work uses the results of refinement
calculus to express valid refinement patterns and their properties.
Intuitively, a low-level security policy is compliant to a high-level security
policy if there is a valid refinement path from the high-level security policy
to the low-level security policy. Our model is capable of detecting violations
of security policies, failures to meet obligations, and capability and modal
conflicts."
"Sosemanuk is a new synchronous software-oriented stream cipher, corresponding
to Profile 1 of the ECRYPT call for stream cipher primitives. Its key length is
variable between 128 and 256 bits. It ac- commodates a 128-bit initial value.
Any key length is claimed to achieve 128-bit security. The Sosemanuk cipher
uses both some basic design principles from the stream cipher SNOW 2.0 and some
transformations derived from the block cipher SERPENT. Sosemanuk aims at
improv- ing SNOW 2.0 both from the security and from the efficiency points of
view. Most notably, it uses a faster IV-setup procedure. It also requires a
reduced amount of static data, yielding better performance on several
architectures."
"Vajda and Buttyan (VB) proposed a set of five lightweight RFID authentication
protocols. Defend, Fu, and Juels (DFJ) did cryptanalysis on two of them - XOR
and SUBSET. To the XOR protocol, DFJ proposed repeated keys attack and nibble
attack. In this paper, we identify the vulnerability existed in the original
VB's successive session key permutation algorithm. We propose three
enhancements to prevent DFJ's attacks and make XOR protocol stronger without
introducing extra resource cost."
"This paper presents a new procedure of generating hash functions which can be
evaluated using some mathematical tools. This procedure is based on discrete
chaotic iterations.
  First, it is mathematically proven, that these discrete chaotic iterations
can be considered as a \linebreak particular case of topological chaos. Then,
the process of generating hash function based on the \linebreak topological
chaos is detailed. Finally it is shown how some tools coming from the domain of
\linebreak topological chaos can be used to measure quantitatively and
qualitatively some desirable properties for hash functions. An illustration
example is detailed in order to show how one can create hash functions using
our theoretical study.
  Key-words : Discrete chaotic iterations. Topological chaos. Hash function"
"A new watermarking algorithm is given, it is based on the so-called chaotic
iterations and on the choice of some coefficients which are deduced from the
description of the carrier medium. After defining these coefficients, chaotic
discrete iterations are used to encrypt the watermark and to embed it in the
carrier medium. This procedure generates a topological chaos and ensures that
the required properties of a watermarking algorithm are satisfied.
  Key-words: Watermarking, Encryption, Chaotic iterations, Topological chaos,
Information hiding"
"This paper offers several contributions for separation of duty (SoD)
administration in role-based access control (RBAC) systems. We first introduce
a new formal framework, based on business perspective, where SoD constraints
are analyzed introducing the activity concept. This notion helps organizations
define SoD constraints in terms of business requirements and reduces management
complexity in large-scale RBAC systems. The model enables the definition of a
wide taxonomy of conflict types. In particular, object-based SoD is introduced
using the SoD domain concept, namely the set of data in which transaction
conflicts may occur. Together with the formalization of the above properties,
in this paper we also show the effectiveness of our proposal: we have applied
the model to a large, existing organization; results highlight the benefits of
adopting the proposed model in terms of reduced administration cost."
"Wiener's attack is a well-known polynomial-time attack on a RSA cryptosystem
with small secret decryption exponent d, which works if d<n^{0.25}, where n=pq
is the modulus of the cryptosystem. Namely, in that case, d is the denominator
of some convergent p_m/q_m of the continued fraction expansion of e/n, and
therefore d can be computed efficiently from the public key (n,e).
  There are several extensions of Wiener's attack that allow the RSA
cryptosystem to be broken when d is a few bits longer than n^{0.25}. They all
have the run-time complexity (at least) O(D^2), where d=Dn^{0.25}. Here we
propose a new variant of Wiener's attack, which uses results on Diophantine
approximations of the form |\alpha - p/q| < c/q^2, and ""meet-in-the-middle""
variant for testing the candidates (of the form rq_{m+1} + sq_m) for the secret
exponent. This decreases the run-time complexity of the attack to O(D log(D))
(with the space complexity O(D))."
"Chaotic cryptography is based on the properties of chaos as source of
entropy. Many different schemes have been proposed to take advantage of those
properties and to design new strategies to encrypt information. However, the
right and efficient use of chaos in the context of cryptography requires a
thorough knowledge about the dynamics of the selected chaotic system. Indeed,
if the final encryption system reveals enough information about the underlying
chaotic system it could be possible for a cryptanalyst to get the key, part of
the key or some information somehow equivalent to the key just analyzing those
dynamical properties leaked by the cryptosystem. This paper shows what those
dynamical properties are and how a cryptanalyst can use them to prove the
inadequacy of an encryption system for the secure exchange of information. This
study is performed through the introduction of a series of mathematical tools
which should be the basic framework of cryptanalysis in the context of digital
chaos-based cryptography."
"In this work we present the first passive attack over the SASI lightweight
authentication protocol with modular rotations. This can be used to fully
recover the secret $ID$ of the RFID tag, which is the value the protocol is
designed to conceal. The attack is described initially for recovering $\lfloor
log_2(96) \rfloor=6$ bits of the secret value $ID$, a result that by itself
allows to mount traceability attacks on any given tag. However, the proposed
scheme can be extended to obtain any amount of bits of the secret $ID$,
provided a sufficiently large number of successful consecutive sessions are
eavesdropped. We also present results on the attack's efficiency, and some
ideas to secure this version of the SASI protocol."
"After attacking the RSA by injecting fault and corresponding countermeasures,
works appear now about the need for protecting RSA public elements against
fault attacks. We provide here an extension of a recent attack based on the
public modulus corruption. The difficulty to decompose the ""Left-To-Right""
exponentiation into partial multiplications is overcome by modifying the public
modulus to a number with known factorization. This fault model is justified
here by a complete study of faulty prime numbers with a fixed size. The good
success rate of this attack combined with its practicability raises the
question of using faults for changing algebraic properties of finite field
based cryptosystems."
"Biometrics make human identification possible with a sample of a biometric
trait and an associated database. Classical identification techniques lead to
privacy concerns. This paper introduces a new method to identify someone using
his biometrics in an encrypted way. Our construction combines Bloom Filters
with Storage and Locality-Sensitive Hashing. We apply this error-tolerant
scheme, in a Hamming space, to achieve biometric identification in an efficient
way. This is the first non-trivial identification scheme dealing with fuzziness
and encrypted data."
"This work introduces FAIR, a novel framework for Fuzzy-based Aggregation
providing In-network Resilience for Wireless Sensor Networks. FAIR addresses
the possibility of malicious aggregator nodes manipulating data. It provides
data-integrity based on a trust level of the WSN response and it tolerates link
or node failures. Compared to available solutions, it offers a general
aggregation model and makes the trust level visible to the querier. We classify
the proposed approach as complementary to protocols ensuring resilience against
sensor leaf nodes providing faulty data. Thanks to our flexible resilient
framework and due to the use of Fuzzy Inference Schemes, we achieve promising
results within a short design cycle."
"Harvard architecture CPU design is common in the embedded world. Examples of
Harvard-based architecture devices are the Mica family of wireless sensors.
Mica motes have limited memory and can process only very small packets.
Stack-based buffer overflow techniques that inject code into the stack and then
execute it are therefore not applicable. It has been a common belief that code
injection is impossible on Harvard architectures. This paper presents a remote
code injection attack for Mica sensors. We show how to exploit program
vulnerabilities to permanently inject any piece of code into the program memory
of an Atmel AVR-based sensor. To our knowledge, this is the first result that
presents a code injection technique for such devices. Previous work only
succeeded in injecting data or performing transient attacks. Injecting
permanent code is more powerful since the attacker can gain full control of the
target sensor. We also show that this attack can be used to inject a worm that
can propagate through the wireless sensor network and possibly create a sensor
botnet. Our attack combines different techniques such as return oriented
programming and fake stack injection. We present implementation details and
suggest some counter-measures."
Ethemba provides a framework and demonstrator for TPM applications.
"Quantum key distribution (QKD) has been developed within the last decade that
is provably secure against arbitrary computing power, and even against quantum
computer attacks. Now there is a strong need of research to exploit this
technology in the existing communication networks. In this paper we have
presented various experimental results pertaining to QKD like Raw key rate and
Quantum bit error rate (QBER). We found these results over 25 km single mode
optical fiber. The experimental setup implemented the enhanced version of BB84
QKD protocol. Based upon the results obtained, we have presented a network
design which can be implemented for the realization of large scale QKD
networks. Furthermore, several new ideas are presented and discussed to
integrate the QKD technique in the classical communication networks."
"This note proposes a method of space efficient secret sharing in which k
secrets are mapped into n shares (n>=k) of the same size. Since, n can be
chosen to be equal to k, the method is space efficient. This method may be
compared with conventional secret sharing schemes that divide a single secret
into n shares."
"This paper presents a recursive secret sharing technique that distributes k-1
secrets of length b each into n shares such that each share is effectively of
length (n/(k-1))*b and any k pieces suffice for reconstructing all the k-1
secrets. Since n/(k-1) is near the optimal factor of n/k, and can be chosen to
be close to 1, the proposed technique is space efficient. Furthermore, each
share is information theoretically secure, i.e. it does not depend on any
unproven assumption of computational intractability. Such a recursive technique
has potential applications in secure and reliable storage of information on the
Web and in sensor networks."
"Most behavioral detectors of malware remain specific to a given language and
platform, mostly PE executables for Windows. The objective of this paper is to
define a generic approach for behavioral detection based on two layers
respectively responsible for abstraction and detection. The first abstraction
layer remains specific to a platform and a language. This first layer
interprets the collected instructions, API calls and arguments and classifies
these operations as well as the involved objects according to their purpose in
the malware lifecycle. The second detection layer remains generic and is
totally interoperable between the different abstraction components. This layer
relies on parallel automata parsing attribute-grammars where semantic rules are
used for object typing (object classification) and object binding (data-flow).
To feed detection and to experiment with our approach we have developed two
different abstraction components: one processing system call traces from native
code and one processing the VBScript interpreted language. The different
experimentations have provided promising detection rates, in particular for
script files (89%), with almost none false positives. In the case of process
traces, the detection rate remains significant (51%) but could be increased by
more sophisticated collection tools."
"Since the seminal work from F. Cohen in the eighties, abstract virology has
seen the apparition of successive viral models, all based on Turing-equivalent
formalisms. But considering recent malware such as rootkits or k-ary codes,
these viral models only partially cover these evolved threats. The problem is
that Turing-equivalent models do not support interactive computations. New
models have thus appeared, offering support for these evolved malware, but
loosing the unified approach in the way. This article provides a basis for a
unified malware model founded on process algebras and in particular the
Join-Calculus. In terms of expressiveness, the new model supports the
fundamental definitions based on self-replication and adds support for
interactions, concurrency and non-termination allows the definition of more
complex behaviors. Evolved malware such as rootkits can now be thoroughly
modeled. In terms of detection and prevention, the fundamental results of
undecidability and isolation still hold. However the process-based model has
permitted to establish new results: identification of fragments from the
Join-Calculus where malware detection becomes decidable, formal definition of
the non-infection property, approximate solutions to restrict malware
propagation."
"NTRU public key cryptosystem is well studied lattice-based Cryptosystem along
with Ajtai-Dwork and GGH systems. Underlying
  NTRU is a hard mathematical problem of finding short vectors in a certain
lattice. (Shamir 1997) presented a lattice-based attack by which he could find
the original secret key or alternate key. Shamir concluded if one designs a
variant of NTRU where the calculations involved during encryption and
decryption are non-commutative then the system will be secure against Lattice
based attack.This paper presents a new cryptosystem with above property and we
have proved that it is completely secure against Lattice based attack. It
operates in the non-commutative ring M=M_k Z[X]/(X^n - I_{k*k}, where M is a
matrix ring of k*k matrices of polynomials in R={Z}[X]/(X^n-1). Moreover We
have got speed improvement by a factor of O(k^{1.624) over NTRU for the same
bit of information."
"This paper presents a recursive hiding scheme for 2 out of 3 secret sharing.
In recursive hiding of secrets, the user encodes additional information about
smaller secrets in the shares of a larger secret without an expansion in the
size of the latter, thereby increasing the efficiency of secret sharing. We
present applications of our proposed protocol to images as well as text."
"Model checking is a widespread automatic formal analysis that has been
successful in discovering flaws in security protocols. However existing
possibilities for state space explosion still hinder analyses of complex
protocols and protocol configurations. Message Inspection, is a technique that
delimits the branching of the state space due to the intruder model without
excluding possible attacks. In a preliminary simulation, the intruder model
tags the eavesdropped messages with specific metadata that enable validation of
feasibility of possible attack actions. The Message Inspection algorithm then
decides based on these metadata, which attacks will certainly fail according to
known security principles. Thus, it is a priori known that i.e. an encryption
scheme attack cannot succeed if the intruder does not posses the right key in
his knowledge. The simulation terminates with a report of the attack actions
that can be safely removed, resulting in a model with a reduced state space."
"We consider representations of algebraic tori $T_n(F_q)$ over finite fields.
We make use of normal elliptic bases to show that, for infinitely many
squarefree integers $n$ and infinitely many values of $q$, we can encode $m$
torus elements, to a small fixed overhead and to $m$ $\phi(n)$-tuples of $F_q$
elements, in quasi-linear time in $\log q$.
  This improves upon previously known algorithms, which all have a
quasi-quadratic complexity. As a result, the cost of the encoding phase is now
negligible in Diffie-Hellman cryptographic schemes."
"Rijndael algorithm was unanimously chosen as the Advanced Encryption Standard
(AES) by the panel of researchers at National Institute of Standards and
Technology (NIST) in October 2000. Since then, Rijndael was destined to be used
massively in various software as well as hardware entities for encrypting data.
However, a few years back, Daniel Bernstein devised a cache timing attack that
was capable enough to break Rijndael seal that encapsulates the encryption key.
In this paper, we propose a new Dynamic Cache Flushing (DCF) algorithm which
shows a set of pragmatic software measures that would make Rijndael impregnable
to cache timing attack. The simulation results demonstrate that the proposed
DCF algorithm provides better security by encrypting key at a constant time."
"Wireless Sensor networks (WSN) is an emerging technology and have great
potential to be employed in critical situations like battlefields and
commercial applications such as building, traffic surveillance, habitat
monitoring and smart homes and many more scenarios. One of the major challenges
wireless sensor networks face today is security. While the deployment of sensor
nodes in an unattended environment makes the networks vulnerable to a variety
of potential attacks, the inherent power and memory limitations of sensor nodes
makes conventional security solutions unfeasible. The sensing technology
combined with processing power and wireless communication makes it profitable
for being exploited in great quantity in future. The wireless communication
technology also acquires various types of security threats. This paper
discusses a wide variety of attacks in WSN and their classification mechanisms
and different securities available to handle them including the challenges
faced."
"Secure access of communication networks has become an increasingly important
area of consideration for the communication service providers of present day.
Broadband Wireless Access (BWA) networks are proving to be an efficient and
cost effective solution for the provisioning of high rate wireless traffic
links in static and mobile domains. The secure access of these networks is
necessary to ensure their superior operation and revenue efficacy. Although
authentication process is a key to secure access in BWA networks, the breaches
present in them limit the networks performance. In this paper, the
vulnerabilities in the authentication frameworks of BWA networks have been
unveiled. Moreover, this paper also describes the limitations of these
protocols and of the solutions proposed to them due to the involved
computational complexities and overheads. The possible attacks on privacy and
performance of BWA networks have been discussed and explained in detail."
"When a person joins in an organization, he becomes authorize to take some
decisions on behalf of that organization; means he is given some authority to
exercise. After some time, on the basis of his performance in the organization,
he is given promotion and he becomes eligible to exercise to some higher
authorities. And further, he may get some higher promotion or he may leave the
organization. So, during his stay in the organization, the authority of that
person varies from the time he joins the organization until he/she leaves the
organization. This paper presents the variation in authorities of a person in
the organization. The method implements the queuing model to analyze the
various people in the queue of their promotion and looks at various parameters
like average waiting time etc."
"Proper privacy protection in RFID systems is important. However, many of the
schemes known are impractical, either because they use hash functions instead
of the more hardware efficient symmetric encryption schemes as a efficient
cryptographic primitive, or because they incur a rather costly key search time
penalty at the reader. Moreover, they do not allow for dynamic, fine-grained
access control to the tag that cater for more complex usage scenarios.
  In this paper we investigate such scenarios, and propose a model and
corresponding privacy friendly protocols for efficient and fine-grained
management of access permissions to tags. In particular we propose an efficient
mutual authentication protocol between a tag and a reader that achieves a
reasonable level of privacy, using only symmetric key cryptography on the tag,
while not requiring a costly key-search algorithm at the reader side. Moreover,
our protocol is able to recover from stolen readers."
"This paper studies the relationships between the traditional Diffie-Hellman
key agreement protocol and the identity-based (ID-based) key agreement protocol
from pairings.
  For the Sakai-Ohgishi-Kasahara (SOK) ID-based key construction, we show that
identical to the Diffie-Hellman protocol, the SOK key agreement protocol also
has three variants, namely \emph{ephemeral}, \emph{semi-static} and
\emph{static} versions. Upon this, we build solid relations between
authenticated Diffie-Hellman (Auth-DH) protocols and ID-based authenticated key
agreement (IB-AK) protocols, whereby we present two \emph{substitution rules}
for this two types of protocols. The rules enable a conversion between the two
types of protocols. In particular, we obtain the \emph{real} ID-based version
of the well-known MQV (and HMQV) protocol.
  Similarly, for the Sakai-Kasahara (SK) key construction, we show that the key
transport protocol underlining the SK ID-based encryption scheme (which we call
the ""SK protocol"") has its non-ID counterpart, namely the Hughes protocol.
Based on this observation, we establish relations between corresponding
ID-based and non-ID-based protocols. In particular, we propose a highly
enhanced version of the McCullagh-Barreto protocol."
"Multi-signcryption is used when different senders wants to authenticate a
single message without revealing it. This paper proposes a multi signcryption
scheme in which no pairing is computed on the signcryption stage and the
signatures can be verified publicly."
"Important document are being kept encrypted in remote servers. In order to
retrieve these encrypted data, efficient search methods needed to enable the
retrieval of the document without knowing the content of the documents In this
paper a technique called a global heuristic search on encrypted data (GHSED)
technique will be described for search in an encrypted files using public key
encryption stored on an untrusted server and retrieve the files that satisfy a
certain search pattern without revealing any information about the original
files. GHSED technique would satisfy the following: (1) Provably secure, the
untrusted server cannot learn anything about the plaintext given only the
cipher text. (2) Provide controlled searching, so that the untrusted server
cannot search for a word without the user's authorization. (3) Support hidden
queries, so that the user may ask the untrusted server to search for a secret
word without revealing the word to the server. (4) Support query isolation, so
the untrusted server learns nothing more than the search result about the
plaintext."
"Over the years security experts in the field of Information Technology have
had a tough time in making passwords secure. This paper studies and takes a
careful look at this issue from the angle of philosophy and cognitive science.
We have studied the process of passwords to rank its strengths and weaknesses
in order to establish a quality metric for passwords. Finally we related the
process to human senses which enables us to propose a constitutional scheme for
the process of password. The basic proposition is to exploit relationship
between human senses and password to ensure improvement in authentication while
keeping it an enjoyable activity."
"Companies have increasingly turned to application service providers (ASPs) or
Software as a Service (SaaS) vendors to offer specialized web-based services
that will cut costs and provide specific and focused applications to users. The
complexity of designing, installing, configuring, deploying, and supporting the
system with internal resources can be eliminated with this type of methodology,
providing great benefit to organizations. However, these models can present an
authentication problem for corporations with a large number of external service
providers. This paper describes the implementation of Security Assertion Markup
Language (SAML) and its capabilities to provide secure single sign-on (SSO)
solutions for externally hosted applications."
"This paper addresses efficient hardware/software implementation approaches
for the AES (Advanced Encryption Standard) algorithm and describes the design
and performance testing algorithm for embedded system. Also, with the spread of
reconfigurable hardware such as FPGAs (Field Programmable Gate Array) embedded
cryptographic hardware became cost-effective. Nevertheless, it is worthy to
note that nowadays, even hardwired cryptographic algorithms are not so safe.
  From another side, the self-reconfiguring platform is reported that enables
an FPGA to dynamically reconfigure itself under the control of an embedded
microprocessor. Hardware acceleration significantly increases the performance
of embedded systems built on programmable logic. Allowing a FPGA-based
MicroBlaze processor to self-select the coprocessors uses can help reduce area
requirements and increase a system's versatility. The architecture proposed in
this paper is an optimal hardware implementation algorithm and takes dynamic
partially reconfigurable of FPGA. This implementation is good solution to
preserve confidentiality and accessibility to the information in the numeric
communication."
"Cyber criminality activities are changing and becoming more and more
professional. With the growth of financial flows through the Internet and the
Information System (IS), new kinds of thread arise involving complex scenarios
spread within multiple IS components. The IS information modeling and
Behavioral Analysis are becoming new solutions to normalize the IS information
and counter these new threads. This paper presents a framework which details
the principal and necessary steps for monitoring an IS. We present the
architecture of the framework, i.e. an ontology of activities carried out
within an IS to model security information and User Behavioral analysis. The
results of the performed experiments on real data show that the modeling is
effective to reduce the amount of events by 91%. The User Behavioral Analysis
on uniform modeled data is also effective, detecting more than 80% of
legitimate actions of attack scenarios."
"This paper presents a new efficient protocol for k-out-of-n oblivious
transfer which is a generalization of Parakh's 1-out-of-2 oblivious transfer
protocol based on Diffie-Hellman key exchange. In the proposed protocol, the
parties involved generate Diffie-Hellman keys obliviously and then use them for
oblivious transfer of secrets."
"Remote Procedure Calls (RPC) are widely used over the Internet as they
provide a simple and elegant way of interaction between the client and the
server. This paper proposes a solution for securing the remote procedure calls
(RPC) by tunneling it through HTTPS (Hypertext Transfer Protocol over Secure
Socket Layer). RPC over HTTP actually uses the Secure Socket Layer (SSL)
protocol as a transport for the traffic. SSL mandates that the server
authenticates itself to the client using a digital certificate (and associated
private key). SSL is normally configured to encrypt traffic before transmitting
it between the server and client and vice versa."
"In many of the cryptography applications like password or IP address
encryption schemes, symmetric cryptography is useful. In these relatively
simpler applications of cryptography, asymmetric cryptography is difficult to
justify on account of the computational and implementation complexities
associated with asymmetric cryptography. Symmetric schemes make use of a single
shared key known only between the two communicating hosts. This shared key is
used both for the encryption as well as the decryption of data. This key has to
be small in size besides being a subset of a potentially large keyspace making
it convenient for the communicating hosts while at the same time making
cryptanalysis difficult for the potential attackers. In the present work, an
abstract Rossler nonlinear dynamical machine has been described first. The
Rossler system exhibits chaotic dynamics for certain values of system
parameters and initial conditions. The chaotic dynamics of the Rossler system
with its apparently erratic and irregular characteristics and extreme
sensitivity to the initial conditions has been used for the design of the
cryptographic key in an attempt to increase the confusion and the challenge for
the potential attackers."
"Malware is a type of malicious program that replicate from host machine and
propagate through network. It has been considered as one type of computer
attack and intrusion that can do a variety of malicious activity on a computer.
This paper addresses the current trend of malware detection techniques and
identifies the significant criteria in each technique to improve malware
detection in Intrusion Detection System (IDS). Several existing techniques are
analyzing from 48 various researches and the capability criteria of malware
detection technique have been reviewed. From the analysis, a new generic
taxonomy of malware detection technique have been proposed named Hybrid Malware
Detection Technique (Hybrid MDT) which consists of Hybrid Signature and Anomaly
detection technique and Hybrid Specification based and Anomaly detection
technique to complement the weaknesses of the existing malware detection
technique in detecting known and unknown attack as well as reducing false alert
before and during the intrusion occur."
"Software piracy has been a very perilous adversary of the software based
industry, from the very beginning of the development of the latter into a
significant business. There has been no developed foolproof system that has
been developed to appropriately tackle this vile issue. We have in our scheme
tried to develop a way to embark upon this problem using a very recently
developed technology of RFID."
"The main objective of the research is to introduce a biologically inspired
execution framework for workflow systems under threat due to some intrusion
attack. Usually vulnerable systems need to be stop and put into wait state,
hence to insure the data security and privacy while being recovered. This
research ensures the availability of services and data to the end user by
keeping the data security, privacy and integrity intact. To achieve the
specified goals, the behavior of chameleons and concept of hibernation has been
considered in combination. Hence the workflow systems become more robust using
biologically inspired methods and remain available to the business consumers
safely even in a vulnerable state."
"Latest developments in VLSI, wireless communications, and biomedical sensing
devices allow very small, lightweight, low power, intelligent sensing devices
called biosensors. A set of these devices can be integrated into a Wireless
Biomedical Sensor Network (WBSN), a new breakthrough technology used in
telemedicine for monitoring the physiological condition of an individual. The
biosensor nodes in WBSN has got resource limitations in terms of battery
lifetime, CPU processing capability, and memory capacity. Replacement or
recharging of batteries on thousands of biosensor nodes is quiet difficult or
too costly. So, a key challenge in wireless biomedical sensor networks is the
reduction of energy and memory consumption. Considering, the sensitivity of
information in WBSN, we must provide security and patient privacy, as it is an
important issue in the design of such systems. Hence this paper proposes an
energy efficient security protocol for WBSN where security is provided to the
physiological data, which is being transmitted from the sensor node to the sink
device. This is achieved by authenticating the data using patients biometric,
encrypting the data using Quasi Group cryptography after compressing the image
data using an energy efficient number theory based technique."
"Trust plays an important role in making collaborative decisions about service
evaluation and service selection in pervasive computing. Context is a
fundamental concept in pervasive systems, which is based on the interpretation
of environment and systems. The dynamic nature of context can strongly affect
trust management and service selection. In this paper, we present a
context-based trust management model for pervasive computing systems. The
concept of context is considered in basic components of the model such as trust
computation module, recommender assessment module, transaction management
module, and request responder. In order to measure a predicted trustworthiness
according to the fuzzy nature of trust in pervasive environments, fuzzy
concepts are integrated in the proposed model."
"With increasing the applications of grid system, the risk in security field
is enhancing too. Recently Trust management system has been recognized as a
noticeable approach in enhancing of security in grid systems. In this article
due to improve the grid security a new trust management system with two levels
is proposed. The benefits of this platform are adding new domain in grid
system, selecting one service provider which has closest adaption with user
requests and using from domains security attribute as an important factor in
computing the trust value."
"Over the recent years, IP and email spoofing gained much importance for
security concerns due to the current changes in manipulating the system
performance in different online environments. Intrusion Detection System (IDS)
has been used to secure these environments for sharing their data over network
and host based IDS approaches. However, the rapid growth of intrusion events
over Internet and local area network become responsible for the distribution of
different threats and vulnerabilities in the computing systems. The current
signature detection approach used by IDS, detects unclear actions based on
analyzing and describing the action patterns such as time, text, password etc
and has been faced difficulties in updating information, detect unknown novel
attacks, maintenance of an IDS which is necessarily connected with analyzing
and patching of security holes, and the lack of information on user privileges
and attack signature structure. Thus, this paper proposes an EADS (Exception
agent detection system) for securing the header information carried by IP over
online environments. The study mainly concerns with the deployment of new
technique for detecting and eliminating the unknown threats attacks during the
data sharing over online environments."
"In this paper, we develop a trust based security protocol based on a cross
layer approach which attains confidentiality and authentication of packets in
both routing and link layers of MANETs. In the first phase of the protocol, we
design a trust based packet forwarding scheme for detecting and isolating the
malicious nodes using the routing layer information. It uses trust values to
favor packet forwarding by maintaining a trust counter for each node. A node is
punished or rewarded by decreasing or increasing the trust counter. If the
trust counter value falls below a trust threshold, the corresponding
intermediate node is marked as malicious. In the next phase of the protocol, we
provide link layer security using the CBCX mode of authentication and
encryption. By simulation results, we show that the proposed cross layer
security protocol achieves high packet delivery ratio while attaining low delay
and overhead."
"Current security model in Global System for Mobile Communications (GSM)
predominantly use symmetric key cryptography. The rapid advancement of Internet
technology facilitates online trading, banking, downloading, emailing using
resource-constrained handheld devices such as personal digital assistants and
cell phones. However, these applications require more security than the present
GSM supports. Consequently, a careful design of GSM security using both
symmetric and asymmetric key cryptography would make GSM security more
adaptable in security intensive applications. This paper presents a secure and
efficient protocol for GSM security using identity based cryptography. The
salient features of the proposed protocol are (i) authenticated key exchange;
(ii) mutual authentication amongst communicating entities; and (iii) user
anonymity. The security analysis of the protocol shows its strength against
some known threats observed in conventional GSM security."
"The first quantitative evaluation of the quality of corporate firewall
configurations appeared in 2004, based on Check Point FireWall-1 rule-sets. In
general that survey indicated that corporate firewalls were often enforcing
poorly written rule-sets, containing many mistakes.
  The goal of this work is to revisit the first survey. The current study is
much larger. Moreover, for the first time, the study includes configurations
from two major vendors. The study also introduce a novel ""Firewall Complexity""
(FC) measure, that applies to both types of firewalls.
  The findings of the current study indeed validate the 2004 study's main
observations: firewalls are (still) poorly configured, and a rule-set's
complexity is (still) positively correlated with the number of detected risk
items. Thus we can conclude that, for well-configured firewalls, ``small is
(still) beautiful''. However, unlike the 2004 study, we see no significant
indication that later software versions have fewer errors (for both vendors)."
"We show that for every effective left conjugacy closed left quasigroup, there
is an induced rack that retains the conjugation structure of the left
translations. This means that cryptographic protocols relying on conjugacy
search can be secure only if conjugacy search of left translations is
infeasible in the induced rack. We note that, in fact, protocols based on
conjugacy search could be simply implemented using a rack. We give an
exposition of the Anshel-Anshel-Goldfeld protocol in such a case."
"We study and develop a robust control framework for malware filtering and
network security. We investigate the malware filtering problem by capturing the
tradeoff between increased security on one hand and continued usability of the
network on the other. We analyze the problem using a linear control system
model with a quadratic cost structure and develop algorithms based on H
infinity-optimal control theory. A dynamic feedback filter is derived and shown
via numerical analysis to be an improvement over various heuristic approaches
to malware filtering. The results are verified and demonstrated with packet
level simulations on the Ns-2 network simulator."
"In this document, we define the NADA security architecture based on refined
use case scenarios, a derived high level model and security analysis. For the
architecure design and verification we are applying the well known STRIDE
model."
"With the growing importance of personal identification and authentication in
todays highly advanced world where most business and personal tasks are being
replaced by electronic means, the need for a technology that is able to
uniquely identify an individual and has high fraud resistance see the rise of
biometric technologies. Making biometric based solution mobile is a promising
trend. A new RST invariant square based palm print ROI extraction method was
successfully implemented and integrated into the current application suite. A
new set of palm print image database captured using embedded cameras in mobile
phone was created to test its robustness. Comparing to those extraction methods
that are based on boundary tracking of the overall hand shape that has
limitation of being unable to process palm print images that has one or more
fingers closed, the system can now effectively handle the segmentation of palm
print images with varying finger positioning. The high flexibility makes palm
print matching mobile possible."
"Research on sensor networks has become much more active and is currently
being applied to many different fields. However since sensor networks are
limited to only collecting and reporting information regarding a certain event,
and requires human intervention with that given information, it is often
difficult to react to an event or situation immediately and proactively. To
overcome this kind of limitation, Wireless Sensor and Actor Networks (WSANs)
with immediate-response actor nodes have been proposed which adds greater
mobility and activity to the existing sensor networks. Although WSANs share
many common grounds with sensor networks, it is difficult to apply existing
security technologies due to the fact that WSANs contain actor nodes that are
resource-independent and mobile. Therefore, this research seeks to demonstrate
ways to provide security, integrity, and authentication services for WSANs
secure operation, by separating networks into hierarchical structure by each
node's abilities and provides different encryption key based secure protocols
for each level of hierarchy, Pairwise key, node key, and region key for sensor
levels, and public key for actor"
"Nowadays, user authentication is one of the important topics in information
security. Strong textbased password schemes could provide with certain degree
of security. However, the fact that strong passwords are difficult to memorize
often leads their owners to write them down on papers or even save them in a
computer file. Graphical authentication has been proposed as a possible
alternative solution to textbased authentication, motivated particularly by the
fact that humans can remember images better than text. In recent years, many
networks, computer systems and Internet based environments try used graphical
authentication technique for their users authentication. All of graphical
passwords have two different aspects which are usability and security.
Unfortunately none of these algorithms were being able to cover both of these
aspects at the same time. In this paper, we described eight recognition based
authentication algorithms in terms of their drawbacks and attacks. In the next
section, the usability standards from ISO and the related attributes for
graphical user authentication usability are discussed. The related attack
patterns for graphical user authentication security part are also discussed.
Finally, a comparison table of all recognition based algorithms is presented
based on ISO and attack patterns standards."
"With the current development of multiprocessor systems, strive for computing
data on such processor have also increased exponentially. If the multi core
processors are not fully utilized, then even though we have the computing power
the speed is not available to the end users for their respective applications.
In accordance to this, the users or application designers also have to design
newer applications taking care of the computing infrastructure available
within. Our approach is to use the CUDA (Compute Unified Device Architecture)
as backend and MATLAB as the front end to design an application for
implementing steganography. Steganography is the term used for hiding
information in the cover object like Image, Audio or Video data. As the
computing required for multimedia data is much more than the text information,
we have been successful in implementing image Steganography with the help of
technology for the next generation."
"Information and computer security is supported largely by passwords which are
the principle part of the authentication process. The most common computer
authentication method is to use alphanumerical username and password which has
significant drawbacks. To overcome the vulnerabilities of traditional methods,
visual or graphical password schemes have been developed as possible
alternative solutions to text based scheme. A potential drawback of graphical
password schemes is that they are more vulnerable to shoulder surfing than
conventional alphanumeric text passwords. When users input their passwords in a
public place, they may be at risk of attackers stealing their password. An
attacker can capture a password by direct observation or by recording the
individuals authentication session. This is referred to as shouldersurfing and
is a known risk, of special concern when authenticating in public places. In
this paper we will present a survey on graphical password schemes from 2005
till 2009 which are proposed to be resistant against shoulder surfing attacks."
"With the tremendous amount of computing because of the wide usage of internet
it is observed that some user(s) are not able to manage their desktop with
antivirus software properly installed. It is happening few times, that we allow
our friends, students and colleagues to sit on our networked PC. Sometimes the
user is unaware of the situation that there workstations are unsecured and so
some one else could also be monitoring your flow of information and your most
important data could go haywire, resulting into leakage of most confidential
data to unwanted or malicious user(s). Example of some such documents could be
question papers designed by the faculty member by various universities. Now a
day most of the universities are having the biggest threat about the question
papers and many other confidential documents designed by their faculty members.
We in this paper present the solution to over come such a situation using the
concept of Steganography. Steganography is a technique through which one can
hide information into some cover object. This technique, if used, in positive
direction could be of great help to solve such a problem and even other."
"Secure Multiparty Computation (SMC) allows parties to know the result of
cooperative computation while preserving privacy of individual data. Secure sum
computation is an important application of SMC. In our proposed protocols
parties are allowed to compute the sum while keeping their individual data
secret with increased computation complexity for hacking individual data. In
this paper the data of individual party is broken into a fixed number of
segments. For increasing the complexity we have used the randomization
technique with segmentation"
"Recently, an image scrambling encryption algorithm of pixel bit based on
chaos map was proposed. Considering the algorithm as a typical binary image
scrambling/permutation algorithm exerting on plaintext of size $M\times (8N)$,
this paper proposes a novel optimal method to break it with some
known/chosen-plaintexts. The spatial complexity and computational complexity of
the attack are only $O(32\cdot MN)$ and $O(16\cdot n_0\cdot MN)$ respectively,
where $n_0$ is the number of known/chosen-plaintexts used. The method can be
easily extended to break any permutation-only encryption scheme exerting on
plaintext of size $M\times N$ and with $L$ different levels of values. The
corresponding spatial complexity and computational complexity are only $O(MN)$
and $O(\lceil\log_L(MN)\rceil \cdot MN)$ respectively. In addition, some
specific remarks on the performance of the image scrambling encryption
algorithm are presented."
"We analyse the complexity of the computation of the class group structure,
regulator, and a system of fundamental units of a certain class of number
fields. Our approach differs from Buchmann's, who proved a complexity bound of
L(1/2,O(1)) when the discriminant tends to infinity with fixed degree. We
achieve a subexponential complexity in O(L(1/3,O(1))) when both the
discriminant and the degree of the extension tend to infinity by using
techniques due to Enge and Gaudry in the context of algebraic curves over
finite fields."
"The paper includes Public Key Infrastructure (PKI), its need and requirements
and introduction of some renowned PKI products. However, the major thrust of
this work is that how PKI can enhance security of various systems. The paper is
intended to serve as a guide on how to adequately prepare for some of the
challenges that may be encountered especially in developing countries like
Pakistan. The detail of PKI implementation issues is also included in the paper
along with future challenges regarding implementation of PKI. Furthermore,
paper includes technical issues hindering the implementation of PKI through
comparison of PKI issues in Pakistan and some of Asian countries mainly Taiwan,
Japan and Singapore. The paper also highlights the PKI issues and learnt
lessons regarding PKI implementation and can act as a comprehensive guide for
successful future PKI deployments."
"In today's world the art of sending & displaying the hidden information
especially in public places, has received more attention and faced many
challenges. Therefore, different methods have been proposed so far for hiding
information in different cover media. In this paper a method for hiding of
information on the billboard display is presented. It is well known that
encryption provides secure channels for communicating entities. However, due to
lack of covertness on these channels, an eavesdropper can identify encrypted
streams through statistical tests and capture them for further cryptanalysis.
In this paper we propose a new form of steganography, on-line hiding of
information on the output screens of the instrument. This method can be used
for announcing a secret message in public place. It can be extended to other
means such as electronic advertising board around sports stadium, railway
station or airport. This method of steganography is very similar to image
steganography and video steganography. Private marking system using symmetric
key steganography technique and LSB technique is used here for hiding the
secret information."
"Side channel attacks have emerged as a serious threat to the security of both
networked and embedded systems -- in particular through the implementations of
cryptographic operations. Side channels can be difficult to model formally, but
with careful coding and program transformation techniques it may be possible to
verify security in the presence of specific side-channel attacks. But what if a
program intentionally makes a tradeoff between security and efficiency and
leaks some information through a side channel? In this paper we study such
tradeoffs using ideas from recent research on declassification. We present a
semantic model of security for programs which allow for declassification
through side channels, and show how side-channel declassification can be
verified using off-the-shelf software model checking tools. Finally, to make it
simpler for verifiers to check that a program conforms to a particular
side-channel declassification policy we introduce a further tradeoff between
efficiency and verifiability: by writing programs in a particular ""manifest
form"" security becomes considerably easier to verify."
"Security and safety are two intertwined terms. It is a common belief that
when a place or system is secure, it is safe. This paper shows a means of
integrating three devices for physical intrusion detection. This paper thus
suggests a means of increasing the level of security in an enclosed area with
the use three of the four security layers necessary for optimum security. This
paper intends to show that a system with more than one security device in place
tends to prevent unauthorized access. This paper would be illustrating the
implementation of this in an enclosed area whose security level must be kept on
the high at all times."
"One of the essential security services needed to safeguard online
transactions is fair exchange. In fair exchange protocols two parties can
exchange their signatures in a fair manner, so that either each party gain the
other's signature or no one obtain anything useful. This paper examines
security solutions for achieving fair exchange. It proposes new security
protocols based on the ""Certified Encrypted Message Being Signature"" (CEMBS) by
using RSA signature scheme. This protocol relies on the help of an ""off-line
Semi-Trusted Third Party"" (STTP) to achieve fairness. They provide with
confidential protection from the STTP for the exchanged items by limiting the
role and power of the STTP. Three different protocols have been proposed. In
the first protocol, the two main parties exchange their signatures on a common
message. In the second protocol, the signatures are exchanged on two different
messages. While in the third one, the exchange is between confidential data and
signature."
"Bit Plane Complexity Segmentation (BPCS) digital picture steganography is a
technique to hide data inside an image file. BPCS achieves high embedding rates
with low distortion based on the theory that noise-like regions in an image's
bit-planes can be replaced with noise-like secret data without significant loss
in image quality. . In this framework we will propose a collaborate approach
for select frame for Hiding Data within MPEG Video Using Bit Plane Complexity
Segmentation. This approach will invent high secure data hidden using select
frame form MPEG Video and furthermore we will assign the well-built of the
approach; during this review the author will answer the question why they used
select frame steganography. In additional to the security issues we will use
the digital video as a cover to the data hidden. The reason behind opt the
video cover in this approach is the huge amount of single frames image per sec
which in turn overcome the problem of the data hiding quantity, as the
experiment result shows the success of the hidden data within select frame,
extract data from the frames sequence. These function without affecting the
quality of the video."
"This paper discusses the application of known techniques, knowledge and
technology in a novel way for encryption. Two distinct and separate methods are
presented.
  Method 1: Alter the symbol set of the language by adding additional redundant
symbols for frequent symbols. This will reduce the high frequency of more
commonly used symbols. Hence, frequency analysis upon ciphertext will not be
possible. Hence, decryption will be possible.
  Method 2: Computers use binary base 2. Most encryption systems use ciphering
to convert data to ciphertext. The author presents the theory and several
possible implementations of a method for computers analogous to speaking
another language. This is done by using a binary base other than base 2. Ex.
Fibonacci, Phi or Prime.
  In addition, steganography may be used for creating alternate binary bases.
  This kind of encryption significantly increases the complexity of decryption.
First the binary base must be known. Only then, can decryption begin.
  This kind of encryption also breaks the transitivity of
plaintext-codebook-binary; the correlation of letters-ASCII-base2. With this
transitivity broken, decryption is logically impossible. Coupled with
encrypting the plaintext, binary encryption makes decryption uncrackable. It
may produce false positives--information theoretic secure, and requires much
more computing power to resolve than is currently used in brute force
decryption. Hence, the assertion that these combination of methods are
computationally secure--impervious to brute force.
  The proposed system has a drawback. It is not as compressed as a base2.
(Similar to adding random padding to the encryption.) However, this is
acceptable, since the goal is very strong encryption:
  Both methods are not decryptable by method uncrackable - by conventional,
statistical means."
"An algorithm is presented that in context of public key use of Elliptic Curve
Cryptography allows discovery of the private key in worst case O(n)."
"Google's Android is a comprehensive software framework for mobile
communication devices (i.e., smartphones, PDAs). The Android framework includes
an operating system, middleware and a set of key applications. The
incorporation of integrated access services to the Internet on such mobile
devices, however, increases their exposure to damages inflicted by various
types of malware. This paper provides a comprehensive security assessment of
the Android framework and the security mechanisms incorporated into it. A
methodological qualitative risk analysis that we conducted identifies the
high-risk threats to the framework and any potential danger to information or
to the system resulting from vulnerabilities that have been uncovered and
exploited. Our review of current academic and commercial solutions in the area
of smartphone security yields a list of applied and recommended defense
mechanisms for hardening mobile devices in general and the Android in
particular. Lastly, we present five major (high-risk) threats to the Android
framework and propose security solutions to mitigate them. We conclude by
proposing a set of security mechanisms that should be explored and introduced
into Android-powered devices."
"Vehicular communication (VC) systems have recently drawn the attention of
industry, authorities, and academia. A consensus on the need to secure VC
systems and protect the privacy of their users led to concerted efforts to
design security architectures. Interestingly, the results different project
contributed thus far bear extensive similarities in terms of objectives and
mechanisms. As a result, this appears to be an auspicious time for setting the
corner-stone of trustworthy VC systems. Nonetheless, there is a considerable
distance to cover till their deployment. This paper ponders on the road ahead.
First, it presents a distillation of the state of the art, covering the
perceived threat model, security requirements, and basic secure VC system
components. Then, it dissects predominant assumptions and design choices and
considers alternatives. Under the prism of what is necessary to render secure
VC systems practical, and given possible non-technical influences, the paper
attempts to chart the landscape towards the deployment of secure VC systems."
"Existing anomaly and intrusion detection schemes of wireless sensor networks
have mainly focused on the detection of intrusions. Once the intrusion is
detected, an alerts or claims will be generated. However, any unidentified
malicious nodes in the network could send faulty anomaly and intrusion claims
about the legitimate nodes to the other nodes. Verifying the validity of such
claims is a critical and challenging issue that is not considered in the
existing cooperative-based distributed anomaly and intrusion detection schemes
of wireless sensor networks. In this paper, we propose a validation algorithm
that addresses this problem. This algorithm utilizes the concept of
intrusion-aware reliability that helps to provide adequate reliability at a
modest communication cost. In this paper, we also provide a security resiliency
analysis of the proposed intrusion-aware alert validation algorithm."
"The Session Initiation Protocol (SIP) has become the most predominant
protocol for Voice over Internet Protocol (VoIP) signaling. Security of SIP is
an important consideration for VoIP communication as the traffic is transmitted
over the insecure IP network. And the authentication process in SIP ranges from
pre-shared secret based solutions to Public Key Infrastructure (PKI) based
solution. However, due to the limitations in PKI based solutions, some PKI less
authentications mechanisms are proposed. This paper aims to present an overview
of different authentication methods used in or together with SIP. We start by
highlighting the security issues in SIP in the context of VoIP communication.
Then we illustrate the current activities regarding the SIP authentication
mechanisms including the recent developments in the research community and
standardization efforts within the Internet Engineering Task Force (IETF).
Finally we analyze the security aspects of these approaches."
"In this paper, we will study Lee, Kim and Yoo, a verifier password typed key
agreement scheme and demonstrate that the scheme is not secure. Then, the
authors will propose an enhanced verifier typed key agreement scheme relied on
Lee, Kim and Yoo scheme and demonstrate that the propose scheme resists against
password guessing attack and stolen verifier attack. The authors are claimed
that the proposed scheme is more secure and efficient compare with Lee, Kim and
Yoo."
"In last few decades large technology development raised various new needs.
Financial sector has also no exception. People are approaching all over the
world to fulfill there dreams. Any sector needs to understand changing need of
customer. In order to satisfy financial need for customer banks are taking help
of new technology such as internet. Only problem remain is of security. The aim
of this work is to provide a secure environment in terms of security for
transaction by various ways. In order to improve security we are making use of
""Steganography"" technique in the way never used before. Task of enhancing
security include construction of formula for both data encryption and also for
hiding pattern. Server should not process any fake request hence concept of
custom ""Session id"" and ""Request id"" is introduced. Implementation of such a
security constraints in banking sector not only help to serve customer in
better way but also make customer confident and satisfy."
"The number of malware variants is growing tremendously and the study of
malware attacks on the Internet is still a demanding research domain. In this
research, various logs from different OSI layer are explore to identify the
traces leave on the attacker and victim logs, and the attack worm trace pattern
are establish in order to reveal true attacker or victim. For the purpose of
this paper, it will only concentrate on cybercrime that caused by malware
network intrusion and used the traditional worm namely blaster worm variants.
This research creates the concept of trace pattern by fusing the attackers and
victims perspective. Therefore, the objective of this paper is to propose on
attackers, victims and multistep, attacker or victim, trace patterns by
combining both perspectives. These three proposed worm trace patterns can be
extended into research areas in alert correlation and computer forensic
investigation."
"In wireless ad hoc networks, the absence of any control on packets
forwarding, make these networks vulnerable by various deny of service attacks
(DoS). A node, in wireless ad hoc network, counts always on intermediate nodes
to send these packets to a given destination node. An intermediate node, which
takes part in packets forwarding, may behave maliciously and drop packets which
goes through it, instead of forwarding them to the following node. Such
behavior is called black hole attack. In this paper, after having specified the
black hole attack, a secure mechanism, which consists in checking the good
forwarding of packets by an intermediate node, was proposed. The proposed
solution avoids the black hole and the cooperative black hole attacks.
Evaluation metrics were considered in simulation to show the effectiveness of
the suggested solution."
"As physical and information security boundaries have become increasingly
blurry many organizations are experiencing challenges with how to effectively
and efficiently manage security within the corporate. There is no current
standard or best practice offered by the security community regarding
convergence; however many organizations such as the Alliance for Enterprise
Security Risk Management (AESRM) offer some excellent suggestions for
integrating a converged security program. This paper reports on how
organizations have traditionally managed asset protection, why that is changing
and how to establish convergence to optimize security value to the business
within an enterprise."
"Online advertising is currently the greatest source of revenue for many
Internet giants. The increased number of specialized websites and modern
profiling techniques, have all contributed to an explosion of the income of ad
brokers from online advertising. The single biggest threat to this growth, is
however, click-fraud. Trained botnets and even individuals are hired by
click-fraud specialists in order to maximize the revenue of certain users from
the ads they publish on their websites, or to launch an attack between
competing businesses.
  In this note we wish to raise the awareness of the networking research
community on potential research areas within this emerging field. As an example
strategy, we present Bluff ads; a class of ads that join forces in order to
increase the effort level for click-fraud spammers. Bluff ads are either
targeted ads, with irrelevant display text, or highly relevant display text,
with irrelevant targeting information. They act as a litmus test for the
legitimacy of the individual clicking on the ads. Together with standard
threshold-based methods, fake ads help to decrease click-fraud levels."
"Secure sum computation of private data inputs is an important component of
Secure Multi party Computation (SMC).In this paper we provide a protocol to
compute the sum of individual data inputs with zero probability of data
leakage. In our proposed protocol we break input of each party into number of
segments and change the arrangement of the parties such that in each round of
the computation the neighbors are changed. In this protocol it becomes
impossible for semi honest parties to know the private data of some other
party."
"Human users have a tough time remembering long cryptographic keys. Hence,
researchers, for so long, have been examining ways to utilize biometric
features of the user instead of a memorable password or passphrase, in an
effort to generate strong and repeatable cryptographic keys. Our objective is
to incorporate the volatility of the users biometric features into the
generated key, so as to make the key unguessable to an attacker lacking
significant knowledge of the users biometrics. We go one step further trying to
incorporate multiple biometric modalities into cryptographic key generation so
as to provide better security. In this article, we propose an efficient
approach based on multimodal biometrics (Iris and fingerprint) for generation
of secure cryptographic key. The proposed approach is composed of three modules
namely, 1) Feature extraction, 2) Multimodal biometric template generation and
3) Cryptographic key generation. Initially, the features, minutiae points and
texture properties are extracted from the fingerprint and iris images
respectively. Subsequently, the extracted features are fused together at the
feature level to construct the multibiometric template. Finally, a 256bit
secure cryptographic key is generated from the multibiometric template. For
experimentation, we have employed the fingerprint images obtained from publicly
available sources and the iris images from CASIA Iris Database. The
experimental results demonstrate the effectiveness of the proposed approach."
"Future security measures will create comfortable living environments that are
embedded with a wide range of intelligent functionalities including home
computing, entertainment, health care and security. These place stringent
requirements on the home networking architecture which integrates various
existing technologies for monitoring and control for future high security
needs. This paper discusses the design and implementation of a gvss gprs Video
Streaming Surveillance System system, which integrates various existing
technologies for providing security for smart home environments. This system
provides security for office, home and other buildings where high security is
required.This allows the mobile user to track the activities from a particular
location. The system will send snapshots of the video and stores them in
different formats. It is also possible to display the time with the image when
it was captured in the gprs enabled mobiles. This system is implemented using
J2me Technology"
"The non-repudiation as an essential requirement of many applications can be
provided by the asymmetric key model. With the evolution of new applications
such as mobile commerce, it is essential to provide secure and efficient
solutions for the mobile environments. The traditional public key cryptography
involves huge computational costs and is not so suitable for the
resource-constrained platforms. The elliptic curve-based approaches as the
newer solutions require certain considerations that are not taken into account
in the traditional public key infrastructures. The main contribution of this
paper is to introduce a Lightweight Public Key Infrastructure (LPKI) for the
constrained platforms such as mobile phones. It takes advantages of elliptic
curve cryptography and signcryption to decrease the computational costs and
communication overheads, and adapting to the constraints. All the computational
costs of required validations can be eliminated from end-entities by
introduction of a validation authority to the introduced infrastructure and
delegating validations to such a component. LPKI is so suitable for mobile
environments and for applications such as mobile commerce where the security is
the great concern."
"The signcryption is a relatively new cryptographic technique that is supposed
to fulfill the functionalities of encryption and digital signature in a single
logical step. Several signcryption schemes are proposed throughout the years,
each of them having its own problems and limitations. In this paper, the
security of a recent signcryption scheme, i.e. Hwang et al.'s scheme is
analyzed, and it is proved that it involves several security flaws and
shortcomings. Several devastating attacks are also introduced to the mentioned
scheme whereby it fails all the desired and essential security attributes of a
signcryption scheme."
"A directly public verifiable signcryption scheme is introduced in this paper
that provides the security attributes of message confidentiality,
authentication, integrity, non-repudiation, unforgeability, and forward secrecy
of message confidentiality. It provides the attribute of direct public
verifiability so anyone can verify the signcryption without any need for any
secret information from the corresponding participants. The proposed scheme is
based on elliptic curve cryptography and is so suitable for environments with
resource constraints."
"Most developed countries have started the implementation of biometric
electronic identification cards, especially passports. The European Union and
the United States of America struggle to introduce and standardize these
electronic documents. Due to the personal nature of the biometric elements used
for the generation of these cards, privacy issues were raised on both sides of
the Atlantic Ocean, leading to civilian protests and concerns. The lack of
transparency from the public authorities responsible with the implementation of
such identification systems, and the poor technological approaches chosen by
these authorities, are the main reasons for the negative popularity of the new
identification methods. The following article shows an approach that provides
all the benefits of modern technological advances in the fields of biometrics
and cryptography, without sacrificing the privacy of those that will be the
beneficiaries of the new system."
"The Hill cipher is a classical symmetric encryption algorithm that succumbs
to the know-plaintext attack. Although its vulnerability to cryptanalysis has
rendered it unusable in practice, it still serves an important pedagogical role
in cryptology and linear algebra. In this paper, a variant of the Hill cipher
is introduced that makes the Hill cipher secure while it retains the
efficiency. The proposed scheme includes a ciphering core for which a
cryptographic protocol is introduced."
"Secure Multi-Party Computation (SMC) allows multiple parties to compute some
function of their inputs without disclosing the actual inputs to one another.
Secure sum computation is an easily understood example and the component of the
various SMC solutions. Secure sum computation allows parties to compute the sum
of their individual inputs without disclosing the inputs to one another. In
this paper, we propose a modified version of our ck-Secure Sum protocol with
more security when a group of the computing parties conspire to know the data
of some party."
"Network Intrusion Detection (NID) is the process of identifying network
activity that can lead to the compromise of a security policy. In this paper,
we will look at four intrusion detection approaches, which include ANN or
Artificial Neural Network, SOM, Fuzzy Logic and SVM. ANN is one of the oldest
systems that have been used for Intrusion Detection System (IDS), which
presents supervised learning methods. However, in this research, we also came
across SOM or Self Organizing Map, which is an ANN-based system, but applies
unsupervised methods. Another approach is Fuzzy Logic (IDS-based), which also
applies unsupervised learning methods. Lastly, we will look at the SVM system
or Support Vector Machine for IDS. The goal of this paper is to draw an image
for hybrid approaches using these supervised and unsupervised methods."
"This paper presents a novel encryption-less algorithm to enhance security in
transmission of data in networks. The algorithm uses an intuitively simple idea
of a ""jigsaw puzzle"" to break the transformed data into multiple parts where
these parts form the pieces of the puzzle. Then these parts are packaged into
packets and sent to the receiver. A secure and efficient mechanism is provided
to convey the information that is necessary for obtaining the original data at
the receiver-end from its parts in the packets, that is, for solving the
""jigsaw puzzle"". The algorithm is designed to provide information-theoretic
(that is, unconditional) security by the use of a one-time pad like scheme so
that no intermediate or unintended node can obtain the entire data. A
parallelizable design has been adopted for the implementation. An
authentication code is also used to ensure authenticity of every packet."
"In this paper we address the problem of protecting elliptic curve scalar
multiplication implementations against side-channel analysis by using the
atomicity principle. First of all we reexamine classical assumptions made by
scalar multiplication designers and we point out that some of them are not
relevant in the context of embedded devices. We then describe the
state-of-the-art of atomic scalar multiplication and propose an atomic pattern
improvement method. Compared to the most efficient atomic scalar multiplication
published so far, our technique shows an average improvement of up to 10.6%."
"Security issues are playing dominant role in today's high speed communication
systems. A fast and compact FPGA based implementation of the Data Encryption
Standard (DES) and Triple DES algorithm is presented in this paper that is
widely used in cryptography for securing the Internet traffic in modern day
communication systems. The design of the digital cryptographic circuit was
implemented in a Vertex 5 series (XCVLX5110T) target device with the use of
VHDL as the hardware description language. In order to confirm the expected
behavior of these algorithms, the proposed design was extensively simulated,
synthesized for different FPGA devices both in Spartan and Virtex series from
Xilinx viz. Spartan 3, Spartan 3AN, Virtex 5, Virtex E device families. The
novelty and contribution of this work is in three folds: (i) Extensive
simulation and synthesis of the proposed design targeted for various FPGA
devices, (ii) Complete hardware implementation of encryption and decryption
algorithms onto Virtex 5 series device (XCVLX5110T) based FPGA boards and,
(iii) Generation of ICON and VIO core for the design and on chip verification
and analyzing using Chipscope Pro. The experimental as well as implementation
results compared to the implementations reported so far are quite encouraging."
"We propose a hybrid technique for image encryption which employs the concept
of carrier image and SCAN patterns generated by SCAN methodology. Although it
involves existing method like SCAN methodology, the novelty of the work lies in
hybridizing and carrier image creation for encryption. Here the carrier image
is created with the help of alphanumeric keyword. Each alphanumeric key will be
having a unique 8bit value generated by 4 out of 8-code. This newly generated
carrier image is added with original image to obtain encrypted image. The scan
methodology is applied to either original image or carrier image, after the
addition of original image and carrier image to obtain highly distorted
encrypted image. The resulting image is found to be more distorted in hybrid
technique. By applying the reverse process we get the decrypted image."
"Up to now, for efficiency reasons cryptographic algorithm has been written in
an imperative language. But to get acquaintance with a functional programming
language a question arises: functional programming offers some new for secure
communication or not? This article investigates this question giving an
overview on some cryptography algorithms and presents how the RSA encryption in
the functional language Clean can be implemented and how can be measured the
efficiency of a certain application."
"Personal identification and authentication is very crucial in the current
scenario. Biometrics plays an important role in this area. Biometric based
authentication has proved superior compared to traditional password based
authentication. Anyhow biometrics is permanent feature of a person and cannot
be reissued when compromised as passwords. To over come this problem, instead
of storing the original biometric templates transformed templates can be
stored. Whenever the transformation function is changed new
revocable/cancelable templates are generated. Soft biometrics is ancillary
information that can be combined with primary biometrics to identify a person
in a better way. Iris has certain advantage compared to other biometric traits
like fingerprint. Iris is an internal part that is less prone to damage.
Moreover is very difficult for an attacker to capture an iris. The key
advantage of iris biometrics is its stability or template longevity. Biometric
systems are vulnerable to a variety of attacks. This work generates cancelable
iris templates by applying user and soft biometric based password
transformations and further secures the templates by biometric cryptographic
construct fuzzy vault."
"Security of any software can be enhanced manifolds if multiple factors for
authorization and authentication are used .The main aim of this work was to
design and implement an Academy Automation Software for IPS Academy which uses
OpenID and Windows CardSpace as Authentication Techniques in addition to Role
Based Authentication (RBA) System to ensure that only authentic users can
access the predefined roles as per their Authorization level. The Automation
covers different computing hardware and software that can be used to digitally
create, manipulate, collect, store, and relay Academy information needed for
accomplishing basic Operation like admissions and registration, student and
faculty interaction, online library, medical and business development. Raw data
storage, electronic transfer, and the management of electronic business
information comprise the basic activities of the Academy automation system.
Further Transport Layer Security (TLS) protocol has been implemented to provide
security and data integrity for communications over networks. TLS encrypts the
segments of network connections at the Transport"
"Digitization of analogue signals has opened up new avenues for information
hiding and the recent advancements in the telecommunication field has taken up
this desire even further. From copper wire to fiber optics, technology has
evolved and so are ways of covert channel communication. By ""Covert"" we mean
""anything not meant for the purpose for which it is being used"". Investigation
and detection of existence of such cover channel communication has always
remained a serious concern of information security professionals which has now
been evolved into a motivating source of an adversary to communicate secretly
in ""open"" without being allegedly caught or noticed. This paper presents a
survey report on steganographic techniques which have been evolved over the
years to hide the existence of secret information inside some cover (Text)
object. The introduction of the subject is followed by the discussion which is
narrowed down to the area where digital ASCII Text documents are being used as
cover. Finally, the conclusion sums up the proceedings."
"Cryptographic hash functions play a central role in cryptography. Hash
functions were introduced in cryptology to provide message integrity and
authentication. MD5, SHA1 and RIPEMD are among the most commonly used message
digest algorithm. Recently proposed attacks on well known and widely used hash
functions motivate a design of new stronger hash function. In this paper a new
approach is presented that produces 192 bit message digest and uses a modified
message expansion mechanism which generates more bit difference in each working
variable to make the algorithm more secure. This hash function is collision
resistant and assures a good compression and preimage resistance."
"Security has become one of the major issue in mobile services. In the
development of recent mobile devices like Software Defined Radio (SDR) secure
method of software downloading is found necessary for reconfiguration. Hash
functions are the important security primitives used for authentication and
data integrity. In this paper, VLSI architecture for implementation of
integrity unit in SDR is proposed. The proposed architecture is reconfigurable
in the sense it operates in two different modes: SHA-192 and MD-5.Due to
applied design technique the proposed architecture achieves multi-mode
operation, which keeps the allocated area resource at minimized level. The
proposed architecture also achieves highspeed performance with pipelined
designed structure. Comparison with related hash function implementation have
been done in terms of operating frequency, allocated-area and area-delay
product. The proposed Integrity Unity can be integrated in security systems for
implementation of network for wireless protocol, with special needs of
integrity in data transmission."
"Wireless Networks rendering varied services has not only become the order of
the day but the demand of a large pool of customers as well. Thus, security of
wireless networks has become a very essential design criterion. This paper
describes our research work focused towards creating secure cognitive wireless
local area networks using soft computing approaches. The present dense Wireless
Local Area Networks (WLAN) pose a huge threat to network integrity and are
vulnerable to attacks. In this paper we propose a secure Cognitive Framework
Architecture (CFA). The Cognitive Security Manager (CSM) is the heart of CFA.
The CSM incorporates access control using Physical Architecture Description
Layer (PADL) and analyzes the operational matrices of the terminals using multi
layer neural networks, acting accordingly to identify authorized access and
unauthorized usage patterns."
"Copyright protection and authentication of digital contents has become a
significant issue in the current digital epoch with efficient communication
mediums such as internet. Plain text is the rampantly used medium used over the
internet for information exchange and it is very crucial to verify the
authenticity of information. There are very limited techniques available for
plain text watermarking and authentication. This paper presents a novel
zero-watermarking algorithm for authentication of plain text. The algorithm
generates a watermark based on the text contents and this watermark can later
be extracted using extraction algorithm to prove the authenticity of text
document. Experimental results demonstrate the effectiveness of the algorithm
against tampering attacks identifying watermark accuracy and distortion rate on
10 different text samples of varying length and attacks."
"Many emerging applications in mobile adhoc networks involve group-oriented
communication. Multicast is an efficient way of supporting group oriented
applications, mainly in mobile environment with limited bandwidth and limited
power. For using such applications in an adversarial environment as military,
it is necessary to provide secure multicast communication. Key management is
the fundamental challenge in designing secure multicast communications. In many
multicast interactions, new member can join and current members can leave at
any time and existing members must communicate securely using multicast key
distribution within constrained energy for mobile adhoc networks. This has to
overcome the challenging element of ""1 affects n"" problem which is due to high
dynamicity of groups. Thus this paper shows the specific challenges towards
multicast key management protocols for securing multicast key distribution in
mobile ad hoc networks, and present relevant multicast key management protocols
in mobile ad hoc networks. A comparison is done against some pertinent
performance criteria."
"When Bluetooth devices come within the range of another, an electronic
conversation takes place to determine whether the devices in range are known or
whether one needs to control the other. Most Bluetooth devices do not require
any form of user interaction for this to occur. If devices within range are
known to one another, the devices automatically form a network known as a
pairing. Authentication addresses the identity of each communicating device.
The sender sends an encrypted authentication request frame to the receiver. The
receiver sends an encrypted challenge frame back to the sender. Both perform a
predefined algorithm. The sender sends its findings back to the receiver, which
in turn either allows or denies the connection. There are three different
functions for authentication in Bluetooth-E1, E2, and E3. E1 is used when
encrypting the authorization challenge-response values.E2 is for generating
different link keys.E3 is used when creating the encryption key."
"Attacks on cryptographic systems are limited by the available computational
resources. A theoretical understanding of these resource limitations is needed
to evaluate the security of cryptographic primitives and procedures. This study
uses an Attacker versus Environment game formalism based on computability logic
to quantify Shannon's work function and evaluate resource use in cryptanalysis.
A simple cost function is defined which allows to quantify a wide range of
theoretical and real computational resources. With this approach the use of
custom hardware, e.g., FPGA boards, in cryptanalysis can be analyzed. Applied
to real cryptanalytic problems, it raises, for instance, the expectation that
the computer time needed to break some simple 90 bit strong cryptographic
primitives might theoretically be less than two years."
"In cluster-based routing protocol (CBRP), two-level hierarchical structure is
successfully used to reduce over-flooding in wireless Ad Hoc networks. As it is
vulnerable to a single point of failure, we propose a new adaptive distributed
threshold scheme to replace the cluster head by a group of cluster heads within
each cluster, called COUNCIL, and distribute the service of single cluster head
to multiple cluster heads using (k,n) threshold secret sharing scheme. An Ad
Hoc network formed by COUNCIL based clusters can work correctly when the number
of compromised cluster heads is smaller than k. To implement this adaptive
threshold scheme in wireless Ad Hoc Networks, membership of the clusters should
be defined in an adaptive way. In this paper, we mainly discuss our algorithm
for forming COUNCIL based clusters using the concept of dominating set from
graph theory."
"The traditional web caching is currently limited to static documents only. A
page generated on the fly from a server side script may have different contents
on different accesses and hence cannot be cached. A number of proposals for
attacking the problem have emerged based on the observation that different
instances of a dynamic document are usually quite similar in most cases, i.e.
they have a lot of common HTML code. In this paper, we first review these
related techniques and show their inadequacy for practical use. We then present
a general and fully automatic technique called Vcache based on the
decomposition of dynamic documents into a hierarchy of templates and bindings.
The technique is designed keeping in mind languages like Perl and C etc that
generate the documents using low-level print like statements. These languages
together, account for the largest number of dynamic documents on the web."
"As the amount of personal information stored at remote service providers
increases, so does the danger of data theft. When connections to remote
services are made in the clear and authenticated sessions are kept using HTTP
cookies, data theft becomes extremely easy to achieve. In this paper, we study
the architecture of the world's largest service provider, i.e., Google. First,
with the exception of a few services that can only be accessed over HTTPS
(e.g., Gmail), we find that many Google services are still vulnerable to simple
session hijacking. Next, we present the Historiographer, a novel attack that
reconstructs the web search history of Google users, i.e., Google's Web
History, even though such a service is supposedly protected from session
hijacking by a stricter access control policy. The Historiographer uses a
reconstruction technique inferring search history from the personalized
suggestions fed by the Google search engine. We validate our technique through
experiments conducted over real network traffic and discuss possible
countermeasures. Our attacks are general and not only specific to Google, and
highlight privacy concerns of mixed architectures using both secure and
insecure connections."
"Many steganographic techniques were proposed for hiding secret message inside
images, the simplest of them being the LSB data hiding. In this paper, we
suggest a novel data hiding technique in an HTML Web page and also propose some
simple techniques to extend the embedding technique to source codes written in
any programming language (both case insensitive like HTML, Pascal and case
sensitive languages like C, C++, Java). We basically try to exploit the
case-redundancy in case-insensitive language, while we try hiding data with
minimal changes in the source code (almost not raising suspicion). HTML Tags
are case insensitive and hence an alphabet in lowercase and one in uppercase
present inside an HTML tag are interpreted in the same manner by the browser,
i.e., change in case in a web page is imperceptible to the browser. We first
exploit this redundancy and use it to embed secret data inside an web page,
with no changes visible to the user of the web page, so that he can not even
suspect about the data hiding. The embedded data can be recovered by viewing
the source of the HTML page. This technique can easily be extended to embed
secret message inside any piece of source-code where the standard interpreter
of that language is case-insensitive. For case-sensitive programming languages
we do minimal changes in the source code (e.g., add an extra character in the
token identified by the lexical analyzer) without violating the lexical and
syntactic notation for that language) and try to make the change almost
imperceptible."
"In this paper, a few novel data hiding techniques are proposed. These
techniques are improvements over the classical LSB data hiding technique and
the Fibonacci LSB data-hiding technique proposed by Battisti et al. \cite{r1}.
The classical LSB technique is the simplest, but using this technique it is
possible to embed only in first few bit-planes, since image quality becomes
drastically distorted when embedding in higher bit-planes. Battisti et al.
\cite{r1} proposed an improvement over this by using Fibonacci decomposition
technique and generating a different set of virtual bit-planes all together,
thereby increasing the number of bit-planes. In this paper, first we
mathematically model and generalize this particular approach of virtual
bit-plane generation. Then we propose two novel embedding techniques, both of
which are special-cases of our generalized model. The first embedding scheme is
based on decomposition of a number (pixel-value) in sum of prime numbers, while
the second one is based on decomposition in sum of natural numbers. Each of
these particular representations generates a different set of (virtual)
bit-planes altogether, suitable for embedding purposes. They not only allow one
to embed secret message in higher bit-planes but also do it without much
distortion, with a much better stego-image quality, in a reliable and secured
manner, guaranteeing efficient retrieval of secret message. A comparative
performance study between the classical Least Significant Bit (LSB) method, the
data hiding technique using Fibonacci -p-Sequence decomposition and our
proposed schemes has been done. Theoretical analysis indicates that image
quality of the stego-image hidden by the technique using Fibonacci
decomposition improves against simple LSB substitution method, while the same
using the prime decomposition method improves drastically against that using
Fibonacci decomposition technique, and finally the natural number decomposition
method is a further improvement against that using prime decomposition
technique. Also, optimality for the last technique is proved. For both of our
data-hiding techniques, the experimental results show that, the stego-image is
visually indistinguishable from the original cover image."
"Noninterference provides a control over information flow in a system for
ensuring confidentiality and integrity properties. In the literature this
notion has been well studied as transitive noninterference and intransitive
noninterference. In this paper we define a framework on the notion of
conditional noninterference, which allows to specify information flow policies
based on the semantics of action channels. Our new policies subsume the
policies of both transitive and intransitive noninterference, and support
dynamic requirements such as upgrading and downgrading. We also present
unwinding relations that are both sound and complete for the new policies."
"In this paper, a novel data hiding technique is proposed, as an improvement
over the Fibonacci LSB data-hiding technique proposed by Battisti et al,based
on decomposition of a number (pixel-value) in sum of natural numbers. This
particular representation again generates a different set of (virtual)
bit-planes altogether, suitable for embedding purposes. We get more bit-planes
than that we get using Prime technique.These bit-planes not only allow one to
embed secret message in higher bit-planes but also do it without much
distortion, with a much better stego-image quality, and in a reliable and
secured manner, guaranteeing efficient retrieval of secret message. A
comparative performance study between the classical Least Significant Bit(LSB)
method, the Fibonacci LSB data-hiding technique and the proposed schemes
indicate that image quality of the stego-image hidden by the technique using
the natural decomposition method improves drastically against that using Prime
and Fibonacci decomposition technique. Experimental results also illustrate
that, the stego-image is visually indistinguishable from the original
cover-image. Also we show the optimality of our technique."
"Secure sum computation of private data inputs is an interesting example of
Secure Multiparty Computation (SMC) which has attracted many researchers to
devise secure protocols with lower probability of data leakage. In this paper,
we provide a novel protocol to compute the sum of individual data inputs with
zero probability of data leakage when two neighbor parties collude to know the
data of a middle party. We break the data block of each party into number of
segments and redistribute the segments among parties before the computation.
These entire steps create a scenario in which it becomes impossible for semi
honest parties to know the private data of some other party."
"With the rapid development of various multimedia technologies, more and more
multimedia data are generated and transmitted in the medical, also the internet
allows for wide distribution of digital media data. It becomes much easier to
edit, modify and duplicate digital information. Besides that, digital documents
are also easy to copy and distribute, therefore it will be faced by many
threats. It is a big security and privacy issue, it become necessary to find
appropriate protection because of the significance, accuracy and sensitivity of
the information, which may include some sensitive information which should not
be accessed by or can only be partially exposed to the general users.
Therefore, security and privacy has become an important. Another problem with
digital document and video is that undetectable modifications can be made with
very simple and widely available equipment, which put the digital material for
evidential purposes under question. Cryptography considers one of the
techniques which used to protect the important information. In this paper a
three algorithm of multimedia encryption schemes have been proposed in the
literature and description. The New Comparative Study between DES, 3DES and AES
within Nine Factors achieving an efficiency, flexibility and security, which is
a challenge of researchers."
"This article presets a review of the achievements rapidly developing field of
cryptography - public-key cryptography based on the lattice theory. Paper
contains the necessary basic concepts and the major problems of the lattice
theory, as well as together with the description on the benefits of this
cryptography class - the properties of the reliability to quantum computers and
full homomorphism, the shortcomings of specific implementations."
"Type-flaw attacks upon security protocols wherein agents are led to
misinterpret message types have been reported frequently in the literature.
Preventing them is crucial for protocol security and verification. Heather et
al. proved that tagging every message field with it's type prevents all
type-flaw attacks under a free message algebra and perfect encryption system.
In this paper, we prove that type-flaw attacks can be prevented with the same
technique even under the ACUN algebraic properties of XOR which is commonly
used in ""real-world"" protocols such as SSL 3.0. Our proof method is general and
can be easily extended to other monoidal operators that possess properties such
as Inverse and Idempotence as well. We also discuss how tagging could be used
to prevent type-flaw attacks under other properties such as associativity of
pairing, commutative encryption, prefix property and homomorphic encryption."
"In this paper, a novel data hiding technique is proposed, as an improvement
over the Fibonacci LSB data-hiding technique proposed by Battisti et al. First
we mathematically model and generalize our approach. Then we propose our novel
technique, based on decomposition of a number (pixel-value) in sum of prime
numbers. The particular representation generates a different set of (virtual)
bit-planes altogether, suitable for embedding purposes. They not only allow one
to embed secret message in higher bit-planes but also do it without much
distortion, with a much better stego-image quality, and in a reliable and
secured manner, guaranteeing efficient retrieval of secret message. A
comparative performance study between the classical Least Significant Bit
(LSB)method, the Fibonacci LSB data-hiding technique and our proposed schemes
has been done. Analysis indicates that image quality of the stego-image hidden
by the technique using Fibonacci decomposition improves against that using
simple LSB substitution method, while the same using the prime decomposition
method improves drastically against that using Fibonacci decomposition
technique. Experimental results show that, the stego-image is visually
indistinguishable from the original cover-image."
"Cryptographic hash functions for calculating the message digest of a message
has been in practical use as an effective measure to maintain message integrity
since a few decades. This message digest is unique, irreversible and avoids all
types of collisions for any given input string. The message digest calculated
from this algorithm is propagated in the communication medium along with the
original message from the sender side and on the receiver side integrity of the
message can be verified by recalculating the message digest of the received
message and comparing the two digest values. In this paper we have designed and
developed a new algorithm for calculating the message digest of any message and
implemented t using a high level programming language. An experimental analysis
and comparison with the existing MD5 hashing algorithm, which is predominantly
being used as a cryptographic hashing tool, shows this algorithm to provide
more randomness and greater strength from intrusion attacks. In this algorithm
the plaintext message string is converted into binary string and fragmented
into blocks of 128 bits after being padded with user defined padding bits. Then
using a pseudo random number generator a key is generated for each block and
operated with the respective block by a bitwise operator. This process is
terated for the whole message and finally a fixed length message digest is
obtained."
"We present a framework for fully-simulatable $h$-out-of-$n$ oblivious
transfer ($OT^{n}_{h}$) with security against non-adaptive malicious
adversaries. The framework costs six communication rounds and costs at most
$40n$ public-key operations in computational overhead. Compared with the known
protocols for fully-simulatable oblivious transfer that works in the plain mode
(where there is no trusted common reference string available) and proven to be
secure under standard model (where there is no random oracle available), the
instantiation based on the decisional Diffie-Hellman assumption of the
framework is the most efficient one, no matter seen from communication rounds
or computational overhead.
  Our framework uses three abstract tools, i.e., perfectly binding commitment,
perfectly hiding commitment and our new smooth projective hash. This allows a
simple and intuitive understanding of its security.
  We instantiate the new smooth projective hash under the lattice assumption,
the decisional Diffie-Hellman assumption, the decisional $N$-th residuosity
assumption, the decisional quadratic residuosity assumption. This indeed shows
that the folklore that it is technically difficult to instantiate the
projective hash framework under the lattice assumption is not true. What's
more, by using this lattice-based hash and lattice-based commitment scheme, we
gain a concrete protocol for $OT^{n}_{h}$ which is secure against quantum
algorithms."
"An efficient algorithm for computing lower bounds on the global linear
complexity of nonlinearly filtered PN-sequences is presented. The technique
here developed is based exclusively on the realization of bit wise logic
operations, which makes it appropriate for both software simulation and
hardware implementation. The present algorithm can be applied to any arbitrary
nonlinear function with a unique term of maximum order. Thus, the extent of its
application for different types of filter generators is quite broad.
Furthermore, emphasis is on the large lower bounds obtained that confirm the
exponential growth of the global linear complexity for the class of nonlinearly
filtered sequences."
"The main goal of this work is to propose the design of secret sharing schemes
based on hard-on-average problems. It includes the description of a new
multiparty protocol whose main application is key management in networks. Its
unconditionally perfect security relies on a discrete mathematics problem
classiffied as DistNP-Complete under the average-case analysis, the so-called
Distributional Matrix Representability Problem. Thanks to the use of the search
version of the mentioned decision problem, the security of the proposed scheme
is guaranteed. Although several secret sharing schemes connected with
combinatorial structures may be found in the bibliography, the main
contribution of this work is the proposal of a new secret sharing scheme based
on a hard-on-average problem, which allows to enlarge the set of tools for
designing more secure cryptographic applications."
"The main objective of this work is twofold. On the one hand, it gives a brief
overview of the area of two-party cryptographic protocols. On the other hand,
it proposes new schemes and guidelines for improving the practice of robust
protocol design. In order to achieve such a double goal, a tour through the
descriptions of the two main cryptographic primitives is carried out. Within
this survey, some of the most representative algorithms based on the Theory of
Finite Fields are provided and new general schemes and specific algorithms
based on Graph Theory are proposed."
"This letter shows that linear Cellular Automata based on rules 90/150
generate all the solutions of linear difference equations with binary constant
coefficients. Some of these solutions are pseudo-random noise sequences with
application in cryptography: the sequences generated by the class of shrinking
generators. Consequently, this contribution show that shrinking generators do
not provide enough guarantees to be used for encryption purposes. Furthermore,
the linearization is achieved through a simple algorithm about which a full
description is provided."
"This work initiates an analysis of several cryptographic protocols from a
rational point of view using a game-theoretical approach, which allows us to
represent not only the protocols but also possible misbehaviours of parties.
Concretely, several concepts of two-person games and of two-party cryptographic
protocols are here combined in order to model the latters as the formers. One
of the main advantages of analysing a cryptographic protocol in the game-theory
setting is the possibility of describing improved and stronger cryptographic
solutions because possible adversarial behaviours may be taken into account
directly. With those tools, protocols can be studied in a malicious model in
order to find equilibrium conditions that make possible to protect honest
parties against all possible strategies of adversaries."
"In this paper, we develop a new cellular automata-based linear model for
several nonlinear pseudorandom number generators with practical applications in
symmetric cryptography. Such a model generates all the solutions of linear
binary difference equations as well as many of these solutions are
pseudo-random keystream sequences. In this way, a linear structure based on
cellular automata may be used to generate not only difference equation
solutions but also cryptographic sequences. The proposed model is very simple
since it is based exclusively on successive concatenations of a basic linear
automaton."
"This work shows that the cryptanalysis of the shrinking generator requires
fewer intercepted bits than what indicated by the linear complexity. Indeed,
whereas the linear complexity of shrunken sequences is between $A \cdot
2^(S-2)$ and $A \cdot 2^(S-1)$, we claim that the initial states of both
component registers are easily computed with less than $A \cdot S$ shrunken
bits. Such a result is proven thanks to the definition of shrunken sequences as
interleaved sequences. Consequently, it is conjectured that this statement can
be extended to all interleaved sequences. Furthermore, this paper confirms that
certain bits of the interleaved sequences have a greater strategic importance
than others, which may be considered as a proof of weakness of interleaved
generators."
"We present a new approach to edit distance attacks on certain
clock-controlled generators, which applies basic concepts of Graph Theory to
simplify the search trees of the original attacks in such a way that only the
most promising branches are analyzed. In particular, the proposed improvement
is based on cut sets defined on some graphs so that certain shortest paths
provide the edit distances. The strongest aspects of the proposal are that the
obtained results from the attack are absolutely deterministic, and that many
inconsistent initial states of the target registers are recognized beforehand
and avoided during search."
"This work proposes a new distributed and self-organized authentication scheme
for Mobile Ad-hoc NETworks (MANETs). Apart from describing all its components,
special emphasis is placed on proving that the proposal fulfils most
requirements derived from the special characteristics of MANETs, including
limited physical protection of broadcast medium, frequent route changes caused
by mobility, and lack of structured hierarchy. Interesting conclusions are
obtained from an analysis of simulation experiments in different scenarios."
"A new class of linear sequence generators based on cellular automata is here
introduced in order to model several nonlinear keystream generators with
practical applications in symmetric cryptography. The output sequences are
written as solutions of linear difference equations, and three basic properties
(period, linear complexity and number of different output sequences) are
analyzed."
"In Mobile Ad Hoc Networks (MANET), various types of Denial of Service Attacks
(DoS) are possible because of the inherent limitations of its routing
protocols. Considering the Ad Hoc On Demand Vector (AODV) routing protocol as
the base protocol it is possible to find a suitable solution to over-come the
attack of initiating / forwarding fake Route Requests (RREQs) that lead to
hogging of network resources and hence denial of service to genuine nodes. In
this paper, a proactive scheme is proposed that could prevent a specific kind
of DoS attack and identify the misbehaving node. Since the proposed scheme is
distributed in nature it has the capability to prevent Distributed DoS (DDoS)
as well. The performance of the proposed algorithm in a series of simulations
reveal that the proposed scheme provides a better solution than existing
approaches with no extra overhead."
"Reactive routing protocols like Ad Hoc On-Demand Distance Vector Routing
(AODV) and Dynamic Source Routing (DSR)in Ad-Hoc Wireless Networks which are
used in Mobile and Ad Hoc Networks (MANETs) work by flooding the network with
control packets. There is generally a limit on the number of these packets that
can be generated or forwarded. But a malicious node can disregard this limit
and flood the network with fake control packets. These packets hog the limited
bandwidth and processing power of genuine nodes in the network while being
forwarded. Due to this, genuine route requests suffer and many routes either do
not get a chance to materialize or they end up being longer than otherwise. In
this paper we propose a non cryptographic solution to the above problem and
prove its efficiency by means of simulation."
"This paper introduces a new framework for data hiding security. Contrary to
the existing ones, the approach introduced here is not based on probability
theory. In this paper, a scheme is considered as secure if its behavior is
proven unpredictable. The objective of this study is to enrich the existing
notions of data hiding security with a new rigorous and practicable one. This
new definition of security is based on the notion of topological chaos. It
could be used to reinforce the confidence on a scheme previously proven as
secure by other approaches and it could also be used to study some classes of
attacks that currently cannot be studied by the existing security approaches.
After presenting the theoretical framework of the study, a concrete example is
detailed in order to show how our approach can be applied."
"A new framework for information hiding security, called chaos-security, has
been proposed in a previous study. It is based on the evaluation of
unpredictability of the scheme, whereas existing notions of security, as
stego-security, are more linked to information leaks. It has been proven that
spread-spectrum techniques, a well-known stego-secure scheme, are chaos-secure
too. In this paper, the links between the two notions of security is deepened
and the usability of chaos-security is clarified, by presenting a novel data
hiding scheme that is twice stego and chaos-secure. This last scheme has better
scores than spread-spectrum when evaluating qualitative and quantitative
chaos-security properties. Incidentally, this result shows that the new
framework for security tends to improve the ability to compare data hiding
scheme."
"Key management in wireless sensor networks faces several new challenges. The
scale, resource limitations, and new threats such as node capture necessitate
the use of an on-line key generation by the nodes themselves. However, the cost
of such schemes is high since their secrecy is based on computational
complexity. Recently, several research contributions justified that the
wireless channel itself can be used to generate information-theoretic secure
keys. By exchanging sampling messages during movement, a bit string can be
derived that is only known to the involved entities. Yet, movement is not the
only possibility to generate randomness. The channel response is also strongly
dependent on the frequency of the transmitted signal. In our work, we introduce
a protocol for key generation based on the frequency-selectivity of channel
fading. The practical advantage of this approach is that we do not require node
movement. Thus, the frequent case of a sensor network with static motes is
supported. Furthermore, the error correction property of the protocol mitigates
the effects of measurement errors and other temporal effects, giving rise to an
agreement rate of over 97%. We show the applicability of our protocol by
implementing it on MICAz motes, and evaluate its robustness and secrecy through
experiments and analysis."
"In this paper, we introduce new learning algorithms for reducing false
positives in intrusion detection. It is based on decision tree-based attribute
weighting with adaptive na\""ive Bayesian tree, which not only reduce the false
positives (FP) at acceptable level, but also scale up the detection rates (DR)
for different types of network intrusions. Due to the tremendous growth of
network-based services, intrusion detection has emerged as an important
technique for network security. Recently data mining algorithms are applied on
network-based traffic data and host-based program behaviors to detect
intrusions or misuse patterns, but there exist some issues in current intrusion
detection algorithms such as unbalanced detection rates, large numbers of false
positives, and redundant attributes that will lead to the complexity of
detection model and degradation of detection accuracy. The purpose of this
study is to identify important input attributes for building an intrusion
detection system (IDS) that is computationally efficient and effective.
Experimental results performed using the KDD99 benchmark network intrusion
detection dataset indicate that the proposed approach can significantly reduce
the number and percentage of false positives and scale up the balance detection
rates for different types of network intrusions."
"In this paper a homomorphic privacy preserving association rule mining
algorithm is proposed which can be deployed in resource constrained devices
(RCD). Privacy preserved exchange of counts of itemsets among distributed
mining sites is a vital part in association rule mining process. Existing
cryptography based privacy preserving solutions consume lot of computation due
to complex mathematical equations involved. Therefore less computation involved
privacy solutions are extremely necessary to deploy mining applications in RCD.
In this algorithm, a semi-trusted mixer is used to unify the counts of itemsets
encrypted by all mining sites without revealing individual values. The proposed
algorithm is built on with a well known communication efficient association
rule mining algorithm named count distribution (CD). Security proofs along with
performance analysis and comparison show the well acceptability and
effectiveness of the proposed algorithm. Efficient and straightforward privacy
model and satisfactory performance of the protocol promote itself among one of
the initiatives in deploying data mining application in RCD."
"nformation security is an issue of global concern. As the Internet is
delivering great convenience and benefits to the modern society, the rapidly
increasing connectivity and accessibility to the Internet is also posing a
serious threat to security and privacy, to individuals, organizations, and
nations alike. Finding effective ways to detect, prevent, and respond to
intrusions and hacker attacks of networked computers and information systems.
This paper presents a knowledge discovery frame work to detect DoS attacks at
the boundary controllers (routers). The idea is to use machine learning
approach to discover network features that can depict the state of the network
connection. Using important network data (DoS relevant features), we have
developed kernel machine based and soft computing detection mechanisms that
achieve high detection accuracies. We also present our work of identifying DoS
pertinent features and evaluating the applicability of these features in
detecting novel DoS attacks. Architecture for detecting DoS attacks at the
router is presented. We demonstrate that highly efficient and accurate
signature based classifiers can be constructed by using important network
features and machine learning techniques to detect DoS attacks at the boundary
controllers."
"Negative databases - negative representations of a set of data - have been
introduced in 2004 to protect the data they contain. Today, no solution is
known to constitute biometric negative databases. This is surprising as
biometric applications are very demanding of such protection for privacy
reasons. The main difficulty comes from the fact that biometric captures of the
same trait give different results and comparisons of the stored reference with
the fresh captured biometric data has to take into account this variability. In
this paper, we give a first answer to this problem by exhibiting a way to
create and exploit biometric negative databases."
"The evolution of encryption algorithms have led to the development of very
complicated and highly versatile algorithms that sacrifice efficiency for
better and harder to decrypt results. But by the application of a genetic
schema to the encryption of data, a new structure can be created. Genetic
methods and procedures are lethal in the way they handle and manipulate data.
The RAmM algorithm uses four genetic operations that have been developed
specifically for encryption of data. The operations are Replication,
Augmentation, Mutation and Multiplication. The proper application of these
methods according to the rules that have been found to be the best for getting
optimal and correct results produces a ""fingerprint"" that is unique to a pair
of <data , key>. This means that every single data entry can only be decrypted
by using the correct set of key. The application of the RAmM algorithm is in
the field of image encryption and restoration. The boundary and the pixel
values are separately encrypted to produce a very genuine sequence that is
never understood to be an image. The beauty of the procedure is that the entire
image can be reproduced without any color loss or loss of pixel quality."
"We present families of (hyper)elliptic curve which admit an efficient
deterministic encoding function."
"In mobile ad hoc networks, by attacking the corresponding routing protocol,
an attacker can easily disturb the operations of the network. For ad hoc
networks, till now many secured routing protocols have been proposed which
contains some disadvantages. Therefore security in ad hoc networks is a
controversial area till now. In this paper, we proposed a Lightweight and
Attack Resistant Authenticated Routing Protocol (LARARP) for mobile ad hoc
networks. For the route discovery attacks in MANET routing protocols, our
protocol gives an effective security. It supports the node to drop the invalid
packets earlier by detecting the malicious nodes quickly by verifying the
digital signatures of all the intermediate nodes. It punishes the misbehaving
nodes by decrementing a credit counter and rewards the well behaving nodes by
incrementing the credit counter. Thus it prevents uncompromised nodes from
attacking the routes with malicious or compromised nodes. It is also used to
prevent the denial-of-service (DoS) attacks. The efficiency and effectiveness
of LARARP are verified through the detailed simulation studies."
"An elliptic curve-based signcryption scheme is introduced in this paper that
effectively combines the functionalities of digital signature and encryption,
and decreases the computational costs and communication overheads in comparison
with the traditional signature-then-encryption schemes. It simultaneously
provides the attributes of message confidentiality, authentication, integrity,
unforgeability, non-repudiation, public verifiability, and forward secrecy of
message confidentiality. Since it is based on elliptic curves and can use any
fast and secure symmetric algorithm for encrypting messages, it has great
advantages to be used for security establishments in store-and-forward
applications and when dealing with resource-constrained devices."
"Hiding information in network traffic may lead to leakage of confidential
information. In this paper we introduce a new steganographic system: the
PadSteg (Padding Steganography). To authors' best knowledge it is the first
information hiding solution which represents interprotocol steganography i.e.
usage of relation between two or more protocols from the TCP/IP stack to enable
secret communication. PadSteg utilizes ARP and TCP protocols together with an
Etherleak vulnerability (improper Ethernet frame padding) to facilitate secret
communication for hidden groups in LANs (Local Area Networks). Basing on real
network traces we confirm that PadSteg is feasible in today's networks and we
estimate what steganographic bandwidth is achievable while limiting the chance
of disclosure. We also point at possible countermeasures against PadSteg."
"In this paper, we suggest a lower and an upper bound for the Generalized
Fibonacci-p-Sequence, for different values of p. The Fibonacci-p-Sequence is a
generalization of the Classical Fibonacci Sequence. We first show that the
ratio of two consecutive terms in generalized Fibonacci sequence converges to a
p-degree polynomial and then use this result to prove the bounds for
generalized Fibonacci-p sequence, thereby generalizing the exponential bounds
for classical Fibonacci Sequence. Then we show how these results can be used to
prove efficiency for data hiding techniques using generalized Fibonacci
sequence. These steganographic techniques use generalized Fibonacci-p-Sequence
for increasing number available of bit-planes to hide data, so that more and
more data can be hidden into the higher bit-planes of any pixel without causing
much distortion of the cover image. This bound can be used as a theoretical
proof for efficiency of those techniques, for instance it explains why more and
more data can be hidden into the higher bit-planes of a pixel, without causing
considerable decrease in PSNR."
"A Vehicular Ad-hoc NETwork (VANET) is a special form of Mobile Ad-hoc Network
designed to provide communications among nearby vehicles and between vehicles
and nearby fixed roadside equipment. Its main goal is to improve safety and
comfort for passengers, but it can also be used for commercial applications. In
this latter case, it will be necessary to motivate drivers to cooperate and
contribute to packet forwarding in Vehicle-to-Vehicle and Vehicle-to-Roadside
communications. This paper examines the problem, analyzes the drawbacks of
known schemes and proposes a new secure incentive scheme to stimulate
cooperation in VANETs, taking into account factors such as time and distance."
"A Vehicular Ad-Hoc Network (VANET) is a form of Mobile ad-hoc network, to
provide communications among nearby vehicles and between vehicles and nearby
fixed roadside equipment. The key operation in VANETs is the broadcast of
messages. Consequently, the vehicles need to make sure that the information has
been sent by an authentic node in the network. VANETs present unique challenges
such as high node mobility, real-time constraints, scalability, gradual
deployment and privacy. No existent technique addresses all these requirements.
In particular, both inter-vehicle and vehicle-to-roadside wireless
communications present different characteristics that should be taken into
account when defining node authentication services. That is exactly what is
done in this paper, where the features of inter-vehicle and vehicle-to-roadside
communications are analyzed to propose differentiated services for node
authentication, according to privacy and efficiency needs."
"This work proposes a new architecture, called Global Authentication Scheme
for Mobile Ad-hoc Networks (GASMAN), for fully distributed and self-organized
authentication. In this paper apart from describing all the GASMAN components,
special emphasis is placed on proving that it fulfils every requirement of a
secure distributed authentication scheme, including limited physical protection
of broadcast medium, frequent route changes caused by mobility, lack of
structured hierarchy, etc. Furthermore, an extensive analysis through
simulation experiments in different scenarios is described and discussed."
"In this paper, we analyze a knapsack schemes. The one is suggested by Su,
which is relied on a new method entitled permutation combination method. We
demonstrate that this permutation method is useless to the security of the
scheme. Since the special super increasing construction, we can break this
scheme employ the algorithm provided by Shamir scheme. Finally, we provide an
enhanced version of Su scheme to avoid these attacks."
"The notion of an ad hoc network is a new paradigm that allows mobile hosts
(nodes) to communicate without relying on a predefined infrastructure to keep
the network connected. Most nodes are assumed to be mobile and communication is
assumed to be wireless. The mobility of nodes in an ad-hoc network means that
both the population and the topology of the network are highly dynamic. It is
very difficult to design a once-for-all intrusion detection system. A secure
protocol should atleast include mechanisms against known attack types. In
addition, it should provide a scheme to easily add new security features in the
future. The paper includes the detailed description of Proposed Intrusion
Detection System based on Local Reputation Scheme. The proposed System also
includes concept of Redemption and Fading these are mechanism that allow nodes
previously considered malicious to become a part of the network again. The
simulation of the proposed system is to be done using NS-2 simulator."
"Biometrics deals with identity verification of an individual by using certain
physiological or behavioral features associated with a person. Biometric
identification systems using fingerprints patterns are called AFIS (Automatic
Fingerprint Identification System). In this paper a composite method for
Fingerprint recognition is considered using a combination of Fast Fourier
Transform (FFT) and Sobel Filters for improvement of a poor quality fingerprint
image. Steganography hides messages inside other messages in such a way that an
""adversary"" would not even know a secret message were present. The objective of
our paper is to make a bio-secure system. In this paper bio-authentication has
been implemented in terms of finger print recognition and the second part of
the paper is an interactive steganographic system hides the user's data by two
options- creating a songs list or hiding the data in an image."
"E-Commerce offers the banking industry great opportunity, but also creates a
set of new risks and vulnerability such as security threats. Information
security, therefore, is an essential management and technical requirement for
any efficient and effective Payment transaction activities over the internet.
Still, its definition is a complex endeavor due to the constant technological
and business change and requires a coordinated match of algorithm and technical
solutions. Ecommerce is not appropriate to all business transactions and,
within e-commerce there is no one technology that can or should be appropriate
to all requirements. E-commerce is not a new phenomenon; electronic markets,
electronic data interchange and customer e-commerce. The use of electronic data
interchanges as a universal and non-proprietary way of doing business. Through
the electronic transaction the security is the most important phenomena to
enhance the banking transaction security via payment transaction."
"Radio Frequency Identification (RFID) technology one of the most promising
technologies in the field of ubiquitous computing. Indeed, RFID technology may
well replace barcode technology. Although it offers many advantages over other
identification systems, there are also associated security risks that are not
easy to be addressed. When designing a real lightweight authentication protocol
for low cost RFID tags, a number of challenges arise due to the extremely
limited computational, storage and communication abilities of Low-cost RFID
tags. This paper proposes a real mutual authentication protocol for low cost
RFID tags. The proposed protocol prevents passive attacks as active attacks are
discounted when designing a protocol to meet the requirements of low cost RFID
tags. However the implementation of the protocol meets the limited abilities of
low cost RFID tags."
"The objective of this is to develop a Fuzzy aided Application layer Semantic
Intrusion Detection System (FASIDS) which works in the application layer of the
network stack. FASIDS consist of semantic IDS and Fuzzy based IDS. Rule based
IDS looks for the specific pattern which is defined as malicious. A
non-intrusive regular pattern can be malicious if it occurs several times with
a short time interval. For detecting such malicious activities, FASIDS is
proposed in this paper. At application layer, HTTP traffic's header and payload
are analyzed for possible intrusion. In the proposed misuse detection module,
the semantic intrusion detection system works on the basis of rules that define
various application layer misuses that are found in the network. An attack
identified by the IDS is based on a corresponding rule in the rule-base. An
event that doesn't make a 'hit' on the rule-base is given to a Fuzzy Intrusion
Detection System (FIDS) for further analysis."
"Quantum Cryptography or Quantum key distribution (QKD) is a technique that
allows the secure distribution of a bit string, used as key in cryptographic
protocols. When it was noted that quantum computers could break public key
cryptosystems based on number theory extensive studies have been undertaken on
QKD. Based on quantum mechanics, QKD offers unconditionally secure
communication. Now, the progress of research in this field allows the
anticipation of QKD to be available outside of laboratories within the next few
years. Efforts are made to improve the performance and reliability of the
implemented technologies. But several challenges remain despite this big
progress. The task of how to test the apparatuses of QKD For example did not
yet receive enough attention. These devises become complex and demand a big
verification effort. In this paper we are interested in an approach based on
the technique of probabilistic model checking for studying quantum information.
Precisely, we use the PRISM tool to analyze the security of BB84 protocol and
we are focused on the specific security property of eavesdropping detection. We
show that this property is affected by the parameters of quantum channel and
the power of eavesdropper."
"In secure multi-party computation $n$ parties jointly evaluate an $n$-variate
function $f$ in the presence of an adversary which can corrupt up till $t$
parties. Almost all the works that have appeared in the literature so far
assume the presence of authenticated channels between the parties. This
assumption is far from realistic. Two directions of research have been borne
from relaxing this (strong) assumption: (a) The adversary is virtually
omnipotent and can control all the communication channels in the network, (b)
Only a partially connected topology of authenticated channels is guaranteed and
adversary controls a subset of the communication channels in the network.
  This work introduces a new setting for (unconditional) secure multiparty
computation problem which is an interesting intermediate model with respect to
the above well studied models from the literature (by sharing a salient feature
from both the above models). We consider the problem of (unconditional) secure
multi-party computation when 'some' of the communication channels connecting
the parties can be corrupted passively as well as actively. For this setting,
some honest parties may be connected to several other honest parties via
corrupted channels and may not be able to authentically communicate with them.
Such parties may not be assured the canonical guarantees of correctness or
privacy. We present refined definitions of security for this new intermediate
model of unconditional multiparty computation. We show how to adapt protocols
for (Unconditional) secure multiparty computation to realize the definitions
and also argue the tightness of the results achieved by us."
"In 1998 [8], Patarin proposed an efficient cryptosystem called Little Dragon
which was a variant a variant of Matsumoto Imai cryptosystem C*. However
Patarin latter found that Little Dragon cryptosystem is not secure [8], [3]. In
this paper we propose a cryptosystem Little Dragon Two which is as efficient as
Little Dragon cryptosystem but secure against all the known attacks. Like
Little Dragon cryptosystem the public key of Little Dragon Two is mixed type
that is quadratic in plaintext and cipher text variables. So the public key
size of Little Dragon Two is equal to Little Dragon Cryptosystem. Our public
key algorithm is bijective and can be used for both encryption and signatures."
"In this paper, the systematisation and classification of modern quantum
technologies of information security against cyber-terrorist attack are carried
out. The characteristic of the basic directions of quantum cryptography from
the viewpoint of the quantum technologies used is given. A qualitative analysis
of the advantages and disadvantages of concrete quantum protocols is made. The
current status of the problem of practical quantum cryptography use in
telecommunication networks is considered. In particular, a short review of
existing commercial systems of quantum key distribution is given."
"Stream Control Transmission Protocol (SCTP) is a new transport layer protocol
that is due to replace TCP (Transmission Control Protocol) and UDP (User
Datagram Protocol) protocols in future IP networks. Currently, it is
implemented in such operating systems like BSD, Linux, HP-UX or Sun Solaris. It
is also supported in Cisco network devices operating system (Cisco IOS) and may
be used in Windows. This paper describes potential steganographic methods that
may be applied to SCTP and may pose a threat to network security. Proposed
methods utilize new, characteristic SCTP features like multi-homing and
multistreaming. Identified new threats and suggested countermeasures may be
used as a supplement to RFC 5062, which describes security attacks in SCTP
protocol and can induce further standard modifications."
"This paper presents a new steganographic method called WiPad (Wireless
Padding). It is based on the insertion of hidden data into the padding of
frames at the physical layer of WLANs (Wireless Local Area Networks). A
performance analysis based on a Markov model, previously introduced and
validated by the authors in [10], is provided for the method in relation to the
IEEE 802.11 a/g standards. Its results prove that maximum steganographic
bandwidth for WiPad is as high as 1.1 Mbit/s for data frames and 0.44 Mbit/s
for acknowledgment (ACK) frames. To the authors' best knowledge this is the
most capacious of all the known steganographic network channels."
"Many significant functionalities of vehicular ad hoc networks (VANETs)
require that nodes have knowledge of the positions of other vehicles, and
notably of those within communication range. However, adversarial nodes could
provide false position information or disrupt the acquisition of such
information. Thus, in VANETs, the discovery of neighbor positions should be
performed in a secure manner. In spite of a multitude of security protocols in
the literature, there is no secure discovery protocol for neighbors positions.
We address this problem in our paper: we design a distributed protocol that
relies solely on information exchange among one-hop neighbors, we analyze its
security properties in presence of one or multiple (independent or colluding)
adversaries, and we evaluate its performance in a VANET environment using
realistic mobility traces. We show that our protocol can be highly effective in
detecting falsified position information, while maintaining a low rate of false
positive detections."
"Secret sharing in user hierarchy represents a challenging area for research.
Although a lot of work has already been done in this direc- tion, this paper
presents a novel approach to share a secret among a hierarchy of users while
overcoming the limitations of the already exist- ing mechanisms. Our work is
based on traditional (k +1; n)-threshold secret sharing, which is secure as
long as an adversary can compromise not more than k secret shares. But in real
life it is often feasible for an adversary to obtain more than k shares over a
long period of time. So, in our work we also present a way to overcome this
vulnerability, while implementing our hierarchical secret sharing scheme. The
use of Elliptic Curve Cryptography makes the computations easier and faster in
our work."
"Improved interoperability between public and private organizations is of key
significance to make digital government newest triumphant. Digital Government
interoperability, information sharing protocol and security are measured the
key issue for achieving a refined stage of digital government. Flawless
interoperability is essential to share the information between diverse and
merely dispersed organisations in several network environments by using
computer based tools. Digital government must ensure security for its
information systems, including computers and networks for providing better
service to the citizens. Governments around the world are increasingly
revolving to information sharing and integration for solving problems in
programs and policy areas. Evils of global worry such as syndrome discovery and
manage, terror campaign, immigration and border control, prohibited drug
trafficking, and more demand information sharing, harmonization and cooperation
amid government agencies within a country and across national borders. A number
of daunting challenges survive to the progress of an efficient information
sharing protocol. A secure and trusted information-sharing protocol is required
to enable users to interact and share information easily and perfectly across
many diverse networks and databases globally."
"We introduce a new simulation platform called Insight, created to design and
simulate cyber-attacks against large arbitrary target scenarios. Insight has
surprisingly low hardware and configuration requirements, while making the
simulation a realistic experience from the attacker's standpoint. The scenarios
include a crowd of simulated actors: network devices, hardware devices,
software applications, protocols, users, etc. A novel characteristic of this
tool is to simulate vulnerabilities (including 0-days) and exploits, allowing
an attacker to compromise machines and use them as pivoting stones to continue
the attack. A user can test and modify complex scenarios, with several
interconnected networks, where the attacker has no initial connectivity with
the objective of the attack. We give a concise description of this new
technology, and its possible uses in the security research field, such as
pentesting training, study of the impact of 0-days vulnerabilities, evaluation
of security countermeasures, and risk assessment tool."
"Multiple rotation-based transformation (MRBT) was introduced recently for
mitigating the apriori-knowledge independent component analysis (AK-ICA) attack
on rotation-based transformation (RBT), which is used for privacy-preserving
data clustering. MRBT is shown to mitigate the AK-ICA attack but at the expense
of data utility by not enabling conventional clustering. In this paper, we
extend the MRBT scheme and introduce an augmented rotation-based transformation
(ARBT) scheme that utilizes linearity of transformation and that both mitigates
the AK-ICA attack and enables conventional clustering on data subsets
transformed using the MRBT. In order to demonstrate the computational
feasibility aspect of ARBT along with RBT and MRBT, we develop a toolkit and
use it to empirically compare the different schemes of privacy-preserving data
clustering based on data transformation in terms of their overhead and privacy."
"Software digital rights management is a pressing need for the software
development industry which remains, as no practical solutions have been
acclamaimed succesful by the industry. We introduce a novel software-protection
method, fully implemented with today's technologies, that provides traitor
tracing and license enforcement and requires no additional hardware nor
inter-connectivity.
  Our work benefits from the use of secure triggers, a cryptographic primitive
that is secure assuming the existence of an ind-cpa secure block cipher. Using
our framework, developers may insert license checks and fingerprints, and
obfuscate the code using secure triggers. As a result, this rises the cost that
software analysis tools have detect and modify protection mechanisms. Thus
rising the complexity of cracking this system."
"In this work we present a prototype for simulating computer network attacks.
Our objective is to simulate large networks (thousands of hosts, with
applications and vulnerabilities) while remaining realistic from the attacker's
point of view. The foundation for the simulator is a model of computer
intrusions, based on the analysis of real world attacks. In particular we show
how to interpret vulnerabilities and exploits as communication channels. This
conceptual model gives a tool to describe the theater of operations, targets,
actions and assets involved in multistep network attacks. We conclude with
applications of the attack simulator."
"The MySQL challenge-and-response authentication protocol is proved insecure.
We show how can an eavesdropper impersonate a valid user after witnessing only
a few executions of this protocol. The algorithm of the underlying attack is
presented. Finally we comment about implementations and statistical results."
"A Cellular Automata (CA) is a computing model of complex System using simple
rule. In CA the problem space into number of cell and each cell can be one or
several final state. Cells are affected by neighbours' to the simple rule.
Cellular Automata are highly parallel and discrete dynamical systems, whose
behaviour is completely specified in terms of a local relation. This paper
deals with the Cellular Automata (CA) in cryptography for a class of Block
Ciphers through a new block encryption algorithm based on Reversible
Programmable Cellular Automata Theory. The proposed algorithm belongs to the
class of symmetric key systems."
"There are plenty of security software in market; each claiming the best,
still we daily face problem of viruses and other malicious activities. If we
know the basic working principal of such malware then we can very easily
prevent most of them even without security software. Hackers and crackers are
experts in psychology to manipulate people into giving them access or the
information necessary to get access. This paper discusses the inner working of
such attacks. Case study of Spyware is provided. In this case study, we got
100% success using social engineering techniques for deception on Linux
operating system, which is considered as the most secure operating system. Few
basic principal of defend, for the individual as well as for the organization,
are discussed here, which will prevent most of such attack if followed."
"Computer systems are facing biggest threat in the form of malicious data
which causing denial of service, information theft, financial and credibility
loss etc. No defense technique has been proved successful in handling these
threats. Intrusion Detection and Prevention Systems (IDPSs) being best of
available solutions. These techniques are getting more and more attention.
Although Intrusion Prevention Systems (IPSs) show a good level of success in
detecting and preventing intrusion attempts to networks, they show a visible
deficiency in their performance when they are employed on fast networks. In
this paper we have presented a design including quantitative and qualitative
methods to identify improvement areas in IPSs. Focus group is used for
qualitative analysis and experiment is used for quantitative analysis. This
paper also describes how to reduce the responding time for IPS when an
intrusion occurs on network, and how can IPS be made to perform its tasks
successfully without effecting network speed negatively."
"An application security has two primary goals: first, it is intended to
prevent unauthorised personnel from accessing information at higher
classification than their authorisation. Second, it is intended to prevent
personnel from declassifying information. Using an object oriented approach to
implementing application security results not only with the problem of code
scattering and code tangling, but also results in weaker enforcement of
security. This weaker enforcement of security could be due to the inherent
design of the system or due to a programming error. Aspect Oriented Programming
(AOP) complements Object-Oriented Programming (OOP) by providing another way of
thinking about program structure. The key unit of modularity in OOP is the
class, whereas in AOP the unit of modularity is the aspect. The goal of the
paper is to present that Aspect Oriented Programming AspectJ integrated with
Spring AOP provides very powerful mechanisms for stronger enforcement of
security.Aspect-oriented programming (AOP) allows weaving a security aspect
into an application providing additional security functionality or introducing
completely new security mechanisms.Implementation of security with AOP is a
flexible method to develop separated, extensible and reusable pieces of code
called aspects.In this comparative study paper, we argue that Spring AOP
provides stronger enforcement of security than AspectJ.We have shown both
Spring AOP and AspectJ strive to provide a comprehensive AOP solutions and
complements each other."
"Cross-border access to a variety of data such as market information,
strategic information, or customer-related information defines the daily
business of many global companies, including financial institutions. These
companies are obliged by law to keep a data processing legal for all offered
services. They need to fulfill different security objectives specified by the
legislation. Therefore, they control access to prevent unauthorized users from
using data. Those security objectives, for example confidentiality or secrecy,
are often defined in the eXtensible Access Control Markup Language that
promotes interoperability between different systems. In this paper, we show the
necessity of incorporating the requirements of legislation into access control.
Based on the work flow in a banking scenario we describe a variety of available
contextual information and their interrelations. Different from other access
control systems our main focus is on law-compliant cross-border data access. By
including legislation directly into access decisions, this lawfulness can be
ensured. We also describe our information model to demonstrate how these
policies can be implemented into an existing network and how the components and
contextual information interrelate. Finally, we outline an event flow for a
request made from a remote user exemplifying how such a system decides about
access."
"The number of crime committed based on the malware intrusion is never ending
as the number of malware variants is growing tremendously and the usage of
internet is expanding globally. Malicious codes easily obtained and use as one
of weapon to gain their objective illegally. Hence, in this research, diverse
logs from different OSI layer are explored to identify the traces left on the
attacker and victim logs in order to establish worm trace pattern to defending
against the attack and help revealing true attacker or victim. For the purpose
of this paper, it focused on malware intrusion and traditional worm namely
sasser worm variants. The concept of trace pattern is created by fusing the
attacker's and victim's perspective. Therefore, the objective of this paper is
to propose a general worm trace pattern for attacker's, victim's and multi-step
(attacker/victim)'s by combining both perspectives. These three proposed worm
trace patterns can be extended into research areas in alert correlation and
computer forensic investigation."
"This article is meant to provide an additional point of view, applying known
knowledge, to supply keys that have a series of non-repeating digits, in a
manner that is not usually thought of. Traditionally, prime numbers are used in
encryption as keys that have non-repeating sequences. Usually, non-repetition,
especially of digits in a key, is very sought after in encryption. Uniqueness
in a digit sequence defeats decryption. In searching for methods of
non-decryptable encryption as well as ways to provide unique sequences, other
than using prime numbers [5], the idea of using repeating decimals came to me.
Applied correctly, a repeating decimal series of sufficient length will stand
in as well for a prime number. This is so, because only numbers prime to each
other will produce repeating decimals and; within the repeating sequence there
is uniqueness of digit sequence."
"Catch 22 of cryptography - ""Before two parties can communicate in secret,
they must first communicate in secret"". The weakness of classical cryptographic
communication systems is that secret communication can only take place after a
key is communicated in secret over a totally secure communication channel. Here
comes quantum key distribution which takes advantage of certain phenomena that
occur at the subatomic level, so that any attempt by an enemy to obtain the
bits in a key not only fails, but gets detected as well."
"Given its low dollar and maintenance cost, RFID is poised to become the
enabling technology for inventory control and supply chain management. However,
as an outcome of its low cost, RFID based inventory control is susceptible to
pernicious security and privacy threats. A deleterious attack on such a system
is corporate espionage, where attackers through illicit inventorying infer
sales and restocking trends for products. In this paper, we first present
plausible aftermaths of corporate espionage using real data from online
sources. Second, to mitigate corporate espionage in a retail store environment,
we present a simple lowcost system called Mirage. Mirage uses additional
programmable low cost passive RFID tags called honeytokens to inject noise in
retail store inven-torying. Using a simple history based algorithm that
controls activation and de-activation of honeytokens, Mirage randomizes sales
and restocking trends. We evaluate Mirage in a real warehouse environment using
a commercial off-the-shelf Motorola MC9090 handheld RFID reader and over 450
Gen2 low cost RFID tags. We show that Mirage successfully flattens and
randomizes sales and restocking trends while adding minimal cost to inventory
control."
"This article is meant to provide an additional point of view, applying known
knowledge, to supply keys that have a series of non-repeating digits, in a
manner that is not usually thought of. Traditionally, prime numbers are used in
encryption as keys that have non-repeating sequences. Non-repetition of digits
in a key is very sought after in encryption. Uniqueness in a digit sequence
defeats decryption by method. In searching for methods of non-decryptable
encryption as well as ways to provide unique sequences, other than using prime
numbers, the idea of using repeating decimals came to me. Applied correctly, a
repeating decimal series of sufficient length will stand in as well for a prime
number. This is so, because only numbers prime to each other will produce
repeating decimals and; within the repeating sequence there is uniqueness of
digit sequence."
"This paper presents one suggestion that comprises the authors' experience in
development and implementation of systems for information security in the
Automated Information Systems of the Bulgarian Armed Forces. The architecture
of risk analysis and assessment system for the communication and information
system's information security (CIS IS) has been presented. E-net model of
""Defining"" Subsystem as a tool that allows to examine the subsystems is
proposed as well. Such approach can be applied successfully for communication
and information systems in the business field."
"With the discovery of new exploit techniques, novel protection mechanisms are
needed as well. Mitigations like DEP (Data Execution Prevention) or ASLR
(Address Space Layout Randomization) created a significantly more difficult
environment for exploitation. Attackers, however, have recently researched new
exploitation methods which are capable of bypassing the operating system's
memory mitigations. One of the newest and most popular exploitation techniques
to bypass both of the aforementioned security protections is JIT memory
spraying, introduced by Dion Blazakis. In this article we will present a short
overview of the JIT spraying technique and also novel mitigation methods
against this innovative class of attacks. An anti-JIT spraying library was
created as part of our shellcode execution prevention system."
"In this paper we report our experiment concerning new attacks detection by a
neural network-based Intrusion Detection System. What is crucial for this topic
is the adaptation of the neural network that is already in use to correct
classification of a new ""normal traffic"" and of an attack representation not
presented during the network training process. When it comes to the new attack
it should also be easy to obtain vectors to test and to retrain the neural
classifier. We describe the proposal of an algorithm and a distributed IDS
architecture that could achieve the goals mentioned above."
"In this paper an analysis of the existing video information protection
methods is made. Analysis of current H.323 protocol stack has been made. A new
encryption/decryption layer has been suggested. An approach for partial data
encryption in the H.323 protocol stack is proposed and sample architecture of a
Virtual Private Video Network is given."
"An encryption technique is widely used to keep data confidential. Most of the
block symmetric algorithms use substitution functions. Often this functions use
so called S-BOX matrix. In this paper author presents one software tool for
testing and measuring square s-boxes. Based of information theory functions for
testing static and dynamic criteria are presented. These criteria are
mathematically defined for square s-boxes. Two new criteria ""private criteria""
a proposed and pseudo codes for they creation and testing are presented."
"This paper reviews the requirements for the security mechanisms that are
currently being developed in the framework of the European research project
INDECT. An overview of features for integrated technologies such as Virtual
Private Networks (VPNs), Cryptographic Algorithms, Quantum Cryptography,
Federated ID Management and Secure Mobile Ad-hoc networking are described
together with their expected use in INDECT."
"Steganography and Cryptography are two popular ways of sending vital
information in a secret way. One hides the existence of the message and the
other distorts the message itself. There are many cryptography techniques
available; among them AES is one of the most powerful techniques. In
Steganography we have various techniques in different domains like spatial
domain, frequency domain etc. to hide the message. It is very difficult to
detect hidden message in frequency domain and for this domain we use various
transformations like DCT, FFT and Wavelets etc. In this project we are
developing a system where we develop a new technique in which Cryptography and
Steganography are used as integrated part along with newly developed enhanced
security module. In Cryptography we are using AES algorithm to encrypt a
message and a part of the message is hidden in DCT of an image; remaining part
of the message is used to generate two secret keys which make this system
highly secured. Keyword: Cryptography, Steganography, Stego- image, Threshold
Value, DCT Coefficient"
"Almost all known secret sharing schemes work on numbers. Such methods will
have difficulty in sharing graphs since the number of graphs increases
exponentially with the number of nodes. We propose a secret sharing scheme for
graphs where we use graph intersection for reconstructing the secret which is
hidden as a sub graph in the shares. Our method does not rely on heavy
computational operations such as modular arithmetic or polynomial interpolation
but makes use of very basic operations like assignment and checking for
equality, and graph intersection can also be performed visually. In certain
cases, the secret could be reconstructed using just pencil and paper by
authorised parties but cannot be broken by an adversary even with unbounded
computational power. The method achieves perfect secrecy for (2, n) scheme and
requires far fewer operations compared to Shamir's algorithm. The proposed
method could be used to share objects such as matrices, sets, plain text and
even a heterogeneous collection of these. Since we do not require a previously
agreed upon encoding scheme, the method is very suitable for sharing
heterogeneous collection of objects in a dynamic fashion."
"This paper presents a survey on several RFID authentication protocols under
low cost restrictions. Low cost RFID are mainly addressed with limited security
and privacy protections. In this study, we explore several protocols with
various authentication mechanisms found in literature that satisfy low cost
restrictions. Assessments of these protocols are based on data protection,
tracking protection, forward security. Finally, it is concluded that no single
low cost RFID protocol fully meets the requirement of the given assessments.
While a protocol satisfies one or two assessments, it fails to fully meet the
requirement of the third assessment. This study provides a new insight in RFID
literature which can be used particularly by small and medium industries to
choose the appropriate RFID protocol for their needs."
"Fighting against computer malware require a mandatory step of reverse
engineering. As soon as the code has been disassemblied/decompiled (including a
dynamic analysis step), there is a hope to understand what the malware actually
does and to implement a detection mean. This also applies to protection of
software whenever one wishes to analyze them. In this paper, we show how to
amour code in such a way that reserse engineering techniques (static and
dymanic) are absolutely impossible by combining malicious cryptography
techniques developped in our laboratory and new types of programming (k-ary
codes). Suitable encryption algorithms combined with new cryptanalytic
approaches to ease the protection of (malicious or not) binaries, enable to
provide both total code armouring and large scale polymorphic features at the
same time. A simple 400 Kb of executable code enables to produce a binary code
and around $2^{140}$ mutated forms natively while going far beyond the old
concept of decryptor."
"Grammars are used to describe sentences structure, thanks to some sets of
rules, which depends on the grammar type. A classification of grammars has been
made by Noam Chomsky, which led to four well-known types. Yet, there are other
types of grammars, which do not exactly fit in Chomsky's classification, such
as the two-level grammars. As their name suggests it, the main idea behind
these grammars is that they are composed of two grammars. Van Wijngaarden
grammars, particularly, are such grammars. They are interesting by their power
(expressiveness), which can be the same, under some hypotheses, as the most
powerful grammars of Chomsky's classification, i.e. Type 0 grammars. Another
point of interest is their relative conciseness and readability. Van
Wijngaarden grammars can describe static and dynamic semantic of a language.
So, by using them as a generative engine, it is possible to generate a possibly
infinite set of words, while assuring us that they all have the same semantic.
Moreover, they can describe K-ary codes, by describing the semantic of each
components of a code."
"In today's world password compromise by some adversaries is common for
different purpose. In ICC 2008 Lei et al. proposed a new user authentication
system based on the virtual password system. In virtual password system they
have used linear randomized function to be secure against identity theft
attacks, phishing attacks, keylogging attack and shoulder surfing system. In
ICC 2010 Li's given a security attack on the Lei's work. This paper gives
modification on Lei's work to prevent the Li's attack with reducing the server
overhead. This paper also discussed the problems with current password recovery
system and gives the better approach."
"An algorithm for constructing a shortest binary k-stage machine generating a
given binary sequence is presented. This algorithm can be considered as an
extension of Berlekamp-Massey algorithm to the non-linear case."
"Developed by Paul Kocher, Joshua Jaffe, and Benjamin Jun in 1999,
Differential Power Analysis (DPA) represents a unique and powerful
cryptanalysis technique. Insight into the encryption and decryption behavior of
a cryptographic device can be determined by examining its electrical power
signature. This paper describes a novel approach for implementation of the AES
algorithm which provides a significantly improved strength against differential
power analysis with a minimal additional hardware overhead. Our method is based
on randomization in composite field arithmetic which entails an area penalty of
only 7% while does not decrease the working frequency, does not alter the
algorithm and keeps perfect compatibility with the published standard. The
efficiency of the proposed technique was verified by practical results obtained
from real implementation on a Xilinx Spartan-II FPGA."
"Since security is one of the most important issues, the evolve of
cryptography and cryptographic analysis are considered as the fields of
on-going research. The latest development on this field is DNA cryptography. It
has emerged after the disclosure of computational ability of Deoxyribo Nucleic
Acid (DNA). DNA cryptography uses DNA as the computational tool along with
several molecular techniques to manipulate it. Due to very high storage
capacity of DNA, this field is becoming very promising. Currently it is in the
development phase and it requires a lot of work and research to reach a mature
stage. By reviewing all the potential and cutting edge technology of current
research, this paper shows the directions that need to be addressed further in
the field of DNA cryptography."
"The search for lightweight authentication protocols suitable for low-cost
RFID tags constitutes an active and challenging research area. In this context,
a family of protocols based on the LPN problem has been proposed: the so-called
HB-family. Despite the rich literature regarding the cryptanalysis of these
protocols, there are no published results about the impact of fault analysis
over them. The purpose of this paper is to fill this gap by presenting a fault
analytic method against a prominent member of the HB-family: HB+ protocol. We
demonstrate that the fault analysis model can lead to a flexible and effective
attack against HB-like protocols, posing a serious threat over them."
"Nearly 70% of information security threats originate from inside an
organization. Opportunities for insider threats have been increasing at an
alarming rate with the latest trends of mobility (portable devices like Laptop,
smart phones etc.), ubiquitous connectivity (wireless or through 3G
connectivity) and this trend increases as more and more web-based applications
are made available over the Internet. Insider threats are generally caused by
current or ex-employees, contractors or partners, who have authorized access to
the organization's network and servers. Theft of confidential information is
often for either material gain or for willful damage. Easy availability of
hacking tools on the Internet, USB devices and wireless connectivity provide
for easy break-ins. The net result is losses worth millions of dollars in terms
of IP theft, leakage of customer / individual information, etc. This paper
presents an understanding of Insider threats, attackers and their motives and
suggests mitigation techniques at the organization level"
"This article presets a review of lattice problems. Paper contains the main
eighteen problems with their reductions and referents to his cryptography
application. As an example of reduction, we detail analyze connection between
SVP and CVP. Moreover, we give an Ajtai theorem and demonstrate its role in
lattice based cryptography."
"With increasing complexity of modern-day mobile devices, security of these
devices in presence of myriad attacks by an intelligent adversary is becoming a
major issue. The vast majority of cell phones still remain unsecured from many
existing and emerging security threats. To address the security threats in
mobile devices we are exploring a technology, which we refer as ""Collaborative
Trust"". It is a technology that uses a system of devices cooperating with each
other (working in a fixed or ad-hoc network) to achieve the individual security
of each device. The idea is that each device is insecure by itself, since in
many cases it is incapable of checking its safety by itself (e.g. when it is
compromised it may lose its ability to monitor its own trustworthiness), but
together, they can ensure each other's security in a collaborative manner."
"Tardos codes are currently the state-of-the-art in the design of practical
collusion-resistant fingerprinting codes. Tardos codes rely on a secret vector
drawn from a publicly known probability distribution in order to generate each
Buyer's fingerprint. For security purposes, this secret vector must not be
revealed to the Buyers. To prevent an untrustworthy Provider forging a copy of
a Work with an innocent Buyer's fingerprint, previous asymmetric fingerprinting
algorithms enforce the idea of the Buyers generating their own fingerprint.
Applying this concept to Tardos codes is challenging since the fingerprint must
be based on this vector secret.
  This paper provides the first solution for an asymmetric fingerprinting
protocol dedicated to Tardos codes. The motivations come from a new attack, in
which an untrustworthy Provider by modifying his secret vector frames an
innocent Buyer."
"In this note, we present a complete characterization of the utility metrics
that allow for non-trivial differential privacy guarantees."
"This document contains the Intellectual Property Statement and the technical
description of the MQQ-SIG - a new public key digital signature scheme. The
complete scientific publication covering the design rationale and the security
analysis will be given in a separate publication. MQQ-SIG consists of $n -
\frac{n}{4}$ quadratic polynomials with $n$ Boolean variables where n=160, 196,
224 or 256."
"In this work a model is going to be used which develops data distributed over
a identified value which is used as nonce (IV). The model considers an
equilibrium equation which is a function of non linear relationships, time
variant and nonce variant values and takes the feed back of earlier round as
input to the present round. The process is repeated for different timings which
are used as time stamps in the encryption mechanism. Thus this model generates
a distributed sequence which is used as sub key. This model supports very
important parameters in symmetric data encryption schemes like non linear
relationships between different values used in the model, variable key length,
timeliness of encryption mechanism and also acknowledgement between the
participating parties. It also supports feed back mode which provides necessary
strength against crypto analysis."
"Wireless sensor networks consist of sensor nodes with limited computational
and communication capabilities. In this paper, the whole network of sensor
nodes is divided into clusters based on their physical locations. In addition,
efficient ways of key distribution among the nodes within the cluster and among
controllers of each cluster are discussed. Also, inter and intra cluster
communications are presented in detail. The security of the entire network
through efficient key management by taking into consideration the network's
power capabilities is discussed. A graphical representation of the simulation
on the scheme is also presented."
"Chaotic communications based on semiconductor lasers have aroused great
research interest since 1990s. Physical-layer encryption using chaotic lasers
is an alternative to transmit message rapidly and confidentially. There are
some practical devices and setups for optical chaotic communications, which are
intuitively considered to be secure. However, there is lack of a set of
security evaluation rules for these communication setups. According to the
recent literature, we summarize several criteria for optical chaotic
communications to evaluate the security and point out some methods to enhance
the security. These criteria and suggested rules are very helpful in designing
secure communication systems using chaotic lasers. Finally we propose some
possible hot topics on security analysis of optical chaotic communications in
future."
"We propose an authentication scheme where forgery (a.k.a. impersonation)
seems infeasible without finding the prover's long-term private key. The latter
would follow from solving the conjugacy search problem in the platform
(noncommutative) semigroup, i.e., to recovering X from X^{-1}AX and A. The
platform semigroup that we suggest here is the semigroup of nxn matrices over
truncated multivariable polynomials over a ring."
"Intrusion detection systems have become a key component in ensuring the
safety of systems and networks. As networks grow in size and speed continues to
increase, it is crucial that efficient scalable techniques should be developed
for IDS systems. Signature based detection is the most extensively used threat
detection technique for Intrusion Detection Systems (IDS). One of the foremost
challenges for signaturebased IDS systems is how to keep up with large volume
of incoming traffic when each packet needs to be compared with every signature
in the database. When an IDS cannot keep up with the traffic flood, all it can
do is to drop packets, therefore, may miss potential attacks. This paper
proposes a new model called Dynamic Multi-Layer Signature based IDS using
Mobile Agents, which can detect imminent threats with very high success rate by
dynamically and automatically creating and using small and efficient multiple
databases, and at the same time, provide mechanism to update these small
signature databases at regular intervals using Mobile Agents"
"In a multi-hop mobile ad hoc network (MANET) mobile nodes communicate with
each other forming a cooperative radio network. Security remains a major
challenge for these networks due to their features of open medium, dynamically
changing topologies, reliance on cooperative algorithms, absence of centralized
monitoring points, and lack of any clear lines of defense. Most of the
currently existing security algorithms designed for these networks are
insecure, in efficient, and have low detection accuracy for nodes'
misbehaviour. In this paper, a new approach has been proposed to bring out the
complementary relationship between key distribution and misbehaviour detection
for developing an integrated security solution for MANETs. The redundancy of
routing information in ad hoc networks is utilized to develop a highly reliable
protocol that works even in presence of transient network partitioning and
Byzantine failure of nodes. The proposed mechanism is fully co-operative, and
thus it is more robust as the vulnerabilities of the election algorithms used
for choosing the subset of nodes for cooperation are absent. Simulation results
show the effectiveness of the proposed protocol."
"We outline the design of a framework for modelling cloud computing
systems.The approach is based on a declarative programming model which takes
the form of a lambda-calculus enriched with suitable mechanisms to express and
enforce application-level security policies governing usages of resources
available in the clouds. We will focus on the server side of cloud systems, by
adopting a pro-active approach, where explicit security policies regulate
server's behaviour."
"This paper presents solutions for cryptography protection in MS Outlook. The
solutions comprise the authors' experience in development and implementation of
systems for information security in the Automated Information Systems of
Bulgarian Armed Forces. The architecture, the models and the methods are being
explained."
"Using cryptography to protect information and communication has bacically two
major drawbacks. First, the specific entropy profile of encrypted data makes
their detection very easy. Second, the use of cryptography can be more or less
regulated, not to say forbidden, according to the countries. If the right to
freely protect our personal and private data is a fundamental right, it must
not hinder the action of Nation States with respect to National security.
Allowing encryption to citizens holds for bad guys as well.
  In this paper we propose a new approach in information and communication
security that may solve all these issues, thus representing a rather
interesting trade-off between apparently opposite security needs. We introduce
the concept of scalable security based on computationnally hard problem of
coding theory with the PERSEUS technology.
  The core idea is to encode date with variable punctured convolutional codes
in such a way that any cryptanalytic attempt will require a time-consuming
encoder reconstruction in order to decode. By adding noise in a suitable way,
that reconstruction becomes untractable in practice except for Intelligence
services that however must use supercomputers during a significant, scalable
amount of time. Hence it limits naturally any will to unduly performs such
attacks (eg. against citizens' privacy).
  On the users' side, encoder and noise parameters are first exchanged through
an initial, short HTTPS session. The principles behind that approach have been
mathematically validated in 1997 and 2007. We present the PERSEUS library we
have developed under the triple GPL/LGPL/MPL licences. This library can be used
to protect any kind of data."
"Computer network is unpredictable due to information warfare and is prone to
various attacks. Such attacks on network compromise the most important
attribute, the privacy. Most of such attacks are devised using special
communication channel called ""Covert Channel"". The word ""Covert"" stands for
hidden or non-transparent. Network Covert Channel is a concealed communication
path within legitimate network communication that clearly violates security
policies laid down. The non-transparency in covert channel is also referred to
as trapdoor. A trapdoor is unintended design within legitimate communication
whose motto is to leak information. Subliminal channel, a variant of covert
channel works similarly except that the trapdoor is set in a cryptographic
algorithm. A composition of covert channel with subliminal channel is the
""Hybrid Covert Channel"". Hybrid covert channel is homogenous or heterogeneous
mixture of two or more variants of covert channels either active at same
instance or at different instances of time. Detecting such malicious channel
activity plays a vital role in removing threat to the legitimate network. In
this paper, we present a study of multi-trapdoor covert channels and introduce
design of a new detection engine for hybrid covert channel in transport layer
visualized in TCP and SSL."
"In this paper, we propose a novel digital watermarking scheme in DCT domain
based fuzzy inference system and the human visual system to adapt the embedding
strength of different blocks. Firstly, the original image is divided into some
8 \times 8 blocks, and then fuzzy inference system according to different
textural features and luminance of each block decide adaptively different
embedding strengths. The watermark detection adopts correlation technology.
Experimental results show that the proposed scheme has good imperceptibility
and high robustness to common image processing operators."
"A mobile ad hoc network (MANET) is a collection of mobile nodes that
communicate with each other by forming a multi-hop radio network. Security
remains a major challenge for these networks due to their features of open
medium, dynamically changing topologies, reliance on cooperative algorithms,
absence of centralized monitoring points, and lack of clear lines of defense.
Design of an efficient and reliable node authentication protocol for such
networks is a particularly challenging task since the nodes are battery-driven
and resource constrained. This paper presents a robust and efficient key
exchange protocol for nodes authentication in a MANET based on multi-path
communication. Simulation results demonstrate that the protocol is effective
even in presence of large fraction of malicious nodes in the network. Moreover,
it has a minimal computation and communication overhead that makes it ideally
suitable for MANETs."
"Since it is impossible to predict and identify all the vulnerabilities of a
network, and penetration into a system by malicious intruders cannot always be
prevented, intrusion detection systems (IDSs) are essential entities for
ensuring the security of a networked system. To be effective in carrying out
their functions, the IDSs need to be accurate, adaptive, and extensible. Given
these stringent requirements and the high level of vulnerabilities of the
current days' networks, the design of an IDS has become a very challenging
task. Although, an extensive research has been done on intrusion detection in a
distributed environment, distributed IDSs suffer from a number of drawbacks
e.g., high rates of false positives, low detection efficiency etc. In this
paper, the design of a distributed IDS is proposed that consists of a group of
autonomous and cooperating agents. In addition to its ability to detect
attacks, the system is capable of identifying and isolating compromised nodes
in the network thereby introducing fault-tolerance in its operations. The
experiments conducted on the system have shown that it has high detection
efficiency and low false positives compared to some of the currently existing
systems."
"This paper studies the current ""identity crisis"" caused by the substantial
security, privacy and usability shortcomings encountered in existing systems
for identity management. Some of these issues are well known, while others are
much less understood. This paper brings them together in a single,
comprehensive study and proposes recommendations to resolve or to mitigate the
problems. Some of these problems cannot be solved without substantial research
and development effort."
"In the almost 20 years since GSM was deployed several security problems have
been found, both in the protocols and in the - originally secret -
cryptography. However, practical exploits of these weaknesses are complicated
because of all the signal processing involved and have not been seen much
outside of their use by law enforcement agencies.
  This could change due to recently developed open-source equipment and
software that can capture and digitize signals from the GSM frequencies. This
might make practical attacks against GSM much simpler to perform.
  Indeed, several claims have recently appeared in the media on successfully
eavesdropping on GSM. When looking at these claims in depth the conclusion is
often that more is claimed than what they are actually capable of. However, it
is undeniable that these claims herald the possibilities to eavesdrop on GSM
using publicly available equipment.
  This paper evaluates the claims and practical possibilities when it comes to
eavesdropping on GSM, using relatively cheap hardware and open source
initiatives which have generated many headlines over the past year. The basis
of the paper is extensive experiments with the USRP (Universal Software Radio
Peripheral) and software projects for this hardware."
"This paper introduces current watermarking techniques available from the
literatures. Requirements for medical watermarking will be discussed. We then
propose a watermarking scheme that can recover the original image from the
watermarked one. The purpose is to verify the integrity and authenticity of
DICOM images. We used ultrasound (US) images in our experiment. SHA-256 of the
whole image is embedded in the least significant bits of the RONI (Region of
Non-Interest). If the image has not been altered, the watermark will be
extracted and the original image will be recovered. SHA-256 of the recovered
image will be compared with the extracted watermark for authentication."
"Use of formal techniques for verifying the security features of electronic
commerce protocols would facilitate, the enhancement of reliability of such
protocols, thereby increasing their usability. This paper projects the
application of logic programming techniques for formal verification of a well
referred security and transactions protocol, the NetBill. The paper uses ALSP
(Action Language for Security Protocols) as an efficient formal specification
language and SMODELS a model generator to formally analyze and plan attacks on
the protocol."
"In recent times, many protocols have been proposed to provide security for
various information and communication systems. Such protocols must be tested
for their functional correctness before they are used in practice. Application
of formal methods for verification of security protocols would enhance their
reliability thereby, increasing the usability of systems that employ them.
Thus, formal verification of security protocols has become a key issue in
computer and communications security. In this paper we present, analyze and
compare some prevalent approaches towards verification of secure systems. We
follow the notion of - same goal through different approaches - as we formally
analyze the Needham Schroeder Public Key protocol for Lowe's attack using each
of our presented approaches."
"In this paper we analyze different biometric authentication protocols
considering an internal adversary. Our contribution takes place at two levels.
On the one hand, we introduce a new comprehensive framework that encompasses
the various schemes we want to look at. On the other hand, we exhibit actual
attacks on recent schemes such as those introduced at ACISP 2007, ACISP 2008,
and SPIE 2010, and some others. We follow a blackbox approach in which we
consider components that perform operations on the biometric data they contain
and where only the input/output behavior of these components is analyzed."
"This paper aims at answering the following two questions in
privacy-preserving data analysis and publishing: What formal privacy guarantee
(if any) does $k$-anonymization provide? How to benefit from the adversary's
uncertainty about the data? We have found that random sampling provides a
connection that helps answer these two questions, as sampling can create
uncertainty. The main result of the paper is that $k$-anonymization, when done
""safely"", and when preceded with a random sampling step, satisfies
$(\epsilon,\delta)$-differential privacy with reasonable parameters. This
result illustrates that ""hiding in a crowd of $k$"" indeed offers some privacy
guarantees. This result also suggests an alternative approach to output
perturbation for satisfying differential privacy: namely, adding a random
sampling step in the beginning and pruning results that are too sensitive to
change of a single tuple. Regarding the second question, we provide both
positive and negative results. On the positive side, we show that adding a
random-sampling pre-processing step to a differentially-private algorithm can
greatly amplify the level of privacy protection. Hence, when given a dataset
resulted from sampling, one can utilize a much large privacy budget. On the
negative side, any privacy notion that takes advantage of the adversary's
uncertainty likely does not compose. We discuss what these results imply in
practice."
"Wireless mesh networks (WMNs) have emerged as a key technology for next
generation wireless broadband networks showing rapid progress and inspiring
numerous compelling applications. A WMN comprises of a set of mesh routers
(MRs) and mesh clients (MCs), where MRs are connected to the Internet backbone
through the Internet gateways (IGWs). The MCs are wireless devices and
communicate among themselves over possibly multi-hop paths with or without the
involvement of MRs. User privacy and security have been primary concerns in
WMNs due to their peer-to-peer network topology, shared wireless medium,
stringent resource constraints, and highly dynamic environment. Moreover, to
support real-time applications, WMNs must also be equipped with robust,
reliable and efficient routing protocols so as to minimize the end-to-end
latency. Design of a secure and efficient routing protocol for WMNs, therefore,
is of paramount importance. In this paper, we propose an efficient and reliable
routing protocol that also provides user anonymity in WMNs. The protocol is
based on an accurate estimation of the available bandwidth in the wireless
links and a robust estimation of the end-to-end delay in a routing path, and
minimization of control message overhead. The user anonymity, authentication
and data privacy is achieved by application of a novel protocol that is based
on Rivest's ring signature scheme. Simulations carried out on the proposed
protocol demonstrate that it is more efficient than some of the existing
routing protocols."
"Differential privacy is a promising approach to privacy preserving data
analysis with a well-developed theory for functions. Despite recent work on
implementing systems that aim to provide differential privacy, the problem of
formally verifying that these systems have differential privacy has not been
adequately addressed. This paper presents the first results towards automated
verification of source code for differentially private interactive systems. We
develop a formal probabilistic automaton model of differential privacy for
systems by adapting prior work on differential privacy for functions. The main
technical result of the paper is a sound proof technique based on a form of
probabilistic bisimulation relation for proving that a system modeled as a
probabilistic automaton satisfies differential privacy. The novelty lies in the
way we track quantitative privacy leakage bounds using a relation family
instead of a single relation. We illustrate the proof technique on a
representative automaton motivated by PINQ, an implemented system that is
intended to provide differential privacy. To make our proof technique easier to
apply to realistic systems, we prove a form of refinement theorem and apply it
to show that a refinement of the abstract PINQ automaton also satisfies our
differential privacy definition. Finally, we begin the process of automating
our proof technique by providing an algorithm for mechanically checking a
restricted class of relations from the proof technique."
"This paper presents new properties of Primitive Pythagorean Triples (PPT)
that have relevance in applications where events of different probability need
to be generated and in cryptography."
"This document presents brief software specification of a secure file exchange
system prototype involving mutual authentication of the users via their browser
and the application server with PKI-based certificates as credentials, the use
of LDAP for credential management, and authentication between the application
and database servers to maintain a high level of trust between all parties."
"We report on the software engineering design and implementation of an web-
and LDAP-based secure file exchange system with bi-directional authentication
of all parties involved in the process that is the user's browsers and the
application server mutually authenticate, and the application and database
servers authenticate using certificates, credentials, etcs. with the directory
service provided by LDAP using open-source technologies."
"This paper proposes a strict authentication watermarking for medical images.
In this scheme, we define region of interest (ROI) by taking the smallest
rectangle around an image. The watermark is generated from hashing the area of
interest. The embedding region is considered to be outside the region of
interest as to preserve the area from distortion as a result from watermarking.
The strict authentication watermarking is robust to some degree of JPEG
compression (SAW-JPEG). JPEG compression will be reviewed. To embed a watermark
in the spatial domain, we have to make sure that the embedded watermark will
survive JPEG quantization process. The watermarking scheme, including data
embedding, extracting and verifying procedure were presented. Experimental
results showed that such a scheme could embed and extract the watermark at a
high compression rate. The watermark is robust to a high compression rate up to
90.6%. The JPEG image quality threshold is 60 for the least significant bit
embedding. The image quality threshold is increased to 61 for 2nd and 3rd LSB
manipulations."
"A mix network by Wikstrom fails in correctness, provable privacy and
soundness. Its claimed advantages in security and efficiency are compromised.
The analysis in this paper illustrates that although the first two failures may
be fixed by modifying the shuffling protocol, the last one is too serious to
fix at a tolerable cost. Especially, an attack is proposed to show how easily
soundness of the shuffling scheme can be compromised. Moreover, the most
surprising discovery in this paper is that it is formally illustrated that in
practice it is impossible to fix soundness of the shuffling scheme by Wikstrom."
"Suppose you find the same username on different online services, what is the
probability that these usernames refer to the same physical person? This work
addresses what appears to be a fairly simple question, which has many
implications for anonymity and privacy on the Internet. One possible way of
estimating this probability would be to look at the public information
associated to the two accounts and try to match them. However, for most
services, these information are chosen by the users themselves and are often
very heterogeneous, possibly false and difficult to collect. Furthermore,
several websites do not disclose any additional public information about users
apart from their usernames (e.g., discus- sion forums or Blog comments),
nonetheless, they might contain sensitive information about users. This paper
explores the possibility of linking users profiles only by looking at their
usernames. The intuition is that the probability that two usernames refer to
the same physical person strongly depends on the ""entropy"" of the username
string itself. Our experiments, based on crawls of real web services, show that
a significant portion of the users' profiles can be linked using their
usernames. To the best of our knowledge, this is the first time that usernames
are considered as a source of information when profiling users on the Internet."
"This study aims to present an adaptive audio watermarking method using ideas
of wavelet-based entropy (WBE). The method converts low-frequency coefficients
of discrete wavelet transform (DWT) into the WBE domain, followed by the
calculations of mean values of each audio as well as derivation of some
essential properties of WBE. A characteristic curve relating the WBE and DWT
coefficients is also presented. The foundation of the embedding process lies on
the approximately invariant property demonstrated from the mean of each audio
and the characteristic curve. Besides, the quality of the watermarked audio is
optimized. In the detecting process, the watermark can be extracted using only
values of the WBE. Finally, the performance of the proposed watermarking method
is analyzed in terms of signal to noise ratio, mean opinion score and
robustness. Experimental results confirm that the embedded data are robust to
resist the common attacks like re-sampling, MP3 compression, low-pass
filtering, and amplitude-scaling"
"Hiding information in network traffic may lead to leakage of confidential
information. In this paper we introduce a new steganographic system: the
PadSteg (Padding Steganography). To authors' best knowledge it is the first
information hiding solution which represents inter-protocol steganography i.e.
usage of relation between two or more protocols from the TCP/IP stack to enable
secret communication. PadSteg utilizes ARP and TCP protocols together with an
Etherleak vulnerability (improper Ethernet frame padding) to facilitate secret
communication for hidden groups in LANs (Local Area Networks). Basing on real
network traces we confirm that PadSteg is feasible in today's networks and we
estimate what steganographic bandwidth is achievable while limiting the chance
of disclosure. We also point at possible countermeasures against PadSteg."
"This work is a part of the SHIVA (Secured Hardware Immune Versatile
Architecture) project whose purpose is to provide a programmable and
reconfigurable hardware module with high level of security. We propose a
recursive double-size fixed precision arithmetic called RecInt. Our work can be
split in two parts. First we developped a C++ software library with
performances comparable to GMP ones. Secondly our simple representation of the
integers allows an implementation on FPGA. Our idea is to consider sizes that
are a power of 2 and to apply doubling techniques to implement them
efficiently: we design a recursive data structure where integers of size 2^k,
for k>k0 can be stored as two integers of size 2^{k-1}. Obviously for k<=k0 we
use machine arithmetic instead (k0 depending on the architecture)."
"Modern distributed communication networks like the Internet and
censorship-resistant networks (also a part of the Internet) are characterized
by nodes (users) interconnected with one another via communication links. In
this regard, the security of individual nodes depend not only on their own
efforts, but also on the efforts and underlying connectivity structure of
neighboring network nodes. By the term 'effort', we imply the amount of
investments made by a user in security mechanisms like antivirus softwares,
firewalls, etc., to improve its security. However, often due to the large
magnitude of such networks, it is not always possible for nodes to have
complete effort and connectivity structure information about all their neighbor
nodes. Added to this is the fact that in many applications, the Internet users
are selfish and are not willing to co-operate with other users on sharing
effort information. In this paper, we adopt a non-cooperative game-theoretic
approach to analyze individual user security in a communication network by
accounting for both, the partial information that a network node possess about
its underlying neighborhood connectivity structure, as well as the presence of
positive externalities arising from efforts exerted by neighboring nodes. We
investigate the equilibrium behavior of nodes and show 1) the existence of
symmetric Bayesian Nash equilibria of efforts and 2) better connected nodes
choose lower efforts to exert but earn higher utilities with respect to
security improvement irrespective of the nature of node degree correlations
amongst the neighboring nodes. Our results provide ways for Internet users to
appropriately invest in security mechanisms under realistic environments of
information uncertainty."
"Multimedia data security is becoming important with the continuous increase
of digital communications on internet. The encryption algorithms developed to
secure text data are not suitable for multimedia application because of the
large data size and real time constraint. In this paper, classification and
description of various video encryption algorithms are presented. Analysis and
Comparison of these algorithms with respect to various parameters like visual
degradation, encryption ratio, speed, compression friendliness, format
compliance and cryptographic security is presented."
"In this paper, we propose a new method for detecting unauthorized network
intrusions, based on a traffic flow model and Cisco NetFlow protocol
application. The method developed allows us not only to detect the most common
types of network attack (DDoS and port scanning), but also to make a list of
trespassers' IP-addresses. Therefore, this method can be applied in intrusion
detection systems, and in those systems which lock these IP-addresses."
"This paper presents a general overview on evolution of concealment methods in
computer viruses and defensive techniques employed by anti-virus products. In
order to stay far from the anti-virus scanners, computer viruses gradually
improve their codes to make them invisible. On the other hand, anti-virus
technologies continually follow the virus tricks and methodologies to overcome
their threats. In this process, anti-virus experts design and develop new
methodologies to make them stronger, more and more, every day. The purpose of
this paper is to review these methodologies and outline their strengths and
weaknesses to encourage those are interested in more investigation on these
areas."
"A new approach to the generation of random sequences and two dimensional
random patterns is proposed in this paper in which random sequences are
generated by making use of either Delaunay triangulation or Voronoi diagrams
drawn from random points taken in a two dimensional plane. Both the random
sequences and two dimensional random patterns generated in this manner are
shown to be more random when compared to pseudo-random sequences and patterns."
"Wireless sensor networks consist of sensor nodes with limited computational
and communication capabilities. This paper deals with mobile sensors which are
divided into clusters based on their physical locations. Efficient ways of key
distribution among the sensors and inter and intra cluster communications are
examined. The security of the entire network is considered through efficient
key management by taking into consideration the network's power capabilities."
"In order to prevent detection and evade signature-based scanning methods,
which are normally exploited by antivirus software, metamorphic viruses use
several various obfuscation approaches. They transform their code in new
instances as look entirely or partly different and contain dissimilar sequences
of string, but their behavior and function remain unchanged. This obfuscation
process allows them to stay away from the string based signature detection. In
this research, we use a statistical technique to compare the similarity between
two files infected by two morphed versions of a given metamorphic virus. Our
proposed solution based on static analysis and it uses the histogram of machine
instructions frequency in various offspring of obfuscated viruses. We use
Euclidean histogram distance metric to compare a pair of portable executable
(PE) files. The aim of this study is to show that for some particular
obfuscation methods, the presented solution can be exploited to detect morphed
varieties of a file. Hence, it can be utilized by non-string based signature
scanning to identify whether a file is a version of a metamorphic virus or not."
"Metamorphic viruses engage different mutation techniques to escape from
string signature based scanning. They try to change their code in new offspring
so that the variants appear non-similar and have no common sequences of string
as signature. However, all versions of a metamorphic virus have similar task
and performance. This obfuscation process helps to keep them safe from the
string based signature detection. In this study, we make use of instructions
statistical features to compare the similarity of two hosted files probably
occupied by two mutated forms of a specific metamorphic virus. The introduced
solution in this paper is relied on static analysis and employs the frequency
histogram of machine opcodes in different instances of obfuscated viruses. We
use Minkowski-form histogram distance measurements in order to check the
likeness of portable executables (PE). The purpose of this research is to
present an idea that for a number of special obfuscation approaches the
presented solution can be used to identify morphed copies of a file. Thus, it
can be applied by antivirus scanner to recognize different versions of a
metamorphic virus."
"The STCP (Stream Control Transmission Protocol) is a candidate for a new
transport layer protocol that may replace the TCP (Transmission Control
Protocol) and the UDP (User Datagram Protocol) protocols in future IP networks.
Currently, the SCTP is implemented in, or can be added to, many popular
operating systems (Windows, BSD, Linux, HPUX or Sun Solaris). This paper
identifies and presents all possible ""places"" where hidden information can be
exchanged using an SCTP. The paper focuses mostly on proposing new
steganographic methods that can be applied to an SCTP and that can utilise new,
characteristic SCTP features, such as multi-homing and multi-streaming.
Moreover, for each method, the countermeasure is covered. When used with
malicious intent, a method may pose a threat to network security. Knowledge
about potential SCTP steganographic methods may be used as a supplement to
RFC5062, which describes security attacks in an SCTP protocol. Presented in
this paper is a complete analysis of information hiding in an SCTP, and this
analysis can be treated as a ""guide"" when developing steganalysis (detection)
tools."
"In this paper we will look at the distribution with which passwords are
chosen. Zipf's Law is commonly observed in lists of chosen words. Using
password lists from four different on-line sources, we will investigate if
Zipf's law is a good candidate for describing the frequency with which
passwords are chosen. We look at a number of standard statistics, used to
measure the security of password distributions, and see if modelling the data
using Zipf's Law produces good estimates of these statistics. We then look at
the the similarity of the password distributions from each of our sources,
using guessing as a metric. This shows that these distributions provide
effective tools for cracking passwords. Finally, we will show how to shape the
distribution of passwords in use, by occasionally asking users to choose a
different password."
"In this paper we propose a method to construct logarithmic signatures which
are not amalgamated transversal and further do not even have a periodic block.
The latter property was crucial for the successful attack on the system MST3 by
Blackburn et al. [1]. The idea for our construction is based on the theory in
Szab\'o's book about group factorizations [12]."
"Mobile ad hoc networks (MANETs) are dynamic wireless networks without any
infrastructure. These networks are weak against many types of attacks. One of
these attacks is the black hole. In this attack, a malicious node advertises
itself as having freshest or shortest path to specific node to absorb packets
to itself. The effect of black hole attack on ad hoc network using AODV as a
routing protocol will be examined in this research. Furthermore, we investigate
solution for increasing security in these networks. Simulation results using
OPNET simulator depict that packet delivery ratio in the presence of malicious
nodes, reduces notably."
"Disk encryption has become an important security measure for a multitude of
clients, including governments, corporations, activists, security-conscious
professionals, and privacy-conscious individuals. Unfortunately, recent
research has discovered an effective side channel attack against any disk
mounted by a running machine\cite{princetonattack}. This attack, known as the
cold boot attack, is effective against any mounted volume using
state-of-the-art disk encryption, is relatively simple to perform for an
attacker with even rudimentary technical knowledge and training, and is
applicable to exactly the scenario against which disk encryption is primarily
supposed to defend: an adversary with physical access. To our knowledge, no
effective software-based countermeasure to this attack supporting multiple
encryption keys has yet been articulated in the literature. Moreover, since no
proposed solution has been implemented in publicly available software, all
general-purpose machines using disk encryption remain vulnerable. We present
Loop-Amnesia, a kernel-based disk encryption mechanism implementing a novel
technique to eliminate vulnerability to the cold boot attack. We offer
theoretical justification of Loop-Amnesia's invulnerability to the attack,
verify that our implementation is not vulnerable in practice, and present
measurements showing our impact on I/O accesses to the encrypted disk is
limited to a slowdown of approximately 2x. Loop-Amnesia is written for x86-64,
but our technique is applicable to other register-based architectures. We base
our work on loop-AES, a state-of-the-art open source disk encryption package
for Linux."
"As the cost of information processing and Internet accessibility falls, most
organizations are becoming increasingly vulnerable to potential cyber threats
which its rate has been dramatically increasing every year in recent times. In
this paper, we study, discuss and classify the most significant malicious
software: viruses, Trojans, worms, adware and pornware which have made step
forward in the science of Virology."
"We address the problem of secure data deletion on log-structured file
systems. We focus on the YAFFS file system, widely used on Android smartphones.
We show that these systems provide no temporal guarantees on data deletion and
that deleted data still persists for nearly 44 hours with average phone use and
indefinitely if the phone is not used after the deletion. Furthermore, we show
that file overwriting and encryption, methods commonly used for secure deletion
on block-structured file systems, do not ensure data deletion in log-structured
file systems.
  We propose three mechanisms for secure deletion on log-structured file
systems. Purging is a user-level mechanism that guarantees secure deletion at
the cost of negligible device wear. Ballooning is a user-level mechanism that
runs continuously and gives probabilistic improvements to secure deletion. Zero
overwriting is a kernel-level mechanism that guarantees immediate secure
deletion without device wear. We implement these mechanisms on Nexus One
smartphones and show that they succeed in secure deletion and neither
prohibitively reduce the longevity of the flash memory nor noticeably reduce
the device's battery lifetime. These techniques provide mobile phone users more
confidence that data they delete from their phones are indeed deleted."
"This paper is concerned with several security notions for information
theoretically secure encryptions defined by the variational (statistical)
distance. To ensure the perfect secrecy (PS), the mutual information is often
used to evaluate the statistical independence between a message and a
cryptogram. On the other hand, in order to recognize the information
theoretically secure encryptions and computationally secure ones
comprehensively, it is necessary to reconsider the notion of PS in terms of the
variational distance. However, based on the variational distance, three kinds
of definitions for PS are naturally introduced, but their relations are not
known. In this paper, we clarify that one of three definitions for PS with the
variational distance, which is a straightforward extension of Shannon's perfect
secrecy, is stronger than the others, and the weaker two definitions of PS are
essentially equivalent to the statistical versions of indistinguishability and
semantic security."
"In this paper, the probability of Eve the Eavesdropper's correct decision is
considered both in the Gaussian and Rayleigh fading wiretap channels when using
lattice codes for the transmission.
  First, it is proved that the secrecy function determining Eve's performance
attains its maximum at y=1 on all known extremal even unimodular lattices. This
is a special case of a conjecture by Belfiore and Sol\'e. Further, a very
simple method to verify or disprove the conjecture on any given unimodular
lattice is given.
  Second, preliminary analysis on the behavior of Eve's probability of correct
decision in the fast fading wiretap channel is provided. More specifically, we
compute the truncated inverse norm power sum factors in Eve's probability
expression. The analysis reveals a performance-secrecy-complexity tradeoff:
relaxing on the legitimate user's performance can significantly increase the
security of transmission. The confusion experienced by the eavesdropper may be
further increased by using skewed lattices, but at the cost of increased
complexity."
"This paper shows how a one-way mapping using majority information on adjacent
bits will improve the randomness of d-sequences. Supporting experimental
results are presented. It is shown that the behavior of d-sequences is
different from that of other RNG sequences."
"We take an important step forward in making Oblivious RAM (O-RAM) practical.
We propose an O-RAM construction achieving an amortized overhead of 20X-35X
(for an O-RAM roughly 1 terabyte in size), about 63 times faster than the best
existing scheme. On the theoretic front, we propose a fundamentally novel
technique for constructing Oblivious RAMs: specifically, we partition a bigger
O-RAM into smaller O-RAMs, and employ a background eviction technique to
obliviously evict blocks from the client-side cache into a randomly assigned
server-side partition. This novel technique is the key to achieving the gains
in practical performance."
"Nowadays, it is a common practice to protect various types of statistical
data before publishing them for different researches. For instance, when
conducting extensive demographic surveys such as national census, the collected
data should be at least depersonalized to guarantee proper level of privacy
preservation. In practice, even more complicated methods of data protection
need to be used. All these methods can be generally divided into two classes.
The first ones aim at providing individual data anonymity, whereas the other
ones are focused on protecting information about a group of respondents. In
this paper, we propose a novel technique of providing group anonymity in
statistical data using singular spectrum analysis (SSA).Also, we apply SSA to
defining hidden patterns in demographic data distribution."
"In security protocol analysis, the traditional choice to consider a single
Dolev-Yao attacker is supported by the fact that models with multiple
collaborating Dolev-Yao attackers have been shown to be reducible to models
with one Dolev-Yao attacker. In this paper, we take a fundamentally different
approach and investigate the case of multiple non-collaborating attackers.
After formalizing the framework for multi-attacker scenarios, we show with a
case study that concurrent competitive attacks can interfere with each other.
We then present a new strategy to defend security protocols, based on active
exploitation of attack interference. The paper can be seen as providing two
proof-of-concept results: (i) it is possible to exploit interference to
mitigate protocol vulnerabilities, thus providing a form of protection to
protocols; (ii) the search for defense strategies requires scenarios with at
least two attackers."
"Certificateless public key cryptography simplifies the complex certificate
management in the traditional public key cryptography and resolves the key
escrow problem in identity-based cryptography. Many certificateless
authenticated key agreement protocols using bilinear pairings have been
proposed. But the relative computation cost of the pairing is approximately
twenty times higher than that of the scalar multiplication over elliptic curve
group. Recently, several certificateless authenticated key agreement protocols
without pairings were proposed to improve the performance. In this paper, we
propose a new certificateless authenticated key agreement protocol without
pairing. The user in our just needs to compute five scale multiplication to
finish the key agreement. We also show the proposed protocol is secure in the
random oracle model."
"In the first quarter of 2011, Android has become the top-selling operating
system for smartphones. In this paper, we present a novel, highly critical
attack that allows unprompted installation of arbitrary applications from the
Android Market. Our attack is based on a single malicious application, which,
in contrast to previously known attacks, does not require the user to grant it
any permissions."
"Nowadays security in communication is increasingly important to the network
communication because many categories of data are required restriction on
authorization of access, modify, delete and insert. Quantum cryptography is one
of the solutions that use property of polarization to ensure that transmitted
data is not tampered. The research paper provides the mechanism that enhances
the data security in quantum cryptography during exchange of information. In
first phase detailed explanation of Quantum key distribution's BB84 protocol is
given. BB84 protocol is used as the basis for the mechanism. In next phase the
proposed mechanism is explained. The proposed mechanism combines BB84 protocol
at two levels, from sender to receiver and then from receiver to sender.
Moreover, a logic circuit is used to combine the bits hence to reduce the
probability of eavesdropping. The key obtained can be used to exchange the
information securely further it can help in encryption and decryption of
crucial data. Double level BB84 mechanism will help in information
reconciliation as well as privacy amplification. In future the proposed
mechanism will be very beneficial where unconditional security is required
during key and other secret information exchange"
"Key predistribution schemes for distributed sensor networks have received
significant attention in the recent literature. In this paper we propose a new
construction method for these schemes based on combinations of duals of
standard block designs. Our method is a broad spectrum one which works for any
intersection threshold. By varying the initial designs, we can generate various
schemes and this makes the method quite flexible. We also obtain explicit
algebraic expressions for the metrics for local connectivity and resiliency.
These schemes are quite efficient with regard to connectivity and resiliency
and at the same time they allow a straightforward shared-key discovery."
"Password authentication is the most commonly used technique to authenticate
the user validity. However, due to its simplicity, it is vulnerable to pseudo
attacks. It can be enhanced using various biometric techniques such as thumb
impression, finger movement, eye movement etc. In this paper, we concentrate on
the most economic technique, based on the user habitual rhythm pattern i.e. not
what they type but how they type is the measure for authenticating the user. We
consider the latency between key events as the trajectory, and trajectory
clustering is used to obtain the hidden patterns of the user. Obtained pattern
can be considered as a cluster of measurements that can be used to
differentiate from other users. We evaluated the proposed technique on the data
obtained from the 100 users."
"The Electronic Data Interchange (EDI) is the exchange of standardized
documents between computer systems for business use. The objective of this
study is to make Electronic Data Interchange secure to use and to eliminate
human intervention in the transfer of data between business partners so that
productivity and efficiency can be improved and also promote its usage between
two or more trading organizations. This paper provides an overview of EDI by
describing the traditional problems of exchanging information in business
environments and how the EDI solves those problems and gives benefits to the
company that makes use of EDI. This paper also introduces the common EDI
Standards and explains how it works, how it is used over the internet and the
security measures implemented. The system was executed on both local area
network and wide area network after a critical study of the existing EDI
methods and also implemented using VB.Net programming language. Finally, an
interactive program was developed that handles the transfer of files, with
special attention to the security of the items that are being transferred from
one computer workstation to another."
"Establishment of pairwise keys between sensor nodes in a sensor network is a
difficult problem due to resource limitations of sensor nodes as well as
vulnerability to physical captures of sensor nodes by the enemy. Public-key
cryptosystems are not much suited for most resource-constrained sensor
networks. Recently, elliptic curve cryptographic techniques show that public
key cryptosystem is also feasible for resource-constrained sensor networks.
However, most researchers accept that the symmetric key cryptosystems are
viable options for resource-constrained sensor networks. In this paper, we
first develop a basic principle to address the key pre-distribution problem in
mobile sensor networks. Then, using this developed basic principle, we propose
a scheme which takes the advantage of the post-deployment knowledge. Our scheme
is a modified version of the key prioritization technique proposed by Liu and
Ning. Our improved scheme provides reasonable network connectivity and
security. Moreover, the proposed scheme works for any deployment topology."
"Classic firewall systems are built to filter traffic based on IP addresses,
source and destination ports and protocol types. The modern networks have grown
to a level where the possibility for users' mobility is a must. In such
networks, modern firewalls may introduce such complexity where administration
can become very frustrating since it needs the intervention of a firewall
administrator. The solution for this problem is an identity based firewall
system. In this paper we will present a new design of a firewall system that
uses the user's identity to filter the traffic. In the design phase we will
define key points which have to be satisfied as a crucial milestone for the
functioning of the whole Identity based firewall system."
"The evolving necessity of the Internet increases the demand on the bandwidth.
Therefore, this demand opens the doors for the hackers' community to develop
new methods and techniques to gain control over networking systems. Hence, the
intrusion detection systems (IDS) are insufficient to prevent/detect
unauthorized access the network. Network Intrusion Detection System (NIDS) is
one example that still suffers from performance degradation due the increase of
the link speed in today's networks. In This paper we proposed a novel algorithm
to detect the intruders, who's trying to gain access to the network using the
packets header parameters such as; source/destination address,
source/destination port, and protocol without the need to inspect each packet
content looking for signatures/patterns. However, the ""Packet Header Matching""
algorithm enhances the overall speed of the matching process between the
incoming packet headers against the rule set. We ran the proposed algorithm to
proof the proposed concept in coping with the traffic arrival speeds and the
various bandwidth demands. The achieved results were of significant enhancement
of the overall performance in terms of detection speed."
"cryptographic hash function is a deterministic procedure that compresses an
arbitrary block of numerical data and returns a fixed-size bit string. There
exist many hash functions: MD5, HAVAL, SHA, ... It was reported that these hash
functions are not longer secure. Our work is focused in the construction of a
new hash function based on composition of functions. The construction used the
NP-completeness of Three-dimensional contingency tables and the relaxation of
the constraint that a hash function should also be a compression function."
"Spam messes up users inbox, consumes resources and spread attacks like DDoS,
MiM, phishing etc. Phishing is a byproduct of email and causes financial loss
to users and loss of reputation to financial institutions. In this paper we
examine the characteristics of phishing and technology used by Phishers. In
order to counter anti-phishing technology, phishers change their mode of
operation; therefore a continuous evaluation of phishing only helps us combat
phisher effectiveness. In our study, we collected seven hundred thousand spam
from a corporate server for a period of 13 months from February 2008 to
February 2009. From the collected data, we identified different kinds of
phishing scams and mode of operation. Our observation shows that phishers are
dynamic and depend more on social engineering techniques rather than software
vulnerabilities. We believe that this study will develop more efficient
anti-phishing methodologies. Based on our analysis, we developed an
anti-phishing methodology and implemented in our network. The results show that
this approach is highly effective to prevent phishing attacks. The proposed
approach reduced more than 80% of the false negatives and more than 95% of
phishing attacks in our network."
"TUBITAK National Research Institute of Electronics and Cryptology (UEKAE)
Department of Information Systems Security makes social engineering attacks to
Turkish public agencies within the frame of ""Information Security Tests"" [19].
This paper will make an analysis of the social engineering tests that have been
carried out in several Turkish public agencies. The tests include phone calling
to sample employees by the social engineer and trying to seize employees'
sensitive information by exploiting their good faith. The aim of this research
is to figure that the employees in Turkish public agencies have a lack of
information security awareness and they compromise the information security
principles which should be necessarily applied for any public agencies. Social
engineering, both with its low cost and ability to take advantage of low
technology, has taken its place in the information security literature as a
very effective form of attack [8]."
"In this paper, after giving a brief definition of Information Security
Management Systems (ISMS), ISO 27001, IT governance and COBIT, pros and cons of
implementing only COBIT, implementing only IS0 27001 and implementing both
COBIT and ISO 27001 together when governing information security in enterprises
will be issued."
"Steganography is the art and science of writing hidden messages in such a way
that no one apart from the intended recipient knows of the existence of the
message. In today's world, it is widely used in order to secure the
information. In this paper, the traditional spectral estimation methods are
introduced. The performance analysis of each method is examined by comparing
all of the spectral estimation methods. Finally, from utilizing those
performance analyses, a brief pros and cons of the spectral estimation methods
are given. Also we give a steganography demo by hiding information into a sound
signal and manage to pull out the information (i.e, the true frequency of the
information signal) from the sound by means of the spectral estimation methods."
"Steganography is the art and science of writing hidden messages in such a way
that no one apart from the intended recipient knows of the existence of the
message. In today's world, it is widely used in order to secure the
information. In this paper, the traditional spectral estimation methods are
introduced. The performance analysis of each method is examined by comparing
all of the spectral estimation methods. Finally, from utilizing those
performance analyses, a brief pros and cons of the spectral estimation methods
are given. Also we give a steganography demo by hiding information into a sound
signal and manage to pull out the information (i.e, the true frequency of the
information signal) from the sound by means of the spectral estimation methods."
"In this paper, different steganographic methods have been analyzed and
implementations of those techniques have been performed. Those methods include
hiding in text, hiding in audio file, hiding in file system, and hiding in
image files."
"Traditionally, ""Cryptography"" is a benediction to information processing and
communications, it helps people to store information securely and the private
communications over long distances. Cryptovirology is the study of applications
of cryptography to build the malicious software. It is an investigation, how
modern cryptographic tools and paradigms can be used to strengthen, develop and
improve new malicious software attacks. Cryptovirology attacks have been
categorized as : give malware enhanced privacy and be more robust against
reverse-engineering, secondly give the attacker enhanced anonymity while
communicating with deployed malware. This paper presents the idea of
""Cryptovirology"" which introduce a twist on how cryptography can also be used
offensively. Being offensive means, it can be used to mount extortion based
attacks that cause loss of access to information, loss of confidentiality, and
information leakage, tasks which cryptography usually prevents. Also analyze
threats and attacks that misuse of cryptography can cause when combined with
fraudulent software (viruses, Trojans). Public-key cryptography is very
essential for the attacks that based on cryptovirology. This paper also suggest
some of the countermeasures, mechanisms to cope with and prevent such attacks.
Even if the attackers actions on the host machine are being monitored, it still
cannot be proven beyond reasonable doubt that he or she is the attacker; and it
is an ""originator-concealing attack"". Evidence should be collected from the
""author's own system which was used for the attack"". These attacks have
implications on how the use of cryptographic tools and techniques should be
audited and managed in general purpose computing environments, and imply that
access to the cryptographic tools should be in well control of the system(such
as API routines)."
"Wireless sensor network (WSN) is regularly deployed in unattended and hostile
environments. The WSN is vulnerable to security threats and susceptible to
physical capture. Thus, it is necessary to use effective mechanisms to protect
the network. It is widely known, that the intrusion detection is one of the
most efficient security mechanisms to protect the network against malicious
attacks or unauthorized access. In this paper, we propose a hybrid intrusion
detection system for clustered WSN. Our intrusion framework uses a combination
between the Anomaly Detection based on support vector machine (SVM) and the
Misuse Detection. Experiments results show that most of routing attacks can be
detected with low false alarm."
"The Google Desktop Search is an indexing tool, currently in beta testing,
designed to allow users fast, intuitive, searching for local files. The
principle interface is provided through a local web server which supports an
interface similar to Google.com's normal web page. Indexing of local files
occurs when the system is idle, and understands a number of common file types.
A optional feature is that Google Desktop can integrate a short summary of a
local search results with Google.com web searches. This summary includes 30-40
character snippets of local files. We have uncovered a vulnerability that would
release private local data to an unauthorized remote entity. Using two
different attacks, we expose the small snippets of private local data to a
remote third party."
"The very nature of operations in peer-to-peer systems such as BitTorrent
exposes information about participants to their peers. Nodes desiring
anonymity, therefore, often chose to route their peer-to-peer traffic through
anonymity relays, such as Tor. Unfortunately, these relays have little
incentive for contribution and struggle to scale with the high loads that P2P
traffic foists upon them. We propose a novel modification for BitTorrent that
we call the BitTorrent Anonymity Marketplace. Peers in our system trade in k
swarms obscuring the actual intent of the participants. But because peers can
cross-trade torrents, the k-1 cover traffic can actually serve a useful
purpose. This creates a system wherein a neighbor cannot determine if a node
actually wants a given torrent, or if it is only using it as leverage to get
the one it really wants. In this paper, we present our design, explore its
operation in simulation, and analyze its effectiveness. We demonstrate that the
upload and download characteristics of cover traffic and desired torrents are
statistically difficult to distinguish."
"The session initiation protocol (SIP) is a powerful signaling protocol that
controls communication on the Internet, establishing, maintaining, and
terminating the sessions. The services that are enabled by SIP are equally
applicable in the world of mobile and ubiquitous computing. In 2009, Tsai
proposed an authenticated key agreement scheme as an enhancement to SIP. Very
recently, Arshad et al. demonstrated that Tsai's scheme was vulnerable to
offline password guessing attack and stolen-verifier attack. They also pointed
that Tsai's scheme did not provide known-key secrecy and perfect forward
secrecy. In order to overcome the weaknesses, Arshad et al. also proposed an
improved mutual authentication scheme based on elliptic curve discrete
logarithm problem for SIP and claimed that their scheme can withstand various
attacks. In this paper, we do a cryptanalysis of Arshad et al.'s scheme and
show that Arshad et al.'s scheme is vulnerable to the password guessing attack."
"In order to determine the user's trust is a growing concern for ensuring
privacy and security in a cloud computing environment. In cloud, user's data is
stored in one or more remote server(s) which poses more security challenges for
the system. One of the most important concerns is to protect user's sensitive
information from other users and hackers that may cause data leakage in cloud
storage. Having this security challenge in mind, this paper focuses on the
development of a more secure cloud environment, to determine the trust of the
service requesting authorities by using a novel VM (Virtual Machine) monitoring
system. Moreover, this research aims towards proposing a new trusted and
collaborative agent-based two-tier framework, titled WAY (Who Are You?), to
protect cloud resources. The framework can be used to provide security in
network, infrastructure, as well as data storage in a heterogeneous cloud
platform. If the trust updating policy is based on network activities, then the
framework can provide network security. Similarly, it provides storage security
by monitoring unauthorized access activities by the Cloud Service Users (CSU).
Infrastructure security can be provided by monitoring the use of privileged
instructions within the isolated VMs. The uniqueness of the proposed security
solution lies in the fact that it ensures security and privacy both at the
service provider level as well as at the user level in a cloud environment."
"Language-based information flow security aims to decide whether an
action-observable program can unintentionally leak confidential information if
it has the authority to access confidential data. Recent concerns about
declassification polices have provided many choices for practical intended
information release, but more precise enforcement mechanism for these policies
is insufficiently studied. In this paper, we propose a security property on the
where-dimension of declassification and present an enforcement based on
automated verification. The approach automatically transforms the abstract
model with a variant of self-composition, and checks the reachability of
illegal-flow state of the model after transformation. The self-composition is
equipped with a store-match pattern to reduce the state space and to model the
equivalence of declassified expressions in the premise of property. The
evaluation shows that our approach is more precise than type-based enforcement."
"We consider a calculus for multiparty sessions enriched with security levels
for messages. We propose a monitored semantics for this calculus, which blocks
the execution of processes as soon as they attempt to leak information. We
illustrate the use of our monitored semantics with various examples, and show
that the induced safety property implies a noninterference property studied
previously."
"The linear complexity and the $k$-error linear complexity of a sequence have
been used as important security measures for key stream sequence strength in
linear feedback shift register design. By studying the linear complexity of
binary sequences with period $2^n$, one could convert the computation of
$k$-error linear complexity into finding error sequences with minimal Hamming
weight. Based on Games-Chan algorithm, the $k$-error linear complexity
distribution of $2^n$-periodic binary sequences is investigated in this paper.
First, for $k=2,3$, the complete counting functions on the $k$-error linear
complexity of $2^n$-periodic balanced binary sequences (with linear complexity
less than $2^n$) are characterized. Second, for $k=3,4$, the complete counting
functions on the $k$-error linear complexity of $2^n$-periodic binary sequences
with linear complexity $2^n$ are presented. Third, as a consequence of these
results, the counting functions for the number of $2^n$-periodic binary
sequences with the $k$-error linear complexity for $k = 2$ and 3 are obtained.
Further more, an important result in a recent paper is proved to be not
completely correct."
"With the success of Web applications, most of our data is now stored on
various third-party servers where they are processed to deliver personalized
services. Naturally we must be authenticated to access this personal
information, but the use of personalized services only restricted by
identification could indirectly and silently leak sensitive data. We analyzed
Google Web Search access mechanisms and found that the current policy applied
to session cookies could be used to retrieve users' personal data. We describe
an attack scheme leveraging the search personalization (based on the same SID
cookie) to retrieve a part of the victim's click history and even some of her
contacts. We implemented a proof of concept of this attack on Firefox and
Chrome Web browsers and conducted an experiment with ten volunteers. Thanks to
this prototype we were able to recover up to 80% of the user's search click
history."
"An Intrusion Detection System (IDS) detects malicious and selfish nodes in a
network. Ad hoc networks are often secured by using either intrusion detection
or by secure routing. Designing efficient IDS for wireless ad-hoc networks that
would not affect the performance of the network significantly is indeed a
challenging task. Arguably, the most common thing in a review paper in the
domain of wireless networks is to compare the performances of different
solutions using simulation results. However, variance in multiple configuration
aspects including that due to different underlying routing protocols, makes the
task of simulation based comparative evaluation of IDS solutions somewhat
unrealistic. In stead, the authors have followed an analytic approach to
identify the gaps in the existing IDS solutions for MANETs and wireless mesh
networks. The paper aims to ease the job of a new researcher by exposing him to
the state of the art research issues on IDS. Nearly 80% of the works cited in
this paper are published with in last 3 to 4 years."
"Ciphers get their strength from the mathematical functions of confusion and
diffusion, also known as substitution and permutation. These were the basics of
classical cryptography and they are still the basic part of modern ciphers. In
block ciphers diffusion is achieved by the use of Maximum Distance Separable
(MDS) matrices. In this paper we present some methods for constructing dynamic
(and random) MDS matrices."
"Recent work in traffic analysis has shown that traffic patterns leaked
through side channels can be used to recover important semantic information.
For instance, attackers can find out which website, or which page on a website,
a user is accessing simply by monitoring the packet size distribution. We show
that traffic analysis is even a greater threat to privacy than previously
thought by introducing a new attack that can be carried out remotely. In
particular, we show that, to perform traffic analysis, adversaries do not need
to directly observe the traffic patterns. Instead, they can gain sufficient
information by sending probes from a far-off vantage point that exploits a
queuing side channel in routers. To demonstrate the threat of such remote
traffic analysis, we study a remote website detection attack that works against
home broadband users. Because the remotely observed traffic patterns are more
noisy than those obtained using previous schemes based on direct local traffic
monitoring, we take a dynamic time warping (DTW) based approach to detecting
fingerprints from the same website. As a new twist on website fingerprinting,
we consider a website detection attack, where the attacker aims to find out
whether a user browses a particular web site, and its privacy implications. We
show experimentally that, although the success of the attack is highly
variable, depending on the target site, for some sites very low error rates. We
also show how such website detection can be used to deanonymize message board
users."
"The use of e-Auction services has been increasing in recent years. Security
requirements in conducting e-Auctions are mainly bid privacy, anonymity and
public verifiability. Most of the secure protocols concentrate on privacy and
anonymity, which are achieved through bidder-resolved multi-party computation,
assuming two or more trusted third parties, either through numerous auctioneers
or with asymmetric models in which the commercial entity of an auction issuer
or registration manager is assumed in addition to the auctioneer.
Multi-attribute reverse auctions promise higher market efficiency and effective
information exchange. This work extends and uses the existing schemes. This
scheme uses scoring function, winner determination in multi-attribute auctions
to implement public verifiability. Anonymity is achieved through bidder side
pseudonym generation. By results and analysis we say this is very simple and
effective scheme. This scheme ensures public verifiability and anonymity in
multi-attribute auctions without revelation of the bids received, third parties
and complex communications."
"Online auction, shopping, electronic billing etc. all such types of
application involves problems of fraudulent transactions. Online fraud
occurrence and its detection is one of the challenging fields for web
development and online phantom transaction. As no-secure specification of
online frauds is in research database, so the techniques to evaluate and stop
them are also in study. We are providing an approach with Hidden Markov Model
(HMM) and mobile implicit authentication to find whether the user interacting
online is a fraud or not. We propose a model based on these approaches to
counter the occurred fraud and prevent the loss of the customer. Our technique
is more parameterized than traditional approaches and so,chances of detecting
legitimate user as a fraud will reduce."
"Distributed hash tables suffer from several security and privacy
vulnerabilities, including the problem of Sybil attacks. Existing social
network-based solutions to mitigate the Sybil attacks in DHT routing have a
high state requirement and do not provide an adequate level of privacy. For
instance, such techniques require a user to reveal their social network
contacts. We design X-Vine, a protection mechanism for distributed hash tables
that operates entirely by communicating over social network links. As with
traditional peer-to-peer systems, X-Vine provides robustness, scalability, and
a platform for innovation. The use of social network links for communication
helps protect participant privacy and adds a new dimension of trust absent from
previous designs. X-Vine is resilient to denial of service via Sybil attacks,
and in fact is the first Sybil defense that requires only a logarithmic amount
of state per node, making it suitable for large-scale and dynamic settings.
X-Vine also helps protect the privacy of users social network contacts and
keeps their IP addresses hidden from those outside of their social circle,
providing a basis for pseudonymous communication. We first evaluate our design
with analysis and simulations, using several real world large-scale social
networking topologies. We show that the constraints of X-Vine allow the
insertion of only a logarithmic number of Sybil identities per attack edge; we
show this mitigates the impact of malicious attacks while not affecting the
performance of honest nodes. Moreover, our algorithms are efficient, maintain
low stretch, and avoid hot spots in the network. We validate our design with a
PlanetLab implementation and a Facebook plugin."
"Collaborative spectrum sensing can significantly improve the detection
performance of secondary unlicensed users (SUs). However, the performance of
collaborative sensing is vulnerable to sensing data falsification attacks,
where malicious SUs (attackers) submit manipulated sensing reports to mislead
the fusion center's decision on spectrum occupancy. Moreover, attackers may not
follow the fusion center's decision regarding their spectrum access. This paper
considers a challenging attack scenario where multiple rational attackers
overhear all honest SUs' sensing reports and cooperatively maximize attackers'
aggregate spectrum utilization. We show that, without attack-prevention
mechanisms, honest SUs are unable to transmit over the licensed spectrum, and
they may further be penalized by the primary user for collisions due to
attackers' aggressive transmissions. To prevent such attacks, we propose two
novel attack-prevention mechanisms with direct and indirect punishments. The
key idea is to identify collisions to the primary user that should not happen
if all SUs follow the fusion center's decision. Unlike prior work, the proposed
simple mechanisms do not require the fusion center to identify and exclude
attackers. The direct punishment can effectively prevent all attackers from
behaving maliciously. The indirect punishment is easier to implement and can
prevent attacks when the attackers care enough about their long-term reward."
"RSA(Rivest, Shamir and Adleman)is being used as a public key exchange and key
agreement tool for many years. Due to large numbers involved in RSA, there is
need for more efficient methods in implementation for public key cryptosystems.
Elliptic Curve Cryptography(ECC) is based on elliptic curves defined over a
finite field. Elliptic curve cryptosystems(ECC) were discovered by Victor
Miller and Neal Koblitz in 1985.This paper comprises of five sections. Section
I is introduction to ECC and its components. Section II describes advantages of
ECC schemes and its comparison with RSA. Section III is about some of the
applications of ECC. Section IV gives some embedded implementations of ECC.
Section V contains ECC implementation on fixed point Digital Signal
Processor(TMS320VC5416). ECC was implemented using general purpose
microcontrollers and Field Programmable Gate Arrays (FPGA) before this work.
DSP is more powerful than microcontrollers and much economical than FPGA. So
this implementation can be efficiently utilized in low-power applications."
"The ubiquitous presence of mobile communication devices and the continuous
development of mo- bile data applications, which results in high level of
mobile devices' activity and exchanged data, often transparent to the user,
makes privacy preservation an important feature of mobile telephony systems. We
present a formal analysis of the UMTS Authentication and Key Agreement
protocol, using the applied pi-calculus and the ProVerif tool. We formally
verify the model with respect to privacy properties. We show a linkability
attack which makes it possible, for individuals with low-cost equipment, to
trace UMTS subscribers. The attack exploits information leaked by poorly
designed error messages."
"This chapter is going to deal with enhancing the efficiency of Biometric by
integrating it with Salt Value (randomly generated value of varying length).
Normally at an enterprise level or data centres, the servers are maintained
with complex passwords and they are known only to the system administrators.
Even after applying lot of securities at an expert level, the hackers are able
to penetrate through the network and break the passwords easily. Here how the
biometric can play a vital role and that too with the inclusion of Salt value
can prevent the hacker from stealing the confidential data's of an
organization."
"This paper presents a mitigation scheme to cope with the random query string
Denial of Service (DoS) attack, which is based on a vulnerability of current
Content Delivery Networks (CDNs). The attack exploits the fact that edge
servers composing a CDN, receiving an HTTP request for a resource with an
appended random query string never saw before, ask the origin server for a
(novel) copy of the resource. Such characteristics can be employed to take an
attack against the origin server by exploiting edge servers. Our strategy
adopts a simple gossip protocol executed by edge servers to detect the attack.
Based on such a detection, countermeasures can be taken to protect the origin
server and the CDN against the attack. We provide simulation results that show
the viability of our approach."
"The linear complexity of a sequence has been used as an important measure of
keystream strength, hence designing a sequence which possesses high linear
complexity and $k$-error linear complexity is a hot topic in cryptography and
communication. Niederreiter first noticed many periodic sequences with high
$k$-error linear complexity over GF(q). In this paper, the concept of stable
$k$-error linear complexity is presented to study sequences with high $k$-error
linear complexity. By studying linear complexity of binary sequences with
period $2^n$, the method using cube theory to construct sequences with maximum
stable $k$-error linear complexity is presented. It is proved that a binary
sequence with period $2^n$ can be decomposed into some disjoint cubes. The cube
theory is a new tool to study $k$-error linear complexity. Finally, it is
proved that the maximum $k$-error linear complexity is $2^n-(2^l-1)$ over all
$2^n$-periodic binary sequences, where $2^{l-1}\le k<2^{l}$."
"The linear complexity (LC) of a sequence has been used as a convenient
measure of the randomness of a sequence. Based on the theories of linear
complexity, $k$-error linear complexity, the minimum error and the $k$-error
linear complexity profile, the notion of $m$-tight error linear complexity is
presented. An efficient algorithm for computing $m$-tight error linear
complexity is derived from the algorithm for computing $k$-error linear
complexity of sequences over GF($p^{m}$) with period $p^n$, where $p$ is a
prime. The validity of the algorithm is shown. The algorithm is also realized
with C language, and an example is presented to illustrate the algorithm."
"The main objective of the paper is to study and develop an efficient method
for Hard Disk Drive(HDD) Security using Full Disk Encryption (FDE) with
Advanced Encryption Standards(AES) for data security specifically for Personal
Computers(PCS) and Laptops . The focus of this work is to authenticate and
protect the content of HDD from illegal use. The paper proposes an adaptive
methods for protecting a HDD based on FDE. The proposed method is labeled as
DiskTrust. FDE encrypts entire content or a single volume on your disk.
DiskTrust implements Symmetric key cryptography with, Advanced Encryption
Standards. Finally, the applicability of these methodologies for HDD security
will be evaluated on a set of data files with different key sizes."
"Most search engines can potentially infer the preferences and interests of a
user based on her history of search queries. While search engines can use these
inferences for a variety of tasks, including targeted advertisements, such
tasks do impose an serious threat to user privacy. In 2006, after AOL disclosed
the search queries of 650,000 users, TrackMeNot was released as a simple
browser extension that sought to hide user search preferences in a cloud of
queries. The first versions of TrackMeNot, though used extensively in the past
three years, was fairly simplistic in design and did not provide any strong
privacy guarantees. In this paper, we present the new design and implementation
of TrackMeNot, which address many of the limitations of the first release.
TrackMeNot addresses two basic problems. First, using a model for
characterizing search queries, TrackMeNot provides a mechanism for obfuscating
the search preferences of a user from a search engine. Second, TrackMeNot
prevents the leakage of information revealing the use of obfuscation to a
search engine via several potential side channels in existing browsers such as
clicks, cookies etc. Finally, we show that TrackMeNot cannot be detected by
current search bot detection mechanisms and demonstrate the effectiveness of
TrackMeNot in obfuscating user interests by testing its efficiency on a major
search engine."
"A crypto system can be used to encrypt messages sent between two
communicating parties so that an eavesdropper who overhears the encrypted
messages will not be able to decode them. The paper mainly concentrates on the
method in which the substitution technique of steganography can been used to
hide data in a 24-bit bitmap file. Popular audio hiding techniques based on
methods of steganography is also discussed here."
"Cloud Computing holds the potential to eliminate the requirements for setting
up of high-cost computing infrastructure for the IT-based solutions and
services that the industry uses. It promises to provide a flexible IT
architecture, accessible through internet for lightweight portable devices.
This would allow many-fold increase in the capacity or capabilities of the
existing and new software. In a cloud computing environment, the entire data
reside over a set of networked resources, enabling the data to be accessed
through virtual machines. Since these data centers may lie in any corner of the
world beyond the reach and control of users, there are multifarious security
and privacy challenges that need to be understood and taken care of. Also, one
can never deny the possibility of a server breakdown that has been witnessed,
rather quite often in the recent times. There are various issues that need to
be dealt with respect to security and privacy in a cloud computing scenario.
This extensive survey paper aims to elaborate and analyze the numerous
unresolved issues threatening the Cloud computing adoption and diffusion
affecting the various stake-holders linked to it."
"We consider the problem of logical data erasure, contrasting with physical
erasure in the same way that end-to-end information flow control contrasts with
access control. We present a semantic hierarchy for erasure policies, using a
possibilistic knowledge-based semantics to define policy satisfaction such that
there is an intuitively clear upper bound on what information an erasure policy
permits to be retained. Our hierarchy allows a rich class of erasure policies
to be expressed, taking account of the power of the attacker, how much
information may be retained, and under what conditions it may be retained.
While our main aim is to specify erasure policies, the semantic framework
allows quite general information-flow policies to be formulated for a variety
of semantic notions of secrecy."
"Phishing is the combination of social engineering and technical exploits
designed to convince a victim to provide personal information, usually for the
monetary gain of the attacker. Phishing has become the most popular practice
among the criminals of the Web. Phishing attacks are becoming more frequent and
sophisticated. The impact of phishing is drastic and significant since it can
involve the risk of identity theft and financial losses. Phishing scams have
become a problem for online banking and e-commerce users. In this paper we
propose a novel approach to detect phishing attacks. We implemented a prototype
web browser which can be used as an agent and processes each arriving email for
phishing attacks. Using email data collected over a period time we demonstrate
data that our approach is able to detect more phishing attacks than existing
schemes."
"Authentication is the act of confirming the truth of an attribute of a datum
or entity. This might involve confirming the identity of a person, tracing the
origins of an artefact, ensuring that a product is what it's packaging and
labelling claims to be, or assuring that a computer program is a trusted one.
The authentication of information can pose special problems (especially
man-in-the-middle attacks), and is often wrapped up with authenticating
identity. Literary can involve imitating the style of a famous author. If an
original manuscript, typewritten text, or recording is available, then the
medium itself (or its packaging - anything from a box to e-mail headers) can
help prove or disprove the authenticity of the document. The use of digital
images of handwritten historical documents has become more popular in recent
years. Volunteers around the world now read thousands of these images as part
of their indexing process. Handwritten text images of old documents are
sometimes difficult to read or noisy due to the preservation of the document
and quality of the image [1]. Handwritten text offers challenges that are
rarely encountered in machine-printed text. In addition, most problems faced in
reading machine- printed text (e.g., character recognition, word segmentation,
letter segmentation, etc.) are more severe, in handwritten text. In this paper
we Here in this paper we proposed a method for authenticating hand written text
images using back propagation algorithm.."
"Cryptography protects users by providing functionality for the encryption of
data and authentication of other users. This technology lets the receiver of an
electronic message verify the sender, ensures that a message can be read only
by the intended person, and assures the recipient that a message has not be
altered in transit. Classical cryptanalysis involves an interesting combination
of analytical reasoning, application of mathematical tools and pattern finding.
The objectives of the proposed work are to propose a new cryptographic method
based on the special matrix called the Hilbert matrix for authentication and
confidentiality and to propose a model for confidentiality and authentication
using shared key cryptosystems with the concept of digital enveloping using a
session key. In the present work various algorithms are presented for
encryption and authentication based on Hilbert matrix using a session key."
"Integrating an efficient Error detection and correction scheme with less
encoding and decoding complexity to support the distribution of keying material
in a secure group communication is an important issue, since the amount of
information carried out in the wireless channel is high which produces more
errors due to noise available in the communication channel. Moreover, the key
must be sent securely to the group members. In this paper, we propose a new
efficient group key computation protocol that provides more security and also
integrates an encoding method in sender side and decoding method in the
receiver side. To achieve security in key computation process, we propose
Euler's totient function based Diffie-hellman key distribution protocol. To
provide efficient error detection and correction method while distributing the
Keying and re-keying information, we introduce tanner graph based encoding
stopping set construction algorithm in sender and receiver side of the group
communication. Two major operations in this scheme are joining and leaving
operations for managing group memberships. The encoding and decoding complexity
of this approach is computed in this paper and it is proved that this proposed
approach takes less decoding time complexity."
"This paper puts forward a safe mechanism of data transmission to tackle the
security problem of information which is transmitted in Internet. The
encryption standards such as DES (Data Encryption Standard), AES (Advanced
Encryption Standard) and EES (Escrowed Encryption Standard) are widely used to
solve the problem of communication over an insecure channel. With advanced
technologies in computer hardware and software, these standards seem not to be
as secure and fast as one would like. In this paper we propose a encryption
technique which provides security to both the message and the secret key
achieving confidentiality and authentication. The Symmetric algorithm used has
two advantages over traditional schemes. First, the encryption and decryption
procedures are much simpler, and consequently, much faster. Second, the
security level is higher due to the inherent poly-alphabetic nature of the
substitution mapping method used here, together with the translation and
transposition operations performed in the algorithm. Asymmetric algorithm RSA
is worldwide known for its high security. In this paper a detailed report of
the process is presented and analysis is done comparing our proposed technique
with familiar techniques"
"The challenging number is used for the detection of Spoofing attack. The IP
Spoofing is considered to be one of the potentially brutal attack which acts as
a tool for the DDoS attack which is considered to be a major threat among
security problems in today's internet. These kinds of attack are extremely
severe. They bring down business of company drastically. DDoS attack can easily
exhaust the computing and communication resources of its victim within a short
period of time. There are attacks exploiting some vulnerability or
implementation bug in the software implementation of a service to bring that
down and some attacks will use all the available resources at the target
machine. This deals on attacks that consume all the bandwidth available to the
victim machine. While concentrating on the bandwidth attack the TCP SYN flood
is the more prominent attack. TCP/IP protocol suite is the most widely used
protocol suite for data communication. The TCP SYN flood works by exhausting
the TCP connection queue of the host and thus denying legitimate connection
request. There are various methods used to detect and prevent this attack, one
of which is to block the packet based on SYN flag count from the same IP
address. This kind of prevention methods becomes unsuitable when the attackers
use the Spoofed IP address. The SYN spoofing becomes a major tool the TCP SYN
flooding. For the prevention of this kind of attacks, the TCP specific probing
is used in the proposed scheme where the client is requested challenging number
while sending the ACK in the three way hand shake. This is very useful to find
the Spoofed IP Packets/TCP SYN flood and preventing them."
"We study oblivious storage (OS), a natural way to model privacy-preserving
data outsourcing where a client, Alice, stores sensitive data at an
honest-but-curious server, Bob. We show that Alice can hide both the content of
her data and the pattern in which she accesses her data, with high probability,
using a method that achieves O(1) amortized rounds of communication between her
and Bob for each data access. We assume that Alice and Bob exchange small
messages, of size $O(N^{1/c})$, for some constant $c\ge2$, in a single round,
where $N$ is the size of the data set that Alice is storing with Bob. We also
assume that Alice has a private memory of size $2N^{1/c}$. These assumptions
model real-world cloud storage scenarios, where trade-offs occur between
latency, bandwidth, and the size of the client's private memory."
"Ubiquitous and pervasive applications, where the Wireless Sensor Networks are
typically deployed, lead to the susceptibility to many kinds of security
attacks. Sensors used for real time response capability also make it difficult
to devise the resource intensive security protocols because of their limited
battery, power, memory and processing capabilities. One of potent form of
Denial of Service attacks is Wormhole attack that affects on the network layer.
In this paper, the techniques dealing with wormhole attack are investigated and
an approach for wormhole prevention is proposed. Our approach is based on the
analysis of the two-hop neighbors forwarding Route Reply packet. To check the
validity of the sender, a unique key between the individual sensor node and the
base station is required to be generated by suitable scheme."
"Safeguarding online communications using public key cryptography is a
well-established practice today, but with the increasing reliance on
`faceless', solely online entities one of the core aspects of public key
cryptography is becoming a substantial problem in practice: Who can we trust to
introduce us to and vouch for some online party whose public key we see for the
first time? Most existing certification models lack flexibility and have come
under attack repeatedly in recent years, and finding practical improvements has
a high priority.
  We propose that the real-world concept of a notary or certifying witness can
be adapted to today's online environment quite easily, and that such a system
when combined with peer-to-peer technologies for defense in depth is a viable
alternative to monolithic trust infrastructures.
  Instead of trusting assurances from a single party, integrity certifications
(and data replication) can be provided among a group of independent parties in
a peer-to-peer fashion. As the likelihood of all such assurance providers being
subverted at the very same time is very much less than that of a single party,
overall robustness is improved.
  This paper presents the design and the implementation of our prototype online
notary system where independent computer notaries provide integrity
certification and highly-available replicated storage, and discusses how this
online notary system handles some common threat patterns."
"Biometric identity-based encryption (Bio-IBE) is a kind of fuzzy
identity-based encryption (fuzzy IBE) where a ciphertext encrypted under an
identity w' can be decrypted using a secret key corresponding to the identity w
which is close to w' as measured by some metric. Recently, Yang et al. proposed
a constant-size Bio-IBE scheme and proved that it is secure against adaptive
chosen-ciphertext attack (CCA2) in the random oracle model. Unfortunately, in
this paper, we will show that their Bio-IBE scheme is even not chosen-plaintext
secure. Specifically, user w using his secret key is able to decrypt any
ciphertext encrypted under an identity w' even though w is not close to w'."
"This paper presents a survey of text steganography methods used for hid- ing
secret information inside some covertext. Widely known hiding techniques (such
as translation based steganography, text generating and syntactic embed- ding)
and detection are considered. It is shown that statistical analysis has an
important role in text steganalysis."
"Administrative role-based access control (ARBAC) is the first comprehensive
administrative model proposed for role-based access control (RBAC). ARBAC has
several features for designing highly expressive policies, but current work has
not highlighted the utility of these expressive policies. In this report, we
present a case study of designing an ARBAC policy for a bank comprising 18
branches. Using this case study we provide an assessment about the features of
ARBAC that are likely to be used in realistic policies."
"This article describes novel text steganalysis method. The archiver ""Bzip2""
used for detection stegotext generated by Texto stegosystem. Experiments show
that proposed approach gets better performance than typical existing methods.
The detection accuracy exceeds 99.98% for text segments with size 400 bytes."
"Passwords provide security mechanism for authentication and protection
services against unwanted access to resources. A graphical based password is
one promising alternatives of textual passwords. According to human psychology,
humans are able to remember pictures easily. In this paper, we have proposed a
new hybrid graphical password based system, which is a combination of
recognition and recall based techniques that offers many advantages over the
existing systems and may be more convenient for the user. Our scheme is
resistant to shoulder surfing attack and many other attacks on graphical
passwords. This scheme is proposed for smart mobile devices (like smart phones
i.e. ipod, iphone, PDAs etc) which are more handy and convenient to use than
traditional desktop computer systems."
"In this paper, we explicitly construct a large class of symmetric Boolean
functions on $2k$ variables with algebraic immunity not less than $d$, where
integer $k$ is given arbitrarily and $d$ is a given suffix of $k$ in binary
representation. If let $d = k$, our constructed functions achieve the maximum
algebraic immunity. Remarkably, $2^{\lfloor \log_2{k} \rfloor + 2}$ symmetric
Boolean functions on $2k$ variables with maximum algebraic immunity are
constructed, which is much more than the previous constructions. Based on our
construction, a lower bound of symmetric Boolean functions with algebraic
immunity not less than $d$ is derived, which is $2^{\lfloor \log_2{d} \rfloor +
2(k-d+1)}$. As far as we know, this is the first lower bound of this kind."
"In this note, we go further on the ""basis exchange"" idea presented in
\cite{LiNa1} by using Mobious inversion. We show that the matrix
$S_1(f)S_0(f)^{-1}$ has a nice form when $f$ is chosen to be the majority
function, where $S_1(f)$ is the matrix with row vectors $\upsilon_k(\alpha)$
for all $\alpha \in 1_f$ and $S_0(f)=S_1(f\oplus1)$. And an exact counting for
Boolean functions with maximum algebraic immunity by exchanging one point in
on-set with one point in off-set of the majority function is given.
Furthermore, we present a necessary condition according to weight distribution
for Boolean functions to achieve algebraic immunity not less than a given
number."
"A proxy signature scheme allows a proxy signer to sign messages on behalf of
an original signer. Proxy signature schemes have found numerous practical
applications such as grid computing, mobile agent systems and cloud
applications. Recently, Jiang et al. proposed the first lattice-based proxy
signature scheme and claimed that their scheme provides all the security
properties of a secure proxy signature scheme. However, in this paper, we
disprove their claim and show that an original signer is able to forge a proxy
signature on any message."
"We review the implementation of two QKD protocols (BB84 and B92) keeping in
mind that their implementations do not easily satisfy the requirement of use of
single photons. We argue that current models do not take into account issues
raised by the Uncertainty Principle related to time-location and transmission
characteristics of single photons. This indicates that security proofs of
current implementations even after the fixes for the recent successful hacks
are made will be hard to obtain."
"Anonymity networks hide user identities with the help of relayed anonymity
routers. However, the state-of-the-art anonymity networks do not provide an
effective trust model. As a result, users cannot circumvent malicious or
vulnerable routers, thus making them susceptible to malicious router based
attacks (e.g., correlation attacks). In this paper, we propose a novel social
network based trust model to help anonymity networks circumvent malicious
routers and obtain secure anonymity. In particular, we design an input
independent fuzzy model to determine trust relationships between friends based
on qualitative and quantitative social attributes, both of which can be readily
obtained from existing social networks. Moreover, we design an algorithm for
propagating trust over an anonymity network. We integrate these two elements in
STor, a novel social network based Tor. We have implemented STor by modifying
the Tor's source code and conducted experiments on PlanetLab to evaluate the
effectiveness of STor. Both simulation and PlanetLab experiment results have
demonstrated that STor can achieve secure anonymity by establishing trust-based
circuits in a distributed way. Although the design of STor is based on Tor
network, the social network based trust model can be adopted by other anonymity
networks."
"This paper analyzes the performance of Kak's quantum cryptography protocol
when intensity monitoring is used to detect the presence of Eve during
transmission. Some difficulties related to interception to obtain useful data
from the transmission are discussed. The analysis shows the resilience of the
protocol towards the man-in-the-middle attack."
"Recently, Yang and Tan proposed a certificateless key exchange protocol
without pairing, and claimed their scheme satisfies forward secrecy, which
means no adversary could derive an already-established session key unless the
full user secret keys (including a private key and an ephemeral secret key) of
both communication parties are compromised. However, in this paper, we point
out their protocol is actually not secure as claimed by presenting an attack
launched by an adversary who has learned the private key of one party and the
ephemeral secret key of the other, but not the full user secret keys of both
parties. Furthermore, to make up this flaw, we also provide an improved
protocol in which the private key and the ephemeral secret key are closely
intertwined with each other for generating the session key, thus above attack
can be efficiently resisted."
"Image applications have been increasing in recent years.Encryption is used to
provide the security needed for image applications. In this paper, we classify
various image encryption schemes and analyze them with respect to various
parameters like tunability, visual degradation, compression friendliness,format
compliance, encryption ratio, speed, and cryptographic security."
"Due to the rapid development of the Internet in recent years, the need to
find new tools to reinforce trust and security through the Internet has became
a major concern. The discovery of new pseudo-random number generators with a
strong level of security is thus becoming a hot topic, because numerous
cryptosystems and data hiding schemes are directly dependent on the quality of
these generators. At the conference Internet`09, we have described a generator
based on chaotic iterations, which behaves chaotically as defined by Devaney.
In this paper, the proposal is to improve the speed and the security of this
generator, to make its use more relevant in the Internet security context. To
do so, a comparative study between various generators is carried out and
statistical results are given. Finally, an application in the information
hiding framework is presented, to give an illustrative example of the use of
such a generator in the Internet security field."
"With the widespread use of communication technologies, cryptosystems are
therefore critical to guarantee security over open networks as the Internet.
Pseudo-random number generators (PRNGs) are fundamental in cryptosystems and
information hiding schemes. One of the existing chaos-based PRNGs is using
chaotic iterations schemes. In prior literature, the iterate function is just
the vectorial boolean negation. In this paper, we propose a method using Graph
with strongly connected components as a selection criterion for chaotic iterate
function. In order to face the challenge of using the proposed chaotic iterate
functions in PRNG, these PRNGs are subjected to a statistical battery of tests,
which is the well-known NIST in the area of cryptography."
"Chaos and its applications in the field of secure communications have
attracted a lot of attention. Chaos-based pseudo-random number generators are
critical to guarantee security over open networks as the Internet. We have
previously demonstrated that it is possible to define such generators with good
statistical properties by using a tool called ""chaotic iterations"", which
depends on an iteration function. An approach to find update functions such
that the associated generator presents a random-like and chaotic behavior is
proposed in this research work. To do so, we use the vectorial Boolean negation
as a prototype and explain how to modify this iteration function without
deflating the good properties of the associated generator. Simulation results
and basic security analysis are then presented to evaluate the randomness of
this new family of generators."
"This paper presents an algorithm for generating pseudorandom numbers using
quasigroups. Random numbers have several applications in the area of secure
communication. The proposed algorithm uses a matrix of size n x n which is
pre-generated and stored. The quality of random numbers generated is compared
with other pseudorandom number generator using Marsaglia's Diehard battery of
tests."
"Guaranteeing the security of information transmitted through the Internet,
against passive or active attacks, is a major concern. The discovery of new
pseudo-random number generators with a strong level of security is a field of
research in full expansion, due to the fact that numerous cryptosystems and
data hiding schemes are directly dependent on the quality of these generators.
At the conference Internet`09, we described a generator based on chaotic
iterations which behaves chaotically as defined by Devaney. In this paper which
is an extension of the work presented at the conference Internet`10, the
proposal is to improve the speed, the security, and the evaluation of this
generator, to make its use more relevant in the Internet security context. In
order to do so, a comparative study between various generators is carried out
and statistical results are improved. Finally, an application in the
information hiding framework is presented with details, to give an illustrative
example of the use of such a generator in the Internet security field."
"This research work presents a new class of non-blind information hiding
algorithms that are stego-secure and robust. They are based on some finite
domains iterations having the Devaney's topological chaos property. Thanks to a
complete formalization of the approach we prove security against watermark-only
attacks of a large class of steganographic algorithms. Finally a complete study
of robustness is given in frequency DWT and DCT domains."
"Security of information transmitted through the Internet is an international
concern. This security is guaranteed by tools like hash functions. However, as
security flaws have been recently identified in the current standard in this
domain, new ways to hash digital media must be investigated. In this document
an original keyed hash function is evaluated. It is based on chaotic iterations
and thus possesses various topological properties as uniform repartition and
sensibility to its initial condition. These properties make our hash function
satisfy the requirements in this field. This claim is verified qualitatively
and experimentally in this research work, among other things by realizing
simulations of diffusion and confusion."
"We are taught from a young age that plagiarism (copying other's work) is
wrong. However, the problem of Illegal copies of multimedia data is exacerbated
by the widespread availability of circumvention devices, which enable people to
make infringing copies of multimedia data. Recently, Joint Video Compression
and Encryption (JVCE) has gained increased attention to reduce the
computational complexity of video compression, as well as provide encryption of
multimedia data. In this paper, a novel protection method for multimedia data
(ECAKP) is proposed. It combines encryption process and compression with
authenticating process. The method had been implemented and the results are
discussed in detail."
"In this paper, we present a novel encryption-less algorithm to enhance
security in transmission of data packets across mobile ad hoc networks. The
paper hinges on the paradigm of multipath routing and exploits the properties
of polynomials. The first step in the algorithm is to transform the data such
that it is impossible to obtain any information without possessing the entire
transformed data. The algorithm then uses an intuitively simple idea of a
jigsaw puzzle to break the transformed data into multiple packets where these
packets form the pieces of the puzzle. Then these packets are sent along
disjoint paths to reach the receiver. A secure and efficient mechanism is
provided to convey the information that is necessary for obtaining the original
data at the receiver-end from its fragments in the packets, that is, for
solving the jigsaw puzzle. The algorithm is designed to be secure so that no
intermediate or unintended node can obtain the entire data. An authentication
code is also used to ensure authenticity of every packet."
"Leveraging quantum mechanics, cryptographers have devised provably secure key
sharing protocols. Despite proving the security in theory, real-world
application falls short of the ideal. Last year, cryptanalysts completed an
experiment demonstrating a successful eavesdropping attack on commercial
quantum key distribution (QKD) systems. This attack exploits a weakness in the
typical real-world implementation of quantum cryptosystems. Cryptanalysts have
successfully attacked several protocols. In this paper, we examine the Kak
quantum cryptography protocol and how it may perform under such attacks."
"This paper describes the problem of securing data by making it disappear
after some time limit, making it impossible for it to be recovered by an
unauthorized party. This method is in response to the need to keep the data
secured and to protect the privacy of archived data on the servers, Cloud and
Peer-to-Peer architectures. Due to the distributed nature of these
architectures, it is impossible to destroy the data completely. So, we store
the data by applying encryption and then manage the key, which is easier to do
as the key is small and it can be hidden in the DHT (Distributed hash table).
Even if the keys in the DHT and the encrypted data were compromised, the data
would still be secure. This paper describes existing solutions, points to their
limitations and suggests improvements with a new secure architecture. We
evaluated and executed this architecture on the Java platform and proved that
it is more secure than other architectures."
"The design of authentication protocols, for online banking services in
particular and any service that is of sensitive nature in general, is quite
challenging. Indeed, enforcing security guarantees has overhead thus imposing
additional computation and design considerations that do not always meet
usability and user requirements. On the other hand, relaxing assumptions and
rigorous security design to improve the user experience can lead to security
breaches that can harm the users' trust in the system.
  In this paper, we demonstrate how careful visualization design can enhance
not only the security but also the usability of the authentication process. To
that end, we propose a family of visualized authentication protocols, a
visualized transaction verification, and a ""decryptable to your eyes only""
protocol. Through rigorous analysis, we verify that our protocols are immune to
many of the challenging authentication attacks applicable in the literature.
Furthermore, using an extensive case study on a prototype of our protocols, we
highlight the potential of our approach for real-world deployment: we were able
to achieve a high level of usability while satisfying stringent security
requirements."
"Vehicular communications play a substantial role in providing safety
transportation by means of safety message exchange. Researchers have proposed
several solutions for securing safety messages. Protocols based on a fixed key
infrastructure are more efficient in implementation and maintain stronger
security in comparison with dynamic structures. The purpose of this paper
present a method based on a fixed key infrastructure for detection
impersonation attack, in other words, Sybil attack, in the vehicular ad hoc
network. This attack, puts a great impact on performance of the network. The
proposed method, using an cryptography mechanism to detection Sybil attack.
Finally, using Mat lab simulator the results of this approach are reviewed,
This method it has low delay for detection Sybil attack, because most
operations are done in Certification Authority, so this proposed schema is a
efficient method for detection Sybil attack."
"The Internet and its current information culture of preserving all kinds of
data cause severe problems with privacy. Most of today's Internet users,
especially teenagers, publish various kinds of sensitive information, yet
without recognizing that revealing this information might be detrimental to
their future life and career. Unflattering images that can be openly accessed
now and in the future, e.g., by potential employers, constitute a particularly
important such privacy concern. We have developed a novel, fast, and scalable
system called X-pire! that allows users to set an expiration date for images in
social networks (e.g., Facebook and Flickr) and on static websites, without
requiring any form of additional interaction with these web pages. Once the
expiration date is reached, the images become unavailable. Moreover, the
publishing user can dynamically prolong or shorten the expiration dates of his
images later, and even enforce instantaneous expiration. Rendering the approach
possible for social networks crucially required us to develop a novel technique
for embedding encrypted information within JPEG files in a way that survives
JPEG compression, even for highly optimized implementations of JPEG
post-processing with their various idiosyncrasies as commonly used in such
networks. We have implemented our system and conducted performance measurements
to demonstrate its robustness and efficiency."
"We consider user-private information retrieval (UPIR), an interesting
alternative to private information retrieval (PIR) introduced by Domingo-Ferrer
et al. In UPIR, the database knows which records have been retrieved, but does
not know the identity of the query issuer. The goal of UPIR is to disguise user
profiles from the database. Domingo-Ferrer et al.\ focus on using a
peer-to-peer community to construct a UPIR scheme, which we term P2P UPIR. In
this paper, we establish a strengthened model for P2P UPIR and clarify the
privacy goals of such schemes using standard terminology from the field of
privacy research. In particular, we argue that any solution providing privacy
against the database should attempt to minimize any corresponding loss of
privacy against other users. We give an analysis of existing schemes, including
a new attack by the database. Finally, we introduce and analyze two new
protocols. Whereas previous work focuses on a special type of combinatorial
design known as a configuration, our protocols make use of more general
designs. This allows for flexibility in protocol set-up, allowing for a choice
between having a dynamic scheme (in which users are permitted to enter and
leave the system), or providing increased privacy against other users."
"Mobile IP is an open standard, defined by the Internet Engineering Task Force
(IETF) RFC 3220. By using Mobile IP, you can keep the same IP address, stay
connected, and maintain ongoing applications while roaming between IP networks.
Mobile IP is scalable for the Internet because it is based on IP - any media
that can support IP can support Mobile IP."
"Researchers have proposed formal definitions of quantitative information flow
based on information theoretic notions such as the Shannon entropy, the min
entropy, the guessing entropy, belief, and channel capacity. This paper
investigates the hardness of precisely checking the quantitative information
flow of a program according to such definitions. More precisely, we study the
""bounding problem"" of quantitative information flow, defined as follows: Given
a program M and a positive real number q, decide if the quantitative
information flow of M is less than or equal to q. We prove that the bounding
problem is not a k-safety property for any k (even when q is fixed, for the
Shannon-entropy-based definition with the uniform distribution), and therefore
is not amenable to the self-composition technique that has been successfully
applied to checking non-interference. We also prove complexity theoretic
hardness results for the case when the program is restricted to loop-free
boolean programs. Specifically, we show that the problem is PP-hard for all
definitions, showing a gap with non-interference which is coNP-complete for the
same class of programs. The paper also compares the results with the recently
proved results on the comparison problems of quantitative information flow."
"Recently, a chaos-based image encryption algorithm using alternate structure
(IEAS) was proposed. This paper focuses on differential cryptanalysis of the
algorithm and finds that some properties of IEAS can support a differential
attack to recover equivalent secret key with a little small number of known
plain-images. Detailed approaches of the cryptanalysis for cryptanalyzing IEAS
of the lower round number are presented and the breaking method can be extended
to the case of higher round number. Both theoretical analysis and experiment
results are provided to support vulnerability of IEAS against differential
attack. In addition, some other security defects of IEAS, including
insensitivity with respect to changes of plain-images and insufficient size of
key space, are also reported."
"In this paper we present a new pseudorandom number generator (PRNG) on
graphics processing units (GPU). This PRNG is based on the so-called chaotic
iterations. It is firstly proven to be chaotic according to the Devaney's
formulation. We thus propose an efficient implementation for GPU that
successfully passes the BigCrush tests, deemed to be the hardest battery of
tests in TestU01. Experiments show that this PRNG can generate about 20 billion
of random numbers per second on Tesla C1060 and NVidia GTX280 cards. It is then
established that, under reasonable assumptions, the proposed PRNG can be
cryptographically secure. A chaotic version of the Blum-Goldwasser asymmetric
key encryption scheme is finally proposed."
"Fraud and terrorism have a close connect in terms of the processes that
enables and promote them. In the era of Internet, its various services that
include Web, e-mail, social networks, blogs, instant messaging, chats, etc. are
used in terrorism not only for communication but also for i) creation of
ideology, ii) resource gathering, iii) recruitment, indoctrination and
training, iv) creation of terror network, and v) information gathering. A major
challenge for law enforcement and intelligence agencies is efficient and
accurate gathering of relevant and growing volume of crime data. This paper
reports on use of established Na\""ive Bayesian filter for classification of
threat e-mails. Efficiency in filtering threat e-mail by use of three different
Na\""ive Bayesian filter approaches i.e. single keywords, weighted multiple
keywords and weighted multiple keywords with keyword context matching are
evaluated on a threat e-mail corpus created by extracting data from sources
that are very close to terrorism."
"In this paper an attempt is made to review technological, economical and
legal aspects of the spam in detail. The technical details will include
different techniques of spam control e.g., filtering techniques, Genetic
Algorithm, Memory Based Classifier, Support Vector Machine Method, etc. The
economic aspect includes Shaping/Rate Throttling Approach/Economic Filtering
and Pricing/Payment based spam control. Finally, the paper discusses the legal
provisions for the control of spam. The scope of the legal options is limited
to USA, European Union, New Zealand, Canada, Britain and Australia."
"In today's business environment, it is difficult to imagine a workplace
without access to the web, yet a variety of email born viruses, spyware,
adware, Trojan horses, phishing attacks, directory harvest attacks, DoS
attacks, and other threats combine to attack businesses and customers. This
paper is an attempt to review phishing - a constantly growing and evolving
threat to Internet based commercial transactions. Various phishing approaches
that include vishing, spear phishng, pharming, keyloggers, malware, web
Trojans, and others will be discussed. This paper also highlights the latest
phishing analysis made by Anti-Phishing Working Group (APWG) and Korean
Internet Security Center."
"The paper analyses current versions of top three used Internet browsers and
compare their security levels to a research done in 2006. The security is
measured by analyzing how user data is stored. Data recorded during different
browsing sessions and by different password management functions it is
considered sensitive data. The paper describes how the browser protects the
sensitive data and how an attacker or a forensic analyst can access it."
"The linear complexity and the $k$-error linear complexity of a sequence have
been used as important security measures for key stream sequence strength in
linear feedback shift register design. By using the sieve method of
combinatorics, the $k$-error linear complexity distribution of $2^n$-periodic
binary sequences is investigated based on Games-Chan algorithm.
  First, for $k=2,3$, the complete counting functions on the $k$-error linear
complexity of $2^n$-periodic binary sequences with linear complexity less than
$2^n$ are characterized. Second, for $k=3,4$, the complete counting functions
on the $k$-error linear complexity of $2^n$-periodic binary sequences with
linear complexity $2^n$ are presented. Third, for $k=4,5$, the complete
counting functions on the $k$-error linear complexity of $2^n$-periodic binary
sequences with linear complexity less than $2^n$ are derived. As a consequence
of these results, the counting functions for the number of $2^n$-periodic
binary sequences with the 3-error linear complexity are obtained, and the
complete counting functions on the 4-error linear complexity of $2^n$-periodic
binary sequences are obvious."
"This paper is a proof-of-concept demonstration for a specific digital
signatures vulnerability that shows the ineffectiveness of the WYSIWYS (What
You See Is What You Sign) concept. The algorithm is fairly simple: the attacker
generates a polymorphic file that has two different types of content (text, as
a PDF document for example, and image: TIFF - two of the most widely used file
formats). When the victim signs the dual content file, he/ she only sees a PDF
document and is unaware of the hidden content inside the file. After obtaining
the legally signed document from the victim, the attacker simply has to change
the extension to the other file format. This will not invalidate the digital
signature, as no bits were altered. The destructive potential of the attack is
considerable, as the Portable Document Format (PDF) is widely used in
e-government and in e-business contexts."
"Current video cards (GPUs - Graphics Processing Units) are very programmable,
have become much more powerful than the CPUs and they are very affordable. In
this paper, we present an implementation for the AES algorithm using Direct3D
10 certified GPUs. The graphics API Direct3D 10 is the first version that
allows the use of integer operations, making from the traditional GPUs (that
works only with floating point numbers), General Purpose GPUs that can be used
for a large number of algorithms, including encryption. We present the
performance of the symmetric key encryption algorithm - AES, on a middle range
GPU and on a middle range quad core CPU. On the testing system, the developed
solution is almost 3 times faster on the GPU than on one single core CPU,
showing that the GPU can perform as an efficient cryptographic accelerator."
"Like most advances, wireless LAN poses both opportunities and risks. The
evolution of wireless networking in recent years has raised many serious
security issues. These security issues are of great concern for this technology
as it is being subjected to numerous attacks. Because of the free-space radio
transmission in wireless networks, eavesdropping becomes easy and consequently
a security breach may result in unauthorized access, information theft,
interference and service degradation. Virtual Private Networks (VPNs) have
emerged as an important solution to security threats surrounding the use of
public networks for private communications. While VPNs for wired line networks
have matured in both research and commercial environments, the design and
deployment of VPNs for WLAN is still an evolving field. This paper presents an
approach to secure IEEE 802.11g WLAN using OpenVPN, a transport layer VPN
solution and its impact on performance of IEEE 802.11g WLAN."
"Recently, Li et al. proposed a dynamic identity based authentication protocol
for multi-server architecture. They claimed their protocol is secure and can
withstand various attacks. But we found some security loopholes in the
protocol. Accordingly, the current paper demonstrates that Li et al.'s protocol
is vulnerable to the replay attack, the password guessing attack and the
masquerade attack."
"Modern technologies are becoming ever more integrated with each other. Mobile
phones are becoming increasing intelligent, and handsets are growing ever more
like computers in functionality. We are entering a new era - the age of smart
houses, global advanced networks which encompass a wide range of devices, all
of them exchanging data with each other. Such trends clearly open new horizons
to malicious users, and the potential threats are self evident. In this paper,
we study and discuss one of the most famous mobile operating systems 'Symbian';
its vulnerabilities and recommended protection technologies."
"Phishing (password + fishing) is a form of cyber crime based on social
engineering and site spoofing techniques. The name of 'phishing' is a conscious
misspelling of the word 'fishing' and involves stealing confidential data from
a user's computer and subsequently using the data to steal the user's money. In
this paper, we study, discuss and propose the phishing attack stages and types,
technologies for detection of phishing web pages, and conclude our paper with
some important recommendations for preventing phishing for both consumer and
company."
"In this work we present and formally analyze CHAT-SRP (CHAos based
Tickets-Secure Registration Protocol), a protocol to provide interactive and
collaborative platforms with a cryptographically robust solution to classical
security issues. Namely, we focus on the secrecy and authenticity properties
while keeping a high usability. In this sense, users are forced to blindly
trust the system administrators and developers. Moreover, as far as we know,
the use of formal methodologies for the verification of security properties of
communication protocols isn't yet a common practice. We propose here a
methodology to fill this gap, i.e., to analyse both the security of the
proposed protocol and the pertinence of the underlying premises. In this
concern, we propose the definition and formal evaluation of a protocol for the
distribution of digital identities. Once distributed, these identities can be
used to verify integrity and source of information. We base our security
analysis on tools for automatic verification of security protocols widely
accepted by the scientific community, and on the principles they are based
upon. In addition, it is assumed perfect cryptographic primitives in order to
focus the analysis on the exchange of protocol messages. The main property of
our protocol is the incorporation of tickets, created using digests of chaos
based nonces (numbers used only once) and users' personal data. Combined with a
multichannel authentication scheme with some previous knowledge, these tickets
provide security during the whole protocol by univocally linking each
registering user with a single request. [..]"
"Biometrical authentication systems are often presented as the best and
simplest way to reach higher security levels. But a deeper analysis shows that
several risks are hidden and the service provider adopting those system has to
carefully check its liabilities before deploying them."
"Cryptography is always very important in data origin authentications, entity
authentication, data integrity and confidentiality. In recent years, a variety
of chaotic cryptographic schemes have been proposed. These schemes have typical
structure which performed the permutation and the diffusion stages,
alternatively. The random number generators are intransitive in cryptographic
schemes and be used in the diffusion functions of the image encryption for
diffused pixels of plain image. In this paper, we propose a chaotic encryption
scheme based on pseudorandom bit padding that the bits be generated by a novel
logistic pseudorandom image algorithm. To evaluate the security of the cipher
image of this scheme, the key space analysis, the correlation of two adjacent
pixels and differential attack were performed. This scheme tries to improve the
problem of failure of encryption such as small key space and level of security."
"In many recent years, the programming world has been introduced about a new
programming language for designing websites, it is CSS that can be be used
together with HTML to develop a web interface. And now, these two programming
languages as if inseparably from each other. As a client-side scripting, CSS is
visible by all users as the original script, but it can not be granted changed.
Website is a tool of information disseminator throughout the world, this is
certainly can be used to a secret communication by using CSS as a message
hider. This paper proposed a new scheme using web tools like CSS for hiding
informations. This is a secret communication mechanism using text steganography
techniques that is embedded messages on CSS files and is further encrypted
using RSA as a public key cryptographic algorithm."
"Pushback is a mechanism for defending against Distributed Denial-of-Service
(DDoS) attacks. DDoS attacks are treated as a congestion-control problem, but
because most such congestion is caused by malicious hosts not obeying
traditional end-to-end congestion control, the problem must be handled by the
routers. Functionality is added to each router to detect and preferentially
drop packets that probably belong to an attack. Upstream routers are also
notified to drop such packets in order that the router's resources be used to
route legitimate traffic hence term pushback. Client puzzles have been
advocated as a promising countermeasure to DoS attacks in the recent years. In
order to identify the attackers, the victim server issues a puzzle to the
client that sent the traffic. When the client is able to solve the puzzle, it
is assumed to be authentic and the traffic from it is allowed into the server.
If the victim suspects that the puzzles are solved by most of the clients, it
increases the complexity of the puzzles. This puzzle solving technique allows
the traversal of the attack traffic throughout the intermediate routers before
reaching the destination. In order to attain the advantages of both pushback
and puzzle solving techniques, a hybrid scheme called Router based Pushback
technique, which involves both the techniques to solve the problem of DDoS
attacks is proposed. In this proposal, the puzzle solving mechanism is pushed
back to the core routers rather than having at the victim. The router based
client puzzle mechanism checks the host system whether it is legitimate or not
by providing a puzzle to be solved by the suspected host."
"Distributed denial-of-service attacks on public servers have recently become
a serious problem. To assure that network services will not be interrupted and
more effective defense mechanisms to protect against malicious traffic,
especially SYN floods. One problem in detecting SYN flood traffic is that
server nodes or firewalls cannot distinguish the SYN packets of normal TCP
connections from those of a SYN flood attack. Another problem is single-point
defenses (e.g. firewalls) lack the scalability needed to handle an increase in
the attack traffic. We have designed a new defense mechanism to detect the SYN
flood attacks. First, we introduce a mechanism for detecting SYN flood traffic
more accurately by taking into consideration the time variation of arrival
traffic. We investigate the statistics regarding the arrival rates of both
normal TCP SYN packets and SYN flood attack packets. We then describe a new
detection mechanism based on these statistics. Through the trace driven
approach defense nodes which receive the alert messages can identify legitimate
traffic and block malicious traffic by delegating SYN/ACK packets."
"Currently, short signature is receiving significant attention since it is
particularly useful in low-bandwidth communication environments. However, most
of the short signature schemes are only based on one intractable assumption.
Recently, Su presented an identity-based short signature scheme based on
knapsack and bilinear pairing. He claimed that the signature scheme is secure
in the random oracle model. Unfortunately, in this paper, we show that his
scheme is insecure. Concretely, an adversary can forge a valid signature on any
message with respect to any identity in Su's scheme."
"This paper presents a new privacy-preserving smart metering system. Our
scheme is private under the differential privacy model and therefore provides
strong and provable guarantees. With our scheme, an (electricity) supplier can
periodically collect data from smart meters and derive aggregated statistics
while learning only limited information about the activities of individual
households. For example, a supplier cannot tell from a user's trace when he
watched TV or turned on heating. Our scheme is simple, efficient and practical.
Processing cost is very limited: smart meters only have to add noise to their
data and encrypt the results with an efficient stream cipher."
"Many operations in power grids, such as fault detection and event location
estimation, depend on precise timing information. In this paper, a novel time
stamp attack (TSA) is proposed to attack the timing information in smart grid.
Since many applications in smart grid utilize synchronous measurements and most
of the measurement devices are equipped with global positioning system (GPS)
for precise timing, it is highly probable to attack the measurement system by
spoofing the GPS. The effectiveness of TSA is demonstrated for three
applications of phasor measurement unit (PMU) in smart grid, namely
transmission line fault detection, voltage stability monitoring and event
locationing."
"In this paper, we proposed an authentication method according to
Diffie-Hellman. First, we introduce different methods for authentication in
IEEE.802.16 then we proposed an authentication method according to
Diffie-Hellman and in the last we compare different methods for authentication
to improve security in IEEE802.16e. CPN is a useful for simulation and compare
protocol together so we use CPN tools in this paper."
"In this paper it is shown that given a sufficient number of (noisy) random
binary linear equations, the Learning from Parity with Noise (LPN) problem can
be solved in essentially cube root time in the number of unknowns. The
techniques used to recover the solution are known from fast correlation attacks
on stream ciphers. As in fast correlation attacks, the performance of the
algorithm depends on the number of equations given. It is shown that if this
number exceeds a certain bound, and the bias of the noisy equations is
polynomial in number of unknowns, the running time of the algorithm is reduced
to almost cube root time compared to the brute force checking of all possible
solutions. The mentioned bound is explicitly given and it is further shown that
when this bound is exceeded, the complexity of the approach can even be further
reduced."
"This paper presents modifications of the Diffie-Hellman (DH) key exchange
method. The presented modifications provide better security than other key
exchange methods. We are going to present a dynamic security that
simultaneously realizes all the three functions with a high efficiency and then
give a security analysis. It also presents secure and dynamic key exchange
method. Signature, encryption and key exchange are some of the most important
and foundational Crypto-graphical tools. In most cases, they are all needed to
provide different secure functions. On the other hand, there are also some
proposals on the efficient combination of key exchange. In this paper, we
present a dynamic, reliable and secure method for the exchange of session key.
Moreover, the proposed modification method could achieve better performance
efficiency."
"We propose a methodology for verifying security properties of network
protocols at design level. It can be separated in two main parts: context and
requirements analysis and informal verification; and formal representation and
procedural verification. It is an iterative process where the early steps are
simpler than the last ones. Therefore, the effort required for detecting flaws
is proportional to the complexity of the associated attack. Thus, we avoid
wasting valuable resources for simple flaws that can be detected early in the
verification process. In order to illustrate the advantages provided by our
methodology, we also analyze three real protocols."
"Biometric authentication systems are presented as the best way to reach high
security levels in controlling access to IT systems or sensitive
infrastructures. But several issues are often not taken properly into account.
In order for the implementation of those systems to be successful, the hidden
risks and the related liabilities have to be carefully analyzed before
biometrics can be used on a large scale for sensitive applications."
"This paper proposes to put forward an innovative algorithm for symmetric key
block cipher named as ""Triple Prime Symmetric Key Block Cipher with Variable
Key-Spaces (TPSKBCVK)"" that employs triple prime integers as private key-spaces
of varying lengths to encrypt data files. Principles of modular arithmetic have
been elegantly used in the proposed idea of the cipher. Depending on
observations of the results of implementation of the proposed cipher on a set
of real data files of several types, all results are registered and analyzed.
The strength of the underlying design of the cipher and the liberty of using a
long key-space expectedly makes it reasonably non-susceptible against possible
cryptanalytic intrusions. As a future scope of the work, it is intended to
formulate and employ an improved scheme that will use a carrier media (image or
multimedia data file) for a secure transmission of the private keys."
"The Internet of Things and Services is a rapidly growing concept that
illustrates that the ever increasing amount of physical items of our daily life
which become addressable through a network could be made more easily manageable
and usable through the use of Services. This surge of exposed resources along
with the level of privacy and value of the information they hold, together with
the increase of their usage make for an augmentation in the number of the
security threats and violation attempts that existing security systems do not
appear robust enough to address. In this paper, the authors underline this
increase in risk and identify the requirements for resources to be more
resilient in this type of environment while keeping an important level of
flexibility. In addition, the authors propose an architectural model of Self
Managed Security Cell, which leverages on current knowledge in large scale
security systems, information management and autonomous systems."
"Business requirements for rapid operational efficiency, customer
responsiveness as well as rapid adaptability are actively driving the need for
ever increasing communication and integration apabilities of software assets.
In this context, security, although acknowledged as being a necessity, is often
perceived as a hindrance. Indeed, dynamic environments require flexible and
understandable security that can be customized, adapted and reconfigured
dynamically to face changing requirements. In this paper, the authors propose
SOA based security governance middleware that handles security requirements on
behalf of a resource exposed through it. The middleware aims at providing
different security settings through the use of managed compositions of security
services called profiles. The main added value of this work compared to
existing handlers or centralized approaches lies in its enhanced flexibility
and transparency."
"In this paper, we analyze several recent schemes for watermarking network
flows that are based on splitting the flow into timing intervals. We show that
this approach creates time-dependent correlations that enable an attack that
combines multiple watermarked flows. Such an attack can easily be mounted in
nearly all applications of network flow watermarking, both in anonymous
communication and stepping stone detection. The attack can be used to detect
the presence of a watermark, recover the secret parameters, and remove the
watermark from a flow. The attack can be effective even if different flows are
marked with different values of a watermark.
  We analyze the efficacy of our attack using a probabilistic model and a
Markov-Modulated Poisson Process (MMPP) model of interactive traffic. We also
implement our attack and test it using both synthetic and real-world traces,
showing that our attack is effective with as few as 10 watermarked flows.
Finally, we propose possible countermeasures to defeat the multi-flow attack."
"Recent research has made great strides in the field of detecting botnets.
However, botnets of all kinds continue to plague the Internet, as many ISPs and
organizations do not deploy these techniques. We aim to mitigate this state by
creating a very low-cost method of detecting infected bot host. Our approach is
to leverage the botnet detection work carried out by some organizations to
easily locate collaborating bots elsewhere. We created BotMosaic as a
countermeasure to IRC-based botnets. BotMosaic relies on captured bot instances
controlled by a watermarker, who inserts a particular pattern into their
network traffic. This pattern can then be detected at a very low cost by client
organizations and the watermark can be tuned to provide acceptable
false-positive rates. A novel feature of the watermark is that it is inserted
collaboratively into the flows of multiple captured bots at once, in order to
ensure the signal is strong enough to be detected. BotMosaic can also be used
to detect stepping stones and to help trace back to the botmaster. It is
content agnostic and can operate on encrypted traffic. We evaluate BotMosaic
using simulations and a testbed deployment."
"A key challenge in censorship-resistant web browsing is being able to direct
legitimate users to redirection proxies while preventing censors, posing as
insiders, from discovering their addresses and blocking them. We propose a new
framework for censorship-resistant web browsing called {\it CensorSpoofer} that
addresses this challenge by exploiting the asymmetric nature of web browsing
traffic and making use of IP spoofing. CensorSpoofer de-couples the upstream
and downstream channels, using a low-bandwidth indirect channel for delivering
outbound requests (URLs) and a high-bandwidth direct channel for downloading
web content. The upstream channel hides the request contents using
steganographic encoding within email or instant messages, whereas the
downstream channel uses IP address spoofing so that the real address of the
proxies is not revealed either to legitimate users or censors. We built a
proof-of-concept prototype that uses encrypted VoIP for this downstream channel
and demonstrated the feasibility of using the CensorSpoofer framework in a
realistic environment."
"Mobile ad hoc networks (MANETs) are self-configuring infrastructure-less
networks comprised of mobile nodes that communicate over wireless links without
any central control on a peer-to-peer basis. These individual nodes act as
routers to forward both their own data and also their neighbours' data by
sending and receiving packets to and from other nodes in the network. The
relatively easy configuration and the quick deployment make ad hoc networks
suitable the emergency situations (such as human or natural disasters) and for
military units in enemy territory. Securing data dissemination between these
nodes in such networks, however, is a very challenging task. Exposing such
information to anyone else other than the intended nodes could cause a privacy
and confidentiality breach, particularly in military scenarios. In this paper
we present a novel framework to enhance the privacy and data confidentiality in
mobile ad hoc networks by attaching the originator policies to the messages as
they are sent between nodes. We evaluate our framework using the Network
Simulator (NS-2) to check whether the privacy and confidentiality of the
originator are met. For this we implemented the Policy Enforcement Points
(PEPs), as NS-2 agents that manage and enforce the policies attached to packets
at every node in the MANET."
"Linking network flows is an important problem in intrusion detection as well
as anonymity. Passive traffic analysis can link flows but requires long periods
of observation to reduce errors. Active traffic analysis, also known as flow
watermarking, allows for better precision and is more scalable. Previous flow
watermarks introduce significant delays to the traffic flow as a side effect of
using a blind detection scheme; this enables attacks that detect and remove the
watermark, while at the same time slowing down legitimate traffic. We propose
the first non-blind approach for flow watermarking, called RAINBOW, that
improves watermark invisibility by inserting delays hundreds of times smaller
than previous blind watermarks, hence reduces the watermark interference on
network flows. We derive and analyze the optimum detectors for RAINBOW as well
as the passive traffic analysis under different traffic models by using
hypothesis testing. Comparing the detection performance of RAINBOW and the
passive approach we observe that both RAINBOW and passive traffic analysis
perform similarly good in the case of uncorrelated traffic, however, the
RAINBOW detector drastically outperforms the optimum passive detector in the
case of correlated network flows. This justifies the use of non-blind
watermarks over passive traffic analysis even though both approaches have
similar scalability constraints. We confirm our analysis by simulating the
detectors and testing them against large traces of real network flows."
"Anomaly-based DDoS detection systems construct profile of the traffic
normally seen in the network, and identify anomalies whenever traffic deviate
from normal profile beyond a threshold. This extend of deviation is normally
not utilised. This paper reports the evaluation results of proposed approach
that utilises this extend of deviation from detection threshold to estimate
strength of DDoS attack using various regression models. A relationship is
established between number of zombies and observed deviation in sample entropy.
Various statistical performance measures, such as coefficient of determination
(R2), coefficient of correlation (CC), sum of square error (SSE), mean square
error (MSE), root mean square error (RMSE), normalised mean square error
(NMSE), Nash-Sutcliffe efficiency index ({\eta}) and mean absolute error (MAE)
are used to measure the performance of various regression models. Internet type
topologies used for simulation are generated using transit-stub model of GT-ITM
topology generator. NS-2 network simulator on Linux platform is used as
simulation test bed for launching DDoS attacks with varied attack strength. A
comparative study is performed using different regression models for estimating
strength of DDoS attack. The simulation results are promising as we are able to
estimate strength of DDoS attack efficiently with very less error rate using
various regression models."
"Disruption from service caused by DDoS attacks is an immense threat to
Internet today. These attacks can disrupt the availability of Internet services
completely, by eating either computational or communication resources through
sheer volume of packets sent from distributed locations in a coordinated manner
or graceful degradation of network performance by sending attack traffic at low
rate. In this paper, we describe a novel framework that deals with the
detection of variety of DDoS attacks by monitoring propagation of abrupt
traffic changes inside ISP Domain and then characterizes flows that carry
attack traffic. Two statistical metrics namely, Volume and Flow are used as
parameters to detect DDoS attacks. Effectiveness of an anomaly based detection
and characterization system highly depends on accuracy of threshold value
settings. Inaccurate threshold values cause a large number of false positives
and negatives. Therefore, in our scheme, Six-Sigma and varying tolerance factor
methods are used to identify threshold values accurately and dynamically for
various statistical metrics. NS-2 network simulator on Linux platform is used
as simulation testbed to validate effectiveness of proposed approach. Different
attack scenarios are implemented by varying total number of zombie machines and
at different attack strengths. The comparison with volume-based approach
clearly indicates the supremacy of our proposed system."
"Distributed Hash Table (DHT) lookup is a core technique in structured
peer-to-peer (P2P) networks. Its decentralized nature introduces security and
privacy vulnerabilities for applications built on top of them; we thus set out
to design a lookup mechanism achieving both security and anonymity, heretofore
an open problem. We present Octopus, a novel DHT lookup which provides strong
guarantees for both security and anonymity. Octopus uses attacker
identification mechanisms to discover and remove malicious nodes, severely
limiting an adversary's ability to carry out active attacks, and splits lookup
queries over separate anonymous paths and introduces dummy queries to achieve
high levels of anonymity. We analyze the security of Octopus by developing an
event-based simulator to show that the attacker discovery mechanisms can
rapidly identify malicious nodes with low error rate. We calculate the
anonymity of Octopus using probabilistic modeling and show that Octopus can
achieve near-optimal anonymity. We evaluate Octopus's efficiency on Planetlab
with 207 nodes and show that Octopus has reasonable lookup latency and
manageable communication overhead."
"Although system administrators are frequently urged to protect the machines
in their network, the fact remains that the decision to protect is far from
universal. To better understand this decision, we formulate a
decision-theoretic model of a system administrator responsible for a network of
size n against an attacker attempting to penetrate the network and infect the
machines with a virus or similar exploit. By analyzing the model we are able to
demonstrate the cost sensitivity of smaller networks as well as identify
tipping points that can lead the administrator to switch away from the decision
to protect."
"The cloud model's dependence on massive parallelism and resource sharing
exacerbates the security challenge of timing side-channels. Timing Information
Flow Control (TIFC) is a novel adaptation of IFC techniques that may offer a
way to reason about, and ultimately control, the flow of sensitive information
through systems via timing channels. With TIFC, objects such as files,
messages, and processes carry not just content labels describing the ownership
of the object's ""bits,"" but also timing labels describing information contained
in timing events affecting the object, such as process creation/termination or
message reception. With two system design tools-deterministic execution and
pacing queues-TIFC enables the construction of ""timing-hardened"" cloud
infrastructure that permits statistical multiplexing, while aggregating and
rate-limiting timing information leakage between hosted computations."
"The smartphone usage among people is increasing rapidly. With the phenomenal
growth of smartphone use, smartphone theft is also increasing. This paper
proposes a model to secure smartphones from theft as well as provides options
to access a smartphone through other smartphone or a normal mobile via Short
Message Service. This model provides option to track and secure the mobile by
locking it. It also provides facilities to receive the incoming call and sms
information to the remotely connected device and enables the remote user to
control the mobile through SMS. The proposed model is validated by the
prototype implementation in Android platform. Various tests are conducted in
the implementation and the results are discussed."
"A novel Strict Friendliness Verification (SFV) scheme based on the integrated
key consisting of symmetric node identity, geographic location and round trip
response time between the sender and the receiver radio in MANET is proposed.
This key is dynamically updated for encryption and decryption of each packet to
resolve Wormhole attack and Sybil attack. Additionally, it meets the minimal
key lengths required for symmetric ciphers to provide adequate commercial
security. Furthermore, the foe or unfriendly node detection is found
significantly increasing with the lower number of symmetric IDs. This paper
presents the simulation demonstrating the performance of SFV in terms of
dynamic range using directional antenna on radios (or nodes), and the
performance in terms of aggregate throughput, average end to end delay and
packet delivered ratio."
"Threshold secret sharing schemes do not prevent any malicious behavior of the
dealer or shareholders and so we need verifiable secret sharing, to detect and
identify the cheaters, to achieve fair reconstruction of a secret. The problem
of verifiable secret sharing is to verify the shares distributed by the dealer.
A novel approach for verifiable secret sharing is presented in this paper where
both the dealer and shareholders are not assumed to be honest. In this paper,
we extend the term verifiable secret sharing to verify the shares, distributed
by a dealer as well as shares submitted by shareholders for secret
reconstruction, and to verify the reconstructed secret. Our proposed scheme
uses a one way hash function and probabilistic homomorphic encryption function
to provide verifiability and fair reconstruction of a secret."
"In medical organizations large amount of personal data are collected and
analyzed by the data miner or researcher, for further perusal. However, the
data collected may contain sensitive information such as specific disease of a
patient and should be kept confidential. Hence, the analysis of such data must
ensure due checks that ensure protection against threats to the individual
privacy. In this context, greater emphasis has now been given to the privacy
preservation algorithms in data mining research. One of the approaches is
anonymization approach that is able to protect private information; however,
valuable information can be lost. Therefore, the main challenge is how to
minimize the information loss during an anonymization process. The proposed
method is grouping similar data together based on sensitive attribute and then
anonymizes them. Our experimental results show the proposed method offers
better outcomes with respect to information loss and execution time."
"Mobile Ad hoc Networks (MANETS) are transient networks of mobile nodes,
connected through wireless links, without any fixed infrastructure or central
management. Due to the self-configuring nature of these networks, the topology
is highly dynamic. This makes the Ad Hoc Routing Protocols in MANETS highly
vulnerable to serious security issues. In this paper, we survey the common
security threats and attacks and summarize the solutions suggested in the
survey to mitigate these security vulnerabilities."
"Role Based Access Control (RBAC) is a very popular access control model, for
long time investigated and widely deployed in the security architecture of
different enterprises. To implement RBAC, roles have to be firstly identified
within the considered organization. Usually the process of (automatically)
defining the roles in a bottom up way, starting from the permissions assigned
to each user, is called {\it role mining}. In literature, the role mining
problem has been formally analyzed and several techniques have been proposed in
order to obtain a set of valid roles.
  Recently, the problem of defining different kind of constraints on the number
and the size of the roles included in the resulting role set has been
addressed. In this paper we provide a formal definition of the role mining
problem under the cardinality constraint, i.e. restricting the maximum number
of permissions that can be included in a role. We discuss formally the
computational complexity of the problem and propose a novel heuristic.
Furthermore we present experimental results obtained after the application of
the proposed heuristic on both real and synthetic datasets, and compare the
resulting performance to previous proposals"
"We present a computational security analysis of the Authentication and Key
Agreement (AKA) protocols for both Long-Term Evolution (LTE) and Universal
Mobile Telecommunications System (UMTS). This work constitutes the first
security analysis of LTE AKA to date and the first computationally sound
analysis of UMTS AKA. Our work is the first formal analysis to consider
messages that are sent in the core network, where we take into account details
of the carrying protocol (i.e., MAP or Diameter) and of the mechanism for
secure transport (i.e., MAPsec/TCAPsec or IPsec ESP). Moreover, we report on a
deficiency in the protocol specifications of UMTS AKA and LTE AKA and the
specifications of the core network security (called network domain security),
which may enable efficient attacks. The vulnerability allows an inside attacker
not only to impersonate an honest protocol participant during a run of the
protocol but also to subsequently use wireless services on his behalf. UMTS AKA
run over MAP with MAPsec seems vulnerable in the most straight-forward
application of the attack. On the other hand, our analysis shows that UMTS and
LTE AKA over Diameter/IPsec and UMTS AKA over MAP/TCAPsec (with sufficiently
long session identifiers) computationally satisfy intended authentication
properties as well as some key secrecy properties, assuming that the used
primitives meet standard cryptographic assumptions."
"Every time the customer (individual or company) has to release personal
information to its service provider (e.g., an online store or a cloud computing
provider), it faces a trade-off between the benefits gained (enhanced or
cheaper services) and the risks it incurs (identity theft and fraudulent uses).
The amount of personal information released is the major decision variable in
that trade-off problem, and has a proxy in the maximum loss the customer may
incur. We find the conditions for a unique optimal solution to exist for that
problem as that maximizing the customer's surplus. We also show that the
optimal amount of personal information is influenced most by the immediate
benefits the customer gets, i.e., the price and the quantity of service offered
by the service provider, rather than by maximum loss it may incur. Easy
spenders take larger risks with respect to low-spenders, but an increase in
price drives customers towards a more careful risk-taking attitude anyway. A
major role is also played by the privacy level, which the service provider
employs to regulate the benefits released to the customers. We also provide a
closed form solution for the limit case of a perfectly secure provider, showing
that the results do not differ significantly from those obtained in the general
case. The trade-off analysis may be employed by the customer to determine its
level of exposure in the relationship with its service provider."
"In this paper we propose a signature scheme based on two intractable
problems, namely the integer factorization problem and the discrete logarithm
problem for elliptic curves. It is suitable for applications requiring
long-term security and provides a more efficient solution than the existing
ones."
"This paper introduces a new model for node behavior namely Correlated Node
Behavior Model which is an extension of Node Behavior Model. The model adopts
semi Markov process in continuous time which clusters the node that has
correlation. The key parameter of the process is determined by five
probabilistic parameters based on the Markovian model. Computed from the
transition probabilities of the semi-Markov process, the node correlation
impact on network survivability and resilience can be measure quantitatively.
From the result, the quantitative analysis of correlated node behavior on the
survivability is obtained through mathematical description, and the
effectiveness and rationality of the proposed model are verified through
numerical analysis. The analytical results show that the effect from correlated
failure nodes on network survivability is much severer than other misbehaviors."
"This article analyzes trust and security in computing and communications
systems. While in human-life, trust usually has some kind of commonly
understood meaning, in the realm of computing and communications systems, it
could be interpreted differently in different environments and settings. On the
other hand, security is about making sure that the participating entities are
legitimate in a communication event or incident so that the core requirements
of privacy, integrity, and authenticity are maintained. This notion is also
true for our human life, even for example entering a house needs legitimacy of
a person. Some boundary lines preserve the security; otherwise an unwanted
access is called a 'security breach'. The intent of this article is to compare
and discuss these two terms with our societal behavior and understanding
amongst entities. To illustrate these issues especially in computing and
communications world, some of the innovating and recent technologies are
discussed which demand trust and security within their core operational
structures. Alongside presenting generally established ideas, some critical
points are mentioned that may be sometimes debatable within the research
community."
"As an interconnection technology, Bluetooth has to address all traditional
security problems, well known from the distributed networks. Moreover, as
Bluetooth networks are formed by the radio links, there are also additional
security aspects whose impact is yet not well understood. In this paper, we
propose a novel Man-In-The-Middle (MITM) attack against Bluetooth enabled
mobile phone that support Simple Secure Pairing(SSP). From the literature it
was proved that the SSP association models such as Numeric comparison, Just
works and passkey Entry are not more secure. Here we propose the Out Of Band
(OOB) channeling with enhanced security than the previous methods."
"Ensuring communications security in Wireless Sensor Networks (WSNs) is very
vital because the security protocols therein, should be devised to work at the
link layer. Theoretically, any link layer security protocol must support three
vital security attributes viz. Confidentiality, Message Integrity and Replay
protection. However, in order to ensure lesser overhead, replay protection is
often not incorporated as part of the link layer security framework. We argue
here, that it is essential to implement replay protection at the link layer
only and devise a simple scheme to do so. We first survey the common approaches
to ensuring replay protection in conventional networks. We also implement the
conventional algorithms for replay protection using the link layer framework
for WSNs viz. TinySec as the underlying platform. Subsequently analyzing their
limitations, we propose a novel Bloom-filter based replay protection algorithm
for unicast communications. We show that our algorithm is better than the other
contemporary approaches for ensuring replay protection in unicast
communications in the WSNs."
"Ensuring communications security in Wireless Sensor Networks (WSNs) indeed is
critical; due to the criticality of the resources in the sensor nodes as well
as due to their ubiquitous and pervasive deployment, with varying attributes
and degrees of security required. The proliferation of the next generation
sensor nodes, has not solved this problem, because of the greater emphasis on
low-cost deployment. In addition, the WSNs use data-centric multi-hop
communication that in turn, necessitates the security support to be devised at
the link layer (increasing the cost of security related operations), instead of
being at the application layer, as in general networks. Therefore, an
energy-efficient link layer security framework is necessitated. There do exists
a number of link layer security architectures that offer some combinations of
the security attributes desired by different WSN applications. However, as we
show in this paper, none of them is responsive to the actual security demands
of the applications. Therefore, we believe that there is a need for
investigating the feasibility of a configurable software-based link layer
security architecture wherein an application can be compiled flexibly, with
respect to its actual security demands. In this paper, we analyze, propose and
experiment with the basic design of such configurable link layer security
architecture for WSNs. We also experimentally evaluate various aspects related
to our scheme viz. configurable block ciphers, configurable block cipher modes
of operations, configurable MAC sizes and configurable replay protection. The
architecture proposed is aimed to offer the optimal level of security at the
minimal overhead, thus saving the precious resources in the WSNs."
"The Wireless Sensor Networks (WSNs) are composed of resource starved sensor
nodes that are deployed to sense, process and communicate vital information to
the base station. Due to the stringent constraints on the resources in the
sensor nodes on one hand and due to the communications costs being always
significantly higher than the data processing costs, the WSNs typically, employ
in-network processing, which aims at reducing effectively, the total number of
packets eventually transmitted to the base station. Such innetwork processing
largely employs data aggregation operations that aggregate the data into a
compact representation for further transmission. However, due to the ubiquitous
& pervasive deployment, heavier resource demands of the security protocols and
due to the stringent resource constraints in WSN nodes, the security concerns
in WSNs are even otherwise critical. These concerns assume alarming proportions
when using data aggregation in which the output of the data aggregator nodes
depends on that of various other nodes. Hence, the protocols for data
aggregation have to carefully devised with a constant vigil on ensuring
security of the data. In this paper, based on our survey of the existing
research efforts for ensuring secure data aggregation, we propose a novel
approach using homomorphic encryption and additive digital signatures to
achieve confidentiality, integrity and availability for secure data aggregation
in wireless sensor networks."
"We present an approach to generalization of practical Identity-Based
Encryption scheme of Boneh and Franklin. In particular we show how the protocol
could be used on finite modular lattices and as a special case on vector spaces
over finite field. The original proof of security for this protocol does not
hold in this general algebraic structure, thus this is still a work in
progress."
"Recently, a colour image encryption algorithm based on chaos was proposed by
cascading two position permutation operations and one substitution operation,
which are all determined by some pseudo-random number sequences generated by
iterating the Logistic map. This paper evaluates the security level of the
encryption algorithm and finds that the position permutation-only part and the
substitution part can be separately broken with only $\lceil (\log_2(3MN))/8
\rceil$ and 2 chosen plain-images, respectively, where $MN$ is the size of the
plain-image. Concise theoretical analyses are provided to support the
chosen-plaintext attack, which are verified by experimental results also."
"Having a precise vulnerability discovery model (VDM) would provide a useful
quantitative insight to assess software security. Thus far, several models have
been proposed with some evidence supporting their goodness-of-fit.
  In this work we describe an independent validation of the applicability of
six existing VDMs in seventeen releases of the three popular browsers Firefox,
Google Chrome and Internet Explorer. We have collected five different kinds of
data sets based on different definitions of a vulnerability. We introduce two
quantitative metrics, goodness-of-fit entropy and goodness-of-fit quality, to
analyze the impact of vulnerability data sets to the stability as well as
quality of VDMs in the software life cycles.
  The experiment result shows that the ""confirmed-by-vendors' advisories"" data
sets apparently yields more stable and better results for VDMs. And the
performance of the s-shape logistic model (AML) seems to be superior
performance in overall. Meanwhile, Anderson thermodynamic model (AT) is indeed
not suitable for modeling the vulnerability discovery process. This means that
the discovery process of vulnerabilities and normal bugs are different because
the interests of people in finding security vulnerabilities are more than
finding normal programming bugs."
"Security and trust are the most important factors in online transaction, this
paper introduces TSET a Token based Secure Electronic Transaction which is an
improvement over the existing SET, Secure Electronic Transaction protocol. We
take the concept of tokens in the TSET protocol to provide end to end security.
It also provides trust evaluation mechanism so that trustworthiness of the
merchants can be known by customers before being involved in the transaction.
Moreover, we also propose a grading mechanism so that quality of service in the
transactions improves."
"This paper proposes a new block cipher termed as ""Modular Arithmetic based
Block Cipher with Varying Key-Spaces (MABCVK)"" that uses private key-spaces of
varying lengths to encrypt data files. There is a simple but intelligent use of
theory of modular arithmetic in the scheme of the cipher. Based on observed
implementation of the proposed cipher on a set of real data files of several
types, all results are tabulated and analyzed.The schematic strength of the
cipher and the freedom of using a long key-space expectedly can make it
reasonably nonvulnerable against possible cryptanalytic attacks. As a part of
the future scope of the work, it is also intended to formulate and implement an
enhanced scheme that will use a carrier image to have a secure transmission of
the private key."
"Actually Information security becomes a very important part for the
organization's intangible assets, so level of confidence and stakeholder
trusted are performance indicator as successes organization. Since information
security has a very important role in supporting the activities of the
organization, we need a standard or benchmark which regulates governance over
information security. The main objective of this paper is to implement a novel
practical approach framework to the development of information security
management system (ISMS) assessment and monitoring software, called by
I-SolFramework. System / software is expected to assist stakeholders in
assessing the level of their ISO27001 compliance readiness, the software could
help stakeholders understood security control or called by compliance
parameters, being shorter and more structured. The case study illustrated
provided to the reader with a set of guidelines, that aims easy understood and
applicable as measuring tools for ISMS standards (ISO27001) compliance."
"Bogdanov and Lee suggested a homomorphic public-key encryption scheme based
on error correcting codes. The underlying public code is a modified
Reed-Solomon code obtained from inserting a zero submatrix in the Vandermonde
generating matrix defining it. The columns that define this submatrix are kept
secret and form a set $L$. We give here a distinguisher that detects if one or
several columns belong to $L$ or not. This distinguisher is obtained by
considering the code generated by component-wise products of codewords of the
public code (the so called ""square code""). This operation is applied to
punctured versions of this square code obtained by picking a subset
  $I$ of the whole set of columns. It turns out that the dimension of the
punctured square code is directly related to the cardinality of the
intersection of $I$ with $L$. This allows an attack which recovers the full set
$L$ and which can then decrypt any ciphertext."
"This paper considers the problem of end-end security enhancement by resorting
to deliberate noise injected in ciphertexts. The main goal is to generate a
degraded wiretap channel in application layer over which Wyner-type secrecy
encoding is invoked to deliver additional secure information. More
specifically, we study secrecy enhancement of DES block cipher working in
cipher feedback model (CFB) when adjustable and intentional noise is introduced
into encrypted data in application layer. A verification strategy in exhaustive
search step of linear attack is designed to allow Eve to mount a successful
attack in the noisy environment. Thus, a controllable wiretap channel is
created over multiple frames by taking advantage of errors in Eve's
cryptanalysis, whose secrecy capacity is found for the case of known channel
states at receivers. As a result, additional secure information can be
delivered by performing Wyner type secrecy encoding over super-frames ahead of
encryption, namely, our proposed secrecy encoding-then-encryption scheme. These
secrecy bits could be taken as symmetric keys for upcoming frames. Numerical
results indicate that a sufficiently large secrecy rate can be achieved by
selective noise addition."
"Many operations in power grids, such as fault detection and event location
estimation, depend on precise timing information. In this paper, a novel Time
Synchronization Attack (TSA) is proposed to attack the timing information in
smart grid. Since many applications in smart grid utilize synchronous
measurements and most of the measurement devices are equipped with global
positioning system (GPS) for precise timing, it is highly probable to attack
the measurement system by spoofing the GPS. The effectiveness of TSA is
demonstrated for three applications of phasor measurement unit (PMU) in smart
grid, namely transmission line fault detection, voltage stability monitoring
and event locationing. The validity of TSA is demonstrated by numerical
simulations."
"A novel time synchronization attack (TSA) on wide area monitoring systems in
smart grid has been identified in the first part of this paper. A cross layer
detection mechanism is proposed to combat TSA in part II of this paper. In the
physical layer, we propose a GPS carrier signal noise ratio (C/No) based
spoofing detection technique. In addition, a patch-monopole hybrid antenna is
applied to receive GPS signal. By computing the standard deviation of the C/No
difference from two GPS receivers, a priori probability of spoofing detection
is fed to the upper layer, where power system state is estimated and
controlled. A trustworthiness based evaluation method is applied to identify
the PMU being under TSA. Both the physical layer and upper layer algorithms are
integrated to detect the TSA, thus forming a cross layer mechanism. Experiment
is carried out to verify the effectiveness of the proposed TSA detection
algorithm."
"Cloud Computing holds the potential to eliminate the requirements for setting
up of high-cost computing infrastructure for IT-based solutions and services
that the industry uses. It promises to provide a flexible IT architecture,
accessible through internet for lightweight portable devices. This would allow
multi-fold increase in the capacity or capabilities of the existing and new
software. In a cloud computing environment, the entire data reside over a set
of networked resources, enabling the data to be accessed through virtual
machines. Since these data-centers may lie in any corner of the world beyond
the reach and control of users, there are multifarious security and privacy
challenges that need to be understood and taken care of. Also, one can never
deny the possibility of a server breakdown that has been witnessed, rather
quite often in the recent times. There are various issues that need to be dealt
with respect to security and privacy in a cloud computing scenario. This
extensive survey paper aims to elaborate and analyze the numerous unresolved
issues threatening the cloud computing adoption and diffusion affecting the
various stake-holders linked to it."
"The characteristic novelty of what is generally meant by a ""physical
unclonable function"" (PUF) is precisely defined, in order to supply a firm
basis for security evaluations and the proposal of new security mechanisms. A
PUF is defined as a hardware device which implements a physical function with
an output value that changes with its argument. A PUF can be clonable, but a
secure PUF must be unclonable. This proposed meaning of a PUF is cleanly
delineated from the closely related concepts of ""conventional unclonable
function"", ""physically obfuscated key"", ""random-number generator"", ""controlled
PUF"" and ""strong PUF"". The structure of a systematic security evaluation of a
PUF enabled by the proposed formal definition is outlined. Practically all
current and novel physical (but not conventional) unclonable physical functions
are PUFs by our definition. Thereby the proposed definition captures the
existing intuition about what is a PUF and remains flexible enough to encompass
further research. In a second part we quantitatively characterize two classes
of PUF security mechanisms, the standard one, based on a minimum secret
read-out time, and a novel one, based on challenge-dependent erasure of stored
information. The new mechanism is shown to allow in principle the construction
of a ""quantum-PUF"", that is absolutely secure while not requiring the storage
of an exponentially large secret. The construction of a PUF that is
mathematically and physically unclonable in principle does not contradict the
laws of physics."
"Web applications require exchanging parameters between a client and a server
to function properly. In real-world systems such as online banking transfer,
traversing multiple pages with parameters contributed by both the user and
server is a must, and hence the applications have to enforce workflow and
parameter dependency controls across multiple requests. An application that
applies insufficient server-side input validations is however vulnerable to
parameter tampering attacks, which manipulate the exchanged parameters.
Existing fuzzing-based scanning approaches however neglected these important
controls, and this caused their fuzzing requests to be dropped before they can
reach any vulnerable code.
  In this paper, we propose a novel approach to identify the workflow and
parameter dependent constraints, which are then maintained and leveraged for
automatic detection of server acceptances during fuzzing. We realized the
approach by building a generic blackbox parameter tampering scanner. It
successfully uncovered a number of severe vulnerabilities, including one from
the largest multi-national banking website, which other scanners miss."
"Business process management (BPM) and accompanying systems aim at enabling
enterprises to become adaptive. In spite of the dependency of enterprises on
secure business processes, BPM languages and techniques provide only little
support for security. Several complementary approaches have been proposed for
security in the domain of BPM. Nevertheless, support for a systematic procedure
for the development of secure electronic business processes is still missing.
In this paper, we pinpoint the need for a security engineering process model in
the domain of BPM and identify key requirements for such process model."
"It is imperative for organizations to us Information Security Management
System (ISMS) to effectively manage their information assets. ISMS starts with
a set of policies that dictate the usage computer resources. It starts with the
""21 essential security controls"" of ISO 27001, which give the basic standard
requirements of information security management. Our research is concerned with
the assessment of the application of these controls to organizations. STOPE
(Strategy, Technology Organization, People and Environment) methodologies were
used to integrated domains as a framework for this assessment. The controls are
mapped on these domains and subsequently refined into ""246 simple and easily
comprehended elements""."
"Nowadays, mobile handsets combine the functionality of mobile phones and
PDAs. Unfortunately, mobile handsets development process has been driven by
market demand, focusing on new features and neglecting security. So, it is
imperative to study the existing challenges that facing the mobile handsets
threat containment process, and the different techniques and methodologies that
used to face those challenges and contain the mobile handsets malwares. This
paper also presents a new approach to group the different malware containment
systems according to their typologies."
"In this paper, a new image encryption scheme using a secret key of 144-bits
is proposed. In the substitution process of the scheme, image is divided into
blocks and subsequently into color components. Each color component is modified
by performing bitwise operation which depends on secret key as well as a few
most significant bits of its previous and next color component. Three rounds
are taken to complete substitution process. To make cipher more robust, a
feedback mechanism is also applied by modifying used secret key after
encrypting each block. Further, resultant image is partitioned into several key
based dynamic sub-images. Each sub-image passes through the scrambling process
where pixels of sub-image are reshuffled within itself by using a generated
magic square matrix. Five rounds are taken for scrambling process. The propose
scheme is simple, fast and sensitive to the secret key. Due to high order of
substitution and permutation, common attacks like linear and differential
cryptanalysis are infeasible. The experimental results show that the proposed
encryption technique is efficient and has high security features."
"This paper presents an efficient fair document exchange protocol. The
exchange of the documents will be between two parties. The protocol is based on
the verifiable and recoverable encryption of a document's key. This verifiable
and recoverable encryption of the document's key will allow one party to verify
the encrypted key. It will also ensure this party that the Semi Trusted Third
Party will be able to recover the key if the other party misbehaves. The
protocol also incorporates the concept of enforcing the honesty of one party.
The proposed protocol consists of only three messages and is more efficient
than related protocols."
"In this paper, a new contract signing protocol is proposed based on the RSA
signature scheme. The protocol will allow two parties to sign the same contract
and then exchange their digital signatures. The protocol ensures fairness in
that it offers parties greater security: either both parties receive each
other's signatures or neither does. The protocol is based on offline Trusted
Third Party (TTP) that will be brought into play only if one party fails to
sign the contract. Otherwise, the TTP remains inactive. The protocol consists
of only three messages that are exchanged between the two parties."
"Nowadays different state and central government in India as well as abroad
are taking initiative to deliver different kind of services electronically
specially using Information and Communication Technology (ICT). Intruders or
hackers can steal or modify the information communicated between Government and
consumer through internet. To implement privacy and confidentiality of the
information we must use suitable encryption technique. In this paper an Object
Oriented Modelling of International Data Encryption Algorithm (IDEA) using GA
based efficient key generation technique has been proposed to incorporate
privacy and confidentiality of information which would be communicated between
government and consumer."
"Web 2.0 systems have drawn the attention of corporation, many of which now
seek to adopt Web 2.0 technologies and transfer its benefits to their
organizations. However, with the number of different social networking
platforms appearing, privacy and security continuously has to be taken into
account and looked at from different perspectives. This paper presents the most
common security risks faced by the major Web 2.0 applications. Additionally, it
introduces the most relevant paths and best practices to avoid these identified
security risks in a corporate environment."
"Physical Unclonable Functions (PUFs) are widely used to generate random
Numbers. In this paper we propose a new architecture in which an Arbiter Based
PUF has been employed as a nonlinear function in Nonlinear Feedback Shift
Register (NFSR) to generate true random numbers. The rate of producing the
output bit streams is 10 million bits per second. The proposed RNG is able to
pass all NIST tests and the entropy of the output stream is 7.999837 bits per
byte. The proposed circuit has very low resource usage of 193 Slices that makes
it suitable for lightweight applications."
"Recently, online video chat services are becoming increasingly popular. While
experiencing tremendous growth, online video chat services have also become yet
another spamming target. Unlike spam propagated via traditional medium like
emails and social networks, we find that spam propagated via online video chat
services is able to draw much larger attention from the users. We have
conducted several experiments to investigate spam propagation on Chatroulette -
the largest online video chat website. We have found that the largest spam
campaign on online video chat websites is dating scams. Our study indicates
that spam carrying dating or pharmacy scams have much higher clickthrough rates
than email spam carrying the same content. In particular, dating scams reach a
clickthrough rate of 14.97%. We also examined and analysed spam prevention
mechanisms that online video chat websites have designed and implemented. Our
study indicates that the prevention mechanisms either harm legitimate user
experience or can be easily bypassed."
"Recent cryptanalytic attacks have exposed the vulnerabilities of some widely
used cryptographic hash functions like MD5 and SHA-1. Attacks in the line of
differential attacks have been used to expose the weaknesses of several other
hash functions like RIPEMD, HAVAL. In this paper we propose a new efficient
hash algorithm that provides a near random hash output and overcomes some of
the earlier weaknesses. Extensive simulations and comparisons with some
existing hash functions have been done to prove the effectiveness of the BSA,
which is an acronym for the name of the 3 authors."
"We propose an efficient protocol for secure comparison of integers when both
integers are shared between two parties. Such protocols are useful for
implementing secure auctions. The proposed protocol's computational complexity
is roughly half the complexity of the best known efficient protocol. The
efficiency of the proposed protocol stems from the removal of the XOR
computation which is a time consuming operation."
"Developed structural scheme implementation of an integrated security and
formulated principles for the creation and development of an effective system
of information security."
"Recent reports reveal that violent extremists are trying to obtain insider
positions that may increase the impact of any attack on critical infrastructure
and could potentially endanger state services, people's lives and even
democracy. It is of utmost importance to be able to adopt extreme security
measures in certain high-risk situations in order to secure critical
infrastructure and thus lower the level of terrorist threats while preserving
the rights of citizens. To counter these threats, our research is aiming for
extreme measures to analyse and evaluate human threats related assessment
methods for employee screening and evaluations using cognitive analysis
technology, in particular functional Magnetic Resonance Imaging (fMRI). The
development of fMRI has led some researchers to conclude that this technology
has forensic potential and may be useful in investing personality traits,
mental illness, psychopathology, racial prejudice and religious extremism.
However, critics claim that this technology may present many new human rights
and ethical dilemmas and could result in potentially disastrous outcomes. The
main thrust of the research is to counter above concerns and harmful
consequences by presenting a set of ethical and professional guidelines that
will substantially reduce the risk of unethical use of this technology. The
significance of this research is to ensure the limits of the
state/organisation's right to peer into an individual's thought process with
and without consent, to define the parameters of a person's right to ensure
that fMRI scans do not pose more than an appropriate threat to cognitive
liberty, and the proper use of such information in civil, forensic and security
settings."
"Traditional password based authentication schemes are mostly considered in
single server environments. They are unfitted for the multi-server environments
from two aspects. On the one hand, users need to register in each server and to
store large sets of data, including identities and passwords. On the other
hand, servers are required to store a verification table containing user
identities and passwords. Recently, On the base on Sood et al.'s
protocol(2011), Li et al. proposed an improved dynamic identity based
authentication and key agreement protocol for multi-server architecture(2012).
Li et al. claims that the proposed scheme can make up the security weaknesses
of Sood et al.'s protocol. Unfortunately, our further research shows that Li et
al.'s protocol contains several drawbacks and can not resist some types of
known attacks, such as replay attack, Deny-of-Service attack, internal attack,
eavesdropping attack, masquerade attack, and so on. In this paper, we further
propose a light dynamic pseudonym identity based authentication and key
agreement protocol for multi-server architecture. In our scheme, service
providing servers don't need to maintain verification tables for users. The
proposed protocol provides not only the declared security features in Li et
al.'s paper, but also some other security features, such as traceability and
identity protection."
"In Europe and North America, the most widely used stream cipher to ensure
privacy and confidentiality of conversations in GSM mobile phones is the A5/1.
In this paper, we present a new attack on the A5/1 stream cipher with an
average time complexity of 2^(48.5), which is much less than the brute-force
attack with a complexity of 2^(64). The attack has a 100% success rate and
requires about 5.65GB storage. We provide a detailed description of our new
attack along with its implementation and results."
"Searching accounts for one of the most frequently performed computations over
the Internet as well as one of the most important applications of outsourced
computing, producing results that critically affect users' decision-making
behaviors. As such, verifying the integrity of Internet-based searches over
vast amounts of web contents is essential.
  We provide the first solution to this general security problem. We introduce
the concept of an authenticated web crawler and present the design and
prototype implementation of this new concept. An authenticated web crawler is a
trusted program that computes a special ""signature"" $s$ of a collection of web
contents it visits. Subject to this signature, web searches can be verified to
be correct with respect to the integrity of their produced results. This
signature also allows the verification of complicated queries on web pages,
such as conjunctive keyword searches. In our solution, along with the web pages
that satisfy any given search query, the search engine also returns a
cryptographic proof. This proof, together with the signature $s$, enables any
user to efficiently verify that no legitimate web pages are omitted from the
result computed by the search engine, and that no pages that are non-conforming
with the query are included in the result. An important property of our
solution is that the proof size and the verification time both depend solely on
the sizes of the query description and the query result, but not on the number
or sizes of the web pages over which the search is performed.
  Our authentication protocols are based on standard Merkle trees and the more
involved bilinear-map accumulators. As we experimentally demonstrate, the
prototype implementation of our system gives a low communication overhead
between the search engine and the user, and allows for fast verification of the
returned results on the user side."
"In this paper, an analytical model for DDoS attacks detection is proposed, in
which propagation of abrupt traffic changes inside public domain is monitored
to detect a wide range of DDoS attacks. Although, various statistical measures
can be used to construct profile of the traffic normally seen in the network to
identify anomalies whenever traffic goes out of profile, we have selected
volume and flow measure. Consideration of varying tolerance factors make
proposed detection system scalable to the varying network conditions and attack
loads in real time. NS-2 network simulator on Linux platform is used as
simulation testbed. Simulation results show that our proposed solution gives a
drastic improvement in terms of detection rate and false positive rate.
However, the mammoth volume generated by DDoS attacks pose the biggest
challenge in terms of memory and computational overheads as far as monitoring
and analysis of traffic at single point connecting victim is concerned. To
address this problem, a distributed cooperative technique is proposed that
distributes memory and computational overheads to all edge routers for
detecting a wide range of DDoS attacks at early stage."
"Denial of service (DoS) attacks and more particularly the distributed ones
(DDoS) are one of the latest threat and pose a grave danger to users,
organizations and infrastructures of the Internet. Several schemes have been
proposed on how to detect some of these attacks, but they suffer from a range
of problems, some of them being impractical and others not being effective
against these attacks. This paper reports the design principles and evaluation
results of our proposed framework that autonomously detects and accurately
characterizes a wide range of flooding DDoS attacks in ISP network. Attacks are
detected by the constant monitoring of propagation of abrupt traffic changes
inside ISP network. For this, a newly designed flow-volume based approach
(FVBA) is used to construct profile of the traffic normally seen in the
network, and identify anomalies whenever traffic goes out of profile.
Consideration of varying tolerance factors make proposed detection system
scalable to the varying network conditions and attack loads in real time.
Six-sigma method is used to identify threshold values accurately for malicious
flows characterization. FVBA has been extensively evaluated in a controlled
test-bed environment. Detection thresholds and efficiency is justified using
receiver operating characteristics (ROC) curve. For validation, KDD 99, a
publicly available benchmark dataset is used. The results show that our
proposed system gives a drastic improvement in terms of detection and false
alarm rate."
"With the increase in the number of security threats, Intrusion Detection
Systems have evolved as a significant countermeasure against these threats. And
as such, the topic of Intrusion Detection Systems has become one of the most
prominent research topics in recent years. This paper gives an overview of the
Intrusion Detection System and looks at two major machine learning paradigms
used in Intrusion Detection System, Genetic Algorithms and Fuzzy Logic and how
to apply them for intrusion detection."
"Baldi et \textit{al.} proposed a variant of McEliece's cryptosystem. The main
idea is to replace its permutation matrix by adding to it a rank 1 matrix. The
motivation for this change is twofold: it would allow the use of codes that
were shown to be insecure in the original McEliece's cryptosystem, and it would
reduce the key size while keeping the same security against generic decoding
attacks. The authors suggest to use generalized Reed-Solomon codes instead of
Goppa codes. The public code built with this method is not anymore a
generalized Reed-Solomon code. On the other hand, it contains a very large
secret generalized Reed-Solomon code. In this paper we present an attack that
is built upon a distinguisher which is able to identify elements of this secret
code. The distinguisher is constructed by considering the code generated by
component-wise products of codewords of the public code (the so-called ""square
code""). By using square-code dimension considerations, the initial generalized
Reed-Solomon code can be recovered which permits to decode any ciphertext. A
similar technique has already been successful for mounting an attack against a
homomorphic encryption scheme suggested by Bogdanoc et \textit{al.}. This work
can be viewed as another illustration of how a distinguisher of Reed-Solomon
codes can be used to devise an attack on cryptosystems based on them."
"We show how an off-path (spoofing-only) attacker can perform cross-site
scripting (XSS), cross-site request forgery (CSRF) and site spoofing/defacement
attacks, without requiring vulnerabilities in either web-browser or server and
circumventing known defenses. Attacker can also launch devastating denial of
service (DoS) attacks, even when the connection between the client and the
server is secured with SSL/TLS. The attacks are practical and require a puppet
(malicious script in browser sandbox) running on a the victim client machine,
and attacker capable of IP-spoofing on the Internet. Our attacks use a
technique allowing an off-path attacker to learn the sequence numbers of both
client and server in a TCP connection. The technique exploits the fact that
many computers, in particular those running Windows, use a global IP-ID
counter, which provides a side channel allowing efficient exposure of the
connection sequence numbers. We present results of experiments evaluating the
learning technique and the attacks that exploit it. Finally, we present
practical defenses that can be deployed at the firewall level; no changes to
existing TCP/IP stacks are required."
"Recently, arithmetic coding has attracted the attention of many scholars
because of its high compression capability. Accordingly, in this paper a method
which adds secrecy to this well-known source code is proposed. Finite state
arithmetic code (FSAC) is used as source code to add security. Its finite state
machine (FSM) characteristic is exploited to insert some random jumps during
source coding process. In addition, a Huffman code is designed for each state
to make decoding possible even in jumps. Being Prefix free, Huffman codes are
useful in tracking correct states for an authorized user when s/he decodes with
correct symmetric pseudo random key. The robustness of our proposed scheme is
further reinforced by adding another extra uncertainty by swapping outputs of
Huffman codes in each state. Several test images are used for inspecting the
validity of the proposed Huffman Finite State Arithmetic Coding (HFSAC). The
results of several experimental, key space analyses, statistical analysis, key
sensitivity and plaintext sensitivity tests show that HFSAC with a little
effect on compression efficiency for image cryptosystem provides an efficient
and secure way for real-time image encryption and transmission."
"We introduce a new perspective into the field of quantitative information
flow (QIF) analysis that invites the community to bound the leakage, reported
by QIF quantifiers, by a range consistent with the size of a program's secret
input instead of by a mathematically sound (but counter-intuitive) upper bound
of that leakage. To substantiate our position, we present a refinement of a
recent QIF metric that appears in the literature. Our refinement is based on
slight changes we bring into the design of that metric. These changes do not
affect the theoretical premises onto which the original metric is laid.
However, they enable the natural association between flow results and the
exhaustive search effort needed to uncover a program's secret information (or
the residual secret part of that information) to be clearly established. The
refinement we discuss in this paper validates our perspective and demonstrates
its importance in the future design of QIF quantifiers."
"In todays world of technology and gadgets almost every person is having a
portable device, be it a laptop or the smart phones. The user would like to
have all the services at his fingertips and access them through the portable
device he owns. Maybe he wants some data from the fellow user or from the
service provider or maybe he wants to control his smart devices at home from
wherever he is. In the present era of mobile environments, interactions between
the user device and the service provider must be secure enough regardless of
the type of device used to access or utilize the services. In this paper we
propose a ""Secure Three Way Authentication (STWA)"" technique intended to
preserve the user privacy and to accomplish ownership authentication in order
to securely deliver the services to the user devices. This technique will also
help the users or the service providers to check if the device is compromised
or not with the help of the encrypted pass-phrases that are being exchanged."
"Englisch: In this paper we study the paillier cryptosystem and derive form it
to new schemes. First we transform the signature of paillier in a Blind
signature. Secondly we propose a three-pass protocol wich use the homomorphic
property instead of the commutativity as the Shamir protocol does.
  German: Basierend auf dem Kryptosystem von Paillier und dem damit
eingef\""uhrten Problem der zusammengesetzten Residuenklasse werden in diesem
Artikel zwei kryptographische Verfahren vorgeschlagen. Zun\""achst wird die
Signatur von Paillier in ein blindes Signaturverfahren umgewandelt. Des
Weiteren wird mit der homomorphen Eigenschaft des Kryptosystems von Paillier
ein sogenanntes Three-Pass-Protocol - auch No-Key-Protocol genannt -
entwickelt."
"Vehicular Ad Hoc Networks (VANET) has mostly gained the attention of today's
research efforts, while current solutions to achieve secure VANET, to protect
the network from adversary and attacks still not enough, trying to reach a
satisfactory level, for the driver and manufacturer to achieve safety of life
and infotainment. The need for a robust VANET networks is strongly dependent on
their security and privacy features, which will be discussed in this paper. In
this paper a various types of security problems and challenges of VANET been
analyzed and discussed; we also discuss a set of solutions presented to solve
these challenges and problems."
"Heap security has been a major concern since the past two decades. Recently
many methods have been proposed to secure heap i.e. to avoid heap overrun and
attacks. The paper describes a method suggested to secure heap at the operating
system level. Major emphasis is given to Solaris operating system's dynamic
memory manager. When memory is required dynamically during runtime, the
SysVmalloc acts as a memory allocator.Vmalloc allocates the chunks of memory in
the form of splay tree structure. A self adjusting binary tree structure is
reviewed in the paper, moreover major security issue to secure heap area is
also suggested in the paper"
"Exponential growth of the volume of Bluetooth-enabled devices indicates that
it has become a popular way of wireless interconnections for exchanging
information. The main goal of this paper is to analyze the most critical
Bluetooth attacks in real scenarios. In order to find out the major
vulnerabilities in modern Bluetooth-enabled mobile devices several attacks have
performed successfully such as- Surveillance, Obfuscation, Sniffing,
Unauthorized Direct Data Access (UDDA) and Man-in-the-Middle Attack (MITM). To
perform the testbed, several devices are used such as mobile phones, laptops,
notebooks, wireless headsets, etc. and all the tests are carried out by
pen-testing software like hcittml, braudit, spoafiooph, hridump, bluesnarfer,
bluebugger and carwhisperer.
  KEYWORDS: Bluetooth, Security, Surveillance, Obfuscation, Sniffing, Denial of
service, Man-in-the-middle."
"With the explosive growth of internet and the fast communication techniques
in recent years the security and the confidentiality of the sensitive data has
become of prime and supreme importance and concern. To protect this data from
unauthorized access and tampering various methods for data hiding like
cryptography, hashing, authentication have been developed and are in practice
today. In this paper we will be discussing one such data hiding technique
called Steganography. Steganography is the process of concealing sensitive
information in any media to transfer it securely over the underlying unreliable
and unsecured communication network. Our paper presents a survey on various
data hiding techniques in Steganography that are in practice today along with
the comparative analysis of these techniques."
"A number of systems in recent times suffer from attacks like DDoS and Ping of
Death. Such attacks result in loss of critical system resources and CPU cycles,
as these compromised systems behave in an abnormal manner. The effect of such
abnormalities is worse in case of compromised systems handling financial
transaction, since it leads to severe monetary losses. In this paper we propose
a system that uses the Replicated State Machine approach to detect abnormality
in system usage. The suggested system is based on PAXOS algorithm, an algorithm
for solving the consensus problem in a network of unreliable processors."
"In spite of existence of many standard security mechanisms for ensuring
secure e-Commerce business, users still fall prey for online attacks. One such
simple but powerful attack is 'Phishing'. Phishing is the most alarming threat
in the e-Commerce world and effective anti-phishing technique is the need of
the hour. This paper focuses on a novel anti-phishing browser plug-in which
uses information hiding technique - Steganography. A Robust Message based Image
Steganography (RMIS) algorithm has been proposed. The same has been
incorporated in the form of a browser plug-in (safari) called Pixastic.
Pixastic is tested in an online banking scenario and it is compared with other
well-known anti-phishing plug-in methods in practice. Various parameters such
as robustness, usability and its behavior on various attacks have been
analysed. From experimental results, it is evident that our method Pixastic
performs well compared to other anti-phishing plug-ins."
"Steganography is the art of hiding secret information in media such as image,
audio and video. The purpose of steganography is to conceal the existence of
the secret information in any given medium. This work aims at strengthening the
security in steganography algorithm by generating dynamic pattern in selection
of indicator sequence. In addition to this dynamicity is also encompassed in
number of bits embedded in data channel. This technique has been implemented
and the results have been compared and evaluated with existing similar
techniques."
"Any Universal Steganalysis algorithm developed should be tested with various
stego-images to prove its efficiency. This work is aimed to build the
stego-image database which is obtained by implementing various RGB Least
Significant Bit Steganographic algorithms. Though there are many stego-images
sources available on the internet it lacks in the information such as how many
rows has been infected by the steganography algorithms, how many bits have been
modified and which channel has been affected. These parameters are important
for Steganalysis algorithms and it helps to rate its efficiency. Images are
chosen from board categories such as animals, nature, person to produce variety
of Stego-Image."
"Cloud computing is a revolutionary computing paradigm which enables flexible,
on-demand and low-cost usage of computing resources. However, those advantages,
ironically, are the causes of security and privacy problems, which emerge
because the data owned by different users are stored in some cloud servers
instead of under their own control. To deal with security problems, various
schemes based on the Attribute- Based Encryption (ABE) have been proposed
recently. However, the privacy problem of cloud computing is yet to be solved.
This paper presents an anonymous privilege control scheme AnonyControl to
address the user and data privacy problem in a cloud. By using multiple
authorities in cloud computing system, our proposed scheme achieves anonymous
cloud data access, finegrained privilege control, and more importantly,
tolerance to up to (N -2) authority compromise. Our security and performance
analysis show that AnonyControl is both secure and efficient for cloud
computing environment."
"Much research has been conducted to securely outsource multiple parties' data
aggregation to an untrusted aggregator without disclosing each individual's
data, or to enable multiple parties to jointly aggregate their data while
preserving privacy. However, those works either assume to have a secure channel
or suffer from high complexity. Here we consider how an external aggregator or
multiple parties learn some algebraic statistics (e.g., summation, product)
over participants' data while any individual's input data is kept secret to
others (the aggregator and other participants). We assume channels in our
construction are insecure. That is, all channels are subject to eavesdropping
attacks, and all the communications throughout the aggregation are open to
others. We successfully guarantee data confidentiality under this weak
assumption while limiting both the communication and computation complexity to
at most linear."
"The major threat in cyber crime for digital forensic examiner is to identify,
analyze and interpret the concealed information inside digital medium such as
image, audio and video. There are strong indications that hiding information
inside digital medium has been used for planning criminal activities. In this
way, it is important to develop a steganalysis technique which detects the
existence of hidden messages inside digital medium. This paper focuses on
universal image steganalysis method which uses RGB to HSI colour model
conversion. Any Universal Steganalysis algorithm developed should be tested
with various stego-images to prove its efficiency. The developed Universal
Steganalysis algorithm is tested in stego-image database which is obtained by
implementing various RGB Least Significant Bit Steganographic algorithms.
Though there are many stego-image sources available on the internet it lacks in
the information such as how many rows has been infected by the steganography
algorithms, how many bits have been modified and which channel has been
affected. These parameters are important for Steganalysis algorithms and it
helps to rate its efficiency. Proposed Steganalysis using Colour Model has been
tested with our Image Database and the results were affirmative."
"With the increasing popularity of the cloud, clients oursource their data to
clouds in order to take advantage of unlimited virtualized storage space and
the low management cost. Such trend prompts the privately oursourcing
computation, called \emph{multiparty cloud computation} (\MCC): Given $k$
clients storing their data in the cloud, how can they perform the joint
functionality by contributing their private data as inputs, and making use of
cloud's powerful computation capability. Namely, the clients wish to oursource
computation to the cloud together with their private data stored in the cloud,
which naturally happens when the computation is involved with large datasets,
e.g., to analyze malicious URLs. We note that the \MCC\ problem is different
from widely considered concepts, e.g., secure multiparty computation and
multiparty computation with server aid.
  To address this problem, we introduce the notion of \emph{homomorphic
threshold proxy re-encryption} schemes, which are encryption schemes that enjoy
three promising properties: proxy re-encryption -- transforming encrypted data
of one user to encrypted data of target user, threshold decryption --
decrypting encrypted data by combining secret key shares obtained by a set of
users, and homomorphic computation -- evaluating functions on the encrypted
data. To demonstrate the feasibility of the proposed approach, we present an
encryption scheme which allows anyone to compute arbitrary many additions and
at most one multiplications."
"Data security is one of the most crucial and a major challenge in the digital
world. Security, privacy and integrity of data are demanded in every operation
performed on internet. Whenever security of data is discussed, it is mostly in
the context of secure transfer of data over the unreliable communication
networks. But the security of the data in databases is also as important. In
this paper we will be presenting some of the common security techniques for the
data that can be implemented in fortifying and strengthening the databases."
"An information is a message which is received and understood. Information can
be sent one person to another over a long range but the process of sending
information must be done in a secure way especially in case of a private
message. Mathematicians and Engineers have historically relied on different
algorithmic techniques to secure messages and signals. Cryptography, to most
people, is concerned with keeping communications private. Indeed, the
protection of sensitive communications has been the emphasis of cryptography
throughout much of its history. Sometimes it is safer to send a message using
an image and thus cryptography can also be done using images during an
emergency. The need to extract information from images and interpret their
contents has been one of the driving factors in the development of image
processing and cryptography during the past decades. In this paper, a simple
cryptographic method was used to decode a message which was in an image and it
was done using a popular computational software."
"Data hiding is the art of embedding data into digital media in a way such
that the existence of data remains concealed from everyone except the intended
recipient. In this paper, we discuss the various Least Significant Bit (LSB)
data hiding techniques. We first look at the classical LSB data hiding
technique and the method to embed secret data into cover media by bit
manipulation. We also take a look at the data hiding technique by bit plane
decomposition based on Fibonacci numbers. This method generates more bit planes
which allows users to embed more data into the cover image without causing
significant distortion. We also discuss the data hiding technique based on bit
plane decomposition by prime numbers and natural numbers. These methods are
based on mapping the sequence of image bit size to the decomposed bit number to
hide the intended information. Finally we present a comparative analysis of
these data hiding techniques."
"Dempster-Shafer theory of imprecise probabilities has proved useful to
incorporate both nonspecificity and conflict uncertainties in an inference
mechanism. The traditional Bayesian approach cannot differentiate between the
two, and is unable to handle non-specific, ambiguous, and conflicting
information without making strong assumptions. This paper presents a
generalization of a recent Bayesian-based method of quantifying information
flow in Dempster-Shafer theory. The generalization concretely enhances the
original method removing all its weaknesses that are highlighted in this paper.
In so many words, our generalized method can handle any number of secret inputs
to a program, it enables the capturing of an attacker's beliefs in all kinds of
sets (singleton or not), and it supports a new and precise quantitative
information flow measure whose reported flow results are plausible in that they
are bounded by the size of a program's secret input, and can be easily
associated with the exhaustive search effort needed to uncover a program's
secret information, unlike the results reported by the original metric."
"Metamorphic viruses are considered the most dangerous of all computer
viruses. Unlike other computer viruses that can be detected statically using
static signature technique or dynamically using emulators, metamorphic viruses
change their code to avoid such detection techniques. This makes metamorphic
viruses a real challenge for computer security researchers. In this thesis, we
investigate the techniques used by metamorphic viruses to alter their code,
such as trivial code insertion, instructions substitution, subroutines
permutation and register renaming. An in-depth survey of the current techniques
used for detection of this kind of viruses is presented. We discuss techniques
that are used by commercial antivirus products, and those introduced in
scientific researches. Moreover, a novel approach is then introduced for
metamorphic virus recognition based on unsupervised machine learning generally
and Eigenfaces technique specifically which is widely used for face
recognition. We analyze the performance of the proposed technique and show the
experimental results compared to results of well-known antivirus engines.
Finally, we discuss the future and potential enhancements of the proposed
approach to detect more and other target viruses."
"We give a generic divide-and-conquer approach for constructing
collusion-resistant probabilistic dynamic traitor tracing schemes with larger
alphabets from schemes with smaller alphabets. This construction offers a
linear tradeoff between the alphabet size and the codelength. In particular, we
show that applying our results to the binary dynamic Tardos scheme of Laarhoven
et al. leads to schemes that are shorter by a factor equal to half the alphabet
size. Asymptotically, these codelengths correspond, up to a constant factor, to
the fingerprinting capacity for static probabilistic schemes. This gives a
hierarchy of probabilistic dynamic traitor tracing schemes, and bridges the gap
between the low bandwidth, high codelength scheme of Laarhoven et al. and the
high bandwidth, low codelength scheme of Fiat and Tassa."
"Advances in technology has given rise to new computing models where any
individual/organization (Cloud Service Consumers here by denoted as CSC's) can
outsource their computational intensive tasks on their data to a remote Cloud
Service Provider (CSP) for many advantages like lower costs, scalability etc.
But such advantages come for a bigger cost ""Security and Privacy of data"" for
this very reason many CSC's are skeptical to move towards cloud computing
models. While the advances in cryptography research are promising, there are no
practical solutions yet for performing any operations on encrypted data [1].
For this very reason there is strong need for finding alternative viable
solutions for us to benefit from Cloud Computing. A technique to provide
confidentiality without encryption was proposed in the past namely ""Chaffing
and Winnowing: Confidentiality without Encryption"" by Ronald L. Rivest [2].
While this technique has been proposed for packet based communication system,
its not adaptable in all cloud service models like Software-as-Service,
Platform-as-Service or Infrastructure-as-Service [3]. In this paper we propose
an adaptation of this technique in a cloud computational setup where CSC's
outsource computational intensive tasks like web log parsing, DNA Sequencing
etc to a MapReduce like CSP service."
"Botnets are prevailing mechanisms for the facilitation of the distributed
denial of service (DDoS) attacks on computer networks or applications.
Currently, Botnet-based DDoS attacks on the application layer are latest and
most problematic trends in network security threats. Botnet-based DDoS attacks
on the application layer limits resources, curtails revenue, and yields
customer dissatisfaction, among others. DDoS attacks are among the most
difficult problems to resolve online, especially, when the target is the Web
server. In this paper, we present a comprehensive study to show the danger of
Botnet-based DDoS attacks on application layer, especially on the Web server
and the increased incidents of such attacks that has evidently increased
recently. Botnet-based DDoS attacks incidents and revenue losses of famous
companies and government websites are also described. This provides better
understanding of the problem, current solution space, and future research scope
to defend against such attacks efficiently."
"Generating keys and keeping them secret is critical in secure communications.
Due to the ""open-air"" nature, key distribution is more susceptible to attacks
in wireless communications. An ingenious solution is to generate common secret
keys by two communicating parties separately without the need of key exchange
or distribution, and regenerate them on needs. Recently, it is promising to
extract keys by measuring the random variation in wireless channels, e.g., RSS.
In this paper, we propose an efficient Secret Key Extraction protocol without
Chasing down Errors, SKECE. It establishes common cryptographic keys for two
communicating parties in wireless networks via the realtime measurement of
Channel State Information (CSI). It outperforms RSS-based approaches for key
generation in terms of multiple subcarriers measurement, perfect symmetry in
channel, rapid decorrelation with distance, and high sensitivity towards
environments. In the SKECE design, we also propose effective mechanisms such as
the adaptive key stream generation, leakage resilient consistence validation,
and weighted key recombination, to fully exploit the excellent properties of
CSI. We implement SKECE on off-the-shelf 802.11n devices and evaluate its
performance via extensive experiments. The results demonstrate that SKECE
achieves a more than 3x throughput gain in the key generation from one
subcarrier in static scenarios, and due to its high efficiency, a 50% reduction
on the communication overhead compared to the state-of-the-art RSS based
approaches."
"This paper proposed several methods to transplant the compound chaotic image
encryption scheme with permutation based on 3D baker into image formats as
Joint Photographic Experts Group (JPEG) and Graphics Interchange Format (GIF).
The new method averts the lossy Discrete Cosine Transform and quantization and
can encrypt and decrypt JPEG images lossless. Our proposed method for GIF keeps
the property of animation successfully. The security test results indicate the
proposed methods have high security. Since JPEG and GIF image formats are
popular contemporarily, this paper shows that the prospect of chaotic image
encryption is promising."
"We introduce the swap-or-not shuffle and show that the technique gives rise
to a new method to convert a pseudorandom function (PRF) into a pseudorandom
permutation (PRP) (or, alternatively, to directly build a confusion/diffusion
blockcipher). We then prove that swap-or-not has excellent quantitative
security bounds, giving a Luby-Rackoff type result that ensures security
(assuming an ideal round function) to a number of adversarial queries that is
nearly the size of the construction's domain. Swap-or-not provides a direct
solution for building a small-domain cipher and achieving format-preserving
encryption, yielding the best bounds known for a practical scheme for
enciphering credit-card numbers. The analysis of swap-or-not is based on the
theory of mixing times of Markov chains."
"Because of the revolution and the success of the technique IBE
(Identification Based Encryption) in the recent years. The need is growing to
have a standardization to this technology to streamline communication based on
it. But this requires a thorough study to extract the strength and weakness of
the most recognized cryptosystems. Our first goal in this work is to approach
to this standardization, by applying a study which permit to extract the best
cryptosystems. As we will see in this work and as Boneh and Boyen said in 2011
(Journal of Cryptology) the BB1 and BB2 are the most efficient schemes in the
model selective ID and without random oracle (they are the only schemes traced
in this model). This is right as those schemes are secure (under this model),
efficient and useful for some applications. Our second goal behind this work is
to make an approvement in BB2 to admit a more efficient schemes. We will study
the security of our schemes, which is basing on an efficient strong
Diffie-Hellman problem compared to BB1 and BB2. More than that our HIBE support
s+ID-HIBE compared to BBG (Boneh Boyen Goh). Additionally the ID in our scheme
will be in Zp instead of Zp* as with BBG. We will cite more clearly all these
statements in in this article."
"Instrumented environments, such as modern building automation systems (BAS),
are becoming commonplace and are increasingly interconnected with (and
sometimes by) enterprise networks and the Internet. Regardless of the
underlying communication platform, secure control of devices in such
environments is a challenging task. The current trend is to move from
proprietary communication media and protocols to IP over Ethernet. While the
move to IP represents progress, new and different Internet architectures might
be better-suited for instrumented environments. In this paper, we consider
security of instrumented environments in the context of Content-Centric
Networking (CCN). In particular, we focus on building automation over
Named-Data Networking (NDN), a prominent instance of CCN. After identifying
security requirements in a specific BAS sub-domain (lighting control), we
construct a concrete NDN-based security architecture, analyze its properties
and report on preliminary implementation and experimental results. We believe
in securing a communication paradigm well outside of its claimed forte of
content distribution. At the same time, we provide a viable (secure and
efficient) communication platform for a class of instrumented environments
exemplified by lighting control."
"The article contains the algorithm for searching a certain kind of bridges in
the protection graph of Take-Grant model. The proposed algorithm is based on a
classical breadth-first search algorithm."
"In ubiquitous computing devices, users tend to store some valuable
information in their device. Even though the device can be borrowed by the
other user temporarily, it is not safe for any user to borrow or lend the
device as it may result the private data of the user to be public. To safeguard
the user data and also to preserve user privacy we propose the technique of
ownership authentication transfer. The user who is willing to sell the device
has to transfer the ownership of the device under sale. Once the device is sold
and the ownership has been transferred, the old owner will not be able to use
that device at any cost. Either of the users will not be able to use the device
if the process of ownership has not been carried out properly. This also takes
care of the scenario when the device has been stolen or lost, avoiding the
impersonation attack. The proposed protocol has been modeled and verified using
Automated Validation of Internet Security Protocols and Applications (AVISPA)
and is found to be safe."
"This paper constructs two encryption methods using 2-D chaotic maps, Duffings
and Arnold's cat maps respectively. Both of the methods are designed using
message embedded scheme and are analyzed for their validity, for plaintext
sensitivity, key sensitivity, known plaintext and brute-force attacks. Due to
the less key space generally many chaotic cryptosystem developed are found to
be weak against Brute force attack which is an essential issue to be solved.
For this issue, concept of identifiability proved to be a necessary condition
to be fulfilled by the designed chaotic cipher to resist brute force attack,
which is a basic attack. As 2-D chaotic maps provide more key space than 1-D
maps thus they are considered to be more suitable. This work is accompanied
with analysis results obtained from these developed cipher. Moreover,
identifiable keys are searched for different input texts at various key values.
The methods are found to have good key sensitivity and possess identifiable
keys thus concluding that they can resist linear attacks and brute-force
attacks."
"Unlike current closed systems such as 2nd and 3rd generations where the core
network is controlled by a sole network operator, multiple network operators
will coexist and manage the core network in Next Generation Networks (NGNs).
This open architecture and the collaboration between different network
operators will support ubiquitous connectivity and thus enhances users'
experience. However, this brings to the fore certain security issues which must
be addressed, the most important of which is the initial Authentication and Key
Agreement (AKA) to identify and authorize mobile nodes on these various
networks. This paper looks at how existing research efforts the HOKEY WG,
Mobile Ethernet and 3GPP frameworks respond to this new environment and provide
security mechanisms. The analysis shows that most of the research had realized
the openness of the core network and tried to deal with it using different
methods. These methods will be extensively analysed in order to highlight their
strengths and weaknesses."
"The paper studies cryptographically useful properties of the sequence of the
sizes of Goldbach ellipses. We show that binary subsequences based on this
sequence have useful properties. They can be used to generate keys and to
provide an index-based mapping to numbers. The paper also presents a protocol
for secure session keys that is based on Goldbach partitions."
"Global System for Mobile Communications (GSM) is one of the most commonly
used cellular technologies in the world. One of the objectives in mobile
communication systems is the security of the exchanged data. GSM employs many
cryptographic algorithms for security like A5/1, A5/2 and A5/3. Even so, these
algorithms do not provide sufficient level of security for protecting the
confidentiality of GSM. Therefore, it is desirable to increase security by
additional encryption methods. This paper presents a voice encryption method
called: ""DES with Random permutation and Inversion"", based on current voice
channel, which overcomes data channel's insufficiencies and solves the problem
of penetrating the RPE-LTP vocoder by the encrypted voice. The proposed method
fulfils an end-to-end secured communication in the GSM; insure a good
compatibility to all GSM networks, and easy implementation without any
modification in these systems."
"Temporal Key Integrity Protocol (TKIP) is a provisional solution for Wired
Equivalent Privacy (WEP) security loopholes present in already widely deployed
legacy 802.11 wireless devices. In this work, we model and analyse the
computational complexity of TKIP security mechanism and propose an optimised
implementation, called LOTKIP, to decrease processing overhead for better
energy efficient security performance. The LOTKIP improvements are based on
minimising key mixing redundancy and a novel frame encapsulation with low
overhead. We simulate and compare LOTKIP with baseline TKIP in terms of
complexity and energy consumption for ad hoc wireless network security. From
simulation results, we demonstrate that LOTKIP executes with lower
computational complexity, hence, with faster encryption time and more
energy-efficient."
"In this paper, a multilayer perceptron guided key generation for
encryption/decryption (MLPKG) has been proposed through recursive replacement
using mutated character code generation for wireless communication of
data/information. Multilayer perceptron transmitting systems at both ends
accept an identical input vector, generate an output bit and the network are
trained based on the output bit which is used to form a protected variable
length secret-key. For each session, different hidden layer of multilayer
neural network is selected randomly and weights or hidden units of this
selected hidden layer help to form a secret session key. The plain text is
encrypted using mutated character code table. Intermediate cipher text is yet
again encrypted through recursive replacement technique to from next
intermediate encrypted text which is again encrypted to form the final cipher
text through chaining, cascaded xoring of multilayer perceptron generated
session key. If size of the final block of intermediate cipher text is less
than the size of the key then this block is kept unaltered. Receiver will use
identical multilayer perceptron generated session key for performing
deciphering process for getting the recursive replacement encrypted cipher text
and then mutated character code table is used for decoding. Parametric tests
have been done and results are compared in terms of Chi-Square test, response
time in transmission with some existing classical techniques, which shows
comparable results for the proposed technique."
"We present a new type of clogging DoS attacks, with the highest amplification
factors achieved by off-path attackers, using only puppets, i.e., sandboxed
malware on victim machines. Specifically, we present off-path variants of the
Opt-ack, Ack-storm and Coremelt DoS attacks, achieving results comparable to
these achieved previously achieved by eavesdropping/MitM attackers and
(unrestricted) malware. In contrast to previous off-path attacks, which
attacked the client (machine) running the malware, our attacks address a very
different goal: large-scale clogging DoS of a third party, or even of backbone
connections.
  Our clogging attacks are based on off-path TCP injections. Indeed, as an
additional contribution, we present improved off-path TCP injection attacks.
Our new attacks significantly relax the requirements cf. to the known attacks;
specifically, our injection attack requires only a Java script in browser
sandbox (not 'restricted malware'), does not depend on specific operating
system properties, and is efficient even when client's port is determined using
recommended algorithm. Our attacks are constructed modularly, allowing reuse of
modules for other scenarios and replacing modules as necessary. We present
specific defenses, however, this work is further proof to the need to base
security on sound foundations, using cryptography to provide security even
against MitM attackers."
"The paper presents initial step toward new network anomaly detection method
that is based on traffic visualisation. The key design principle of the
proposed approach is the lack of direct, linear time dependencies for the
created network traffic visualisations. The method's feasibility is
demonstrated in network steganography environment by presenting steg-tomography
methodology and developing the dedicated visualisation tool. To authors' best
knowledge this is the first utilization of network traffic visualisations for
steganalysis purposes."
"We propose in this paper a new propagation vector for malicious software by
abusing the Tor network. Tor is particularly relevant, since operating a Tor
exit node is easy and involves low costs compared to attack institutional or
ISP networks. After presenting the Tor network from an attacker perspective, we
describe an automated exploitation malware which is operated on a Tor exit node
targeting to infect web browsers. Our experiments show that the current
deployed Tor network, provides a large amount of potential victims."
"We present a new quasigroup based block encryption system with and without
cipher-block-chaining. We compare its performance against Advanced Encryption
Standard-256 (AES256) bit algorithm using the NIST statistical test suite
(NIST-STS) that tests for randomness of a sequence. Since it is well known that
a good encryption algorithm must destroy any statistical properties of the
input sequence and produce an output close to a true random sequence, the
NIST-STS suite results provide a good test bench. In almost all tests from the
suite the proposed algorithm performs better than AES256."
"With the proliferation of high-speed wireless networking, the necessity for
efficient, robust and secure encryption modes is ever increasing. But,
cryptography is primarily a computationally intensive process. This paper
investigates the performance and efficiency of IEEE 802.11i approved Advanced
Encryption Standard (AES)-Rijndael ciphering/deciphering software in Cipher
Block Chaining (CBC) mode. Simulations are used to analyse the speed, resource
consumption and robustness of AES-CBC to investigate its viability for image
encryption usage on common low power devices. The detailed results presented in
this paper provide a basis for performance estimation of AES cryptosystems
implemented on wireless devices. The use of optimized AES-CBC software
implementation gives a superior encryption speed performance by 12 - 30%, but
at the cost of twice more memory for code size."
"In this paper, the author explore the challenges with respect to the security
aspect in MANETs and propose a new approach which makes use of a bio-inspired
methodology. This paper elaborates various attacks which can be perpetrated on
MANETs and current solutions to the aforementioned problems, and then it
describes a Bio-Inspired Method which could be a possible solution to security
issues in MANETs."
"The significance of the DDoS problem and the increased occurrence,
sophistication and strength of attacks has led to the dawn of numerous
prevention mechanisms. Each proposed prevention mechanism has some unique
advantages and disadvantages over the others. In this paper, we present a
classification of available mechanisms that are proposed in literature on
preventing Internet services from possible DDoS attacks and discuss the
strengths and weaknesses of each mechanism. This provides better understanding
of the problem and enables a security administrator to effectively equip his
arsenal with proper prevention mechanisms for fighting against DDoS threat."
"Nowadays, the increased use of battery-powered mobile appliances and the urge
to access time-sensitive data anytime anywhere has fuelled a high demand for
wireless networks. However, wireless networks are susceptible to intrusion and
security problems. There is an inherent need to secure the wireless data
communication to ensure the confidentiality, authenticity, integrity and non
repudiation of the data being exchanged. On the other hand, the computation and
the resultant energy consumption to achieve sufficient security can be high.
Encryption algorithms are generally computationally intensive, and consume a
significant amount of computing resources (such as CPU time, memory, and
battery power). Considering the limited resources on wireless devices, it is
crucial that security protocols be implemented efficiently. This manuscript
focuses on how energy consumption is impacted by the use of unoptimised
AES-CCMP algorithms and proposes an optimized AES CCMP algorithm using 2-way
interleaving that does not compromise the security of wireless communication
sessions. There is also analysis of the performance of AES (a.k.a. Rijndael) in
its AES-CCMP implementation. The 2-way interleaving technique is an
optimization of the CBC-MAC that is investigated using two performance metrics
(namely encryption time and throughput)."
"The use of anonymity-based infrastructures and anonymisers is a plausible
solution to mitigate privacy problems on the Internet. Tor (short for The onion
router) is a popular low-latency anonymity system that can be installed as an
end-user application on a wide range of operating systems to redirect the
traffic through a series of anonymising proxy circuits. The construction of
these circuits determines both the latency and the anonymity degree of the Tor
anonymity system. While some circuit construction strategies lead to delays
which are tolerated for activities like Web browsing, they can make the system
vulnerable to linking attacks. We evaluate in this paper three classical
strategies for the construction of Tor circuits, with respect to their
de-anonymisation risk and latency performance. We then develop a new circuit
selection algorithm that considerably reduces the success probability of
linking attacks while keeping a good degree of performance. We finally conduct
experiments on a real-world Tor deployment over PlanetLab. Our experimental
results confirm the validity of our strategy and its performance increase for
Web browsing."
"Wireless Sensor Network (WSN) consists of low cost sensor nodes which cannot
afford to implement sophisticated security system in it. That is why intrusion
detection architecture for WSN is considerably different and difficult to
implement. Most of the current implementations are based on exchanging anomaly
signals among the leaf level sensors resulting in too much power consumption.
We propose a novel architecture for Intrusion Detection System (IDS) in WSN
based on Hierarchical Overlay Design (HOD) that will distribute the overall
responsibility of intrusion detection into entities and thus conserve memory
and power of the nodes. The architecture uses layered design with GSM cell like
structure based on special monitor nodes. The HOD structure enables the sensors
to communicate using far less messages and thus conserve precious power and
also saves memory by not implementing IDS module on each sensor. The proposal
also uses rippling of alarm through layers and thus ensures proper delivery to
the uppermost layer with redundancy."
"In recent years, wireless ad hoc sensor network becomes popular both in civil
and military jobs. However, security is one of the significant challenges for
sensor network because of their deployment in open and unprotected environment.
As cryptographic mechanism is not enough to protect sensor network from
external attacks, intrusion detection system needs to be introduced. Though
intrusion prevention mechanism is one of the major and efficient methods
against attacks, but there might be some attacks for which prevention method is
not known. Besides preventing the system from some known attacks, intrusion
detection system gather necessary information related to attack technique and
help in the development of intrusion prevention system. In addition to
reviewing the present attacks available in wireless sensor network this paper
examines the current efforts to intrusion detection system against wireless
sensor network. In this paper we propose a hierarchical architectural design
based intrusion detection system that fits the current demands and restrictions
of wireless ad hoc sensor network. In this proposed intrusion detection system
architecture we followed clustering mechanism to build a four level
hierarchical network which enhances network scalability to large geographical
area and use both anomaly and misuse detection techniques for intrusion
detection. We introduce policy based detection mechanism as well as intrusion
response together with GSM cell concept for intrusion detection architecture."
"In today's world of E-Commerce everything comes online like Music, E-Books,
Shopping all most everything is online. If you are using some service or buying
things online then you have to pay for that. For that you have to do Net
Banking or you have to use Credit card which will do online payment for you. In
today's environment when everything is online, the service you are using for
E-Payment must be secure and you must protect your banking information like
debit card or credit card information from possible threat of hacking. There
were lots way to threat like Key logger, Forgery Detection, Phishing, Shoulder
surfing. Therefore, we reveal our actual information of Bank and Credit Card
then there will be a chance to lose data and same credit card and hackers can
use banking information for malicious purpose. In this paper we discuss
available E-Payment protocols, examine its advantages and delimitation's and
shows that there are steel needs to design a more secure E-Payment protocol.
The suggested protocol is based on using hash function and using dynamic or
virtual password, which protects your banking or credit card information from
possible threat of hacking when doing online transactions."
"This paper presents the chief security officer (CSO) problem, defines its
scope, and investigates several important research questions related within the
scope. The CSO problem is defined based on the concept of secrecy capacity of
wireless communication channels. It is also related to the chief
Estimation/Executive Officer (CEO) problem that has been well studied in
information theory. The CSO problem consists of a CSO, several agents capable
of having two-way communication with the CSO, and a group of eavesdroppers.
There are two scenarios in the CSO problem; one in which agents are not allowed
to cooperate with one another and the other in which agents are allowed to
cooperate with one another. While there are several research questions relevant
to the CSO problem, this paper focusses on the following and provides answers:
(1) How much information can be exchanged back and forth between the CSO and
the agents without leaking any information to the eavesdroppers? (2) What is
the power allocation strategy that the CSO needs to follow so as to maximize
the secrecy capacity? (3) How can agents cooperate with one another in order to
increase the overall secrecy capacity?."
"In this paper we deal with the dimension of multisequences and related
properties. For a given multisequence W and an m tuple of positive integers R,
we define the R extension of W. Further we count the number of multisequences W
whose R extensions have maximum dimension and give an algorithm to derive such
multisequences. We then go on to use this theory to count the number of Linear
Feedback Shift Register(LFSR) configurations with multi input multi output
delay blocks for any given primitive characteristic polynomial and also to
design such LFSRs. Further, we use the result on multisequences to count the
number of Hankel matrices of any given dimension."
"In a recent approach, we proposed to model an access control mechanism as a
Markov Decision Process, thus claiming that in order to make an access control
decision, one can use well-defined mechanisms from decision theory. We present
in this paper an implementation of such mechanism, using the open-source solver
GLPK, and we model the problem in the GMPL language. We illustrate our approach
with a simple, yet expressive example, and we show how the variation of some
parameters can change the final outcome. In particular, we show that in
addition to returning a decision, we can also calculate the value of each
decision."
"This paper1 presents an efficient approach to an existing batch verification
system on Identity based group signature (IBGS) which can be applied to any
Mobile ad hoc network device including Vehicle Ad hoc Networks (VANET). We
propose an optimized way to batch signatures in order to get maximum throughput
from a device in runtime environment. In addition, we minimize the number of
pairing computations in batch verification proposed by B. Qin et al. for large
scale VANET. We introduce a batch scheduling algorithm for batch verification
targeting further minimization the batch computation time."
"Extended private information retrieval (EPIR) was defined by \cite{BCPT07} at
CANS'07 and generalized by \cite{BC09} at AFRICACRYPT'09. In the generalized
setting, EPIR allows a user to evaluate a function on a database block such
that the database can learn neither which function has been evaluated nor on
which block the function has been evaluated and the user learns no more
information on the database blocks except for the expected result. An EPIR
protocol for evaluating polynomials over a finite field $L$ was proposed by
Bringer and Chabanne in \cite{BC09}. We show that the protocol does not satisfy
the correctness requirement as they have claimed. In particular, we show that
it does not give the user the expected result with large probability if one of
the coefficients of the polynomial to be evaluated is primitive in $L$ and the
others belong to the prime subfield of $L$."
"Recently, the number of requests for multicast services through the wireless
networks has been increased. However, for successful deployment, security and
efficiency of content delivery must be provided at first. This paper presents a
new approach for secure multicast in wireless networks. This approach, CRAW
(Combination of Re-keying and Authentication in Wireless networks) combines
member authentication procedure with group key management protocol to provide
an efficient group re-keying process. One-time password is proposed for member
authentication and CKC (Code for Key Calculation) is suggested for group key
management in wireless networks. In fact, the combination of authentication
with group key management in wireless networks results in a simple and secure
mechanism both for authentication and group key management while mobile members
join/leave a group or move inter-area. Simulation results show that CRAW
reduces re-keying overhead at join from O(log2 n+1) to O(1) while security
requirements are saved. Also, CRAW introduces storing a main list to manage
mobile members' location while they move intra-group inter-area."
"This paper presents an efficient group key management protocol, CKCS (Code
for Key Calculation in Simultaneous join/leave) for simultaneous join/leave in
secure multicast. This protocol is based on logical key hierarchy. In this
protocol, when new members join the group simultaneously, server sends only the
group key for those new members. Then, current members and new members
calculate the necessary keys by node codes and one-way hash function. A node
code is a random number which is assigned to each key to help users calculate
the necessary keys. Again, at leave, the server just sends the new group key to
remaining members. The results show that CKCS reduces computational and
communication overhead, and also message size in simultaneous join/leave."
"Temporal Key Integrity Protocol (TKIP) is the IEEE TaskGroupi solution for
the security loop holes present in the already widely deployed 802.11 hardware.
It is a set of algorithms that wrap WEP to give the best possible solution
given design constraints such as paucity of the CPU cycles, hardwiring of the
WEP encryption algorithm and software upgrade dependent. Thus, TKIP is
significantly more difficult and challenging to implement and optimise than
WEP. The objective of this research is to examine the cost and benefit of TKIP
security mechanisms and optimise its implementation to reduce security overhead
for better performance. We propose a modified TKIP (MoTKIP) with improved
packet encapsulation and decapsulation procedure that reduces computation and
packet overhead in classic TKIP substantially and optimises total wireless
network throughput rates."
"We develop a theory for state-based noninterference in a setting where
different security policies---we call them local policies---apply in different
parts of a given system. Our theory comprises appropriate security definitions,
characterizations of these definitions, for instance in terms of unwindings,
algorithms for analyzing the security of systems with local policies, and
corresponding complexity results."
"A review study of NIST Statistical Test Suite is undertaken with a motivation
to understand all its test algorithms and to write their C codes independently
without looking at various sites mentioned in the NIST document. All the codes
are tested with the test data given in the NIST document and excellent
agreements have been found. The codes have been put together in a package
executable in MS Windows platform. Based on the package, exhaustive test runs
are executed on three PRNGs, e.g. LCG by Park & Miller, LCG by Knuth and BBSG.
Our findings support the present belief that BBSG is a better PRNG than the
other two."
"This paper investigates the use of different transformations for improving
the randomness of sequences. In particular, convolutional codes are used for
increasing the size of a given sequence and then a random mapping function is
used for further randomization. We have shown how such a method can convert
highly correlated sequences into random ones."
"In Ciphertext-Policy Attribute Based Encryption (CP-ABE), attributes are
attached to the user's secret key and access policy is at-tached to the
ciphertext. If attributes in the secret key of a user satisfy the policy then
only the genuine user can decrypt the ciphertext. However, such scenario also
necessitates periodic updating of the secret key with the changing attributes.
According to our observations, the existing attempts at doing so are not
efficient. In this paper, we propose a newer approach to add, update or delete
the value of particular attribute effi-ciently without the knowledge of the
other attributes."
"Ciphertext policy attribute based encryption (CP-ABE) is a technique in which
user with secret key containing attributes, only able to decrypt the message if
the attributes in the policy match with the attributes in secret key. The
existing methods that use reasonably computable decryption policies produce the
ciphertext of size at least linearly varying with the number of attributes with
additional pairing operations during encryption and decryption. In this paper,
we propose a scheme in which ciphertext remains constant in length,
irrespective of the number of attributes. Our scheme works for a threshold
case: the number of attributes in a policy must be a subset of attributes in a
secret key. The security of propose scheme is based on Decisional Bilinear
Diffie-Hellman (DBDH) problem."
"Security of computers and the networks that connect them is increasingly
becoming of great significance. Intrusion detection system is one of the
security defense tools for computer networks. This paper compares two different
model Approaches for representing intrusion detection system by using decision
tree techniques. These approaches are Phase-model approach and Level-model
approach. Each model is implemented by using two techniques, New Attacks and
Data partitioning techniques. The experimental results showed that Phase
approach has higher classification rate in both New Attacks and Data
Partitioning techniques than Level approach."
"In recent years, information security essential in various arenas like
internet communication, multimedia systems, medical imaging, tele-medicine and
military communication. However, most of them faced with some problems such as
the lack of robustness and security. In this letter, after reviewing the main
points of the chaotic trigonometric maps and the coupled map lattices, we
introduce the scheme of chaos-based image encryption based on coupled map lat
tices. The scheme decreases periodic effect of the ergodic dynamical systems in
the chaos-based image encryption. To evaluate the security of the encrypted
image of this scheme, the key space analysis, the correlation of two adjacent
pixels and differential attack were performed. This scheme tries to improve the
problem of failure of encryption such as small key space and level of security."
"Recently, the problem of privacy amplification with an active adversary has
received a lot of attention. Given a shared n-bit weak random source X with
min-entropy k and a security parameter s, the main goal is to construct an
explicit 2-round privacy amplification protocol that achieves entropy loss
O(s). Dodis and Wichs \cite{DW09} showed that optimal protocols can be achieved
by constructing explicit non-malleable extractors. However, the best known
explicit non-malleable extractor only achieves k=0.49n \cite{Li12b} and
evidence in \cite{Li12b} suggests that constructing explicit non-malleable
extractors for smaller min-entropy may be hard. In an alternative approach, Li
\cite{Li12} introduced the notion of a non-malleable condenser and showed that
explicit non-malleable condensers also give optimal privacy amplification
protocols.
  In this paper, we give the first construction of non-malleable condensers for
arbitrary min-entropy. Using our construction, we obtain a 2-round privacy
amplification protocol with optimal entropy loss for security parameter up to
s=\Omega(\sqrt{k}). This is the first protocol that simultaneously achieves
optimal round complexity and optimal entropy loss for arbitrary min-entropy k.
We also generalize this result to obtain a protocol that runs in O(s/\sqrt{k})
rounds with optimal entropy loss, for security parameter up to s=\Omega(k).
This significantly improves the protocol in \cite{ckor}. Finally, we give a
better non-malleable condenser for linear min-entropy, and in this case obtain
a 2-round protocol with optimal entropy loss for security parameter up to
s=\Omega(k), which improves the entropy loss and communication complexity of
the protocol in \cite{Li12b}."
"Intrusion detection systems (IDSs) have become a widely used measure for
security systems. The main problem for those systems results is the irrelevant
alerts on those results. We will propose a data mining based method for
classification to distinguish serious alerts and irrelevant one with a
performance of 99.9% which is better in comparison with the other recent data
mining methods that have reached the performance of 97%. A ranked alerts list
also created according to alerts importance to minimize human interventions."
"In her 2011 EVT/WOTE keynote, Travis County, Texas County Clerk Dana
DeBeauvoir described the qualities she wanted in her ideal election system to
replace their existing DREs. In response, in April of 2012, the authors,
working with DeBeauvoir and her staff, jointly architected STAR-Vote, a voting
system with a DRE-style human interface and a ""belt and suspenders"" approach to
verifiability. It provides both a paper trail and end-to-end cryptography using
COTS hardware. It is designed to support both ballot-level risk-limiting
audits, and auditing by individual voters and observers. The human interface
and process flow is based on modern usability research. This paper describes
the STAR-Vote architecture, which could well be the next-generation voting
system for Travis County and perhaps elsewhere."
"Peer-to-peer (P2P) networks have become popular as a new paradigm for
information exchange and are being used in many applications such as file
sharing, distributed computing, video conference, VoIP, radio and TV
broadcasting. This popularity comes with security implications and
vulnerabilities that need to be addressed. Especially duo to direct
communication between two end nodes in P2P networks, these networks are
potentially vulnerable to ""Man-in-the-Middle"" attacks. In this paper, we
propose a new public-key cryptosystem for P2P networks that is robust against
Man-in-the-Middle adversary. This cryptosystem is based on RSA and knapsack
problems. Our precoding-based algorithm uses knapsack problem for performing
permutation and padding random data to the message. We show that comparing to
other proposed cryptosystems, our algorithm is more efficient and it is fully
secure against an active adversary."
"This paper shows that the six classes of PPTs can be put into two groups.
Autocorrelation and cross-correlation functions of the six classes derived from
the gaps between each class type have been computed. It is shown that Classes A
and D (in which the largest term is divisible by 5) are different from the
other four classes in their randomness properties if they are ordered by the
largest term. In the other two orderings each of the six random Baudhayana
sequences has excellent randomness properties."
"With the development of sensor network, mobile computing, and web
applications, data are now collected from many distributed sources to form big
datasets. Such datasets can be hosted in the cloud to achieve economical
processing. However, these data might be highly sensitive requiring secure
storage and processing. We envision a cloud-based data storage and processing
framework that enables users to economically and securely share and handle big
datasets. Under this framework, we study the matrix-based data mining
algorithms with a focus on the secure top-k eigenvector algorithm. Our approach
uses an iterative processing model in which the authorized user interacts with
the cloud to achieve the result. In this process, both the source matrix and
the intermediate results keep confidential and the client-side incurs low
costs. The security of this approach is guaranteed by using Paillier Encryption
and a random perturbation technique. We carefully analyze its security under a
cloud-specific threat model. Our experimental results show that the proposed
method is scalable to big matrices while requiring low client-side costs."
"Open communication over the Internet poses a serious threat to countries with
repressive regimes, leading them to develop and deploy censorship mechanisms
within their networks. Unfortunately, existing censorship circumvention systems
do not provide high availability guarantees to their users, as censors can
identify, hence disrupt, the traffic belonging to these systems using today's
advanced censorship technologies. In this paper we propose SWEET, a highly
available censorship-resistant infrastructure. SWEET works by encapsulating a
censored user's traffic to a proxy server inside email messages that are
carried over by public email service providers, like Gmail and Yahoo Mail. As
the operation of SWEET is not bound to specific email providers we argue that a
censor will need to block all email communications in order to disrupt SWEET,
which is infeasible as email constitutes an important part of today's Internet.
Through experiments with a prototype of our system we find that SWEET's
performance is sufficient for web traffic. In particular, regular websites are
downloaded within couple of seconds."
"Recently, a novel image encryption scheme based on improved hyperchaotic
sequences was proposed. A pseudo-random number sequence, generated by a
hyper-chaos system, is used to determine two involved encryption functions,
bitwise exclusive or (XOR) operation and modulo addition. It was reported that
the scheme can be broken with some pairs of chosen plain-images and the
corresponding cipherimages. This paper re-evaluates the security of the
encryption scheme and finds that the encryption scheme can be broken with only
one known plain-image. The performance of the known-plaintext attack, in terms
of success probability and computation load, become even much better when two
known plain-images are available. In addition, security defects on
insensitivity of the encryption result with respect to changes of secret key
and plain-image are also reported."
"We exploit edit distance to quantify keywords similarity and develop two
advanced techniques on constructing fuzzy keyword sets, which achieve optimized
storage and representation overheads. We further propose a brand new
symbol-based trie-traverse searching scheme, where a multi-way tree structure
is built up using symbols transformed from the resulted fuzzy keyword sets.
Through rigorous security analysis, we show that our proposed solution is
secure and privacy-preserving, while correctly realizing the goal of fuzzy
keyword search. Extensive experimental results demonstrate the efficiency of
the proposed solution."
"The robust development of Electronic Health Records (EHRs) causes a
significant growth in sharing EHRs for clinical research. However, such a
sharing makes it difficult to protect patient's privacy. A number of automated
de-identification tools have been developed to reduce the re-identification
risk of published data, while preserving its statistical meaning. In this
paper, we focus on the experimental evaluation of existing automated
de-identification tools, as applied to our EHR database, to assess which tool
performs better with each quasi-identifiers defined in our paper. Performance
of each tool is analyzed wrt. two aspects: individual disclosure risk and
information loss. Through this experiment, the generalization method has better
performance on reducing risk and lower degree of information loss than
suppression, which validates it as more appropriate de-identification technique
for EHR databases."
"Supervisory Control and Data Acquisition (SCADA) systems support and control
the operation of many critical infrastructures that our society depend on, such
as power grids. Since SCADA systems become a target for cyber attacks and the
potential impact of a successful attack could lead to disastrous consequences
in the physical world, ensuring the security of these systems is of vital
importance. A fundamental prerequisite to securing a SCADA system is a clear
understanding and a consistent view of its architecture. However, because of
the complexity and scale of SCADA systems, this is challenging to acquire. In
this paper, we propose a layered architectural view for SCADA systems, which
aims at building a common ground among stakeholders and supporting the
implementation of security analysis. In order to manage the complexity and
scale, we define four interrelated architectural layers, and uses the concept
of viewpoints to focus on a subset of the system. We indicate the applicability
of our approach in the context of SCADA system security analysis."
"This paper is focused on privacy issues related to the prefix part of IPv6
addresses. Long-lived prefixes may introduce additional tracking opportunities
for communication partners and third parties. We outline a number of prefix
alteration schemes that may be deployed to maintain the unlinkability of users'
activities. While none of the schemes will solve all privacy problems on the
Internet on their own, we argue that the development of practical prefix
alteration techniques constitutes a worthwile avenue to pursue: They would
allow Internet Service Providers to increase the attainable privacy level well
above the status quo in today's IPv4 networks."
"In this paper, a key generation and certification technique using multilayer
perceptron (KGCMLP) has been proposed in wireless communication of
data/information. In this proposed KGCMLP technique both sender and receiver
uses an identical multilayer perceptrons. Both perceptrons are start
synchronization by exchanging some control frames. During synchronization
process message integrity test and synchronization test has been carried out.
Only the synchronization test does not guarantee the security for this reason
key certification phase also been introduced in KGCMLP technique. After Key
generation and certification procedure synchronized identical weight vector
forms the key for encryption/decryption. Parametric tests have been done and
results are compared with some existing classical techniques, which show
comparable results for the proposed technique."
"There are many scenarios in which inferring the type of a client browser is
desirable, for instance to fight against session stealing. This is known as
browser fingerprinting. This paper presents and evaluates a novel
fingerprinting technique to determine the exact nature (browser type and
version, eg Firefox 15) of a web-browser, exploiting HTML parser quirks
exercised through XSS. Our experiments show that the exact version of a web
browser can be determined with 71% of accuracy, and that only 6 tests are
sufficient to quickly determine the exact family a web browser belongs to."
"With the ever increasing volume of information over wireless medium, security
has assumed an important dimension. The security of transmitted data over a
wireless channel aims at protecting the data from unauthorized intrusion.
Wireless network security is achieved using cryptographic primitives. Some
properties that give encryption mechanism their cryptographic strength also
make them very sensitive to channel error as well. Therefore, security for data
transmission over wireless channel results in throughput loss. Trade-off
between security and throughput is always a major concern in wireless networks.
In this paper, a Link Adaptive Encryption scheme is evaluated that adapts to
channel variations and enhances the security level of WLANs without making any
compromise with the network performance. Numerical results obtained through
simulation are compared with the fixed block length encryption technique in two
different modes of operation- Electronic Code Book (ECB) & Cipher Block
Chaining (CBC). Optimal block length is also computed, which is assumed to be
the effective strength of the cipher. It has been observed that security
attained with link adaptive scheme operating in ECB mode of cipher is a better
solution for security and throughput trade-off. However, it is found that if
computational security is a major concern, link adaptive scheme in CBC mode
should be preferred."
"This paper primarily addresses the issue of identifying all possible levels
of digital anonymity, thereby allowing electronic services and mechanisms to be
categorised. For this purpose, we sophisticate the generic idea of anonymity
and, filling a niche in the field, bring the scope of trust into the focus of
categorisation. One major concern of our work is to propose a novel and
universal taxonomy which enables a dynamic, trust-based comparison between
systems at an abstract level. On the other hand, our contribution intentionally
does not offer an alternative to anonymity metrics, but neither is it concerned
with methods of anonymous data retrieval (cf. data-mining techniques). However,
for ease of comprehension, it provides a systematic 'application manual' and
also presents a lucid overview of the correspondence between the current and
related taxonomies. Additionally, as a generalisation of group signatures, we
introduce the notion of group schemes."
"The emergence of many challenges and the rapid development of the means of
communications and computer networks and the Internet. Digital information
revolution has affected a lot on human societies. Data today has become
available in digital format (text, image, audio, and video), which led to the
emergence of many opportunities for creativity for innovation as well as the
emergence of a new kind of challenges"
"We revisit recent results from the area of collusion-resistant traitor
tracing, and show how they can be combined and improved to obtain more
efficient dynamic traitor tracing schemes. In particular, we show how the
dynamic Tardos scheme of Laarhoven et al. can be combined with the optimized
score functions of Oosterwijk et al. to trace coalitions much faster. If the
attack strategy is known, in many cases the order of the code length goes down
from quadratic to linear in the number of colluders, while if the attack is not
known, we show how the interleaving defense may be used to catch all colluders
about twice as fast as in the dynamic Tardos scheme. Some of these results also
apply to the static traitor tracing setting where the attack strategy is known
in advance, and to group testing."
"Increasingly more attention is paid to the privacy in online applications due
to the widespread data collection for various analysis purposes. Sensitive
information might be mined from the raw data during the analysis, and this led
to a great privacy concern among people (data providers) these days. To deal
with this privacy concerns, multitudes of privacy-preserving computation
schemes are proposed to address various computation problems, and we have found
many of them fall into a class of problems which can be solved by greedy
algorithms.
  In this paper, we propose a framework for distributed greedy algorithms in
which instances in the feasible set come from different parties. By our
framework, most generic distributed greedy algorithms can be converted to a
privacy preserving one which achieves the same result as the original greedy
algorithm while the private information associated with the instances is still
protected."
"With the rapid development of MANET, secure and practical authentication is
becoming increasingly important. The existing works perform the research from
two aspects, i.e., (a)secure key division and distributed storage, (b)secure
distributed authentication. But there still exist several unsolved problems.
Specifically, it may suffer from cheating problems and fault authentication
attack, which can result in authentication failure and DoS attack towards
authentication service. Besides, most existing schemes are not with
satisfactory efficiency due to exponential arithmetic based on Shamir's scheme.
In this paper, we explore the property of verifiable secret sharing(VSS)
schemes with Chinese Remainder Theorem (CRT), then propose a secret key
distributed storage scheme based on CRT-VSS and trusted computing for MANET.
Specifically, we utilize trusted computing technology to solve two existing
cheating problems in secret sharing area before. After that, we do the analysis
of homomorphism property with CRT-VSS and design the corresponding
shares-product sharing scheme with better concision. On such basis, a secure
distributed Elliptic Curve-Digital Signature Standard signature (ECC-DSS)
authentication scheme based on CRT-VSS scheme and trusted computing is
proposed. Furthermore, as an important property of authentication scheme, we
discuss the refreshing property of CRT-VSS and do thorough comparisons with
Shamir's scheme. Finally, we provide formal guarantees towards our schemes
proposed in this paper."
"Advanced Encryption Standard (AES) algorithm is considered as a secured
algorithm. Still, some security issues lie in the S-Box and the key used. In
this paper, we have tried to give focus on the security of the key used. Here,
the proposed modified algorithms for the AES have been simulated and tested
with different chaotic variations such as 1-D logistic chaos equation, cross
chaos equation as well as combination of both. For the evaluation purpose, the
CPU time has been taken as the parameter. Though the variations of AES
algorithms are taking some more time as compared to the standard AES algorithm,
still the variations can be taken into consideration in case of more sensitive
information. As we are giving more security to the key used for AES algorithm,
our proposed algorithms are very much secured from unauthorized people."
"Post-quantum cryptography studies the security of classical, i.e. non-quantum
cryptographic protocols against quantum attacks. Until recently, the considered
adversaries were assumed to use quantum computers and behave like classical
adversaries otherwise. A more conservative approach is to assume that also the
communication between the honest parties and the adversary is (partly) quantum.
We discuss several options to define secure encryption and authentication
against these stronger adversaries who can carry out 'superposition attacks'.
We re-prove a recent result of Boneh and Zhandry, stating that a uniformly
random function (and hence also a quantum-secure pseudorandom function) can
serve as a message-authentication code which is secure, even if the adversary
can evaluate this function in superposition."
"The aim of this paper is to develop a model to ensure data stored in the
cloud. Model based on situations that arise in a business environment. The
model also includes individual participants and their data operations.
Implementation of the model is transferred using UML. The model is divided into
7 modules. Each module is apparent from the terms of data security and
described specific situations when working with data. Based on this model it is
possible to convert the implementation of cloud into enterprise environments
with respect to data security in the firm."
"We present the design and implementation of the PeerShare, a system that can
be used by applications to securely distribute sensitive data to social
contacts of a user. PeerShare incorporates a generic framework that allows
different applications to distribute data with different security requirements.
By using interfaces available from existing popular social networks. PeerShare
is designed to be easy to use for both end users as well as developers of
applications. PeerShare can be used to distribute shared keys, public keys and
any other data that need to be distributed with authenticity and
confidentiality guarantees to an authorized set of recipients, specified in
terms of social relationships. We have used \peershare already in three
different applications and plan to make it available for developers."
"We formally study iterated block ciphers that alternate between two sequences
of independent and identically distributed (i.i.d.) rounds. It is demonstrated
that, in some cases the effect of alternating increases security, while in
other cases the effect may strictly decrease security relative to the
corresponding product of one of its component sequences. As this would appear
to contradict conventional wisdom based on the ideal cipher approximation, we
introduce new machinery for provable security comparisons. The comparisons made
here simultaneously establish a coherent ordering of security metrics ranging
from key-recovery cost to computational indistinguishability."
"Recently, a RGB image encryption algorithm based on DNA encoding and chaos
map has been proposed. It was reported that the encryption algorithm can be
broken with four pairs of chosen plain-images and the corresponding
cipher-images. This paper re-evaluates the security of the encryption
algorithm, and finds that the encryption algorithm can be broken efficiently
with only one known plain-image. The effectiveness of the proposed
known-plaintext attack is supported by both rigorous theoretical analysis and
experimental results. In addition, two other security defects are also
reported."
"For the past decade, query processing on relational data has been studied
extensively, and many theoretical and practical solutions to query processing
have been proposed under various scenarios. With the recent popularity of cloud
computing, users now have the opportunity to outsource their data as well as
the data management tasks to the cloud. However, due to the rise of various
privacy issues, sensitive data (e.g., medical records) need to be encrypted
before outsourcing to the cloud. In addition, query processing tasks should be
handled by the cloud; otherwise, there would be no point to outsource the data
at the first place. To process queries over encrypted data without the cloud
ever decrypting the data is a very challenging task. In this paper, we focus on
solving the k-nearest neighbor (kNN) query problem over encrypted database
outsourced to a cloud: a user issues an encrypted query record to the cloud,
and the cloud returns the k closest records to the user. We first present a
basic scheme and demonstrate that such a naive solution is not secure. To
provide better security, we propose a secure kNN protocol that protects the
confidentiality of the data, user's input query, and data access patterns.
Also, we empirically analyze the efficiency of our protocols through various
experiments. These results indicate that our secure protocol is very efficient
on the user end, and this lightweight scheme allows a user to use any mobile
device to perform the kNN query."
"Android is an open software platform for mobile devices with a large market
share in the smartphone sector. The openness of the system as well as its wide
adoption lead to an increasing amount of malware developed for this platform.
ANANAS is an expandable and modular framework for analyzing Android
applications. It takes care of common needs for dynamic malware analysis and
provides an interface for the development of plugins. Adaptability and
expandability have been main design goals during the development process. An
abstraction layer for simple user interaction and phone event simulation is
also part of the framework. It allows an analyst to script the required user
simulation or phone events on demand or adjust the simulation to his needs. Six
plugins have been developed for ANANAS. They represent well known techniques
for malware analysis, such as system call hooking and network traffic analysis.
The focus clearly lies on dynamic analysis, as five of the six plugins are
dynamic analysis methods."
"As the anti-viruses run in a trusted kernel level any loophole in the
anti-virus program can enable attackers to take full control over the computer
system and steal data or do serious damages. Hence the anti-virus engines must
be developed with proper security in mind. The ant-virus should be able to any
type of specially created executable files, compression packages or documents
that are intentionally created to exploit the anti-virus weakness.
  Viruses are present in almost every system even though there are anti-viruses
installed. This is because every anti-virus, however good it may be, leads to
some extent of false positives and false negatives. Our faith on the anti-virus
system often makes us more careless about hygienic habits which increases the
possibility of infection. It is necessary for an anti-virus to detect and
destroy the malware before its own files are detected and destroyed by the
malware."
"Jamming techniques require just moderate resources to be deployed, while
their effectiveness in disrupting communications is unprecedented. In this
paper we introduce several contributions to jamming mitigation. In particular,
we introduce a novel adversary model that has both (unlimited) jamming reactive
capabilities as well as powerful (but limited) proactive jamming capabilities.
Under this powerful but yet realistic adversary model, the communication
bandwidth provided by current anti-jamming solutions drops to zero. We then
present Silence is Golden (SiG): a novel anti jamming protocol that,
introducing a tunable, asymmetric communication channel, is able to mitigate
the adversary capabilities, enabling the parties to communicate. For instance,
with SiG it is possible to deliver a 128 bits long message with a probability
greater than 99% in 4096 time slots in the presence of a jammer that jams all
the on-the-fly communications and the 74% of the silent radio spectrum---while
competing proposals simply fail. The provided solution enjoys a thorough
theoretical analysis and is supported by extensive experimental results,
showing the viability of our proposal."
"A growing concern with advertisement libraries on Android is their ability to
exfiltrate personal information from their host applications. While previous
work has looked at the libraries' abilities to measure private information on
their own, advertising libraries also include APIs through which a host
application can deliberately leak private information about the user. This
study considers a corpus of 114,000 apps. We reconstruct the APIs for 103 ad
libraries used in the corpus, and study how the privacy leaking APIs from the
top 20 ad libraries are used by the applications. Notably, we have found that
app popularity correlates with privacy leakage; the marginal increase in
advertising revenue, multiplied over a larger user base, seems to incentivize
these app vendors to violate their users' privacy."
"During a fight between viruses and anti-viruses it is not always predictable
that the anti-virus is going to win. There are many malicious viruses which
target to attack and paralyze the anti-viruses. It is necessary for an
anti-virus to detect and destroy the malware before its own files are detected
and destroyed by the malware. The anti-virus may follow thorough testing and
auditing procedures to fix all its bugs before releasing the software in the
market. Besides the anti-virus may use all the obfuscation techniques like
polymorphism that the viruses generally use to hide their codes. This article
also shows how to use TRIZ Inventive Standards to solve the harmful effects of
the viruses on the anti-virus."
"Protection of faces in pictures and videos of people in connection with
sensitive information, activism, abused cases and others on public broadcasting
media and social net- works is very important. On social networks like
YouTube,facebook, Twitter and others, videos are being posted with blurring
techniques of which some of them cannot be recoverable. Most blurring
techniques used can easily be recoverable using off-the-shelf software. The
ones that are difficult to be recovered also can easily be used by abusers and
ther wrong doers.
  This paper proposes an image encryption technique that will make it possible
for selected facial area to be encrypted based on RGB pixel shuffling of an m*n
size image. This will make it difficult for off-the-shelf software to restore
the ncrypted image and also make it easy for the law enforcement agencies to
reconstruct the face back in case the picture or video is related to an abuse
case. The implementation of the encryption method will be done using MATLAB. At
the and, there will be no change in the total size of the image during
encryption and decryption process."
"We investigate the $k$-error linear complexity of $p^2$-periodic binary
sequences defined from the polynomial quotients (including the well-studied
Fermat quotients), which is defined by $$ q_{p,w}(u)\equiv \frac{u^w-u^{wp}}{p}
\bmod p ~ \mathrm{with} 0 \le q_{p,w}(u) \le p-1, ~u\ge 0, $$ where $p$ is an
odd prime and $1\le w<p$. Indeed, first for all integers $k$, we determine
exact values of the $k$-error linear complexity over the finite field $\F_2$
for these binary sequences under the assumption of f2 being a primitive root
modulo $p^2$, and then we determine their $k$-error linear complexity over the
finite field $\F_p$ for either $0\le k<p$ when $w=1$ or $0\le k<p-1$ when $2\le
w<p$. Theoretical results obtained indicate that such sequences possess `good'
error linear complexity."
"Privacy-aware processing of personal data on the web of services requires
managing a number of issues arising both from the technical and the legal
domain. Several approaches have been proposed to matching privacy requirements
(on the clients side) and privacy guarantees (on the service provider side).
Still, the assurance of effective data protection (when possible) relies on
substantial human effort and exposes organizations to significant
(non-)compliance risks. In this paper we put forward the idea that a privacy
certification scheme producing and managing machine-readable artifacts in the
form of privacy certificates can play an important role towards the solution of
this problem. Digital privacy certificates represent the reasons why a privacy
property holds for a service and describe the privacy measures supporting it.
Also, privacy certificates can be used to automatically select services whose
certificates match the client policies (privacy requirements).
  Our proposal relies on an evolution of the conceptual model developed in the
Assert4Soa project and on a certificate format specifically tailored to
represent privacy properties. To validate our approach, we present a worked-out
instance showing how privacy property Retention-based unlinkability can be
certified for a banking financial service."
"We introduce and investigate the ability of an attacker to surreptitiously
use an otherwise secure wireless network to detect moving people through walls,
in an area in which people expect their location to be private. We call this
attack on location privacy of people an ""exploiting radio windows"" (ERW)
attack. We design and implement the ERW attack methodology for through wall
people localization that relies on reliably detecting when people cross the
link lines by using physical layer measurements between the legitimate
transmitters and the attack receivers. We also develop a method to estimate the
direction of movement of a person from the sequence of link lines crossed
during a short time interval. Additionally, we describe how an attacker may
estimate any artificial changes in transmit power (used as a countermeasure),
compensate for these power changes using measurements from sufficient number of
links, and still detect line crossings. We implement our methodology on WiFi
and ZigBee nodes and experimentally evaluate the ERW attack by monitoring
people movements through walls in two real-world settings. We find that our
methods achieve very high accuracy in detecting line crossings and determining
direction of motion."
"Lattice reduction algorithms have numerous applications in number theory,
algebra, as well as in cryptanalysis. The most famous algorithm for lattice
reduction is the LLL algorithm. In polynomial time it computes a reduced basis
with provable output quality. One early improvement of the LLL algorithm was
LLL with deep insertions (DeepLLL). The output of this version of LLL has
higher quality in practice but the running time seems to explode. Weaker
variants of DeepLLL, where the insertions are restricted to blocks, behave
nicely in practice concerning the running time. However no proof of polynomial
running time is known. In this paper PotLLL, a new variant of DeepLLL with
provably polynomial running time, is presented. We compare the practical
behavior of the new algorithm to classical LLL, BKZ as well as blockwise
variants of DeepLLL regarding both the output quality and running time."
"Privacy is one of the key issues addressed by information Security. Through
cryptographic encryption methods, one can prevent a third party from
understanding transmitted raw data over unsecured channel during signal
transmission. The cryptographic methods for enhancing the security of digital
contents have gained high significance in the current era. Breach of security
and misuse of confidential information that has been intercepted by
unauthorized parties are key problems that information security tries to solve.
This paper sets out to contribute to the general body of knowledge in the area
of classical cryptography by develop- ing a new hybrid way of encryption of
plaintext. The cryptosystem performs its encryption by encrypting the plaintext
using columnar transposition cipher and further using the ciphertext to encrypt
the plaintext again using Vigen\`ere ci- pher. At the end, cryptanalysis was
performed on the ciphertext. The implementation will be done using java
program- ming."
"The increased growth in the use of transmission of multimedia medical
contents over unsecured and open networks provides insecurity for confidential
patient information over these networks. Digital encryption of medical images
before transmission and storage is proposed as a way to effectively provide
protection of patient information. Encryption before watermarking of these
images is necessary in order to ensure inaccessibility of information to
unauthorized personnel with patient. This paper presented a visual
cryptographic technique for encrypting of medical images before transmission or
storage of them. This will make such images inaccessible by unauthorized
personnel and also ensures confidentiality. The process made use of an
encryption technique that is based on pixel shuffling and a secret key
generated from the image."
"Building a password cracking server that preserves the privacy of the queries
made to the server is a problem that has not yet been solved. Such a server
could acquire practical relevance in the future: for instance, the tables used
to crack the passwords could be calculated, stored and hosted in
cloud-computing services, and could be queried from devices with limited
computing power.
  In this paper we present a method to preserve the confidentiality of a
password cracker---wherein the tables used to crack the passwords are stored by
a third party---by combining Hellman tables and Private Information Retrieval
(PIR) protocols. We provide the technical details of this method, analyze its
complexity, and show the experimental results obtained with our implementation."
"A Publicly Verifiable Secret Sharing (PVSS) scheme allows anyone to verify
the validity of the shares computed and distributed by a dealer. The idea of
PVSS was introduced by Stadler in [18] where he presented a PVSS scheme based
on Discrete Logarithm. Later, several PVSS schemes were proposed. In [2],
Behnad and Eghlidos present an interesting PVSS scheme with explicit membership
and disputation processes. In this paper, we present a new PVSS having the
advantage of being simpler while offering the same features."
"Security Policies (SP) constitute the core of communication networks
protection infrastructures. It offers a set of rules allowing differentiating
between legitimate actions and prohibited ones and consequently, associates
each entity in the network with a set of permissions and privileges. Moreover,
in today's technological society and to allow applications perpetuity,
communication networks must support the collaboration between entities to face
up any unavailability or flinching. This collaboration must be governed by
security mechanisms according to the established permissions and privileges.
Delegation is a common practice that is used to simplify the sharing of
responsibilities and privileges. The delegation process in a SP environment can
be implanted through the use of adequate formalisms and modeling. The main
contribution of this paper is then, the proposition of a generic and formal
modeling of delegation process. This modeling is based on three steps composing
the delegation life cycle: negotiation used for delegation initiation,
verification of the SP respect while delegating and revocation of an
established delegation. Hence, we propose to deal with each step according to
the main delegation characteristics and extend them by some new specificities."
"In this paper, we will present how to find keys elliptic curve cryptosystems
(ECC) with simple tools of Delphi 7 console application, using the software
problem solving of the scalar point multiplication in the field GF(p), where p
is an arbitrary prime number."
"We present the design and prototype implementation of ConScript, a framework
for using JavaScript to allow casual Web users to participate in an anonymous
communication system. When a Web user visits a cooperative Web site, the site
serves a JavaScript application that instructs the browser to create and submit
""dummy"" messages into the anonymity system. Users who want to send non-dummy
messages through the anonymity system use a browser plug-in to replace these
dummy messages with real messages. Creating such conscripted anonymity sets can
increase the anonymity set size available to users of remailer, e-voting, and
verifiable shuffle-style anonymity systems. We outline ConScript's
architecture, we address a number of potential attacks against ConScript, and
we discuss the ethical issues related to deploying such a system. Our
implementation results demonstrate the practicality of ConScript: a workstation
running our ConScript prototype JavaScript client generates a dummy message for
a mix-net in 81 milliseconds and it generates a dummy message for a
DoS-resistant DC-net in 156 milliseconds."
"To encourage users to use stronger and more secure passwords, modern web
browsers offer users password management services, allowing users to save
previously entered passwords locally onto their hard drives. We present Lupin,
a tool that automatically extracts these saved passwords without the user's
knowledge. Lupin allows a network adversary to obtain passwords as long as the
login form appears on a non-HTTPS page. Unlike existing password sniffing
tools, Lupin can obtain passwords for websites users are not visiting.
Furthermore, Lupin can extract passwords embedded in login forms with a
destination address served in HTTPS. To determine the number of websites
vulnerable to our attack, we crawled the top 45,000 most popular websites from
Alexa's top website list and discovered that at least 28% of these sites are
vulnerable. To further demonstrate the feasibility of our attack, we tested
Lupin under controlled conditions using one of the authors' computers. Lupin
was able to extract passwords from 1,000 websites in less than 35 seconds. We
suggest techniques for web developers to protect their web applications from
attack, and we propose alternative designs for a secure password manager."
"In this paper, a new method is presented to compute the 2-adic complexity of
pseudo-random sequences. With this method, the 2-adic complexities of all the
known sequences with ideal 2-level autocorrelation are uniformly determined.
Results show that their 2-adic complexities equal their periods. In other
words, their 2-adic complexities attain the maximum. Moreover, 2-adic
complexities of two classes of optimal autocorrelation sequences with period
$N\equiv1\mod4$, namely Legendre sequences and Ding-Helleseth-Lam sequences,
are investigated. Besides, this method also can be used to compute the linear
complexity of binary sequences regarded as sequences over other finite fields."
"This document describes the symmetric encryption algorithm called Puzzle. It
is free and open. The objective of this paper is to get an opinion about its
security from the cryptology community. It is separated in two parts, a
technical description of the algorithm and its cryptanalysis. The algorithm has
some interesting properties :
  The block size is variable and unknown from an attacker. The size of the key
has no limit and is unknown from an attacker. The key size does not affect the
algorithm speed (using a 256 bit key is the same as using a 1024 bit key). The
algorithm is much faster than the average cryptographic function. Experimental
test showed 600 Mo/s - 4 cycles/byte on an Intel Core 2 Duo P8600 2.40GHz and
1,2 Go/s - 2 cycles/byte on an Intel i5-3210M 2.50GHz. Both CPU had only 2
cores."
"We consider traffic-update mobile applications that let users learn traffic
conditions based on reports from other users. These applications are becoming
increasingly popular (e.g., Waze reported 30 million users in 2013) since they
aggregate real-time road traffic updates from actual users traveling on the
roads. However, the providers of these mobile services have access to such
sensitive information as timestamped locations and movements of its users. In
this paper, we describe Haze, a protocol for traffic-update applications that
supports the creation of traffic statistics from user reports while protecting
the privacy of the users. Haze relies on a small subset of users to jointly
aggregate encrypted speed and alert data and report the result to the service
provider. We use jury-voting protocols based on threshold cryptosystem and
differential privacy techniques to hide user data from anyone participating in
the protocol while allowing only aggregate information to be extracted and sent
to the service provider. We show that Haze is effective in practice by
developing a prototype implementation and performing experiments on a
real-world dataset of car trajectories."
"The increasingly rapid use of mobile devices for data transaction around the
world has consequently led to a new problem, and that is, how to engage in
mobile data transactions while maintaining an acceptable level of data privacy
and security. While most mobile devices engage in data transactions through a
data cloud or a set of data servers, it is still possible to apply data
confidentiality across data servers, and, as such, preserving privacy in any
mobile data transaction. Yet still, it is essential that a review of data
privacy, data utility, the techniques, and methodologies employed in the data
privacy process, is done, as the underlying data privacy principles remain the
same. In this paper, as a contribution, we present a review of data privacy
essentials that are fundamental in delivering any appropriate analysis and
specific methodology implementation for various data privacy needs in mobile
data transactions and computation."
"The internet is increasingly becoming a standard for both the production and
consumption of data while at the same time cyber-crime involving the theft of
private data is growing. Therefore in efforts to securely transact in data,
privacy and security concerns must be taken into account to ensure that the
confidentiality of individuals and entities involved is not compromised, and
that the data published is compliant to privacy laws. In this paper, we take a
look at noise addition as one of the data privacy providing techniques. Our
endeavor in this overview is to give a foundational perspective on noise
addition data privacy techniques, provide statistical consideration for noise
addition techniques and look at the current state of the art in the field,
while outlining future areas of research."
"Telecare medicine information systems (TMIS) present the platform to deliver
clinical service door to door. The technological advances in mobile computing
are enhancing the quality of healthcare and a user can access these services
using its mobile device. Existing authentication schemes for TMIS are either
vulnerable to attacks or they have higher computational cost. We propose a
biometric based efficient authentication scheme for TMIS which only requires
the computation of the hash and XOR functions."
"Remote user authentication is desirable for a Telecare medicine information
system (TMIS) to verify the correctness of remote users and server over the
insecure channel. We propose an authentication scheme for TMIS."
"Remote user authentication is desirable for a Telecare medicine information
system (TMIS) to verify the correctness of remote users. In 2013, Jiang et al.
proposed privacy preserving authentication scheme for TMIS. Recently, Wu and Xu
analyzed Jiang's scheme and identify serious security flaws in their scheme,
namely, user impersonation attack, DoS attack and off-line password guessing
attack. In this article, we analyze Wu and Xu's scheme and show that their
scheme is also vulnerable to off-line password guessing attack and does not
protect user anonymity. Moreover, we identify the inefficiency of incorrect
input detection of the login phase in Wu and Xu's scheme, where the smart card
executes the login session in-spite of wrong input."
"The MIS data is critical to an organization and should be protected from
misuse by wrong persons. Although The MIS data is typically meant for the
senior managers each MIS report may not be required by every manager. The
access to MIS data is determined by the role of an individual in the
organization and controlled by the MIS administrator accordingly. The access is
generally determined by the following parameters, (a) the type of user (such as
staff or manager etc.), (b) the type of data (whether general data or
managerial data), (c) level of access (read/ write/ admin access) and (d)
special access allocated by MIS admin. By combining all the above four
parameters, each individual user can be allocated exact specific rights
required to access the MIS."
"Security has become, nowadays, a major concern for the organizations as the
majority of its applications are exposed to Internet, which increases the
threats of security considerably. Thus, the solution is to improve tools and
mechanisms to strengthen the protection of applications against attacks and
ensure the different security objectives. Among solutions we will talking
about, in this paper, there is Mutation Analysis which is a technique of test
that evaluates the quality of software tests and their ability to detect
errors, It also compares the criteria and test generation strategies. In this
study we will use the Mutation Analysis as a mean to qualify the penetration
tests, and then, apply this technique in the security mechanisms and exactly on
the mechanisms of access control. At the end we will propose a method for the
elimination of hidden mechanisms for access control that will allow the access
control policy to evolve."
"In this paper, we explore new area/throughput trade- offs for the Girault,
Poupard and Stern authentication protocol (GPS). This authentication protocol
was selected in the NESSIE competition and is even part of the standard ISO/IEC
9798. The originality of our work comes from the fact that we exploit a fixed
key to increase the throughput. It leads us to implement GPS using the Chapman
constant multiplier. This parallel implementation is 40 times faster but 10
times bigger than the reference serial one. We propose to serialize this
multiplier to reduce its area at the cost of lower throughput. Our hybrid
Chapman's multiplier is 8 times faster but only twice bigger than the
reference. Results presented here allow designers to adapt the performance of
GPS authentication to their hardware resources. The complete GPS prover side is
also integrated in the network stack of the PowWow sensor which contains an
Actel IGLOO AGL250 FPGA as a proof of concept."
"While a number of data privacy techniques have been proposed in the recent
years, a few frameworks have been suggested for the implementation of the data
privacy process. Most of the proposed approaches are tailored towards
implementing a specific data privacy algorithm but not the overall data privacy
engineering and design process. Therefore, as a contribution, this study
proposes SIED (Specification, Implementation, Evaluation, and Dissemination), a
conceptual framework that takes a holistic approach to the data privacy
engineering procedure by looking at the specifications, implementation,
evaluation, and finally, dissemination of the privatized data sets."
"The security of any cryptosystem relies on the secrecy of the system's secret
keys. Yet, recent experimental work demonstrates that tens of thousands of
devices on the Internet use RSA and DSA secrets drawn from a small pool of
candidate values. As a result, an adversary can derive the device's secret keys
without breaking the underlying cryptosystem. We introduce a new threat model,
under which there is a systemic solution to such randomness flaws. In our
model, when a device generates a cryptographic key, it incorporates some random
values from an entropy authority into its cryptographic secrets and then proves
to the authority, using zero-knowledge-proof techniques, that it performed this
operation correctly. By presenting an entropy-authority-signed public-key
certificate to a third party (like a certificate authority or SSH client), the
device can demonstrate that its public key incorporates randomness from the
authority and is therefore drawn from a large pool of candidate values. Where
possible, our protocol protects against eavesdroppers, entropy authority
misbehavior, and devices attempting to discredit the entropy authority. To
demonstrate the practicality of our protocol, we have implemented and evaluated
its performance on a commodity wireless home router. When running on a home
router, our protocol incurs a 2.1x slowdown over conventional RSA key
generation and it incurs a 4.4x slowdown over conventional EC-DSA key
generation."
"Today people increasingly have the opportunity to opt-in to ""usage-based""
automotive insurance programs for reducing insurance premiums. In these
programs, participants install devices in their vehicles that monitor their
driving behavior, which raises some privacy concerns. Some devices collect
fine-grained speed data to monitor driving habits. Companies that use these
devices claim that their approach is privacy-preserving because speedometer
measurements do not have physical locations. However, we show that with
knowledge of the user's home location, as the insurance companies have, speed
data is sufficient to discover driving routes and destinations when trip data
is collected over a period of weeks. To demonstrate the real-world
applicability of our approach we applied our algorithm, elastic pathing, to
data collected over hundreds of driving trips occurring over several months.
With this data and our approach, we were able to predict trip destinations to
within 250 meters of ground truth in 10% of the traces and within 500 meters in
20% of the traces. This result, combined with the amount of speed data that is
being collected by insurance companies, constitutes a substantial breach of
privacy because a person's regular driving pattern can be deduced with repeated
examples of the same paths with just a few weeks of monitoring."
"In this paper we show that the existence of general indistinguishability
obfuscators conjectured in a few recent works implies, somewhat
counterintuitively, strong impossibility results for virtual black box
obfuscation. In particular, we show that indistinguishability obfuscation for
all circuits implies:
  * The impossibility of average-case virtual black box obfuscation with
auxiliary input for any circuit family with super-polynomial pseudo-entropy.
Such circuit families include all pseudo-random function families, and all
families of encryption algorithms and randomized digital signatures that
generate their required coin flips pseudo-randomly. Impossibility holds even
when the auxiliary input depends only on the public circuit family, and not the
specific circuit in the family being obfuscated.
  * The impossibility of average-case virtual black box obfuscation with a
universal simulator (with or without any auxiliary input) for any circuit
family with super-polynomial pseudo-entropy.
  These bounds significantly strengthen the impossibility results of Goldwasser
and Kalai (STOC 2005)."
"In this paper we present a novel approach for anonymizing Online Social
Network graphs which can be used in conjunction with existing perturbation
approaches such as clustering and modification. The main insight of this paper
is that by imposing additional constraints on which nodes can be selected we
can reduce the information loss with respect to key structural metrics, while
maintaining an acceptable risk. We present and evaluate two constraints,
'local1' and 'local2' which select the most similar subgraphs within the same
community while excluding some key structural nodes. To this end, we introduce
a novel distance metric based on local subgraph characteristics and which is
calibrated using an isomorphism matcher. Empirical testing is conducted with
three real OSN datasets, six information loss measures, five adversary queries
as risk measures, and different levels of k-anonymity. The results show that
overall, the methods with constraints give the best results for information
loss and risk of disclosure."
"In this paper it has been developed an algorithm for cryptography, using the
Mellin's transform. Cryptography is very important to protect data to ensure
that two people, using an insecure channel, may communicate in a secure way. In
the present age, ensure the communications will essential to shared data that
have to be protected. The original message is a plain text, and the encrypted
form as cipher text. The cipher text message contains all the information of
the plain text, but is cannot be read from a human without a key and a method
to decrypt it."
"The rapid development of Internet of Things (IoT) technology, which is an
inter connection of networks through an insecure public channel i.e. Internet
demands for authenticating the remote user trying to access the secure network
resources. In 2013, Ankita et al. proposed an improved three factor remote user
authentication scheme. In this poster we will show that Ankita et al scheme is
vulnerable to known session specific temporary information attack, on
successfully performing the attack, the adversary can perform all other major
cryptographic attacks. As a part of our contribution, we will propose an
improved scheme which is resistance to all major cryptographic attacks and
overcomes the defects in Ankita et al. scheme."
"In this paper we present the experimental results that more clearly than any
theory suggest an answer to the question: when in detection of large (probably)
prime numbers to apply, a very resource demanding, Miller-Rabin algorithm. Or,
to put it another way, when the dividing by first several tens of prime numbers
should be replaced by primality testing? As an innovation, the procedure above
will be supplemented by considering the use of the well-known Goldbach's
conjecture in the solving of this and some other important questions about the
RSA cryptosystem, always guided by the motto ""do not harm"" - neither the
security nor the time spent."
"Real time operation of the power grid and synchronism of its different
elements require accurate estimation of its state variables. Errors in state
estimation will lead to sub-optimal Optimal Power Flow (OPF) solutions and
subsequent increase in the price of electricity in the market or, potentially
overload and create line outages. This paper studies hidden data attacks on
power systems by an adversary trying to manipulate state estimators. The
adversary gains control of a few meters, and is able to introduce spurious
measurements in them. The paper presents a polynomial time algorithm using
min-cut calculations to determine the minimum number of measurements an
adversary needs to manipulate in order to perform a hidden attack. Greedy
techniques are presented to aid the system operator in identifying critical
measurements for protection to prevent such hidden data attacks. Secure PMU
placement against data attacks is also discussed and an algorithm for placing
PMUs for this purpose is developed. The performances of the proposed algorithms
are shown through simulations on IEEE test cases."
"NIST SP800-22 (2010) proposes the state of art testing suite for (pseudo)
random generators to detect deviations of a binary sequence from randomness. On
the one hand, as a counter example to NIST SP800-22 test suite, it is easy to
construct functions that are considered as GOOD pseudorandom generators by NIST
SP800-22 test suite though the output of these functions are easily
distinguishable from the uniform distribution. Thus these functions are not
pseudorandom generators by definition. On the other hand, NIST SP800-22 does
not cover some of the important laws for randomness. Two fundamental limit
theorems about random binary strings are the central limit theorem and the law
of the iterated logarithm (LIL). Several frequency related tests in NIST
SP800-22 cover the central limit theorem while no NIST SP800-22 test covers
LIL.
  This paper proposes techniques to address the above challenges that NIST
SP800-22 testing suite faces. Firstly, we propose statistical distance based
testing techniques for (pseudo) random generators to reduce the above mentioned
Type II errors in NIST SP800-22 test suite. Secondly, we propose LIL based
statistical testing techniques, calculate the probabilities, and carry out
experimental tests on widely used pseudorandom generators by generating around
30TB of pseudorandom sequences. The experimental results show that for a sample
size of 1000 sequences (2TB), the statistical distance between the generated
sequences and the uniform distribution is around 0.07 (with $0$ for
statistically indistinguishable and $1$ for completely distinguishable) and the
root-mean-square deviation is around 0.005."
"With the many benefits of cloud computing, an entity may want to outsource
its data and their related analytics tasks to a cloud. When data are sensitive,
it is in the interest of the entity to outsource encrypted data to the cloud;
however, this limits the types of operations that can be performed on the cloud
side. Especially, evaluating queries over the encrypted data stored on the
cloud without the entity performing any computation and without ever decrypting
the data become a very challenging problem. In this paper, we propose solutions
to conduct range queries over outsourced encrypted data. The existing methods
leak valuable information to the cloud which can violate the security guarantee
of the underlying encryption schemes. In general, the main security primitive
used to evaluate range queries is secure comparison (SC) of encrypted integers.
However, we observe that the existing SC protocols are not very efficient. To
this end, we first propose a novel SC scheme that takes encrypted integers and
outputs encrypted comparison result. We empirically show its practical
advantage over the current state-of-the-art. We then utilize the proposed SC
scheme to construct two new secure range query protocols. Our protocols protect
data confidentiality, privacy of user's query, and also preserve the semantic
security of the encrypted data; therefore, they are more secure than the
existing protocols. Furthermore, our second protocol is lightweight at the user
end, and it can allow an authorized user to use any device with limited storage
and computing capability to perform the range queries over outsourced encrypted
data."
"Smart grid security is crucial to maintain stable and reliable power system
operation during the contingency situation due to the failure of any critical
power system component. Ensuring a secured smart grid involves with a less
possibility of power grid collapse or equipment malfunction. Due to lack of the
proper security measures, a major blackout may occur which can even lead to a
cascading failure. Therefore, to protect this critical power system
infrastructure and to ensure a reliable and an uninterrupted power supply to
the end users, smart grid security issues must be addressed with high priority.
In a smart grid environment, electric power infrastructure is modernized by
incorporating the current and future requirements and advanced functionalities
to its consumers. To make the smart grid happen, cyber system is integrated
with the physical power system. Although adoption of cyber system has made the
grid more energy efficient and modernized, it has introduced cyber-attack
issues which are critical for national infrastructure security and customer
satisfaction. Due to the cyber-attack, power grid may face operational failures
and loss of synchronization. This operational failure may damage critical power
system components which may interrupt the power supply and make the system
unstable resulting high financial penalties. In this chapter, some recent cyber
attack related incidents into a smart grid environment are discussed. The
requirements and the state of the art of cyber security issues of a critical
power system infrastructure are illustrated elaborately."
"The Web Bulletin Board (WBB) is a key component of verifiable election
systems. It is used in the context of election verification to publish evidence
of voting and tallying that voters and officials can check, and where
challenges can be launched in the event of malfeasance. In practice, the
election authority has responsibility for implementing the web bulletin board
correctly and reliably, and will wish to ensure that it behaves correctly even
in the presence of failures and attacks. To ensure robustness, an
implementation will typically use a number of peers to be able to provide a
correct service even when some peers go down or behave dishonestly. In this
paper we propose a new protocol to implement such a Web Bulletin Board,
motivated by the needs of the vVote verifiable voting system. Using a
distributed algorithm increases the complexity of the protocol and requires
careful reasoning in order to establish correctness. Here we use the Event-B
modelling and refinement approach to establish correctness of the peered design
against an idealised specification of the bulletin board behaviour. In
particular we show that for n peers, a threshold of t > 2n/3 peers behaving
correctly is sufficient to ensure correct behaviour of the bulletin board
distributed design. The algorithm also behaves correctly even if honest or
dishonest peers temporarily drop out of the protocol and then return. The
verification approach also establishes that the protocols used within the
bulletin board do not interfere with each other. This is the first time a
peered web bulletin board suite of protocols has been formally verified."
"Identity federations operating in a business or consumer context need to
prevent the collection of user data across trust service providers for legal
and business case reasons. Legal reasons are given by data protection
legislation. Other reasons include business owners becoming increasingly aware
of confidentiality risks that go beyond traditional information security, e.g.,
the numbers of authentications to an EDI service might provide insights into
the volume of invoices, from which one could derive insider information. This
paper proposes extended technical controls supporting three privacy
requirements: a) Limit d Linkability: Two service providers cannot link data
related to a user without the help of a third party, using neither an
identifier nor other identifying attributes like email addresses or payment
data; b) Limited Observability: An identity provider cannot trace which
services a user is using without the help of a third party; c) Non-Disclosure:
Attributes provided to the service provider by an attribute provider are not
disclosed to the identity provider or an intermediate service broker. Using a
hub-and-spoke federation style following the privacy-by-design principle, this
reference architecture addresses the privacy controls mentioned above."
"Advancement in communication technology provides a scalable platform for
various services where a remote user can access the server from anywhere
without moving from its place. It has provided a unique opportunity for online
services, such that the user need not physically present at the service center.
These services adopt authentication and key agreement protocols to ensure
authorized and secure access to resources. Most of the authentication schemes
support single server environment where the user has to register with each
server. If a user wishes to access multiple application servers, he requires to
register with each of the servers. Although multi-server authentication schemes
introduced a scalable platform such that a user can interact with any server
using single registration. Recently, Chuang and Chen proposed an efficient
multi-server authenticated key agreement scheme based on smart cards along with
password and biometrics. This is a lightweight authentication scheme which
requires the computation of only hash function. In this article, we present a
brief review of Chuang and Chen's scheme. We analyze Chuang and Chen's scheme
and identify that their scheme does not resist stolen smart card attack which
causes the user's impersonation attack, server spoofing attack and man-in-the
middle attack. Additionally, we show that their scheme has a weak key agreement
protocol, which does not ensure forward secrecy."
"Several hundred Tor exit relays together push more than 1 GiB/s of network
traffic. However, it is easy for exit relays to snoop and tamper with
anonymised network traffic and as all relays are run by independent volunteers,
not all of them are innocuous.
  In this paper, we seek to expose malicious exit relays and document their
actions. First, we monitored the Tor network after developing a fast and
modular exit relay scanner. We implemented several scanning modules for
detecting common attacks and used them to probe all exit relays over a period
of four months. We discovered numerous malicious exit relays engaging in
different attacks. To reduce the attack surface users are exposed to, we
further discuss the design and implementation of a browser extension patch
which fetches and compares suspicious X.509 certificates over independent Tor
circuits.
  Our work makes it possible to continuously monitor Tor exit relays. We are
able to detect and thwart many man-in-the-middle attacks which makes the
network safer for its users. All our code is available under a free license."
"In this work is proposed a method using orthogonal matrix transform
properties to encrypt and decrypt a message. It will be showed how to use
matrix functions to create complex encryptions. Because orthogonal matrix are
always diagonalizable on R, and the exponential of a diagonal matrix is easy to
compute, the exponential of orthogonal matrix will be used to encrypt text
messages."
"In modern cryptography, the secret sharing scheme is an important
cryptographic primitive and it is used in various situations. In this paper, a
timed-release secret sharing scheme (TR-SS) with information-theoretic security
is first studied. TR-SS is a secret sharing scheme with the property that
participants more than a threshold number can reconstruct a secret by using
their shares only when the time specified by a dealer has come. Specifically,
in this paper we first introduce a model and formalization of security for
TR-SS based on the traditional secret sharing scheme and information-theoretic
timed-release security. We also derive tight lower bounds on the sizes of
shares, time-signals, and entities' secret-keys required for TR-SS. In
addition, we propose a direct construction for TR-SS. Our direct construction
is optimal in the sense that the construction meets equality in each of our
bounds. As a result, it is shown that the timed-release security can be
realized without any additional redundancy on the share-size."
"Website fingerprinting attacks enable an adversary to infer which website a
victim is visiting, even if the victim uses an encrypting proxy, such as Tor.
Previous work has shown that all proposed defenses against website
fingerprinting attacks are ineffective.
  This paper advances the study of website fingerprinting attacks and defenses
in two ways. First, we develop bounds on the trade-off between security and
bandwidth overhead that any fingerprinting defense scheme can achieve. This
enables us to compare schemes with different security/overhead trade-offs by
comparing how close they are to the lower bound. We then refine, implement, and
evaluate the Congestion Sensitive BuFLO scheme outlined by Cai, et al.
CS-BuFLO, which is based on the provably-secure BuFLO defense proposed by Dyer,
et al., was not fully-specified by Cai, et al, but has nonetheless attracted
the attention of the Tor developers. Our experiments find that CS-BuFLO has
high overhead (around 2.3-2.8x) but can get 6x closer to the bandwidth/security
trade-off lower bound than Tor or plain SSH."
"The propagation techniques and the payload of Duqu have been closely studied
over the past year and it has been said that Duqu shared functionalities with
Stuxnet. We focused on the driver used by Duqu during the infection, our
contribution consists in reverse-engineering the driver: we rebuilt its source
code and analyzed the mechanisms it uses to execute the payload while avoiding
detection. Then we diverted the driver into a defensive version capable of
detecting injections in Windows binaries, thus preventing further attacks. We
specifically show how Duqu's modified driver would have detected Duqu."
"In 2013, Tsai et al. cryptanalyzed Yeh et al. scheme and shown that Yeh et
al., scheme is vulnerable to various cryptographic attacks and proposed an
improved scheme. In this poster we will show that Tsai et al., scheme is also
vulnerable to undetectable online password guessing attack, on success of the
attack, the adversary can perform all major cryptographic attacks. As apart of
our contribution, we have proposed an improved scheme which overcomes the
defects in Tsai et al. and Yeh et al. schemes."
"Distributed Denial of Service (DDoS) attacks exhaust victim's bandwidth or
services. Traditional architecture of Internet is vulnerable to DDoS attacks
and an ongoing cycle of attack & defense is observed. In this paper, different
types and techniques of DDoS attacks and their countermeasures are reviewed.
The significance of this paper is the coverage of many aspects of countering
DDoS attacks including new research on the topic. We survey different papers
describing methods of defense against DDoS attacks based on entropy variations,
traffic anomaly parameters, neural networks, device level defense, botnet flux
identifications and application layer DDoS defense. We also discuss some
traditional methods of defense such as traceback and packet filtering
techniques so that readers can identify major differences between traditional
and current techniques of defense against DDoS attacks. Before the discussion
on countermeasures, we mention different attack types under DDoS with
traditional and advanced schemes while some information on DDoS trends in the
year 2012 Quarter-1 is also provided. We identify that application layer DDoS
attacks possess the ability to produce greater impact on the victim as they are
driven by legitimate-like traffic making it quite difficult to identify and
distinguish from legitimate requests. The need of improved defense against such
attacks is therefore more demanding in research. The study conducted in this
paper can be helpful for readers and researchers to recognize better techniques
of defense in current times against DDoS attacks and contribute with more
research on the topic in the light of future challenges identified in this
paper."
"Police SWAT teams and Military Special Forces face mounting pressure and
challenges from adversaries that can only be resolved by way of ever more
sophisticated inputs into tactical operations. Lethal Autonomy provides
constrained military/security forces with a viable option, but only if
implementation has got proper empirically supported foundations. Autonomous
weapon systems can be designed and developed to conduct ground, air and naval
operations. This monograph offers some insights into the challenges of
developing legal, reliable and ethical forms of autonomous weapons, that
address the gap between Police or Law Enforcement and Military operations that
is growing exponentially small. National adversaries are today in many
instances hybrid threats, that manifest criminal and military traits, these
often require deployment of hybrid-capability autonomous weapons imbued with
the capability to taken on both Military and/or Security objectives. The
Westgate Terrorist Attack of 21st September 2013 in the Westlands suburb of
Nairobi, Kenya is a very clear manifestation of the hybrid combat scenario that
required military response and police investigations against a fighting cell of
the Somalia based globally networked Al Shabaab terrorist group."
"Mobile devices implementing Android operating systems inherently create
opportunities to present environments that are conducive to anti-forensic
activities. Previous mobile forensics research focused on applications and data
hiding anti-forensics solutions. In this work, a set of modifications were
developed and implemented on a CyanogenMod community distribution of the
Android operating system. The execution of these solutions successfully
prevented data extractions, blocked the installation of forensic tools, created
extraction delays and presented false data to industry accepted forensic
analysis tools without impacting normal use of the device. The research
contribution is an initial empirical analysis of the viability of operating
system modifications in an anti-forensics context along with providing the
foundation for future research."
"We propose a general approach to construct cryptographic significant Boolean
functions of $(r+1)m$ variables based on the additive decomposition
$\mathbb{F}_{2^{rm}}\times\mathbb{F}_{2^m}$ of the finite field
$\mathbb{F}_{2^{(r+1)m}}$, where $r$ is odd and $m\geq3$. A class of unbalanced
functions are constructed first via this approach, which coincides with a
variant of the unbalanced class of generalized Tu-Deng functions in the case
$r=1$. This class of functions have high algebraic degree, but their algebraic
immunity does not exceeds $m$, which is impossible to be optimal when $r>1$. By
modifying these unbalanced functions, we obtain a class of balanced functions
which have optimal algebraic degree and high nonlinearity (shown by a lower
bound we prove). These functions have optimal algebraic immunity provided a
combinatorial conjecture on binary strings which generalizes the Tu-Deng
conjecture is true. Computer investigations show that, at least for small
values of number of variables, functions from this class also behave well
against fast algebraic attacks."
"This paper presents an overview of the use of elliptic curves in
cryptography. The security of this cryptosystem is based on the discrete
logarithm problem, which appears to be much harder compared to the discrete
logarithm problem in other cryptosystems. An overview of common cryptosystems
is given, such as Diffie-Hellman and RSA, and an elliptic curve cryptography
scheme is discussed.
  --------
  Este trabalho apresenta o uso das curvas el\'ipticas em criptografia. Sua
seguran\c{c}a est\'a baseada no problema do logaritmo discreto. Este problema
aparentemente \'e significativamente mais dif\'icil de resolver, comparado com
o problema do logaritmo discreto usado por outros sistemas de criptografia. \'E
dada uma vis\~ao geral de sistemas de criptografia comuns, como Diffie-Hellman
e RSA, e discute-se um esquema de criptografia usando curvas el\'ipticas."
"As mobile phones have evolved into `smartphones', with complex operating
systems running third- party software, they have become increasingly vulnerable
to malicious applications (malware). We introduce a new design for mitigating
malware attacks against smartphone users, based on a small trusted computing
base module, denoted uTCB. The uTCB manages sensitive data and sensors, and
provides core services to applications, independently of the operating system.
The user invokes uTCB using a simple secure attention key, which is pressed in
order to validate physical possession of the device and authorize a sensitive
action; this protects private information even if the device is infected with
malware. We present a proof-of-concept implementation of uTCB based on ARM's
TrustZone, a secure execution environment increasingly found in smartphones,
and evaluate our implementation using simulations."
"SAML assertions are becoming popular method for passing authentication and
authorisation information between identity providers and consumers using
various single sign-on protocols. However their practical security strongly
depends on correct implementation, especially on the consumer side. Somorovsky
and others have demonstrated a number of XML signature related vulnerabilities
in SAML assertion validation frameworks. This article demonstrates how bad
library documentation and examples can lead to vulnerable consumer code and how
this can be avoided."
"The rapid developments of mobile devices and online social networks have
resulted in increasing attention to Mobile Social Networking (MSN). The
explosive growth of mobile-connected and location-aware devices makes it
possible and meaningful to do the Proximity-based Mobile Social Networks
(PMSNs). Users can discover and make new social interactions easily with
physical-proximate mobile users through WiFi/Bluetooth interfaces embedded in
their smartphones. However, users enjoy these conveniences at the cost of their
growing privacy concerns. To address this problem, we propose a suit of
priority-aware private matching schemes to privately match the similarity with
potential friends in the vicinity. Unlike most existing work, our proposed
priority-aware matching scheme (P-match) achieves the privacy goal by combining
the commutative encryption function and the Tanimoto similarity coefficient
which considers both the number of common attributes between users as well as
the corresponding priorities on each common attribute. Further, based on the
newly constructed similarity function which takes the ratio of attributes
matched over all the input set into consideration, we design an enhanced
version to deal with some potential attacks such as unlimitedly inputting the
attribute set on either the initiator side or the responder side, etc. Finally,
our proposed E-match avoids the heavy cryptographic operations and improves the
system performance significantly by employing a novel use of the Bloom filter.
The security and communication/computation overhead of our schemes are
thoroughly analyzed and evaluated via detailed simulations and implementation."
"In this article, we describe a methodology that aims at either breaking or
proving the security of CRT-RSA implementations against fault injection
attacks. In the specific case-study of the BellCoRe attack, our work bridges a
gap between formal proofs and implementation-level attacks. We apply our
results to three implementations of CRT-RSA, namely the unprotected one, that
of Shamir, and that of Aum\""uller et al. Our findings are that many attacks are
possible on both the unprotected and the Shamir implementations, while the
implementation of Aum\""uller et al. is resistant to all single-fault attacks.
It is also resistant to double-fault attacks if we consider the less powerful
threat-model of its authors."
"In our paper at PROOFS 2013, we formally studied a few known countermeasures
to protect CRT-RSA against the BellCoRe fault injection attack. However, we
left Vigilant's countermeasure and its alleged repaired version by Coron et al.
as future work, because the arithmetical framework of our tool was not
sufficiently powerful. In this paper we bridge this gap and then use the same
methodology to formally study both versions of the countermeasure. We obtain
surprising results, which we believe demonstrate the importance of formal
analysis in the field of implementation security. Indeed, the original version
of Vigilant's countermeasure is actually broken, but not as much as Coron et
al. thought it was. As a consequence, the repaired version they proposed can be
simplified. It can actually be simplified even further as two of the nine
modular verifications happen to be unnecessary. Fortunately, we could formally
prove the simplified repaired version to be resistant to the BellCoRe attack,
which was considered a ""challenging issue"" by the authors of the countermeasure
themselves."
"Active cyber defenses based on temporal platform diversity have been proposed
as way to make systems more resistant to attacks. These defenses change the
properties of the platforms in order to make attacks more complicated.
Unfortunately, little work has been done on measuring the effectiveness of
these defenses. In this work, we use four different approaches to
quantitatively analyze these defenses; an abstract analysis studies the
algebraic models of a temporal platform diversity system; a set of experiments
on a test bed measures the metrics of interest for the system; a game theoretic
analysis studies the impact of preferential selection of platforms and derives
an optimal strategy; finally, a set of simulations evaluates the metrics of
interest on the models. Our results from these approaches all agree and yet are
counter-intuitive. We show that although platform diversity can mitigate some
attacks, it can be detrimental for others. We also illustrate that the benefit
from these systems heavily depends on their threat model and that the
preferential selection of platforms can achieve better protection."
This paper has been withdrawn
This paper has been withdrawn
This paper has been withdrawn
"Private handshaking allows pairs of users to determine which (secret) groups
they are both a member of. Group membership is kept secret to everybody else.
Private handshaking is a more private form of secret handshaking, because it
does not allow the group administrator to trace users. We extend the original
definition of a handshaking protocol to allow and test for membership of
multiple groups simultaneously. We present simple and efficient protocols for
both the single group and multiple group membership case.
  Private handshaking is a useful tool for mutual authentication, demanded by
many pervasive applications (including RFID) for privacy. Our implementations
are efficient enough to support such usually resource constrained scenarios."
"We introduce a problem setting which we call ``the freedom fighters'
problem''. It subtly differs from the prisoners' problem. We propose a
steganographic method that allows Alice and Bob to fool Wendy the warden in
this setting. Their messages are hidden in encryption keys. The recipient has
no prior knowledge of these keys, and has to cryptanalyze ciphertexts in order
to recover them. We show an example of the protocol and give a partial security
analysis."
"Recent emergence of electronic culture uplifts healthcare facilities to a new
era with the aid of wireless sensor network (WSN) technology. Due to the
sensitiveness of medical data, austere privacy and security are inevitable for
all parts of healthcare systems. However, the constantly evolving nature and
constrained resources of sensors in WSN inflict unavailability of a lucid line
of defense to ensure perfect security. In order to provide holistic security,
protections must be incorporated in every component of healthcare sensor
networks. This paper proposes an efficient security scheme for healthcare
applications of WSN which uses the notion of public key cryptosystem. Our
entire security scheme comprises basically of two parts; a key handshaking
scheme based on simple linear operations and the derivation of decryption key
by a receiver node for a particular sender in the network. Our architecture
allows both base station to node or node to base station secure communications,
and node-to-node secure communications. We consider both the issues of
stringent security and network performance to propose our security scheme."
"In 2005, Yang, Wang, and Chang proposed an improved timestamp-based password
authentication scheme in an attempt to overcome the flaws of Yang-Shieh_s
legendary timestamp-based remote authentication scheme using smart cards. After
analyzing the improved scheme proposed by Yang-Wang-Chang, we have found that
their scheme is still insecure and vulnerable to four types of forgery attacks.
Hence, in this paper, we prove that, their claim that their scheme is
intractable is incorrect. Also, we show that even an attack based on Sun et
al._s attack could be launched against their scheme which they claimed to
resolve with their proposal."
"Let p be a prime and a, c be integers such that a<>0 mod p. The quadratic
generator is a sequence (u_n) of pseudorandom numbers defined by
u_{n+1}=a*(u_n)^2+c mod p. In this article we probe that if we know
sufficiently many of the most significant bits of two consecutive values u_n,
u_{n+1}, then we can compute the seed u_0 except for a small number of
exceptional values.
  -----
  Sean p un primo, a y c enteros tales que a<>0 mod p. El generador cuadratico
es una sucesion (u_n) de numeros pseudoaleatorios definidos por la relacion
u_{n+1}=a*(u_n)^2+c mod p. En este trabajo demostramos que si conocemos un
numero suficientemente grande de los bits mas significativos para dos valores
consecutivos u_n, u_{n+1}, entonces podemos descubrir en tiempo polinomial la
semilla u_0, excepto para un conjunto pequeno de valores excepcionales."
"In this note we propose an encryption communication protocol which also
provides database security. For the encryption of the data communication we use
a transformation similar to the Cubic Public-key transformation. This method
represents a many-to-one mapping which increases the complexity for any brute
force attack. Some interesting properties of the transformation are also
included which are basic in the authentication protocol."
"Internet voting will probably be one of the most significant achievements of
the future information society. It will have an enormous impact on the election
process making it fast, reliable and inexpensive. Nonetheless, so far remote
voting is considered to be very difficult, as one has to take into account
susceptibility of the voter's PC to various cyber-attacks. As a result, most
the research effort is put into developing protocols and machines for poll-site
electronic voting. Although these solutions yield promising results, they
cannot be directly adopted to Internet voting because of secure platform
problem. However, the cryptographic components they utilize may be very useful.
This paper presents a scheme based on combination of mixnets and homomorphic
encryption borrowed from robust poll-site voting, along with techniques
recommended for remote voting -- code sheets and test ballots. The protocol
tries to minimize the trust put in voter's PC by making the voter responsible
for manual encryption of his vote. To achieve this, the voter obtains a paper
ballot that allows him to scramble the vote by performing simple operations
(lookup in a table). Creation of paper ballots, as well as decryption of votes,
is performed by a group of cooperating trusted servers. As a result, the scheme
is characterized by strong asymmetry -- all computations are carried out on the
server side. In consequence it does not require any additional hardware on the
voter's side, and offers distributed trust, receipt-freeness and verifiability."
"Recently, Rawat and Saxena proposed a method for protecting data using
``Disclaimer Statement''. This paper presents some issues and several flaws in
their proposal."
"In this paper, we will propose a new synchronous stream cipher named DICING,
which can be viewed as a clock-controlled one but with a new mechanism of
altering steps. It has satisfactory performance and there have not been found
weakness for the known attacks, the key sizes can be 128bits and 256bits
respectively."
"In this paper we will discuss the design of abstract firewall model along
with platform-independent policy definition language. We will also discuss the
main design challenges and solutions to these challenges, as well as examine
several differences in policy semantics between vendors and how it could be
mapped to our platform-independent language. We will also touch upon a
processing model, describing the mechanism by which an abstract policy could be
compiled into a concrete firewall policy syntax. We will discuss briefly some
future research directions, such as policy optimization and validation"
"In this paper, we will propose a new type of cipher named DICING_csb, which
is derived from our previous stream cipher DICING. It has applied a stream of
subkey and an encryption form of block ciphers, so it may be viewed as a
combinative of stream cipher and block cipher. Hence, the new type of cipher
has fast rate like a stream cipher and need no MAC."
"We study the relationship between obfuscation and white-box cryptography. We
capture the requirements of any white-box primitive using a \emph{White-Box
Property (WBP)} and give some negative/positive results. Loosely speaking, the
WBP is defined for some scheme and a security notion (we call the pair a
\emph{specification}), and implies that w.r.t. the specification, an
obfuscation does not leak any ``useful'' information, even though it may leak
some ``useless'' non-black-box information.
  Our main result is a negative one - for most interesting programs, an
obfuscation (under \emph{any} definition) cannot satisfy the WBP for every
specification in which the program may be present. To do this, we define a
\emph{Universal White-Box Property (UWBP)}, which if satisfied, would imply
that under \emph{whatever} specification we conceive, the WBP is satisfied. We
then show that for every non-approximately-learnable family, there exist
(contrived) specifications for which the WBP (and thus, the UWBP) fails.
  On the positive side, we show that there exists an obfuscator for a
non-approximately-learnable family that achieves the WBP for a certain
specification. Furthermore, there exists an obfuscator for a non-learnable (but
approximately-learnable) family that achieves the UWBP.
  Our results can also be viewed as formalizing the distinction between
``useful'' and ``useless'' non-black-box information."
"Recently, Liaw et al. proposed a remote user authentication scheme using
smartcards. They claimed a number of features of their scheme, e.g. a
dictionary of verification tables is not required to authenticate users; users
can choose their password freely; mutual authentication is provided between the
user and the remote system; the communication cost and the computational cost
are very low; users can update their password after the registration phase; a
session key agreed by the user and the remote system is generated in every
session; and the nonce-based scheme which does not require a timestamp (to
solve the serious time synchronization problem) etc.
  In this paper We show that Liaw et al.'s scheme does not stand with various
security requirements and is completely insecure.
  Keywords: Authentication, Smartcards, Remote system, Attack."
"The paper concerns performance analysis of a steganographic method, dedicated
primarily for VoIP, which was recently filed for patenting under the name LACK.
The performance of the method depends on the procedure of inserting covert data
into the stream of audio packets. After a brief presentation of the LACK
method, the paper focuses on analysis of the dependence of the insertion
procedure on the probability distribution of VoIP call duration."
"Proxy signature schemes have been invented to delegate signing rights. The
paper proposes a new concept of Identify Based Strong Bi-Designated Verifier
threshold proxy signature (ID-SBDVTPS) schemes. Such scheme enables an original
signer to delegate the signature authority to a group of 'n' proxy signers with
the condition that 't' or more proxy signers can cooperatively sign messages on
behalf of the original signer and the signatures can only be verified by any
two designated verifiers and that they cannot convince anyone else of this
fact."
"The dynamic establishment of shared information (e.g. secret key) between two
entities is particularly important in networks with no pre-determined structure
such as wireless sensor networks (and in general wireless mobile ad-hoc
networks). In such networks, nodes establish and terminate communication
sessions dynamically with other nodes which may have never been encountered
before, in order to somehow exchange information which will enable them to
subsequently communicate in a secure manner. In this paper we give and
theoretically analyze a series of protocols that enables two entities that have
never encountered each other before to establish a shared piece of information
for use as a key in setting up a secure communication session with the aid of a
shared key encryption algorithm. These protocols do not require previous
pre-distribution of candidate keys or some other piece of information of
specialized form except a small seed value, from which the two entities can
produce arbitrarily long strings with many similarities."
"We present three voting protocols with unconditional privacy and
information-theoretic correctness, without assuming any bound on the number of
corrupt voters or voting authorities. All protocols have polynomial complexity
and require private channels and a simultaneous broadcast channel. Our first
protocol is a basic voting scheme which allows voters to interact in order to
compute the tally. Privacy of the ballot is unconditional, but any voter can
cause the protocol to fail, in which case information about the tally may
nevertheless transpire. Our second protocol introduces voting authorities which
allow the implementation of the first protocol, while reducing the interaction
and limiting it to be only between voters and authorities and among the
authorities themselves. The simultaneous broadcast is also limited to the
authorities. As long as a single authority is honest, the privacy is
unconditional, however, a single corrupt authority or a single corrupt voter
can cause the protocol to fail. Our final protocol provides a safeguard against
corrupt voters by enabling a verification technique to allow the authorities to
revoke incorrect votes. We also discuss the implementation of a simultaneous
broadcast channel with the use of temporary computational assumptions, yielding
versions of our protocols achieving everlasting security."
"A new 4-pass Key-Agreement Protocol is presented. The security of the
protocol mainly relies on the existence of a (polynomial-computable)
One-Way-Function and the supposed computational hardness of solving a specific
system of equations."
"The role of mathematics in a complex system such as the Internet has yet to
be deeply explored. In this paper, we summarize some of the important and
pressing problems in cyber security from the viewpoint of open science
environments. We start by posing the question ""What fundamental problems exist
within cyber security research that can be helped by advanced mathematics and
statistics?"" Our first and most important assumption is that access to
real-world data is necessary to understand large and complex systems like the
Internet. Our second assumption is that many proposed cyber security solutions
could critically damage both the openness and the productivity of scientific
research. After examining a range of cyber security problems, we come to the
conclusion that the field of cyber security poses a rich set of new and
exciting research opportunities for the mathematical and statistical sciences."
"A new protocol for 1-2 (String) Oblivious Transfer is proposed. The protocol
uses 5 rounds of message exchange."
"This paper presents a new identity based strong designated verifier parallel
multi-proxy signature scheme. Multi-Proxy signatures allow the original signer
to delegate his signing power to a group of proxy signers. In our scheme, the
designated verifier can only validate proxy signatures created by a group of
proxy signer."
"Braids groups provide an alternative to number theoretic public cryptography
and can be implemented quite efficiently. The paper proposes five signature
schemes: Proxy Signature, Designated Verifier, Bi-Designated Verifier,
Designated Verifier Proxy Signature And Bi-Designated Verifier Proxy Signature
scheme based on braid groups. We also discuss the security aspects of each of
the proposed schemes."
"Software obfuscation or obscuring a software is an approach to defeat the
practice of reverse engineering a software for using its functionality
illegally in the development of another software. Java applications are more
amenable to reverse engineering and re-engineering attacks through methods such
as decompilation because Java class files store the program in a semi complied
form called byte codes. The existing obfuscation systems obfuscate the Java
class files. Obfuscated source code produce obfuscated byte codes and hence two
level obfuscation (source code and byte code level) of the program makes it
more resilient to reverse engineering attacks . But source code obfuscation is
much more difficult due to richer set of programming constructs and the scope
of the different variables used in the program and only very little progress
has been made on this front. We in this paper are proposing a framework named
JConstHide for hiding constants, especially integers in the java source codes,
to defeat reverse engineering through decompilation. To the best of our
knowledge, no data hiding software are available for java source code constant
hiding."
"In this paper, we question the common practice of assigning security impact
ratings to OS updates. Specifically, we present evidence that ranking updates
by their perceived security importance, in order to defer applying some
updates, exposes systems to significant risk.
  We argue that OS vendors and security groups should not focus on security
updates to the detriment of other updates, but should instead seek update
technologies that make it feasible to distribute updates for all disclosed OS
bugs in a timely manner."
"A divide-and-conquer cryptanalysis can often be mounted against some
keystream generators composed of several (nonlinear) independent devices
combined by a Boolean function. In particular, any parity-check relation
derived from the periods of some constituent sequences usually leads to a
distinguishing attack whose complexity is determined by the bias of the
relation. However, estimating this bias is a difficult problem since the
piling-up lemma cannot be used. Here, we give two exact expressions for this
bias. Most notably, these expressions lead to a new algorithm for computing the
bias of a parity-check relation, and they also provide some simple formulae for
this bias in some particular cases which are commonly used in cryptography."
"The paper presents a new steganographic method called RSTEG (Retransmission
Steganography), which is intended for a broad class of protocols that utilises
retransmission mechanisms. The main innovation of RSTEG is to not acknowledge a
successfully received packet in order to intentionally invoke retransmission.
The retransmitted packet carries a steganogram instead of user data in the
payload field. RSTEG is presented in the broad context of network
steganography, and the utilisation of RSTEG for TCP (Transport Control
Protocol) retransmission mechanisms is described in detail. Simulation results
are also presented with the main aim to measure and compare the steganographic
bandwidth of the proposed method for different TCP retransmission mechanisms as
well as to determine the influence of RSTEG on the network retransmissions
level."
"We show how to use the RSA one-way accumulator to realize an efficient and
dynamic authenticated dictionary, where untrusted directories provide
cryptographically verifiable answers to membership queries on a set maintained
by a trusted source. Our accumulator-based scheme for authenticated
dictionaries supports efficient incremental updates of the underlying set by
insertions and deletions of elements. Also, the user can optimally verify in
constant time the authenticity of the answer provided by a directory with a
simple and practical algorithm. We have also implemented this scheme and we
give empirical results that can be used to determine the best strategy for
systems implementation with respect to resources that are available. This work
has applications to certificate revocation in public key infrastructure and
end-to-end integrity of data collections published by third parties on the
Internet."
"At present, applications of biometrics are rapidly increasing due to
inconveniences in using traditional passwords and physical keys. Hand geometry,
one of the most well-known biometrics, is implemented in many verification
systems with various feature extraction methods. In recent work, a hand
geometry verification system using time series conversion techniques and
Dynamic Time Warping (DTW) distance measure with Sakoe-Chiba band has been
proposed. This system demonstrates many advantages, especially ease of
implementation and small storage space requirement using time series
representation. In this paper, we propose a novel hand geometry verification
system that exploits DTW distance measure and R-K band learning to further
improve the system performance. Finally, our evaluation reveals that our
proposed system outperforms the current system by a wide margin, in terms of
False Acceptance Rate (FAR), False Rejection Rate (FRR), and Total Success Rate
(TSR) at Equal Error Rate (EER)."
"Wireless Sensor Networks (WSNs) provide sensing and monitoring services by
means of many tiny autonomous devices equipped with wireless radio
transceivers. As WSNs are deployed on a large-scale and/or on long-term basis,
not only traditional security but also privacy issues must be taken into
account. Furthermore, when network operators offer on-demand access to sensor
measurements to their clients, query mechanisms should ideally leak neither
client interests nor query patterns. In this paper, we present a
privacy-preserving WSN query mechanism that uses standard cryptographic
techniques. Besides preventing unauthorized entities from accessing sensor
readings, it minimizes leakage of (potentially sensitive) information about
users' query targets and patterns."
"Nowadays most of the malware applications are either packed or protected.
This techniques are applied especially to evade signature based detectors and
also to complicate the job of reverse engineers or security analysts. The time
one must spend on unpacking or decrypting malware layers is often very long and
in fact remains the most complicated task in the overall process of malware
analysis. In this report author proposes MmmBop as a relatively new concept of
using dynamic binary instrumentation techniques for unpacking and bypassing
detection by self-modifying and highly aggressive packed binary code. MmmBop is
able to deal with most of the known and unknown packing algorithms and it is
also suitable to successfully bypass most of currently used anti-reversing
tricks. This framework does not depend on any other 3rd party software and it
is developed entirely in user mode (ring3). MmmBop supports the IA-32
architecture and it is targeted for Microsoft Windows XP, some of the further
deliberations will be referring directly to this operating system."
"Web applications are becoming truly pervasive in all kinds of business models
and organizations. Today, most critical systems such as those related to health
care, banking, or even emergency response, are relying on these applications.
They must therefore include, in addition to the expected value offered to their
users, reliable mechanisms to ensure their security. In this paper, we focus on
the specific problem of cross-site scripting attacks against web applications.
We present a study of this kind of attacks, and survey current approaches for
their prevention. Applicability and limitations of each proposal are also
discussed."
"The rotation based transformation (RBT) for privacy preserving data mining
(PPDM) is vulnerable to the independent component analysis (ICA) attack. This
paper introduces a modified multiple rotation based transformation (MRBT)
technique for special mining applications mitigating the ICA attack while
maintaining the advantages of the RBT."
"Power analysis attacks against embedded secret key cryptosystems are widely
studied since the seminal paper of Paul Kocher, Joshua Ja, and Benjamin Jun in
1998 where has been introduced the powerful Differential Power Analysis. The
strength of DPA is such that it became necessary to develop sound and efficient
countermeasures. Nowadays embedded cryptographic primitives usually integrate
one or several of these countermeasures (e.g. masking techniques, asynchronous
designs, balanced dynamic dual-rail gates designs, noise adding, power
consumption smoothing, etc. ...). This document presents a simple, yet
interesting, countermeasure to DPA and HO-DPA attacks, called brutal
countermeasure and new power analysis attacks using multi-linear approximations
(MLPA attacks) based on very recent and still unpublished results of Tavernier
et al.."
"Paper addresses the process of dynamic data flow analysis using virtual code
integration (VCI), often refered to as dynamic binary rewriting. This article
will try to demonstrate all of the techniques that were applied in the
SpiderPig project. It will also discuss the main differences between the
methods that were employed and those used in other available software, as well
as introducing other related work. SpiderPig's approach was found to be very
fast and was transparent enough for reliable and usable data flow analysis. It
was created with the purpose of providing a tool which would aid vulnerability
and security researchers with tracing and analyzing any necessary data and its
further propagation through a program. At the current state it works on IA-32
platforms with Microsoft Windows systems and it supports FPU, SSE, MMX and all
of the IA-32 general instructions. SpiderPig also demonstrates the usage of a
virtual code integration (VCI) framework which allows for modifying the target
application code at the instruction level. By this I mean that the VCI
framework allows for custom code insertion, original code modification and full
customization of the original application's code. Instructions can be swapped
out, deleted or modified at a whim, without corrupting the surrounding code and
side-effects of the modification are resolved."
"This paper studies pipelined algorithms for protecting distributed grid
computations from cheating participants, who wish to be rewarded for tasks they
receive but don't perform. We present improved cheater detection algorithms
that utilize natural delays that exist in long-term grid computations. In
particular, we partition the sequence of grid tasks into two interleaved
sequences of task rounds, and we show how to use those rounds to devise the
first general-purpose scheme that can catch all cheaters, even when cheaters
collude. The main idea of this algorithm might at first seem
counter-intuitive--we have the participants check each other's work. A naive
implementation of this approach would, of course, be susceptible to collusion
attacks, but we show that by, adapting efficient solutions to the parallel
processor diagnosis problem, we can tolerate collusions of lazy cheaters, even
if the number of such cheaters is a fraction of the total number of
participants. We also include a simple economic analysis of cheaters in grid
computations and a parameterization of the main deterrent that can be used
against them--the probability of being caught."
"The paper analyzes wormhole attack modes and classes and point to its threat
impacts on ad hoc networks. New improvements are suggested to these types of
attacks."
"Recently more and more attention has been paid to the intrusion detection
systems (IDS) which don't rely on signature based detection approach. Such
solutions try to increase their defense level by using heuristics detection
methods like network-level emulation. This technique allows the intrusion
detection systems to stop unknown threats, which normally couldn't be stopped
by standard signature detection techniques.
  In this article author will describe general concepts of network-level
emulation technique including its advantages and disadvantages (weak sides)
together with providing potential countermeasures against this type of
detection method."
"In this paper, we describe an attack against one of the
Oblivious-Transfer-based blind signatures scheme, proposed in [1]. An attacker
with a primitive capability of producing specific-range random numbers, while
exhibiting a partial MITM behavior, is able to corrupt the communication
between the protocol participants. The attack is quite efficient as it leads to
a protocol communication corruption and has a sound-minimal computational cost.
We propose a solution to fix the security flaw."
"Botnets are networks of compromised computers with malicious code which are
remotely controlled and which are used for starting distributed denial of
service (DDoS) attacks, sending enormous number of e-mails (SPAM) and other
sorts of attacks. Defense against modern Botnets is a real challenge. This
paper offers several strategies for defense against Botnets with a list and
description of measures and activities which should be carried out in order to
establish successful defense. The paper also offers parallel preview of the
strategies with their advantages and disadvantages considered in accordance
with various criteria."
"Traditionally, agent and web service are two separate research areas. We
figure that, through agent communication, agent is suitable to coordinate web
services. However, there exist agent communication problems due to the lack of
uniform, cross-platform vocabulary. Fortunately, ontology defines a vocabulary.
We thus propose a new agent communication layer and present the web ontology
language (OWL)-based operational ontologies that provides a declarative
description. It can be accessed by various engines to facilitate agent
communication. Further, in our operational ontologies, we define the mental
attitudes of agents that can be shared among other agents. Our architecture
enhanced the 3APL agent platform, and it is implemented as an agent
communication framework. Finally, we extended the framework to be compatible
with the web ontology language for service (OWL-S), and then develop a movie
recommendation system with four OWL-S semantic web services on the framework.
The benefits of this work are: 1) dynamic web service coordination, 2)
ontological reasoning through uniform representation, namely, the declarative
description, and 3) easy reuse and extension of both ontology and engine
through extending ontology."
"With the evolution of the Internet, multicast communications seem
particularly well adapted for large scale commercial distribution applications,
for example, the pay TV channels and secure videoconferencing. Key management
for multicast remains an open topic in secure Communications today. Key
management mainly has to do with the distribution and update of keying material
during the group life. Several key tree based approach has been proposed by
various authors to create and distribute the multicast group key in effective
manner. There are different key management algorithms that facilitate efficient
distribution and rekeying of the group key. These protocols normally add
communication overhead as well as computation overhead at the group key
controller and at the group members. This paper explores the various algorithms
along with the performances and derives an improved method."
"Memory corruption attacks remain the primary threat for computer security.
Information flow tracking or taint analysis has been proven to be effective
against most memory corruption attacks. However, there are two shortcomings
with current taint analysis based techniques. First, these techniques cause
application slowdown by about 76% thereby limiting their practicality. Second,
these techniques cannot handle non-control data attacks i.e., attacks that do
not overwrite control data such as return address, but instead overwrite
critical application configuration data or user identity data. In this work, to
address these problems, we describe a coarse-grained taint analysis technique
that uses information flow tracking at the level of application data objects.
We propagate a one-bit taint over each application object that is modified by
untrusted data thereby reducing the taint management overhead considerably. We
performed extensive experimental evaluation of our approach and show that it
can detect all critical attacks such as buffer overflows, and format string
attacks, including non-control data attacks. Unlike the currently known
approaches that can detect such a wide range of attacks, our approach does not
require the source code or any hardware extensions. Run-time performance
overhead evaluation shows that, on an average, our approach causes application
slowdown by only 37% which is an order of magnitude improvement over existing
approaches. Finally, since our approach performs run-time binary
instrumentation, it is easier to integrate it with existing applications and
systems."
"The vast majority of RFID authentication protocols assume the proximity
between readers and tags due to the limited range of the radio channel.
However, in real scenarios an intruder can be located between the prover (tag)
and the verifier (reader) and trick this last one into thinking that the prover
is in close proximity. This attack is generally known as a relay attack in
which scope distance fraud, mafia fraud and terrorist attacks are included.
Distance bounding protocols represent a promising countermeasure to hinder
relay attacks. Several protocols have been proposed during the last years but
vulnerabilities of major or minor relevance have been identified in most of
them. In 2008, Kim et al. [1] proposed a new distance bounding protocol with
the objective of being the best in terms of security, privacy, tag
computational overhead and fault tolerance. In this paper, we analyze this
protocol and we present a passive full disclosure attack, which allows an
adversary to discover the long-term secret key of the tag. The presented attack
is very relevant, since no security objectives are met in Kim et al.'s
protocol. Then, design guidelines are introduced with the aim of facilitating
protocol designers the stimulating task of designing secure and efficient
schemes against relay attacks. Finally a new protocol, named Hitomi and
inspired by [1], is designed conforming the guidelines proposed previously."
"Human memory is not perfect - people constantly memorize new facts and forget
old ones. One example is forgetting a password, a common problem raised at IT
help desks. We present several protocols that allow a user to automatically
recover a password from a server using partial knowledge of the password. These
protocols can be easily adapted to the personal entropy setting, where a user
can recover a password only if he can answer a large enough subset of personal
questions.
  We introduce client-server password recovery methods, in which the recovery
data are stored at the server, and the recovery procedures are integrated into
the login procedures. These methods apply to two of the most common types of
password based authentication systems. The security of these solutions is
significantly better than the security of presently proposed password recovery
schemes. Our protocols are based on a variation of threshold encryption that
may be of independent interest."
"This paper focuses on the design and implementation of a high-quality and
high-throughput true-random number generator (TRNG) in FPGA. Various practical
issues which we encountered are highlighted and the influence of the various
parameters on the functioning of the TRNG are discussed. We also propose a few
values for the parameters which use the minimum amount of the resources but
still pass common random number generator test batteries such as DieHard and
TestU01."
"The exponential growth of Internet traffic has made public servers
increasingly vulnerable to unauthorized accesses and intrusions. In addition to
maintaining low latency for the client, filtering unauthorized accesses has
become one of the major concerns of a server maintainer. This implementation of
an Intrusion Detection System distinguishes between the traffic coming from
clients and the traffic originated from the attackers, in an attempt to
simultaneously mitigate the problems of both latency and security. We then
present the results of a series of stress and scalability tests, and suggest a
number of potential uses for such a system. As computer attacks are becoming
more and more difficult to identify the need for better and more efficient
intrusion detection systems increases. The main problem with current intrusion
detection systems is high rate of false alarms. Using honeypots provides
effective solution to increase the security."
"A computer network can be attacked in a number of ways. The security-related
threats have become not only numerous but also diverse and they may also come
in the form of blended attacks. It becomes difficult for any security system to
block all types of attacks. This gives rise to the need of an incidence
handling capability which is necessary for rapidly detecting incidents,
minimizing loss and destruction, mitigating the weaknesses that were exploited
and restoring the computing services. Incidence response has always been an
important aspect of information security but it is often overlooked by security
administrators. in this paper, we propose an automated system which will handle
the security threats and make the computer network capable enough to withstand
any kind of attack. we also present the state-of-the-art technology in
computer, network and software which is required to build such a system."
"The cryptanalysis of simplified data encryption standard can be formulated as
NP-Hard combinatorial problem. The goal of this paper is two fold. First we
want to make a study about how evolutionary computation techniques can
efficiently solve the NP-Hard combinatorial problem. For achieving this goal we
test several evolutionary computation techniques like memetic algorithm,
genetic algorithm and simulated annealing for the cryptanalysis of simplified
data encryption standard problem (SDES). And second was a comparison between
memetic algorithm, genetic algorithm and simulated annealing were made in order
to investigate the performance for the cryptanalysis on SDES. The methods were
tested and extensive computational results show that memetic algorithm performs
better than genetic algorithms and simulated annealing for such type of NP-Hard
combinatorial problem. This paper represents our first effort toward efficient
memetic algorithm for the cryptanalysis of SDES."
"- In this paper a session based symmetric key encryption system has been
proposed and is termed as Permutated Cipher Technique (PCT). This technique is
more fast, suitable and secure for larger files. In this technique the input
file is broken down int"
"Security concern for a Sensor Networks and level of security desired may
differ according to application specific needs where the sensor networks are
deployed. Till now, most of the security solutions proposed for sensor networks
are layer wise i.e a particular solution is applicable to single layer itself.
So, to integrate them all is a new research challenge. In this paper we took up
the challenge and have proposed an integrated comprehensive security framework
that will provide security services for all services of sensor network. We have
added one extra component i.e. Intelligent Security Agent (ISA) to assess level
of security and cross layer interactions. This framework has many components
like Intrusion Detection System, Trust Framework, Key Management scheme and
Link layer communication protocol. We have also tested it on three different
application scenarios in Castalia and Omnet++ simulator."
"The hurried development of multimedia and internet allows for wide
distribution of digital media data. It becomes much easier to edit, modify and
duplicate digital information. In additional, digital document is also easy to
copy and distribute, therefore it may face many threats. It became necessary to
find an appropriate protection due to the significance, accuracy and
sensitivity of the information. Furthermore, there is no formal method to be
followed to discover a hidden data. In this paper, a new information hiding
framework is presented.The proposed framework aim is implementation of
framework computation between advance encryption standard (AES) and distortion
technique (DT) which embeds information in image page within executable file
(EXE file) to find a secure solution to cover file without change the size of
cover file. The framework includes two main functions; first is the hiding of
the information in the image page of EXE file, through the execution of four
process (specify the cover file, specify the information file, encryption of
the information, and hiding the information) and the second function is the
extraction of the hiding information through three process (specify the stego
file, extract the information, and decryption of the information)."
"The authors discuss what is provable security in cryptography. Think that
provable security is asymptotic, relative, and dynamic, and only a supplement
to but not a replacement of exact security analysis. Because the conjecture P
!= NP has not been proven yet, and it is possible in terms of the two
incompleteness theorems of Kurt Godel that there is some cryptosystem of which
the security cannot or only ideally be proven in the random oracle model, the
security of a cryptosystem is between provability and unprovability, and any
academic conclusion must be checked and verified with practices or experiments
as much as possible. Extra, a new approach to proof of P != NP is pointed out.
Lastly, a reward is offered for the subexponential time solutions to the three
REESSE1+ problems: MPP, ASPP, and TLP with n >= 80 and lg M >= 80, which may be
regarded as a type of security proof by experiment."
"The Encrypted File System (EFS) pushes encryption services into the file
system itself. EFS supports secure storage at the system level through a
standard UNIX file system interface to encrypted files. User can associate a
cryptographic key with the directories they wish to protect. Files in these
directories (as well as their pathname components) are transparently encrypted
and decrypted with the specified key without further user intervention; clear
text is never stored on a disk or sent to a remote file server. EFS can use any
available file system for its underlying storage without modifications,
including remote file servers such as NFS. System management functions, such as
file backup, work in a normal manner and without knowledge of the key.
Performance is an important factor to users since encryption can be time
consuming. This paper describes the design and implementation of EFS in user
space using faster cryptographic algorithms on UNIX Operating system.
Implementing EFS in user space makes it portable and flexible; Kernel size will
also not increase resulting in more reliable & efficient Operating System.
Encryption techniques for file system level encryption are described, and
general issues of cryptographic system interfaces to support routine secure
computing are discussed."
"Privacy and security are often intertwined. For example, identity theft is
rampant because we have become accustomed to authentication by identification.
To obtain some service, we provide enough information about our identity for an
unscrupulous person to steal it (for example, we give our credit card number to
Amazon.com). One of the consequences is that many people avoid e-commerce
entirely due to privacy and security concerns. The solution is to perform
authentication without identification. In fact, all on-line actions should be
as anonymous as possible, for this is the only way to guarantee security for
the overall system. A credential system is a system in which users can obtain
credentials from organizations and demonstrate possession of these credentials.
Such a system is anonymous when transactions carried out by the same user
cannot be linked. An anonymous credential system is of significant practical
relevance because it is the best means of providing privacy for users."
"At ISCAS'2005, Yen et al. presented a new chaos-based cryptosystem for
multimedia transmission named ""Multimedia Cryptography System"" (MCS). No
cryptanalytic results have been reported so far. This paper presents a
differential attack to break MCS, which requires only seven chosen plaintexts.
The complexity of the attack is O(N), where $N$ is the size of plaintext.
Experimental results are also given to show the real performance of the
proposed attack."
"Secure group communication in heterogeneous environment is gaining popularity
due to the advent of wireless and ubiquitous computing. Although a number of
protocols for group key agreement have been proposed, most of them are not
applicable in heterogeneous environment where a number of computationally
limited nodes coexist with one or more computationally efficient nodes. Among
the few existing protocols, where some fail to satisfy the key agreement
properties, some are unable to handle the agreement for dynamic group. In this
work, we propose a constant round group key agreement protocol for
heterogeneous environment using polynomial interpolation. The protocol ensures
both communication and computation efficiency by shifting the major computation
load on powerful users, achieves true contributory key agreement property and
dynamic handling of user join and leave. The security of the protocol has been
analyzed under formal model. The comparison result shows considerable
improvement in protocol efficiency compared to the existing ones."
"This version of the paper has been withdrawn due to an error. Please contact
one of the authors for an updated copy."
"Blaster worm of 2003 is still persistent, the infection appears to have
successfully transitioned to new hosts as the original systems are cleaned or
shut off, suggesting that the Blaster worm, and other similar worms, will
remain significant Internet threats for many years after their initial release.
This paper is to propose technique on tracing the Blaster attack from various
logs in different OSI layers based on fingerprint of Blaster attack on victim
logs, attacker logs and IDS alert log. The researchers intended to do a
preliminary investigation upon this particular attack so that it can be used
for further research in alert correlation and computer forensic investigation."
"This paper presents a new discrete Hilbert transform (DHT) based measure of
randomness for discrete sequences. The measure has been used to test three
different classes of sequences with satisfactory results."
"In this paper, we use the ten security requirements proposed by Liao et al.
for a smart card based authentication protocol to examine five recent work in
this area. After analyses, we found that the protocols of Juang et al.'s ,
Hsiang et al.'s, Kim et al.'s, and Li et al.'s all suffer from offline password
guessing attack if the smart card is lost, and the protocol of Xu et al.'s is
subjected to an insider impersonation attack."
"In this paper, we analyze four authentication protocols of Bindu et al.,
Goriparthi et al., Wang et al. and H\""olbl et al.. After investigation, we
reveal several weaknesses of these schemes. First, Bindu et al.'s protocol
suffers from an insider impersonation attack if a malicious user obtains a lost
smart card. Second, both Goriparthi et al.'s and Wang et al.'s protocols cannot
withstand a DoS attack in the password change phase, i.e. an attacker can
involve the phase to make user's password never be used in subsequent
authentications. Third, H\""olbl et al.'s protocol is vulnerable to an insider
attack since a legal but malevolent user can deduce KGC's secret key."
"This paper addresses an interesting security problem in wireless ad hoc
networks: the Dynamic Group Key Agreement key establishment. For secure group
communication in an Ad hoc network, a group key shared by all group members is
required. This group key should be updated when there are membership changes
(when the new member joins or current member leaves) in the group. In this
paper, We propose a novel, secure, scalable and efficient Region-Based Group
Key Agreement protocol (RBGKA) for ad-hoc networks. This is implemented by a
two-level structure and a new scheme of group key update. The idea is to divide
the group into subgroups, each maintaining its subgroup keys using Group
Diffie-Hellman (GDH) Protocol and links with other subgroups in a Tree
structure using Tree-based Group Diffie-Hellman (TGDH) protocol. By introducing
region-based approach, messages and key updates will be limited within subgroup
and outer group; hence computation load is distributed among many hosts. Both
theoretical analysis and experimental results show that this Region-based key
agreement protocol performs better for the key establishment problem in ad-hoc
network in terms of memory cost, computation cost and communication cost."
"Anti-collusion digital fingerprinting codes have been of significant current
interest in the context of deterring unauthorized use of multimedia content by
a coalition of users. In this article, partially cover-free families of sets
are considered and these are employed to obtain such codes. Compared to the
existing methods of construction, our methods ensure gains in terms of
accommodating more users and/or reducing the number of basis vectors."
"The establishment of trust relationships to a computing platform relies on
validation processes. Validation allows an external entity to build trust in
the expected behaviour of the platform based on provided evidence of the
platform's configuration. In a process like remote attestation, the 'trusted'
platform submits verification data created during a start up process. These
data consist of hardware-protected values of platform configuration registers,
containing nested measurement values, e.g., hash values, of loaded or started
components. Commonly, the register values are created in linear order by a
hardware-secured operation. Fine-grained diagnosis of components, based on the
linear order of verification data and associated measurement logs, is not
optimal. We propose a method to use tree-formed verification data to validate a
platform. Component measurement values represent leaves, and protected
registers represent roots of a hash tree. We describe the basic mechanism of
validating a platform using tree-formed measurement logs and root registers and
show an logarithmic speed-up for the search of faults. Secure creation of a
tree is possible using a limited number of hardware-protected registers and a
single protected operation. In this way, the security of tree-formed
verification data is maintained."
"This paper presents experimental results of the implementation of network
steganography method called RSTEG (Retransmission Steganography). The main idea
of RSTEG is to not acknowledge a successfully received packet to intentionally
invoke retransmission. The retransmitted packet carries a steganogram instead
of user data in the payload field. RSTEG can be applied to many network
protocols that utilize retransmissions. We present experimental results for
RSTEG applied to TCP (Transmission Control Protocol) as TCP is the most popular
network protocol which ensures reliable data transfer. The main aim of the
performed experiments was to estimate RSTEG steganographic bandwidth and
detectability by observing its influence on the network retransmission level."
"Leakage of confidential information represents a serious security risk.
Despite a number of novel, theoretical advances, it has been unclear if and how
quantitative approaches to measuring leakage of confidential information could
be applied to substantial, real-world programs. This is mostly due to the high
complexity of computing precise leakage quantities. In this paper, we introduce
a technique which makes it possible to decide if a program conforms to a
quantitative policy which scales to large state-spaces with the help of bounded
model checking.
  Our technique is applied to a number of officially reported information leak
vulnerabilities in the Linux Kernel. Additionally, we also analysed
authentication routines in the Secure Remote Password suite and of a Internet
Message Support Protocol implementation. Our technique shows when there is
unacceptable leakage; the same technique is also used to verify, for the first
time, that the applied software patches indeed plug the information leaks.
  This is the first demonstration of quantitative information flow addressing
security concerns of real-world industrial programs."
"Internet worm attacks pose a significant threat to network security and
management. In this work, we coin the term Internet worm tomography as
inferring the characteristics of Internet worms from the observations of
Darknet or network telescopes that monitor a routable but unused IP address
space. Under the framework of Internet worm tomography, we attempt to infer
Internet worm temporal behaviors, i.e., the host infection time and the worm
infection sequence, and thus pinpoint patient zero or initially infected hosts.
Specifically, we introduce statistical estimation techniques and propose method
of moments, maximum likelihood, and linear regression estimators. We show
analytically and empirically that our proposed estimators can better infer worm
temporal characteristics than a naive estimator that has been used in the
previous work. We also demonstrate that our estimators can be applied to worms
using different scanning strategies such as random scanning and localized
scanning."
"Key establishment is the basic necessary tool in the network security, by
which pairs in the network can establish shared keys for protecting their
pairwise communications. There have been some key agreement or predistribution
schemes with the property that the key can be established without the
interaction (\cite{Blom84,BSHKY92,S97}). Recently the hierarchical cryptography
and the key management for hierarchical networks have been active topics(see
\cite{BBG05,GHKRRW08,GS02,HNZI02,HL02,Matt04}. ). Key agreement schemes for
hierarchical networks were presented in \cite{Matt04,GHKRRW08} which is based
on the Blom key predistribution scheme(Blom KPS, [1]) and pairing. In this
paper we introduce generalized Blom-Blundo et al key predistribution schemes.
These generalized Blom-Blundo et al key predistribution schemes have the same
security functionality as the Blom-Blundo et al KPS. However different and
random these KPSs can be used for various parts of the networks for enhancing
the resilience. We also presentkey predistribution schemes from a family
hyperelliptic curves. These key predistribution schemes from different random
curves can be used for various parts of hierarchical networks. Then the
non-interactive, identity-based and dynamic key predistributon scheme based on
this generalized Blom-Blundo et al KPSs and hyperelliptic curve KPSs for
hierarchical networks with the following properties are constructed.
1)$O(A_KU)$ storage at each node in the network where $U$ is the expansion
number and $A_K$ is the number of nodes at the $K$-th level of the hierarchical
network; 2)Strongly resilience to the compromising of arbitrary many leaf and
internal nodes; 3)Information theoretical security without random oracle."
"Recently, a chaos-based image encryption algorithm called MCKBA (Modified
Chaotic-Key Based Algorithm) was proposed. This paper analyzes the security of
MCKBA and finds that it can be broken with a differential attack, which
requires only four chosen plain-images. Performance of the attack is verified
by experimental results. In addition, some defects of MCKBA, including
insensitivity with respect to changes of plain-image/secret key, are reported."
"As a variant of the HB authentication protocol for RFID systems, which relies
on the complexity of decoding linear codes against passive attacks, Madhavan et
al. presented Non-Linear HB(NLHB) protocol. In contrast to HB, NLHB relies on
the complexity of decoding a class of non-linear codes to render the passive
attacks proposed against HB ineffective. In this paper, we show that passive
attacks against HB protocol can still be applicable to NLHB and this protocol
does not provide the desired security margin. In our attack, we first linearize
the non-linear part of NLHB to obtain a HB equivalent for NLHB, and then
exploit the passive attack techniques proposed for the HB to evaluate the
security margin of NLHB. The results show that although NLHB's security margin
is relatively higher than HB against similar passive attack techniques, it has
been overestimated and, in contrary to what is claimed, NLHB is vulnerable to
passive attacks against HB, especially when the noise vector in the protocol
has a low weight."
"We propose a novel high-speed stream cipher encryption scheme based on the
true random key generated by a chaotic semiconductor laser. A 5-Gbits/s
non-return-to-zero plaintext is successfully encrypted and decrypted using this
cryptography. The scheme can be applied in the areas of real-time high-speed
physical encryption."
"The NIST Fingerprint Image Quality (NFIQ) algorithm has become a standard
method to assess fingerprint image quality. However, in many applications a
more accurate and reliable assessment is desirable. In this publication, we
report on our efforts to optimize the NFIQ algorithm by a re-training of the
underlying neural network based on a large fingerprint image database. Although
we only achieved a marginal improvement, our work has revealed several areas
for potential optimization."
"The fuzzy vault is an error tolerant authentication method that ensures the
privacy of the stored reference data. Several publications have proposed the
application of the fuzzy vault to fingerprints, but the results of subsequent
analyses indicate that a single finger does not contain sufficient information
for a secure implementation. In this contribution, we present an implementation
of a fuzzy vault based on minutiae information in several fingerprints aiming
at a security level comparable to current cryptographic applications. We
analyze and empirically evaluate the security, efficiency, and robustness of
the construction and several optimizations. The results allow an assessment of
the capacity of the scheme and an appropriate selection of parameters. Finally,
we report on a practical simulation conducted with ten users."
"This paper proposes a generic approach for providing enhanced security to
communication systems which encode their data for reliability before encrypting
it through a stream cipher for security. We call this counter-intuitive
technique the {\em encoding-encryption} paradigm, and use as motivating example
the standard for mobile telephony GSM. The enhanced security is based on a
dedicated homophonic or wire-tap channel coding that introduces pure
randomness, combined with the randomness of the noise occurring over the
communication channel. Security evaluation regarding recovery of the secret key
employed in the keystream generator is done through an information theoretical
approach. We show that with the aid of a dedicated wire-tap encoder, the amount
of uncertainty that the adversary must face about the secret key given all the
information he could gather during different passive or active attacks he can
mount, is a decreasing function of the sample available for cryptanalysis. This
means that the wire-tap encoder can indeed provide an information theoretical
security level over a period of time, but after a large enough sample is
collected the function tends to zero, entering a regime in which a
computational security analysis is needed for estimation of the resistance
against the secret key recovery."
"In AFRICACRYPT 2010, Abdalla et al. first proposed a slight modification to
the computations steps of the BD protocol, called mBD+P. Then they extended
mBD+P protocol into mBD+S protocol. In this paper, we show that both of mBD+P
and mBD+S protocols are vulnerable to malicious insiders attack. Further, we
propose a simple countermeasure against this attack."
"Improved interoperability between public and private organizations is of key
significance to make digital government newest triumphant. Digital Government
interoperability, information sharing protocol and security are measured the
key issue for achieving a refined stage of digital government. Flawless
interoperability is essential to share the information between diverse and
merely dispersed organisations in several network environments by using
computer based tools. Digital government must ensure security for its
information systems, including computers and networks for providing better
service to the citizens. Governments around the world are increasingly
revolving to information sharing and integration for solving problems in
programs and policy areas. Evils of global worry such as syndrome discovery and
manage, terror campaign, immigration and border control, prohibited drug
trafficking, and more demand information sharing, harmonization and cooperation
amid government agencies within a country and across national borders. A number
of daunting challenges survive to the progress of an efficient information
sharing protocol. A secure and trusted information-sharing protocol is required
to enable users to interact and share information easily and perfectly across
many diverse networks and databases globally."
"A TPM (trusted platform module) is a chip present mostly on newer
motherboards, and its primary function is to create, store and work with
cryptographic keys. This dedicated chip can serve to authenticate other devices
or to protect encryption keys used by various software applications. Among
other features, it comes with a True Random Number Generator (TRNG) that can be
used for cryptographic purposes. This random number generator consists of a
state machine that mixes unpredictable data with the output of a one way hash
function. According the specification it can be a good source of unpredictable
random numbers even without having to require a genuine source of hardware
entropy. However the specification recommends collecting entropy from any
internal sources available such as clock jitter or thermal noise in the chip
itself, a feature that was implemented by most manufacturers. This paper will
benchmark the random number generator of several TPM chips from two
perspectives: the quality of the random bit sequences generated, as well as the
output bit rate."
"Security and privacy are the inherent problems in RFID communications. There
are several protocols have been proposed to overcome those problems. Hash chain
is commonly employed by the protocols to improve security and privacy for RFID
authentication. Although the protocols able to provide specific solution for
RFID security and privacy problems, they fail to provide integrated solution.
This article is a survey to closely observe those protocols in terms of its
focus and limitations."
"In 1994, Josh Benaloh proposed a probabilistic homomorphic encryption scheme,
enhancing the poor expansion factor provided by Goldwasser and Micali's scheme.
Since then, numerous papers have taken advantage of Benaloh's homomorphic
encryption function, including voting schemes, computing multi-party trust
privately, non-interactive verifiable secret sharing, online poker... In this
paper we show that the original description of the scheme is incorrect,
possibly resulting in ambiguous decryption of ciphertexts. We give a corrected
description of the scheme and provide a complete proof of correctness. We also
compute the probability of failure of the original scheme. Finally we analyze
several applications using Benaloh's encryption scheme. We show in each case
the impact of a bad choice in the key generation phase of Benaloh's scheme. For
instance in the application of e-voting protocol, it can inverse the result of
an election, which is a non negligible consequence."
"We define secure operations with tree-formed, protected verification data
registers. Functionality is conceptually added to Trusted Platform Modules
(TPMs) to handle Platform Configuration Registers (PCRs) which represent roots
of hash trees protecting the integrity of tree-formed Stored Measurement Logs
(SMLs). This enables verification and update of an inner node of an SML and
even attestation to its value with the same security level as for ordinary
PCRs. As an important application, it is shown how certification of SML
subtrees enables attestation of platform properties."
"In this paper, we analyze the security of an RFID authentication protocol
proposed by Liu and Bailey [1], called Privacy and Authentication Protocol
(PAP), and show its vulnerabilities and faulty assumptions. PAP is a privacy
and authentication protocol designed for passive tags. The authors claim that
the protocol, being resistant to commonly assumed attacks, requires little
computation and provides privacy protection and authentication. Nevertheless,
we propose two traceability attacks and an impersonation attack, in which the
revealing of secret information (i.e., secret key and static identifier) shared
between the tag and the reader is unnecessary. Moreover, we review all basic
assumptions on which the design of the protocol resides, and show how many of
them are incorrect and are contrary to the common assumptions in RFID systems."
"With the discovery of new exploit techniques, new protection mechanisms are
needed as well. Mitigations like DEP (Data Execution Prevention) or ASLR
(Address Space Layout Randomization) created a significantly more difficult
environment for vulnerability exploitation. Attackers, however, have recently
developed new exploitation methods which are capable of bypassing the operating
system's security protection mechanisms. In this paper we present a short
summary of novel and known mitigation techniques against return-oriented
programming (ROP) attacks. The techniques described in this article are related
mostly to x86-32 processors and Microsoft Windows operating systems."
"Each day, anti-virus companies receive tens of thousands samples of
potentially harmful executables. Many of the malicious samples are variations
of previously encountered malware, created by their authors to evade
pattern-based detection. Dealing with these large amounts of data requires
robust, automatic detection approaches. This paper studies malware
classification based on call graph clustering. By representing malware samples
as call graphs, it is possible to abstract certain variations away, and enable
the detection of structural similarities between samples. The ability to
cluster similar samples together will make more generic detection techniques
possible, thereby targeting the commonalities of the samples within a cluster.
To compare call graphs mutually, we compute pairwise graph similarity scores
via graph matchings which approximately minimize the graph edit distance. Next,
to facilitate the discovery of similar malware samples, we employ several
clustering algorithms, including k-medoids and DBSCAN. Clustering experiments
are conducted on a collection of real malware samples, and the results are
evaluated against manual classifications provided by human malware analysts.
Experiments show that it is indeed possible to accurately detect malware
families via call graph clustering. We anticipate that in the future, call
graphs can be used to analyse the emergence of new malware families, and
ultimately to automate implementation of generic detection schemes."
"In this paper, we introduce an efficient and trustworthy conditional
privacy-preserving communication protocol for VANETs based on proxy
re-signature. The proposed protocol is characterized by the Trusted Authority
(TA) designating the Roadside Units (RSUs) to translate signatures computed by
the On-Board Units (OBUs) into one that are valid with respect to TA's public
key. In addition, the proposed protocol offers both a priori and a posteriori
countermeasures: it can not only provide fast anonymous authentication and
privacy tracking, but guarantees message trustworthiness for vehicle-to-vehicle
(V2V) communications. Furthermore, it reduces the communication overhead and
offers fast message authentication and, low storage requirements. We use
extensive analysis to demonstrate the merits of the proposed protocol and to
contrast it with previously proposed solutions."
"Recently, Alomair et al. proposed the first UnConditionally Secure mutual
authentication protocol for low-cost RFID systems(UCS-RFID). The security of
the UCS-RFID relies on five dynamic secret keys which are updated at every
protocol run using a fresh random number (nonce) secretly transmitted from a
reader to tags. Our results show that, at the highest security level of the
protocol (security parameter= 256), inferring a nonce is feasible with the
probability of 0.99 by eavesdropping(observing) about 90 runs of the protocol.
Finding a nonce enable a passive attacker to recover all five secret keys of
the protocol. To do so, we propose a three-phase probabilistic approach in this
paper. Our attack recovers the secret keys with a probability that increases by
accessing to more protocol runs. We also show that tracing a tag using this
protocol is also possible even with less runs of the protocol."
"Peer-to-peer systems have gained a lot of attention as information sharing
systems for the widespread exchange of resources and voluminous information
that is easily accessible among thousands of users. However, current
peer-to-peer information sharing systems work mostly on wired networks. With
the growing number of communication-equipped mobile devices that can
self-organize into infrastructure-less communication platform, namely mobile ad
hoc networks (MANETs), peer-to-peer information sharing over MANETs becomes a
promising research area. In this paper, we propose a Region-Based structure
that enables efficient and secure peer-to-peer information sharing over MANETs.
The implementation shows that the proposed scheme is Secure, scalable,
efficient, and adaptive to node mobility and provides Reliable information
sharing."
"In Ciphertext Policy Attribute based Encryption scheme, the encryptor can fix
the policy, who can decrypt the encrypted message. The policy can be formed
with the help of attributes. In CP-ABE, access policy is sent along with the
ciphertext. We propose a method in which the access policy need not be sent
along with the ciphertext, by which we are able to preserve the privacy of the
encryptor. The proposed construction is provably secure under Decision Bilinear
Diffe-Hellman assumption."
"This paper presents solutions for cryptography protection for web pages. The
solutions comprise the authors' experience in development and implementation of
systems for information security in the Automated Information Systems of
Bulgarian Armed Forces. The architecture, the models and the methods are being
explained."
"In recent years the amount of digital data in the world has risen immensely.
But, the more information exists, the greater is the possibility of its
unwanted disclosure. Thus, the data privacy protection has become a pressing
problem of the present time. The task of individual privacy-preserving is being
thoroughly studied nowadays. At the same time, the problem of statistical
disclosure control for collective (or group) data is still open. In this paper
we propose an effective and relatively simple (wavelet-based) way to provide
group anonymity in collective data. We also provide a real-life example to
illustrate the method."
"Providing public access to unprotected digital data can pose a threat of
unwanted disclosing the restricted information. The problem of protecting such
information can be divided into two main subclasses, namely, individual and
group data anonymity. By group anonymity we define protecting important data
patterns, distributions, and collective features which cannot be determined
through analyzing individual records only. An effective and comparatively
simple way of solving group anonymity problem is doubtlessly applying wavelet
transform. It's easy-to-implement, powerful enough, and might produce
acceptable results if used properly. In the paper, we present a novel method of
using wavelet transform for providing group anonymity; it is gained through
redistributing wavelet approximation values, along with simultaneous fixing
data mean value and leaving wavelet details unchanged (or proportionally
altering them). Moreover, we provide a comprehensive example to illustrate the
method."
"Existing methods of providing data anonymity preserve individual privacy,
but, the task of protecting respondent groups' information in publicly
available datasets remains open. Group anonymity lies in hiding (masking) data
patterns that cannot be revealed by analyzing individual records. We discuss
main corresponding problems, and provide methods for solving each one.
Keywords: group anonymity, wavelet transform."
"Public access to digital data can turn out to be a cause of undesirable
information disclosure. That's why it is vital to somehow protect the data
before publishing. There exist two main subclasses of such a task, namely,
providing individual and group anonymity. In the paper, we introduce a novel
method of protecting group data patterns. Also, we provide a comprehensive
illustrative example."
"In the recent time, the problem of protecting privacy in statistical data
before they are published has become a pressing one. Many reliable studies have
been accomplished, and loads of solutions have been proposed. Though, all these
researches take into consideration only the problem of protecting individual
privacy, i.e., privacy of a single person, household, etc. In our previous
articles, we addressed a completely new type of anonymity problems. We
introduced a novel kind of anonymity to achieve in statistical data and called
it group anonymity. In this paper, we aim at summarizing and generalizing our
previous results, propose a complete mathematical description of how to provide
group anonymity, and illustrate it with a couple of real-life examples."
"Malware usually target computers according to their operating system. Thus we
have Windows malwares, Linux malwares and so on ... In this paper, we consider
a different approach and show on a technical basis how easily malware can
recognize and target systems selectively, according to the onboard processor
chip. This technology is very easy to build since it does not rely on deep
analysis of chip logical gates architecture. Floating Point Arithmetic (FPA)
looks promising to define a set of tests to identify the processor or, more
precisely, a subset of possible processors. We give results for different
families of processors: AMD, Intel (Dual Core, Atom), Sparc, Digital Alpha,
Cell, Atom ... As a conclusion, we propose two {\it open problems} that are
new, to the authors' knowledge."
"Wireless mesh networks (WMNs) are evolving as a key technology for
next-generation wireless networks showing raid progress and numerous
applications. These networks have the potential to provide robust and
high-throughput data delivery to wireless users. In a WMN, high speed routers
equipped with advanced antennas, communicate with each other in a multi-hop
fashion over wireless channels and form a broadband backhaul. However, the
throughput of a WMN may be severely degraded due to presence of some selfish
routers that avoid forwarding packets for other nodes even as they send their
own traffic through the network. This paper presents an algorithm for detection
of selfish nodes in a WMN. It uses statistical theory of inference for reliable
clustering of the nodes and is based on local observations by the nodes.
Simulation results show that the algorithm has a high detection rate while
having a low rate of false positives."
"A traditional paper-based passport contains a Machine- Readable Zone (MRZ)
and a Visual Inspection Zone (VIZ). The MRZ has two lines of the holder's
personal data, some document data, and verification characters encoded using
the Optical Character Recognition font B (OCRB). The encoded data includes the
holder's name, date of birth, and other identifying information for the holder
or the document. The VIZ contains the holder's photo and signature, usually on
the data page. However, the MRZ and VIZ can be easily duplicated with normal
document reproduction technology to produce a fake passport which can pass
traditional verification. Neither of these features actively verify the
holder's identity; nor do they bind the holder's identity to the document. A
passport also contains pages for stamps of visas and of country entry and exit
dates, which can be easily altered to produce fake permissions and travel
records. The electronic passport, supporting authentication using secure
credentials on a tamper-resistant chip, is an attempt to improve on the
security of the paper-based passport at minimum cost. This paper surveys the
security mechanisms built into the firstgeneration of authentication mechanisms
and compares them with second-generation passports. It analyzes and describes
the cryptographic protocols used in Basic Access Control (BAC) and Extended
Access Control (EAC)."
"In pervasive computing environments, Location- Based Services (LBSs) are
becoming increasingly important due to continuous advances in mobile networks
and positioning technologies. Nevertheless, the wide deployment of LBSs can
jeopardize the location privacy of mobile users. Consequently, providing
safeguards for location privacy of mobile users against being attacked is an
important research issue. In this paper a new scheme for safeguarding location
privacy is proposed. Our approach supports location K-anonymity for a wide
range of mobile users with their own desired anonymity levels by clustering.
The whole area of all users is divided into clusters recursively in order to
get the Minimum Bounding Rectangle (MBR). The exact location information of a
user is replaced by his MBR. Privacy analysis shows that our approach can
achieve high resilience to location privacy threats and provide more privacy
than users expect. Complexity analysis shows clusters can be adjusted in real
time as mobile users join or leave. Moreover, the clustering algorithms possess
strong robustness."
"Ensuring security of e-government applications and infrastructures is crucial
to maintain trust among stakeholders to store, process and exchange information
over the e-government systems. Due to dynamic and continuous threats on
e-government information security, policy makers need to perform evaluation on
existing information security strategy as to deliver trusted e-government
services. This paper presents an information security evaluation framework
based on new fuzzy multi criteria decision making (MCDM) to help policy makers
conduct comprehensive assessment of e-government security strategy."
"This paper presents solutions for distribution, access and use of resources
in information security systems. The solutions comprise the authors' experience
in development and implementation of systems for information security in the
Automated Information Systems. The models, the methods and the modus operandi
are being explained."
"Spam messes up user's inbox, consumes network resources and spread worms and
viruses. Spam is flooding of unsolicited, unwanted e mail. Spam in blogs is
called blog spam or comment spam.It is done by posting comments or flooding
spams to the services such as blogs, forums,news,email archives and guestbooks.
Blog spams generally appears on guestbooks or comment pages where spammers fill
a comment box with spam words. In addition to wasting user's time with unwanted
comments, spam also consumes a lot of bandwidth. In this paper, we propose a
software tool to prevent such blog spams by using Bayesian Algorithm based
technique. It is derived from Bayes' Theorem. It gives an output which has a
probability that any comment is spam, given that it has certain words in it.
With using our past entries and a comment entry, this value is obtained and
compared with a threshold value to find if it exceeds the threshold value or
not. By using this concept, we developed a software tool to block comment spam.
The experimental results show that the Bayesian based tool is working well.
This paper has the major findings and their significance of blog spam filter."
"Commutative encryption is a useful but rather strict notion in cryptography.
In this paper, we deny a loose variation of commutative
encryption-commutative-like encryption and give an example: the generalization
of ElGamal scheme. The application of the new variation is also discussed."
"We present three voting protocols with unconditional privacy and correctness,
without assuming any bound on the number of corrupt participants. All protocols
have polynomial complexity and require private channels and a simultaneous
broadcast channel. Unlike previously proposed protocols in this model, the
protocols that we present deterministically output the exact tally. Our first
protocol is a basic voting scheme which allows voters to interact in order to
compute the tally. Privacy of the ballot is unconditional in the sense that
regardless of the behavior of the dishonest participants nothing can be learned
through the protocol that could not be learned in an ideal realisation.
Unfortunately, a single dishonest participant can make the protocol abort, in
which case the dishonest participants can nevertheless learn the outcome of the
tally. Our second protocol introduces voting authorities which improves the
communication complexity by limiting interaction to be only between voters and
authorities and among the authorities themselves; the simultaneous broadcast is
also limited to the authorities. In the second protocol, as long as a single
authority is honest, the privacy is unconditional, however, a single corrupt
authority or a single corrupt voter can cause the protocol to abort. Our final
protocol provides a safeguard against corrupt voters by enabling a verification
technique to allow the authorities to revoke incorrect votes without aborting
the protocol. Finally, we discuss the implementation of a simultaneous
broadcast channel with the use of temporary computational assumptions, yielding
versions of our protocols that achieve everlasting security."
"Secure distance bounding (DB) protocols allow one entity, the verifier, to
securely obtain an upper-bound on the distance to another entity, the prover.
Thus far, DB was considered mostly in the context of a single prover and a
single verifier. There has been no substantial prior work on secure DB in group
settings, where a set of provers interact with a set of verifiers. The need for
group distance bounding (GDB) is motivated by many practical scenarios,
including: group device pairing, location-based access control and secure
distributed localization. GDB is also useful in mission-critical networks and
automotive computer systems. This paper addresses, for the first time, GDB
protocols by utilizing the new passive DB primitive and the novel mutual
multi-party GDB protocol. We show how they can be used to construct secure and
efficient GDB protocols for various settings. We analyze security and
performance of our protocols and compare them with existing DB techniques when
applied to group settings."
"A protocol for computing a functionality is secure if an adversary in this
protocol cannot cause more harm than in an ideal computation where parties give
their inputs to a trusted party which returns the output of the functionality
to all parties. In particular, in the ideal model such computation is fair --
all parties get the output. Cleve (STOC 1986) proved that, in general, fairness
is not possible without an honest majority. To overcome this impossibility,
Gordon and Katz (Eurocrypt 2010) suggested a relaxed definition -- 1/p-secure
computation -- which guarantees partial fairness. For two parties, they
construct 1/p-secure protocols for functionalities for which the size of either
their domain or their range is polynomial (in the security parameter). Gordon
and Katz ask whether their results can be extended to multiparty protocols.
  We study 1/p-secure protocols in the multiparty setting for general
functionalities. Our main result is constructions of 1/p-secure protocols when
the number of parties is constant provided that less than 2/3 of the parties
are corrupt. Our protocols require that either (1) the functionality is
deterministic and the size of the domain is polynomial (in the security
parameter), or (2) the functionality can be randomized and the size of the
range is polynomial. If the size of the domain is constant and the
functionality is deterministic, then our protocol is efficient even when the
number of parties is O(log log n) (where n is the security parameter). On the
negative side, we show that when the number of parties is super-constant,
1/p-secure protocols are not possible when the size of the domain is
polynomial."
"We use Hidden Markov Models to motivate a quantitative compositional
semantics for noninterference-based security with iteration, including a
refinement- or ""implements"" relation that compares two programs with respect to
their information leakage; and we propose a program algebra for source-level
reasoning about such programs, in particular as a means of establishing that an
""implementation"" program leaks no more than its ""specification"" program.
<p>This joins two themes: we extend our earlier work, having iteration but only
qualitative, by making it quantitative; and we extend our earlier quantitative
work by including iteration. <p>We advocate stepwise refinement and
source-level program algebra, both as conceptual reasoning tools and as targets
for automated assistance. A selection of algebraic laws is given to support
this view in the case of quantitative noninterference; and it is demonstrated
on a simple iterated password-guessing attack."
"We compute the channel capacity of non-binary fingerprinting under the
Marking Assumption, in the limit of large coalition size c. The solution for
the binary case was found by Huang and Moulin. They showed that asymptotically,
the capacity is $1/(c^2 2\ln 2)$, the interleaving attack is optimal and the
arcsine distribution is the optimal bias distribution. In this paper we prove
that the asymptotic capacity for general alphabet size q is $(q-1)/(c^2 2\ln
q)$. Our proof technique does not reveal the optimal attack or bias
distribution. The fact that the capacity is an increasing function of q shows
that there is a real gain in going to non-binary alphabets."
"We use a method recently introduced by Simone and Skoric to study accusation
probabilities for non-binary Tardos fingerprinting codes. We generalize the
pre-computation steps in this approach to include a broad class of collusion
attack strategies. We analytically derive properties of a special attack that
asymptotically maximizes false accusation probabilities. We present numerical
results on sufficient code lengths for this attack, and explain the abrupt
transitions that occur in these results."
"The goal of any cryptographic system is the exchange of information among the
intended users without any leakage of information to others who may have
unauthorized access to it. A common secret key could be created over a public
channel accessible to any opponent. Neural networks can be used to generate
common secret key. In case of neural cryptography, both the communicating
networks receive an identical input vector, generate an output bit and are
trained based on the output bit. The two networks and their weight vectors
exhibit a novel phenomenon, where the networks synchronize to a state with
identical time-dependent weights. The generated secret key over a public
channel is used for encrypting and decrypting the information being sent on the
channel. This secret key is distributed to the other vendor efficiently by
using an agent based approach."
"Yeh et al. recently have proposed a mutual authentication protocol based on
EPC Class-1 Gen.-2 standard [1]. They have claimed that their protocol is
secure against adversarial attacks and also provides forward secrecy. In this
paper we will show that the proposed protocol does not have proper security
features. A powerful and practical attack is presented on this protocol whereby
the whole security of the protocol is broken. Furthermore, Yeh et al. protocol
does not assure the untraceabilitiy and backward untraceabilitiy aspects.
Namely, all past and next transactions of a compromised tag will be traceable
by an adversary."
"Radio Frequency Identification (RFID) is appearing as a favorite technology
for automated identification, which can be widely applied to many applications
such as e-passport, supply chain management and ticketing. However, researchers
have found many security and privacy problems along RFID technology. In recent
years, many researchers are interested in RFID authentication protocols and
their security flaws. In this paper, we analyze two of the newest RFID
authentication protocols which proposed by Fu et al. and Li et al. from several
security viewpoints. We present different attacks such as desynchronization
attack and privacy analysis over these protocols."
"Security becomes an extremely important issue in smart grid. To maintain the
steady operation for smart power grid, massive measurement devices must be
allocated widely among the power grid. Previous studies are focused on false
data injection attack to the smart grid system. In practice, false data
injection attack is not easy to implement, since it is not easy to hack the
power grid data communication system. In this paper, we demonstrate that a
novel time stamp attack is a practical and dangerous attack scheme for smart
grid. Since most of measurement devices are equipped with global positioning
system (GPS) to provide the time information of measurements, it is highly
probable to attack the measurement system by spoofing the GPS. By employing the
real measurement data in North American Power Grid, simulation results
demonstrate the effectiveness of the time stamp attack on smart grid."
"In recent years, reversible data hiding has attracted much more attention
than before. Reversibility signifies that the original media can be recovered
without any loss from the marked media after extracting the embedded message.
This paper presents a new method that adopts two-level wavelet transform and
exploits the feature of large wavelet coefficient variance to achieve the goal
of high capacity with imperceptibility. Our method differs from those of
previous ones in which the wavelet coefficients histogram not gray-level
histogram is manipulated. Besides, clever shifting rules are introduced into
histogram to avoid the decimal problem in pixel values after recovery to
achieve reversibility. With small alteration of the wavelet coefficients in the
embedding process, and therefore low visual distortion is obtained in the
marked image. In addition, an important feature of our design is that the use
of threshold is much different from previous studies. The results indicate that
our design is superior to many other state-of-the-art reversible data hiding
schemes."
"We claim that the Open Mobile Alliance (OMA) License Choice Algorithm,
implemented in mobile DRM agents as specified by OMA suffers from a bug. More
precisely there exist some cases that the user, may end up losing some rights
without even to exercise them. We redesign this algorithm and claim that our
approach eliminates this bug."
"This paper discusses a new protocol implementing authentication in a
multi-located environment that avoids man-in-the-middle (MIM) attack, replay
attack and provides privacy, integrity of a message for multi-located parties.
The protocol uses the concept that each party is associated with a subsidiary
agent."
"Smartphone apps often run with full privileges to access the network and
sensitive local resources, making it difficult for remote systems to have any
trust in the provenance of network connections they receive. Even within the
phone, different apps with different privileges can communicate with one
another, allowing one app to trick another into improperly exercising its
privileges (a Confused Deputy attack). In Quire, we engineered two new security
mechanisms into Android to address these issues. First, we track the call chain
of IPCs, allowing an app the choice of operating with the diminished privileges
of its callers or to act explicitly on its own behalf. Second, a lightweight
signature scheme allows any app to create a signed statement that can be
verified anywhere inside the phone. Both of these mechanisms are reflected in
network RPCs, allowing remote systems visibility into the state of the phone
when an RPC is made. We demonstrate the usefulness of Quire with two example
applications. We built an advertising service, running distinctly from the app
which wants to display ads, which can validate clicks passed to it from its
host. We also built a payment service, allowing an app to issue a request which
the payment service validates with the user. An app cannot not forge a payment
request by directly connecting to the remote server, nor can the local payment
service tamper with the request."
"In this paper we discuss the ability of channel codes to enhance
cryptographic secrecy. Toward that end, we present the secrecy metric of
degrees of freedom in an attacker's knowledge of the cryptogram, which is
similar to equivocation. Using this notion of secrecy, we show how a specific
practical channel coding system can be used to hide information about the
ciphertext, thus increasing the difficulty of cryptographic attacks. The system
setup is the wiretap channel model where transmitted data traverse through
independent packet erasure channels with public feedback for authenticated ARQ
(Automatic Repeat reQuest). The code design relies on puncturing nonsystematic
low-density parity-check codes with the intent of inflicting an eavesdropper
with stopping sets in the decoder. Furthermore, the design amplifies errors
when stopping sets occur such that a receiver must guess all the channel-erased
bits correctly to avoid an expected error rate of one half in the ciphertext.
We extend previous results on the coding scheme by giving design criteria that
reduces the effectiveness of a maximum-likelihood attack to that of a
message-passing attack. We further extend security analysis to models with
multiple receivers and collaborative attackers. Cryptographic security is
enhanced in all these cases by exploiting properties of the physical-layer. The
enhancement is accurately presented as a function of the degrees of freedom in
the eavesdropper's knowledge of the ciphertext, and is even shown to be present
when eavesdroppers have better channel quality than legitimate receivers."
"We explore the additional security obtained by noise at the physical layer in
a wiretap channel model setting. Security enhancements at the physical layer
have been proposed recently using a secrecy metric based on the degrees of
freedom that an attacker has with respect to the sent ciphertext. Prior work
focused on cases in which the wiretap channel could be modeled as statistically
independent packet erasure channels for the legitimate receiver and an
eavesdropper. In this paper, we go beyond the state-of-the-art by addressing
correlated erasure events across the two communication channels. The resulting
security enhancement is presented as a function of the correlation coefficient
and the erasure probabilities for both channels. It is shown that security
improvements are achievable by means of judicious physical-layer design even
when the eavesdropper has a better channel than the legitimate receiver. The
only case in which this assertion may not hold is when erasures are highly
correlated across channels. However, we are able to prove that correlation
cannot nullify the expected security enhancement if the channel quality of the
legitimate receiver is strictly better than that of the eavesdropper."
"A bandwidth puzzle was recently proposed to defend against colluding
adversaries in peer-to-peer networks. The colluding adversaries do not do
actual work but claim to have uploaded contents for each other to gain free
credits from the system. The bandwidth puzzle guarantees that if the
adversaries can solve the puzzle, they must have spent substantial bandwidth,
the size of which is comparable to the size of the contents they claim to have
uploaded for each other. Therefore, the puzzle discourages the collusion. In
this paper, we study the performance of the bandwidth puzzle and give a lower
bound on the average number of bits the adversaries must receive to be able to
solve the puzzles with a certain probability. We show that our bound is tight
in the sense that there exists a strategy to approach this lower bound
asymptotically within a small factor. The new bound gives better security
guarantees than the existing bound, and can be used to guide better choices of
puzzle parameters to improve the system performance."
"Privacy policies often place requirements on the purposes for which a
governed entity may use personal information. For example, regulations, such as
HIPAA, require that hospital employees use medical information for only certain
purposes, such as treatment. Thus, using formal or automated methods for
enforcing privacy policies requires a semantics of purpose requirements to
determine whether an action is for a purpose or not. We provide such a
semantics using a formalism based on planning. We model planning using a
modified version of Markov Decision Processes, which exclude redundant actions
for a formal definition of redundant. We use the model to formalize when a
sequence of actions is only for or not for a purpose. This semantics enables us
to provide an algorithm for automating auditing, and to describe formally and
compare rigorously previous enforcement methods."
"This paper presents new results on randomization using Kak's Mesh Array for
matrix multiplication. These results include the periods of the longest cycles
when the the array is used for scrambling and the autocorrelation function of
the binary sequence obtained from the cycles."
"The Long Term Evolution of UMTS is one of the latest steps in an advancing
series of mobile telecommunications systems. Many articles have already been
published on the LTE subject but these publications have viewed the subject
from particular perspectives. In the present paper, a different approach has
been taken. We are interested in the security features and the cryptographic
algorithms used to ensure confidentiality and integrity of the transmitted
data. A closer look is taken to the two EPS confidentiality and integrity
algorithms based on the block cipher algorithm AES: the confidentiality
algorithm EEA2 and the integrity algorithm EIA2. Furthermore, we focused on the
implementation of both algorithms in C language in respect to the
specifications requirements. We have tested our implementations according to
the testsets given by the 3rd Generation Partnership Project (3GPP)
implementation document. Some examples of the implementation tests are
presented bellow."
"Highly dynamic computing environments, like ubiquitous and pervasive
computing environments, require frequent adaptation of applications. Context is
a key to adapt suiting user needs. On the other hand, standard access control
trusts users once they have authenticated, despite the fact that they may reach
unauthorized contexts. We analyse how taking into account dynamic information
like context in the authorization subsystem can improve security, and how this
new access control applies to interaction patterns, like messaging or eventing.
We experiment and validate our approach using context as an authorization
factor for eventing in Web service for device (like UPnP or DPWS), in smart
home security."
"Available purely software based code attestation protocols have recently been
shown to be cheatable. In this work we propose to upload compressed instruction
code to make the code attestation protocol robust against a so called
compresssion attack. The described secure code attestation protocol makes use
of recently proposed microcontroller architectures for reading out compressed
instruction code. We point out that the proposed concept only makes sense if
the provided cost/benefit ratio for the aforementioned microcontroller is
higher than an alternative hardware based solution requiring a tamperresistant
hardware module."
"File carving is one of the most important procedures in Digital Forensic
Investigation (DFI). But it is also requires the most computational resources.
Parallel processing on Graphics Processing Units have proven to be many times
faster than when executed on standard CPU. This paper is inspecting the
algorithms and methods to use parallel processing for development of file
carving tools that will do their job much faster than the conventional DFI
tools."
"Although smartcards are widely used, secure smartcard interoperability has
remained a significant challenge. Usually each manufacturer provides a closed
environment for their smartcard based applications including the microchip,
associated firmware and application software. While the security of this
""package"" can be tested and certified for example based on the Common Criteria,
the secure and convenient interoperability with other smartcards and smartcard
applications is not guaranteed. Ideally one would have a middleware that can
support various smartcards and smartcard applications. In our ongoing research
we study this scenario with the goal to develop a way to certify secure
smartcard interoperability in such an environment. Here we discuss and
experimentally demonstrate one critical security problem: if several smartcards
are connected via a middleware it is possible that a smartcard of type S
receives commands that were supposed to be executed on a different smartcard of
type S'. Such ""external commands"" can interleave with the commands that were
supposed to be executed on S. Here we demonstrate this problem experimentally
with a Common Criteria certified digital signature process on two commercially
available smartcards. Importantly, in some of these cases the digital signature
processes terminate without generating an error message or warning to the user."
"In this paper, we suggest a multi-dimensional approach towards intrusion
detection. Network and system usage parameters like source and destination IP
addresses; source and destination ports; incoming and outgoing network traffic
data rate and number of CPU cycles per request are divided into multiple
dimensions. Rather than analyzing raw bytes of data corresponding to the values
of the network parameters, a mature function is inferred during the training
phase for each dimension. This mature function takes a dimension value as an
input and returns a value that represents the level of abnormality in the
system usage with respect to that dimension. This mature function is referred
to as Individual Anomaly Indicator. Individual Anomaly Indicators recorded for
each of the dimensions are then used to generate a Global Anomaly Indicator, a
function with n variables (n is the number of dimensions) that provides the
Global Anomaly Factor, an indicator of anomaly in the system usage based on all
the dimensions considered together. The Global Anomaly Indicator inferred
during the training phase is then used to detect anomaly in the network traffic
during the detection phase. Network traffic data encountered during the
detection phase is fed back to the system to improve the maturity of the
Individual Anomaly Indicators and hence the Global Anomaly Indicator."
"Secure communication between two nodes in a network depends on reliable key
management systems that generate and distribute keys between communicating
nodes and a secure routing protocol that establishes a route between them. But
due to lack of central server and infrastructure in Mobile Ad hoc Networks
(MANETs), this is major problem to manage the keys in the network. Dynamically
changes in network's topology causes weak trust relationship among the nodes in
the network. In MANETs a mobile node operates as not only end terminal but also
as an intermediate router. Therefore, a multi-hop scenario occurs for
communication in MANETs; where there may be one or more malicious nodes in
between source and destination. A routing protocol is said to be secure that
detects the detrimental effects of malicious node(s in the path from source to
destination). In this paper, we proposed a key management scheme and a secure
routing protocol that secures on demand routing protocol such as DSR and AODV.
We assume that MANETs is divided into groups having a group leader in each
group. Group leader has responsibility of key management in its group. Proposed
key management scheme is a decentralized scheme that does not require any
Trusted Third Party (TTP) for key management. In proposed key management
system, both a new node and group leader authenticates each other mutually
before joining the network. While proposed secure routing protocol allows both
communicating parties as well as intermediate nodes to authenticate other nodes
and maintains message integrity"
"Privacy Security of data in Cloud Storage is one of the main issues. Many
Frameworks and Technologies are used to preserve data security in cloud
storage. [1] Proposes a framework which includes the design of data
organization structure, the generation and management of keys, the treatment of
change of user's access right and dynamic operations of data, and the
interaction between participants. It also design an interactive protocol and an
extirpation-based key derivation algorithm, which are combined with lazy
revocation, it uses multi-tree structure and symmetric encryption to form a
privacy-preserving, efficient framework for cloud storage. [2] Proposes a
framework which design a privacy-preserving cloud storage framework in which he
designed an interaction protocol among participants, use key derivation
algorithm to generate and manage keys, use both symmetric and asymmetric
encryption to hide the sensitive data of users, and apply Bloom filter for
cipher text retrieval. A system based on this framework is realized. This paper
analyzes both the frameworks in terms of the feasibility of the frameworks,
running overhead of the system and the privacy security of the frameworks."
"In this paper we describe a new cryptosystem we call ""The Hush Cryptosystem""
for hiding encrypted data in innocent Arabic sentences. The main purpose of
this cryptosystem is to fool observer-supporting software into thinking that
the encrypted data is not encrypted at all. We employ a modified Word
Substitution Method known as the Grammatical Substitution Method in our
cryptosystem. We also make use of Hidden Markov Models. We test our
cryptosystem using a computer program written in the Java Programming Language.
Finally, we test the output of our cryptosystem using statistical tests."
"We present practical poisoning and name-server block- ing attacks on standard
DNS resolvers, by off-path, spoofing adversaries. Our attacks exploit large DNS
responses that cause IP fragmentation; such long re- sponses are increasingly
common, mainly due to the use of DNSSEC. In common scenarios, where DNSSEC is
partially or incorrectly deployed, our poisoning attacks allow 'com- plete'
domain hijacking. When DNSSEC is fully de- ployed, attacker can force use of
fake name server; we show exploits of this allowing off-path traffic analy- sis
and covert channel. When using NSEC3 opt-out, attacker can also create fake
subdomains, circumvent- ing same origin restrictions. Our attacks circumvent
resolver-side defenses, e.g., port randomisation, IP ran- domisation and query
randomisation. The (new) name server (NS) blocking attacks force re- solver to
use specific name server. This attack allows Degradation of Service,
traffic-analysis and covert chan- nel, and also facilitates DNS poisoning. We
validated the attacks using standard resolver soft- ware and standard DNS name
servers and zones, e.g., org."
"In this paper the author presents a new cryptographic technique to exclude
the repetitive terms in a message, when it is to be encrypted, so that it
becomes almost impossible for a person to retrieve or predict the original
message from the encrypted message. In modern world, cryptography hackers try
to break a code or cryptographic algorithm or try to retrieve the key, which is
needed to encrypt a message, by analyzing the insertion or presence of
repetitive bits / characters (bytes) in the message and encrypted message to
find out the encryption algorithm or the key used for it. So it is must for a
good encryption method to exclude the repetitive terms such that no trace of
repetitions can be tracked down. For this reason we apply SD-AREE cryptographic
method to exclude repetitive terms from a message, which is to be encrypted. In
SD-AREE method the repetitive bits / characters are removed and there is no
trace of any repetition in the message."
"A number of works in the field of intrusion detection have been based on
Artificial Immune System and Soft Computing. Artificial Immune System based
approaches attempt to leverage the adaptability, error tolerance, self-
monitoring and distributed nature of Human Immune Systems. Whereas Soft
Computing based approaches are instrumental in developing fuzzy rule based
systems for detecting intrusions. They are computationally intensive and apply
machine learning (both supervised and unsupervised) techniques to detect
intrusions in a given system. A combination of these two approaches could
provide significant advantages for intrusion detection. In this paper we
attempt to leverage the adaptability of Artificial Immune System and the
computation intensive nature of Soft Computing to develop a system that can
effectively detect intrusions in a given network."
"Recent years have seen significant interest in designing networks that are
self-healing in the sense that they can automatically recover from adversarial
attacks. Previous work shows that it is possible for a network to automatically
recover, even when an adversary repeatedly deletes nodes in the network.
However, there have not yet been any algorithms that self-heal in the case
where an adversary takes over nodes in the network. In this paper, we address
this gap. In particular, we describe a communication network over n nodes that
ensures the following properties, even when an adversary controls up to t <=
(1/8 - \epsilon)n nodes, for any non-negative \epsilon. First, the network
provides a point-to-point communication with bandwidth and latency costs that
are asymptotically optimal. Second, the expected total number of message
corruptions is O(t(log* n)^2) before the adversarially controlled nodes are
effectively quarantined so that they cause no more corruptions. Empirical
results show that our algorithm can reduce the bandwidth cost by up to a factor
of 70."
"In this paper the author present a new technique of using QR Codes (commonly
known as 'Quick Respond Codes') in the field of Cryptography. QR Codes are
mainly used to convey or store messages because they have higher or large
storage capacity than any other normal conventional 'barcodes'. In this paper
the primary focus will be on storing messages in encrypted format with a
password and send it to the required destination hiding in a QR Code, without
being tracked or decrypted properly by any hacker or spyware. Since QR Codes
have fast response time and have large storage capacity, QR Codes can be used
perfectly to send encrypted data (messages) to the receiver. This method will
be suitable in any business house, government sectors, communication network to
send their encrypted messages faster to the destination. Or a person can even
use this method to keep his important documents, like passport number, pan-card
id, social security number, perfectly secured with him all the time, without
the information getting leaked to outside world. The new method is achieved by
entering the message along with a password. This password will generate a
secret code, which will be added to each digit or alphabet in the numbers or
text entered in the message (which is needed to be encrypted) and generate the
first phase of encryption. That newly generated encrypted message will again be
encrypted using various other methods to generate the final encrypted message."
"In this paper, the author presents a new cryptographic technique, SD-REE, to
exclude the repetitive terms in a message, when it is to be encrypted, so that
it becomes almost impossible for a person to retrieve or predict the original
message from the encrypted message. In modern world, cryptography hackers try
to break a code or cryptographic algorithm [1,2] or retrieve the key, used for
encryption, by inserting repetitive bytes / characters in the message and
encrypt the message or by analyzing repetitions in the encrypted message, to
find out the encryption algorithm or retrieve the key used for the encryption.
But in SD-REE method the repetitive bytes / characters are removed and there is
no trace of any repetition in the message, which was encrypted."
"The wireless sensor network has become a hot research area due its wide range
of application in military and civilian domain, but as it uses wireless media
for communication these are easily prone to security attacks. There are number
of attacks on wireless sensor networks like black hole attack, sink hole
attack, Sybil attack, selective forwarding attacks etc. in this paper we will
concentrate on selective forwarding attacks In selective forwarding attacks,
malicious nodes behave like normal nodes and selectively drop packets. The
selection of dropping nodes may be random. Identifying such attacks is very
difficult and sometimes impossible. In this paper we have listed up some
detection techniques, which have been proposed by different researcher in
recent years, there we also have tabular representation of qualitative analysis
of detection techniques"
"In spite of the availability of DNSSEC, which protects against cache
poisoning even by MitM attackers, many caching DNS resolvers still rely for
their security against poisoning on merely validating that DNS responses
contain some 'unpredictable' values, copied from the re- quest. These values
include the 16 bit identifier field, and other fields, randomised and validated
by different 'patches' to DNS. We investigate the prominent patches, and show
how attackers can circumvent all of them, namely: - We show how attackers can
circumvent source port randomisation, in the (common) case where the resolver
connects to the Internet via different NAT devices. - We show how attackers can
circumvent IP address randomisation, using some (standard-conforming)
resolvers. - We show how attackers can circumvent query randomisation,
including both randomisation by prepending a random nonce and case
randomisation (0x20 encoding). We present countermeasures preventing our
attacks; however, we believe that our attacks provide additional motivation for
adoption of DNSSEC (or other MitM-secure defenses)."
"The McEliece public-key encryption scheme has become an interesting
alternative to cryptosystems based on number-theoretical problems. Differently
from RSA and ElGa- mal, McEliece PKC is not known to be broken by a quantum
computer. Moreover, even tough McEliece PKC has a relatively big key size,
encryption and decryption operations are rather efficient. In spite of all the
recent results in coding theory based cryptosystems, to the date, there are no
constructions secure against chosen ciphertext attacks in the standard model -
the de facto security notion for public-key cryptosystems. In this work, we
show the first construction of a McEliece based public-key cryptosystem secure
against chosen ciphertext attacks in the standard model. Our construction is
inspired by a recently proposed technique by Rosen and Segev."
"Virtual organizations are dynamic, inter-organizational collaborations that
involve systems and services belonging to different security domains. Several
solutions have been proposed to guarantee the enforcement of the access control
policies protecting the information exchanged in a distributed system, but none
of them addresses the dynamicity characterizing virtual organizations. In this
paper we propose a dynamic hierarchical attribute-based encryption (D-HABE)
scheme that allows the institutions in a virtual organization to encrypt
information according to an attribute-based policy in such a way that only
users with the appropriate attributes can decrypt it. In addition, we introduce
a key management scheme that determines which user is entitled to receive which
attribute key from which domain authority."
"Digital watermarking system is a paramount for safeguarding valuable
resources and information. Digital watermarks are generally imperceptible to
the human eye and ear. Digital watermark can be used in video, audio and
digital images for a wide variety of applications such as copy prevention right
management, authentication and filtering of internet content. The proposed
system is able to protect copyright or owner identification of digital media,
such as audio, image, video, or text. The system permutated the watermark and
embed the permutated watermark into the wavelet coefficients of the original
image by using a key. The key is randomly generated and used to select the
locations in the wavelet domain in which to embed the permutated watermark.
Finally, the system combines the concept of cryptography and digital
watermarking techniques to implement a more secure digital watermarking system."
"ZigBee is a fairly new but promising wireless sensor network standard that
offers the advantages of simple and low resource communication. Nevertheless,
security is of great concern to ZigBee, and enhancements are prescribed in the
latest ZigBee specication: ZigBee-2007. In this technical report, we identify
an important gap in the specification on key updates, and present a methodology
for determining optimal key update policies and security parameters. We exploit
the stochastic model checking approach using the probabilistic model checker
PRISM, and assess the security needs for realistic application scenarios."
"In this report, we present our approach for protocol analysis together with a
real example where we find an important flow in a contemporary wireless sensor
network security protocol. We start by modelling protocols using a specific
process algebraic formalism called LySa process calculus. We then apply an
analysis based on a special program analysis technique called control flow
analysis. We apply this technique to the ZigBee-2007 End-to-End Application Key
Establishment Protocol and with the help of the analysis discover an unknown
flaw. Finally we suggest a fix for the protocol, and verify that the fix works
by using the same technique."
"In a gray scale image the pixel value ranges from 0 to 255. But when we use
pixel-value differencing (pvd) method as image steganographic scheme, the pixel
values in the stego-image may exceed gray scale range. An adaptive
steganography based on modified pixel-value differencing through management of
pixel values within the range of gray scale has been proposed in this paper.
PVD method is used and check whether the pixel value exceeds the range on
embedding. Positions where the pixel exceeds boundary has been marked and a
delicate handle is used to keep the value within the range. From the
experimental it is seen that the results obtained in proposed method provides
with identical payload and visual fidelity of stego-image compared to the pvd
method."
"It is known that the exchange of information between web applications is done
by means of the SOAP protocol. Securing this protocol is obviously a vital
issue for any computer network. However, when it comes to cloud computing
systems, the sensitivity of this issue rises, as the clients of system, release
their data to the cloud. XML signature is employed to secure SOAP messages.
However, there are also some weak points that have been identified, named as
XML signature wrapping attacks, which have been categorized into four major
groups; Simple Ancestry Context Attack, Optional element context attacks,
Sibling Value Context Attack, Sibling Order Context. In this paper, two
existing methods, for referencing the signed part of SOAP Message, named as ID
referencing and XPath method, are analyzed and examined. In addition, a new
method is proposed and tested, to secure the SOAP message. In the new method,
the XML any signature wrapping attack is prevented by employing the concept of
XML digital signature on the SOAP message. The results of conducted experiments
show that the proposed method is approximately three times faster than the
XPath method and even a little faster than ID."
"With the raise in practice of Internet, in social, personal, commercial and
other aspects of life, the cybercrime is as well escalating at an alarming
rate. Such usage of Internet in diversified areas also augmented the illegal
activities, which in turn, bids many network attacks and threats. Network
forensics is used to detect the network attacks. This can be viewed as the
extension of network security. It is the technology, which detects and also
suggests prevention of the various network attacks. Botnet is one of the most
common attacks and is regarded as a network of hacked computers. It captures
the network packet, store it and then analyze and correlate to find the source
of attack. Various methods based on this approach for botnet detection are in
literature, but a generalized method is lacking. So, there is a requirement to
design a generic framework that can be used by any botnet detection. This
framework is of use for researchers, in the development of their own method of
botnet detection, by means of providing methodology and guidelines. In this
paper, various prevalent methods of botnet detection are studied, commonalities
among them are established and then a generalized model for the detection of
botnet is proposed. The proposed framework is described as UML diagrams."
"This paper suggests a message authentication scheme, which can be efficiently
used for secure digital signature creation. The algorithm used here is an
adjusted union of the concepts which underlie projective geometry and group
structure on circles. The authentication is done through a key, which iterates
over the complete message string to produce the signature. The iteration is not
only based on the frequency distribution of the message string alphabet, but
also on the probability of occurrence of another given reference string in the
message. The complete process can be easily computed in a small time, producing
signatures which are highly dependent on the message string. Consequently, the
odds in favor of existence of a forgery are highly reduced."
"Homomorphic encryption has largely been studied in context of public key
cryptosystems. But there are applications which inherently would require
symmetric keys. We propose a symmetric key encryption scheme with fully
homomorphic evaluation capabilities. The operations are matrix based, that is
the scheme consists of mapping the operations on integers to operations on
matrix. We also include a protocol which uses the proposed scheme for private
data processing in clouds."
"WiMAX is a promising technology that provides high data throughput with low
delays for various user types and modes of operation. These advantages make
WiMAX applicable both for infrastructure purposes and end-client usage. Since
WiMAX is presented as a network framework and a last-mile technology, it is
believed to be capable of handling a wide range of usage scenarios. For
example, while the end users have an opportunity to use WiMAX as the primary
connection medium for acquiring services such as on-demand video streaming,
VoIP connections and mobile bank transactions, the service providers may use it
for data relaying purposes among access points. To meet the technical
requirements of these various scenarios, majority of the WiMAX research has
been conducted on physical and MAC layers; however little has been invested in
a comprehensive and efficient security solution, which has resulted in a wide
range of security weaknesses and reactive solutions. Many security problems
remain to be addressed in different modes and for different user types even in
the final security standard of WiMAX, PKMv2. Mobile multi-hop relay (MMR) WiMAX
networks have attracted lots of interest in wireless communication industry
because of its scalable coverage, improved data rate and relatively low cost.
Even with the additional security functionalities security of MMR WiMAX network
is the main challenge because messages have to be transmitted through one or
more relay stations, which makes it more difficult to ensure the authenticity
of messages and entities involved in the transmission. In this thesis, we
present a hybrid security solution to overcome the security problem of rogue
station (BS/RS) attack and denial of service attack (DoS) in MMR WiMAX."
"This paper presents 10-point and 12-point versions of the recently introduced
number theoretic Hilbert (NHT) transforms. Such transforms have applications in
signal processing and scrambling. Polymorphic solutions with respect to
different moduli for each of the two cases have been found. The multiplicity of
solutions for the same moduli increases their applicability to cryptography."
"The emerging threats to user privacy over the internet are increasing at an
alarming rate. Signing in from an unreliable terminal into a web account may
result in compromising private details of a user such as username and password,
by means of keylogger software. Such software are capable of recording
keystrokes secretly, via covert channels without the knowledge of the user. In
this paper we propose a secure method for signing in using Quick Response (QR)
codes with mobile authentication. Through this method, the user can securely
sign-in into a web account by authenticating the user session on an unreliable
terminal browser, using a mobile device."
"This work proposes a novel approach to infer and characterize Internet-scale
DNS amplification DDoS attacks by leveraging the darknet space. Complementary
to the pioneer work on inferring Distributed Denial of Service (DDoS)
activities using darknet, this work shows that we can extract DDoS activities
without relying on backscattered analysis. The aim of this work is to extract
cyber security intelligence related to DNS Amplification DDoS activities such
as detection period, attack duration, intensity, packet size, rate and
geo-location in addition to various network-layer and flow-based insights. To
achieve this task, the proposed approach exploits certain DDoS parameters to
detect the attacks. We empirically evaluate the proposed approach using 720 GB
of real darknet data collected from a /13 address space during a recent three
months period. Our analysis reveals that the approach was successful in
inferring significant DNS amplification DDoS activities including the recent
prominent attack that targeted one of the largest anti-spam organizations.
Moreover, the analysis disclosed the mechanism of such DNS amplification DDoS
attacks. Further, the results uncover high-speed and stealthy attempts that
were never previously documented. The case study of the largest DDoS attack in
history lead to a better understanding of the nature and scale of this threat
and can generate inferences that could contribute in detecting, preventing,
assessing, mitigating and even attributing of DNS amplification DDoS
activities."
"Each member of an $n$-person team has a secret, say a password. The $k$ out
of $n$ gruppen secret sharing requires that any group of $k$ members should be
able to recover the secrets of the other $n-k$ members, while any group of
$k-1$ or less members should have no information on the secret of other team
member even if other secrets leak out. We prove that when all secrets are
chosen independently and have size $s$, then each team member must have a share
of size at least $(n-k)s$, and we present a scheme which achieves this bound
when $s$ is large enough. This result shows a significant saving over $n$
independent applications of Shamir's $k$ out of $n-1$ threshold schemes which
assigns shares of size $(n-1)s$ to each team member independently of $k$.
  We also show how to set up such a scheme without any trusted dealer, and how
the secrets can be recovered, possibly multiple times, without leaking
information. We also discuss how our scheme fits to the much-investigated
multiple secret sharing methods."
"We present a practical and provably-secure multimode communication scheme in
the presence of a passive eavesdropper. The scheme is based on a random
scheduling approach that hides the identity of the transmitter from the
eavesdropper. This random scheduling leads to ambiguity at the eavesdropper
with regard to the origin of the transmitted frame. We present the details of
the technique and analyze it to quantify the secrecy-fairness-overhead
trade-off. Implementation of the scheme over Crossbow Telosb motes, equipped
with CC2420 radio chips, shows that the scheme can achieve significant secrecy
gain with vanishing outage probability. In addition, it has significant
overhead advantage over direct extensions to two-nodes schemes. The technique
also has the advantage of allowing inactive nodes to leverage sleep mode to
further save energy."
"Radio Frequency Identification (RFID) is a technology aimed at eficiently
identifying and tracking goods and assets. Such identification may be performed
without requiring line-of-sight alignment or physical contact between the RFID
tag and the RFID reader, whilst tracking is naturally achieved due to the short
interrogation field of RFID readers. That is why the reduction in price of the
RFID tags has been accompanied with an increasing attention paid to this
technology. However, since tags are resource-constrained devices sending
identification data wirelessly, designing secure and private RFID
identification protocols is a challenging task. This scenario is even more
complex when scalability must be met by those protocols.
  Assuming the existence of a lightweight, secure, private and scalable RFID
identification protocol, there exist other concerns surrounding the RFID
technology. Some of them arise from the technology itself, such as distance
checking, but others are related to the potential of RFID systems to gather
huge amount of tracking data. Publishing and mining such moving objects data is
essential to improve efficiency of supervisory control, assets management and
localisation, transportation, etc. However, obvious privacy threats arise if an
individual can be linked with some of those published trajectories. The present
dissertation contributes to the design of algorithms and protocols aimed at
dealing with the issues explained above. First, we propose a set of protocols
and heuristics based on a distributed architecture that improve the efficiency
of the identification process without compromising privacy or security.
Moreover, we present a novel distance-bounding protocol based on graphs that is
extremely low-resource consuming. Finally, we present two trajectory
anonymisation methods aimed at preserving the individuals' privacy when their
trajectories are released."
"It was the problem of finding the minimum value of the sum of the distances
of the path through all cities Overview TSP. We propose an authentication with
the problem that the deformation sum of the distances of the path to be a
constant value. In this document, it is intended to construct an authentication
function robust implementation is easy and the Blog. After it was shown that
the first, to determine the replacement group and path are the same, we propose
the authentication method to consider the deformation of the traveling salesman
problem in the directed graph, using a sequence of bytes. Instead of providing
illumination mathematically rigorous, describes a verifiable algorithm."
"The Telecare medicine information system (TMIS) is developed to provide
Telecare services to the remote user. A user can access remote medical servers
using internet without moving from his place. Although remote user and server
exchange their messages/data via public networks. An adversary is considered to
be enough powerful that he may have full control over the public network. This
makes these Telecare services vulnerable to attacks. To ensure secure
communication between the user and server many password based authentication
schemes have been proposed. In 2013, Hao et al. presented chaotic maps-based
password authentication scheme for TMIS. Recently, Lee identified that Hao et
al.'s scheme fails to satisfy key agreement property, such that a malicious
server can predetermine the session key. Lee also presented an efficient
chaotic map-based password authentication and key agreement scheme using Smart
cards for TMIS. In this article, we briefly review Lee's scheme and
demonstrates the weakness of Lee's scheme. The study shows that the Lee's
scheme inefficiency of password change phase causes denial of service attack
and login phase results extra computation and communication overhead."
"Until now the discussion on perfect security for steganographic systems has
remained confined within the realm of mathematicians and information theory
experts whose concise and symbolic representation of their philosophies,
postulates, and inference thereafter has made it hard for the na\""ive academics
to have an insight of the concepts. This paper is an endeavor not only to
appraise on the limitations of one of such pioneer comprehensions but also to
illustrate a pitfall in another scheme that asserts on having perfect security
without the use of public or secret key. Goals set are accomplished through
contrasting test results of a steganographic scheme that exploits English words
with corresponding acronyms for hiding bits of secret information in chat - a
preferred way to exchange messages these days. The misapprehension about
perfect security and reign in characteristic of stego key in bit embedding
process are unfolded respectively by launching elementary chosen-message and
chosen-cover attack, and through proposed enhancement of target scheme."
"Dynamic ID-based remote user authentication schemes ensure efficient and
anonymous mutual authentication between entities. In 2013, Khan et al. proposed
an improved dynamic ID-based authentication scheme to overcome the security
flaws of Wang et al.'s authentication scheme. Recently, Sun and Cao showed that
Khan et al. does not satisfies the claim of the user's privacy and proposed an
efficient authentication scheme with user anonymity. The Sun and Cao's scheme
achieve improvement over Khan et al.'s scheme in both privacy and performance
point of view. Unfortunately, we identify that Sun and Cao's scheme does not
resist password guessing attack. Additionally, Sun and Cao's scheme does not
achieve forward secrecy."
"This paper presents new results in the theory of number theoretic Hilbert
(NHT) transforms. New polymorphic solutions have been found for the 14-point
and 16-point transforms. Several transform pairs are computed and solutions
found for which the sequence and the transform have the same shape. The
multiplicity of solutions for the same moduli increases their applicability to
cryptography."
"A new mechanism aimed at misleading a power system control center about the
source of a data attack is proposed. As a man-in-the-middle state attack, a
data framing attack is proposed to exploit the bad data detection and
identification mechanisms currently in use at most control centers. In
particular, the proposed attack frames meters that are providing correct data
as sources of bad data such that the control center will remove useful
measurements that would otherwise be used by the state estimator.
  The optimal design of a data framing attack is formulated as a quadratically
constrained quadratic program (QCQP). It is shown that the proposed attack is
capable of perturbing the power system state estimate by an arbitrary degree
controlling only half of a critical set of measurements that are needed to make
a system unobservable. Implications of this attack on power system operations
are discussed, and the attack performance is evaluated using benchmark systems."
"We present three simple and efficient protocol constructions to solve Yao's
Millionaire Problem when the parties involved are non-colluding and
semi-honest. The first construction uses a partially homomorphic Encryption
Scheme and is a 4-round scheme using 2 encryptions, 2 homomorphic circuit
evaluations (subtraction and XOR) and a single decryption. The second
construction uses an untrusted third party and achieves a communication
overhead linear in input bit-size with the help of an order preserving
function.Moreover, the second construction does not require an apriori input
bound and can work on inputs of different bit-sizes. The third construction
does not use a third party and, even though, it has a quadratic communication
overhead, it is a fairly simple construction."
"An interesting challenge for the cryptography community is to design
authentication protocols that are so simple that a human can execute them
without relying on a fully trusted computer. We propose several candidate
authentication protocols for a setting in which the human user can only receive
assistance from a semi-trusted computer --- a computer that stores information
and performs computations correctly but does not provide confidentiality. Our
schemes use a semi-trusted computer to store and display public challenges
$C_i\in[n]^k$. The human user memorizes a random secret mapping
$\sigma:[n]\rightarrow\mathbb{Z}_d$ and authenticates by computing responses
$f(\sigma(C_i))$ to a sequence of public challenges where
$f:\mathbb{Z}_d^k\rightarrow\mathbb{Z}_d$ is a function that is easy for the
human to evaluate. We prove that any statistical adversary needs to sample
$m=\tilde{\Omega}(n^{s(f)})$ challenge-response pairs to recover $\sigma$, for
a security parameter $s(f)$ that depends on two key properties of $f$. To
obtain our results, we apply the general hypercontractivity theorem to lower
bound the statistical dimension of the distribution over challenge-response
pairs induced by $f$ and $\sigma$. Our lower bounds apply to arbitrary
functions $f $ (not just to functions that are easy for a human to evaluate),
and generalize recent results of Feldman et al. As an application, we propose a
family of human computable password functions $f_{k_1,k_2}$ in which the user
needs to perform $2k_1+2k_2+1$ primitive operations (e.g., adding two digits or
remembering $\sigma(i)$), and we show that $s(f) = \min\{k_1+1, (k_2+1)/2\}$.
For these schemes, we prove that forging passwords is equivalent to recovering
the secret mapping. Thus, our human computable password schemes can maintain
strong security guarantees even after an adversary has observed the user login
to many different accounts."
"In this paper, we prove an important cryptographic property of
$PE$-transformation proposed elsewhere. If $PE$-transformation is used as
encrypting function then after $n$ applications of it on arbitrary message the
distribution of $l$-tuples ($l=1,2,\dots, n$) is uniform. This property implies
the resistance of statistical kind of attack of this transformation. For
illustration of theoretical results, some experimental results are presented as
well."
"We introduce the Android Security Framework (ASF), a generic, extensible
security framework for Android that enables the development and integration of
a wide spectrum of security models in form of code-based security modules. The
design of ASF reflects lessons learned from the literature on established
security frameworks (such as Linux Security Modules or the BSD MAC Framework)
and intertwines them with the particular requirements and challenges from the
design of Android's software stack. ASF provides a novel security API that
supports authors of Android security extensions in developing their modules.
This overcomes the current unsatisfactory situation to provide security
solutions as separate patches to the Android software stack or to embed them
into Android's mainline codebase. As a result, ASF provides different practical
benefits such as a higher degree of acceptance, adaptation, and maintenance of
security solutions than previously possible on Android. We present a
prototypical implementation of ASF and demonstrate its effectiveness and
efficiency by modularizing different security models from related work, such as
context-aware access control, inlined reference monitoring, and type
enforcement."
"The present volume contains the proceedings of the First International
Workshop on Graphical Models for Security (GraMSec'14). The workshop was held
in Grenoble, France, on April 12, 2014, as one of the satellite events of the
European Joint Conferences on Theory and Practice of Software 2014 (ETAPS'14).
  Graphical security models provide an intuitive but systematic methodology to
analyze security weaknesses of systems and to evaluate potential protection
measures. Such models have been subject of academic research and they have also
been widely accepted by the industrial sector, as a means to support and
facilitate threat analysis and risk management processes.
  The objective of GraMSec is to contribute to the development of well-founded
graphical security models, efficient algorithms for their analysis, as well as
methodologies for their practical usage. The workshop brings together academic
researchers and industry practitioners designing and employing visual models
for security in order to provide a platform for discussion, knowledge exchange
and collaborations."
"We estimate the security of dictionary-based PINs (Personal Identification
Numbers) that a user selects from his/her memory without any additional aids.
The estimates take into account the distribution of words in source language.
We use established security metrics, such as entropy, guesswork, marginal
guesswork and marginal success rate. The metrics are evaluated for various
scenarios -- aimed at improving the security of the produced PINs. In general,
plain and straightforward construction of memory-only dictionary PINs yields
unsatisfactory results and more involved methods must be used to produce secure
PINs."
"We review the security requirements for vehicular communication networks and
provide a critical assessment of some typical communication security solutions.
We also propose a novel unconditionally secure vehicular communication
architecture that utilizes the Kirchhoff-law-Johnson-noise (KLJN) key
distribution scheme."
"Security risk management can be applied on well-defined or existing systems;
in this case, the objective is to identify existing vulnerabilities, assess the
risks and provide for the adequate countermeasures. Security risk management
can also be applied very early in the system's development life-cycle, when its
architecture is still poorly defined; in this case, the objective is to
positively influence the design work so as to produce a secure architecture
from the start. The latter work is made difficult by the uncertainties on the
architecture and the multiple round-trips required to keep the risk assessment
study and the system architecture aligned. This is particularly true for very
large projects running over many years. This paper addresses the issues raised
by those risk assessment studies performed early in the system's development
life-cycle. Based on industrial experience, it asserts that attack trees can
help solve the human cognitive scalability issue related to securing those
large, continuously-changing system-designs. However, big attack trees are
difficult to build, and even more difficult to maintain. This paper therefore
proposes a systematic approach to automate the construction and maintenance of
such big attack trees, based on the system's operational and logical
architectures, the system's traditional risk assessment study and a security
knowledge database."
"In workflows and business processes, there are often security requirements on
both the data, i.e. confidentiality and integrity, and the process, e.g.
separation of duty. Graphical notations exist for specifying both workflows and
associated security requirements. We present an approach for formally verifying
that a workflow satisfies such security requirements. For this purpose, we
define the semantics of a workflow as a state-event system and formalise
security properties in a trace-based way, i.e. on an abstract level without
depending on details of enforcement mechanisms such as Role-Based Access
Control (RBAC). This formal model then allows us to build upon well-known
verification techniques for information flow control. We describe how a
compositional verification methodology for possibilistic information flow can
be adapted to verify that a specification of a distributed workflow management
system satisfies security requirements on both data and processes."